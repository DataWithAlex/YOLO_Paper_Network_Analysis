<!DOCTYPE html>

<!--

This Google Scholar network visualization was generated with
https://github.com/edsu/etudier using the following command:

% etudier --pages 10 --depth 1 https://scholar.google.com/scholar?cites=6382612685700818764&as_sdt=20000005&sciodt=0,21&hl=en

--> 

<html>
  <head>
    <meta charset="utf-8" />
    <style>
      body {
        overflow: hidden;
        margin: 0;
      }

      text {
        font-family: sans-serif;
        pointer-events: none;
      }
    </style>
  </head>

  <body>
    <script src="https://d3js.org/d3.v3.min.js"></script>
    <script>
      var graph = {
  "nodes": [
    {
      "label": "Transformers in vision: A survey",
      "id": "7522504961268153944",
      "url": "https://dl.acm.org/doi/abs/10.1145/3505244",
      "title": "Transformers in vision: A survey",
      "authors": "S Khan, M Naseer, M Hayat, SW Zamir\u2026",
      "year": "2022",
      "cited_by": 1327,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7522504961268153944&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "You only look once: Unified, real-time object detection",
      "id": "6382612685700818764",
      "title": "You only look once: Unified, real-time object detection",
      "cited_by": 39552,
      "modularity": 0
    },
    {
      "label": "Attention mechanisms in computer vision: A survey",
      "id": "15456065911372617945",
      "url": "https://link.springer.com/article/10.1007/s41095-022-0271-y",
      "title": "Attention mechanisms in computer vision: A survey",
      "authors": "MH Guo, TX Xu, JJ Liu, ZN Liu, PT Jiang, TJ Mu\u2026",
      "year": "2022",
      "cited_by": 644,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15456065911372617945&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "A survey of transformers",
      "id": "7749897961068121501",
      "url": "https://www.sciencedirect.com/science/article/pii/S2666651022000146",
      "title": "A survey of transformers",
      "authors": "T Lin, Y Wang, X Liu, X Qiu",
      "year": "2022",
      "cited_by": 494,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7749897961068121501&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Restormer: Efficient transformer for high-resolution image restoration",
      "id": "16431204865977056518",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zamir_Restormer_Efficient_Transformer_for_High-Resolution_Image_Restoration_CVPR_2022_paper.html",
      "title": "Restormer: Efficient transformer for high-resolution image restoration",
      "authors": "SW Zamir, A Arora, S Khan, M Hayat\u2026",
      "year": "2022",
      "cited_by": 742,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16431204865977056518&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Coatnet: Marrying convolution and attention for all data sizes",
      "id": "10110104334022835757",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/20568692db622456cc42a2e853ca21f8-Abstract.html",
      "title": "Coatnet: Marrying convolution and attention for all data sizes",
      "authors": "Z Dai, H Liu, QV Le, M Tan",
      "year": "2021",
      "cited_by": 736,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10110104334022835757&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Multi-stage progressive image restoration",
      "id": "14988305211504802629",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Zamir_Multi-Stage_Progressive_Image_Restoration_CVPR_2021_paper.html",
      "title": "Multi-stage progressive image restoration",
      "authors": "SW Zamir, A Arora, S Khan, M Hayat\u2026",
      "year": "2021",
      "cited_by": 906,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14988305211504802629&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Transreid: Transformer-based object re-identification",
      "id": "15635397108812213817",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/He_TransReID_Transformer-Based_Object_Re-Identification_ICCV_2021_paper.html",
      "title": "Transreid: Transformer-based object re-identification",
      "authors": "S He, H Luo, P Wang, F Wang, H Li\u2026",
      "year": "2021",
      "cited_by": 506,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15635397108812213817&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Intriguing properties of vision transformers",
      "id": "15172072370662904150",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/c404a5adbf90e09631678b13b05d9d7a-Abstract.html",
      "title": "Intriguing properties of vision transformers",
      "authors": "MM Naseer, K Ranasinghe, SH Khan\u2026",
      "year": "2021",
      "cited_by": 377,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15172072370662904150&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "A survey of modern deep learning based object detection models",
      "id": "14311400318178337111",
      "url": "https://www.sciencedirect.com/science/article/pii/S1051200422001312",
      "title": "A survey of modern deep learning based object detection models",
      "authors": "SSA Zaidi, MS Ansari, A Aslam, N Kanwal\u2026",
      "year": "2022",
      "cited_by": 445,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14311400318178337111&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Point-bert: Pre-training 3d point cloud transformers with masked point modeling",
      "id": "17327663970405370182",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yu_Point-BERT_Pre-Training_3D_Point_Cloud_Transformers_With_Masked_Point_Modeling_CVPR_2022_paper.html",
      "title": "Point-bert: Pre-training 3d point cloud transformers with masked point modeling",
      "authors": "X Yu, L Tang, Y Rao, T Huang\u2026",
      "year": "2022",
      "cited_by": 227,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17327663970405370182&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Maxvit: Multi-axis vision transformer",
      "id": "6784655767122395745",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20053-3_27",
      "title": "Maxvit: Multi-axis vision transformer",
      "authors": "Z Tu, H Talebi, H Zhang, F Yang, P Milanfar\u2026",
      "year": "2022",
      "cited_by": 174,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6784655767122395745&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Dynamic neural networks: A survey",
      "id": "10445431151558976110",
      "url": "https://ieeexplore.ieee.org/abstract/document/9560049/",
      "title": "Dynamic neural networks: A survey",
      "authors": "Y Han, G Huang, S Song, L Yang\u2026",
      "year": "2021",
      "cited_by": 368,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10445431151558976110&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Focal self-attention for local-global interactions in vision transformers",
      "id": "17272204730668948165",
      "url": "https://arxiv.org/abs/2107.00641",
      "title": "Focal self-attention for local-global interactions in vision transformers",
      "authors": "J Yang, C Li, P Zhang, X Dai, B Xiao, L Yuan\u2026",
      "year": "2021",
      "cited_by": 301,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17272204730668948165&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Threat of adversarial attacks on deep learning in computer vision: A survey",
      "id": "4397240948250887492",
      "url": "https://ieeexplore.ieee.org/abstract/document/8294186/",
      "title": "Threat of adversarial attacks on deep learning in computer vision: A survey",
      "authors": "N Akhtar, A Mian",
      "year": "2018",
      "cited_by": 1955,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4397240948250887492&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Transformers in medical imaging: A survey",
      "id": "982391967541643955",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841523000634",
      "title": "Transformers in medical imaging: A survey",
      "authors": "F Shamshad, S Khan, SW Zamir, MH Khan\u2026",
      "year": "2023",
      "cited_by": 190,
      "cited_by_url": "https://scholar.google.com/scholar?cites=982391967541643955&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Understanding robustness of transformers for image classification",
      "id": "2524690293389739454",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Bhojanapalli_Understanding_Robustness_of_Transformers_for_Image_Classification_ICCV_2021_paper.html",
      "title": "Understanding robustness of transformers for image classification",
      "authors": "S Bhojanapalli, A Chakrabarti\u2026",
      "year": "2021",
      "cited_by": 255,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2524690293389739454&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Deep neural networks and tabular data: A survey",
      "id": "8226119387953108124",
      "url": "https://ieeexplore.ieee.org/abstract/document/9998482/",
      "title": "Deep neural networks and tabular data: A survey",
      "authors": "V Borisov, T Leemann, K Se\u00dfler, J Haug\u2026",
      "year": "2022",
      "cited_by": 256,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8226119387953108124&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "3d human pose estimation with spatial and temporal transformers",
      "id": "4109211049740650760",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zheng_3D_Human_Pose_Estimation_With_Spatial_and_Temporal_Transformers_ICCV_2021_paper.html",
      "title": "3d human pose estimation with spatial and temporal transformers",
      "authors": "C Zheng, S Zhu, M Mendieta, T Yang\u2026",
      "year": "2021",
      "cited_by": 276,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4109211049740650760&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "A survey of human-in-the-loop for machine learning",
      "id": "13405798017275933263",
      "url": "https://www.sciencedirect.com/science/article/pii/S0167739X22001790",
      "title": "A survey of human-in-the-loop for machine learning",
      "authors": "X Wu, L Xiao, Y Sun, J Zhang, T Ma, L He",
      "year": "2022",
      "cited_by": 221,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13405798017275933263&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Transformers in time series: A survey",
      "id": "7207323120779432545",
      "url": "https://arxiv.org/abs/2202.07125",
      "title": "Transformers in time series: A survey",
      "authors": "Q Wen, T Zhou, C Zhang, W Chen, Z Ma, J Yan\u2026",
      "year": "2022",
      "cited_by": 223,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7207323120779432545&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "An attentive survey of attention models",
      "id": "572712567324091714",
      "url": "https://dl.acm.org/doi/abs/10.1145/3465055",
      "title": "An attentive survey of attention models",
      "authors": "S Chaudhari, V Mithal, G Polatkan\u2026",
      "year": "2021",
      "cited_by": 635,
      "cited_by_url": "https://scholar.google.com/scholar?cites=572712567324091714&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Autoformer: Searching transformers for visual recognition",
      "id": "12569071048746881465",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Chen_AutoFormer_Searching_Transformers_for_Visual_Recognition_ICCV_2021_paper.html",
      "title": "Autoformer: Searching transformers for visual recognition",
      "authors": "M Chen, H Peng, J Fu, H Ling",
      "year": "2021",
      "cited_by": 159,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12569071048746881465&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Mesh graphormer",
      "id": "10894599314289744077",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Lin_Mesh_Graphormer_ICCV_2021_paper.html",
      "title": "Mesh graphormer",
      "authors": "K Lin, L Wang, Z Liu",
      "year": "2021",
      "cited_by": 186,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10894599314289744077&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Deep learning-based human pose estimation: A survey",
      "id": "13410997068826787348",
      "url": "https://dl.acm.org/doi/abs/10.1145/3603618",
      "title": "Deep learning-based human pose estimation: A survey",
      "authors": "C Zheng, W Wu, C Chen, T Yang, S Zhu, J Shen\u2026",
      "year": "2023",
      "cited_by": 179,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13410997068826787348&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "A generalist framework for panoptic segmentation of images and videos",
      "id": "8678112700060654133",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_A_Generalist_Framework_for_Panoptic_Segmentation_of_Images_and_Videos_ICCV_2023_paper.html",
      "title": "A generalist framework for panoptic segmentation of images and videos",
      "authors": "T Chen, L Li, S Saxena, G Hinton\u2026",
      "year": "2023",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8678112700060654133&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Styleswin: Transformer-based gan for high-resolution image generation",
      "id": "14580693445961229120",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhang_StyleSwin_Transformer-Based_GAN_for_High-Resolution_Image_Generation_CVPR_2022_paper.html",
      "title": "Styleswin: Transformer-based gan for high-resolution image generation",
      "authors": "B Zhang, S Gu, B Zhang, J Bao\u2026",
      "year": "2022",
      "cited_by": 100,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14580693445961229120&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Focal attention for long-range interactions in vision transformers",
      "id": "8840944912676876934",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/fc1a36821b02abbd2503fd949bfc9131-Abstract.html",
      "title": "Focal attention for long-range interactions in vision transformers",
      "authors": "J Yang, C Li, P Zhang, X Dai, B Xiao\u2026",
      "year": "2021",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8840944912676876934&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Multi-class token transformer for weakly supervised semantic segmentation",
      "id": "9207086502844896554",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Xu_Multi-Class_Token_Transformer_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html",
      "title": "Multi-class token transformer for weakly supervised semantic segmentation",
      "authors": "L Xu, W Ouyang, M Bennamoun\u2026",
      "year": "2022",
      "cited_by": 77,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9207086502844896554&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Multimodal learning with transformers: A survey",
      "id": "10761248177036470713",
      "url": "https://ieeexplore.ieee.org/abstract/document/10123038/",
      "title": "Multimodal learning with transformers: A survey",
      "authors": "P Xu, X Zhu, DA Clifton",
      "year": "2023",
      "cited_by": 114,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10761248177036470713&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Deep contextual video compression",
      "id": "7877485587962972033",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/96b250a90d3cf0868c83f8c965142d2a-Abstract.html",
      "title": "Deep contextual video compression",
      "authors": "J Li, B Li, Y Lu",
      "year": "2021",
      "cited_by": 103,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7877485587962972033&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Curriculum learning: A survey",
      "id": "10471521790809284341",
      "url": "https://link.springer.com/article/10.1007/s11263-022-01611-x",
      "title": "Curriculum learning: A survey",
      "authors": "P Soviany, RT Ionescu, P Rota, N Sebe",
      "year": "2022",
      "cited_by": 167,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10471521790809284341&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Focal modulation networks",
      "id": "12867511582517934835",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/1b08f585b0171b74d1401a5195e986f1-Abstract-Conference.html",
      "title": "Focal modulation networks",
      "authors": "J Yang, C Li, X Dai, J Gao",
      "year": "2022",
      "cited_by": 68,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12867511582517934835&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Human action recognition from various data modalities: A review",
      "id": "2898208138417725333",
      "url": "https://ieeexplore.ieee.org/abstract/document/9795869/",
      "title": "Human action recognition from various data modalities: A review",
      "authors": "Z Sun, Q Ke, H Rahmani, M Bennamoun\u2026",
      "year": "2022",
      "cited_by": 183,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2898208138417725333&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Imagebart: Bidirectional context with multinomial diffusion for autoregressive image synthesis",
      "id": "5446507817827610731",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/1cdf14d1e3699d61d237cf76ce1c2dca-Abstract.html",
      "title": "Imagebart: Bidirectional context with multinomial diffusion for autoregressive image synthesis",
      "authors": "P Esser, R Rombach, A Blattmann\u2026",
      "year": "2021",
      "cited_by": 84,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5446507817827610731&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "A survey of visual transformers",
      "id": "14136709172791920331",
      "url": "https://ieeexplore.ieee.org/abstract/document/10088164/",
      "title": "A survey of visual transformers",
      "authors": "Y Liu, Y Zhang, Y Wang, F Hou, J Yuan\u2026",
      "year": "2023",
      "cited_by": 110,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14136709172791920331&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Scene representation transformer: Geometry-free novel view synthesis through set-latent scene representations",
      "id": "568699136349469348",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Sajjadi_Scene_Representation_Transformer_Geometry-Free_Novel_View_Synthesis_Through_Set-Latent_Scene_CVPR_2022_paper.html",
      "title": "Scene representation transformer: Geometry-free novel view synthesis through set-latent scene representations",
      "authors": "MSM Sajjadi, H Meyer, E Pot\u2026",
      "year": "2022",
      "cited_by": 66,
      "cited_by_url": "https://scholar.google.com/scholar?cites=568699136349469348&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Ammus: A survey of transformer-based pretrained models in natural language processing",
      "id": "4431578198915484435",
      "url": "https://arxiv.org/abs/2108.05542",
      "title": "Ammus: A survey of transformer-based pretrained models in natural language processing",
      "authors": "KS Kalyan, A Rajasekharan, S Sangeetha",
      "year": "2021",
      "cited_by": 146,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4431578198915484435&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Simpleclick: Interactive image segmentation with simple vision transformers",
      "id": "9280402251304953591",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.html",
      "title": "Simpleclick: Interactive image segmentation with simple vision transformers",
      "authors": "Q Liu, Z Xu, G Bertasius\u2026",
      "year": "2023",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9280402251304953591&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Ow-detr: Open-world detection transformer",
      "id": "5601871542106060008",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Gupta_OW-DETR_Open-World_Detection_Transformer_CVPR_2022_paper.html",
      "title": "Ow-detr: Open-world detection transformer",
      "authors": "A Gupta, S Narayan, KJ Joseph\u2026",
      "year": "2022",
      "cited_by": 76,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5601871542106060008&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Advances in adversarial attacks and defenses in computer vision: A survey",
      "id": "10835602930051801712",
      "url": "https://ieeexplore.ieee.org/abstract/document/9614158/",
      "title": "Advances in adversarial attacks and defenses in computer vision: A survey",
      "authors": "N Akhtar, A Mian, N Kardan, M Shah",
      "year": "2021",
      "cited_by": 121,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10835602930051801712&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Transformerfusion: Monocular rgb scene reconstruction using transformers",
      "id": "12895029264791091547",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/0a87257e5308197df43230edf4ad1dae-Abstract.html",
      "title": "Transformerfusion: Monocular rgb scene reconstruction using transformers",
      "authors": "A Bozic, P Palafox, J Thies, A Dai\u2026",
      "year": "2021",
      "cited_by": 80,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12895029264791091547&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "GAN-based anomaly detection: A review",
      "id": "4988077150684599939",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231221019482",
      "title": "GAN-based anomaly detection: A review",
      "authors": "X Xia, X Pan, N Li, X He, L Ma, X Zhang, N Ding",
      "year": "2022",
      "cited_by": 89,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4988077150684599939&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "U-net transformer: Self and cross attention for medical image segmentation",
      "id": "5670723070535415123",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-87589-3_28",
      "title": "U-net transformer: Self and cross attention for medical image segmentation",
      "authors": "O Petit, N Thome, C Rambour, L Themyr\u2026",
      "year": "2021",
      "cited_by": 148,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5670723070535415123&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "A transformer-based siamese network for change detection",
      "id": "7525849990631181493",
      "url": "https://ieeexplore.ieee.org/abstract/document/9883686/",
      "title": "A transformer-based siamese network for change detection",
      "authors": "WGC Bandara, VM Patel",
      "year": "2022",
      "cited_by": 158,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7525849990631181493&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "SNR-aware low-light image enhancement",
      "id": "2246956610590692796",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Xu_SNR-Aware_Low-Light_Image_Enhancement_CVPR_2022_paper.html",
      "title": "SNR-aware low-light image enhancement",
      "authors": "X Xu, R Wang, CW Fu, J Jia",
      "year": "2022",
      "cited_by": 69,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2246956610590692796&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "GasHis-Transformer: A multi-scale visual transformer approach for gastric histopathological image detection",
      "id": "10743434876113045449",
      "url": "https://www.sciencedirect.com/science/article/pii/S0031320322003089",
      "title": "GasHis-Transformer: A multi-scale visual transformer approach for gastric histopathological image detection",
      "authors": "H Chen, C Li, G Wang, X Li, MM Rahaman, H Sun\u2026",
      "year": "2022",
      "cited_by": 88,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10743434876113045449&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Cdtrans: Cross-domain transformer for unsupervised domain adaptation",
      "id": "9897783945226246229",
      "url": "https://arxiv.org/abs/2109.06165",
      "title": "Cdtrans: Cross-domain transformer for unsupervised domain adaptation",
      "authors": "T Xu, W Chen, P Wang, F Wang, H Li, R Jin",
      "year": "2021",
      "cited_by": 126,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9897783945226246229&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Learning enriched features for fast image restoration and enhancement",
      "id": "278490733091580759",
      "url": "https://ieeexplore.ieee.org/abstract/document/9756908/",
      "title": "Learning enriched features for fast image restoration and enhancement",
      "authors": "SW Zamir, A Arora, S Khan, M Hayat\u2026",
      "year": "2022",
      "cited_by": 58,
      "cited_by_url": "https://scholar.google.com/scholar?cites=278490733091580759&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Perceptual image quality assessment with transformers",
      "id": "12384531505899273984",
      "url": "http://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Cheon_Perceptual_Image_Quality_Assessment_With_Transformers_CVPRW_2021_paper.html",
      "title": "Perceptual image quality assessment with transformers",
      "authors": "M Cheon, SJ Yoon, B Kang\u2026",
      "year": "2021",
      "cited_by": 84,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12384531505899273984&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Physformer: Facial video-based physiological measurement with temporal difference transformer",
      "id": "8053588590478703627",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yu_PhysFormer_Facial_Video-Based_Physiological_Measurement_With_Temporal_Difference_Transformer_CVPR_2022_paper.html",
      "title": "Physformer: Facial video-based physiological measurement with temporal difference transformer",
      "authors": "Z Yu, Y Shen, J Shi, H Zhao\u2026",
      "year": "2022",
      "cited_by": 55,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8053588590478703627&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Query2label: A simple transformer way to multi-label classification",
      "id": "2012981774095049918",
      "url": "https://arxiv.org/abs/2107.10834",
      "title": "Query2label: A simple transformer way to multi-label classification",
      "authors": "S Liu, L Zhang, X Yang, H Su, J Zhu",
      "year": "2021",
      "cited_by": 105,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2012981774095049918&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Efficient transformer for remote sensing image segmentation",
      "id": "17245415599430658769",
      "url": "https://www.mdpi.com/2072-4292/13/18/3585",
      "title": "Efficient transformer for remote sensing image segmentation",
      "authors": "Z Xu, W Zhang, T Zhang, Z Yang, J Li",
      "year": "2021",
      "cited_by": 83,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17245415599430658769&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Sotr: Segmenting objects with transformers",
      "id": "10019448087059497602",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Guo_SOTR_Segmenting_Objects_With_Transformers_ICCV_2021_paper.html",
      "title": "Sotr: Segmenting objects with transformers",
      "authors": "R Guo, D Niu, L Qu, Z Li",
      "year": "2021",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10019448087059497602&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Self-supervised video transformer",
      "id": "11308628305789992240",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Ranasinghe_Self-Supervised_Video_Transformer_CVPR_2022_paper.html",
      "title": "Self-supervised video transformer",
      "authors": "K Ranasinghe, M Naseer, S Khan\u2026",
      "year": "2022",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11308628305789992240&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Edgenext: efficiently amalgamated cnn-transformer architecture for mobile vision applications",
      "id": "14281222646840020216",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-25082-8_1",
      "title": "Edgenext: efficiently amalgamated cnn-transformer architecture for mobile vision applications",
      "authors": "M Maaz, A Shaker, H Cholakkal, S Khan\u2026",
      "year": "2022",
      "cited_by": 56,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14281222646840020216&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Is it time to replace cnns with transformers for medical images?",
      "id": "350651523509452369",
      "url": "https://arxiv.org/abs/2108.09038",
      "title": "Is it time to replace cnns with transformers for medical images?",
      "authors": "C Matsoukas, JF Haslum, M S\u00f6derberg\u2026",
      "year": "2021",
      "cited_by": 94,
      "cited_by_url": "https://scholar.google.com/scholar?cites=350651523509452369&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "NTIRE 2022 challenge on perceptual image quality assessment",
      "id": "14640072730760349377",
      "url": "http://openaccess.thecvf.com/content/CVPR2022W/NTIRE/html/Gu_NTIRE_2022_Challenge_on_Perceptual_Image_Quality_Assessment_CVPRW_2022_paper.html",
      "title": "NTIRE 2022 challenge on perceptual image quality assessment",
      "authors": "J Gu, H Cai, C Dong, JS Ren\u2026",
      "year": "2022",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14640072730760349377&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Transformer and CNN hybrid deep neural network for semantic segmentation of very-high-resolution remote sensing imagery",
      "id": "16207837178250254474",
      "url": "https://ieeexplore.ieee.org/abstract/document/9686732/",
      "title": "Transformer and CNN hybrid deep neural network for semantic segmentation of very-high-resolution remote sensing imagery",
      "authors": "C Zhang, W Jiang, Y Zhang, W Wang\u2026",
      "year": "2022",
      "cited_by": 76,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16207837178250254474&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Machine learning and deep learning based predictive quality in manufacturing: a systematic review",
      "id": "13079493271785323872",
      "url": "https://link.springer.com/article/10.1007/s10845-022-01963-8",
      "title": "Machine learning and deep learning based predictive quality in manufacturing: a systematic review",
      "authors": "H Tercan, T Meisen",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13079493271785323872&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Continual learning with lifelong vision transformer",
      "id": "7347143883946966195",
      "url": "https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Continual_Learning_With_Lifelong_Vision_Transformer_CVPR_2022_paper.html?ref=https://githubhelp.com",
      "title": "Continual learning with lifelong vision transformer",
      "authors": "Z Wang, L Liu, Y Duan, Y Kong\u2026",
      "year": "2022",
      "cited_by": 31,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7347143883946966195&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Sit: Self-supervised vision transformer",
      "id": "10437338697213367930",
      "url": "https://arxiv.org/abs/2104.03602",
      "title": "Sit: Self-supervised vision transformer",
      "authors": "S Atito, M Awais, J Kittler",
      "year": "2021",
      "cited_by": 80,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10437338697213367930&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Multi-task vision transformer using low-level chest X-ray feature corpus for COVID-19 diagnosis and severity quantification",
      "id": "17121643192375450290",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841521003443",
      "title": "Multi-task vision transformer using low-level chest X-ray feature corpus for COVID-19 diagnosis and severity quantification",
      "authors": "S Park, G Kim, Y Oh, JB Seo, SM Lee, JH Kim\u2026",
      "year": "2022",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17121643192375450290&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Transformer neural network for weed and crop classification of high resolution UAV images",
      "id": "906783918798836468",
      "url": "https://www.mdpi.com/2072-4292/14/3/592",
      "title": "Transformer neural network for weed and crop classification of high resolution UAV images",
      "authors": "R Reedha, E Dericquebourg, R Canals, A Hafiane",
      "year": "2022",
      "cited_by": 65,
      "cited_by_url": "https://scholar.google.com/scholar?cites=906783918798836468&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Attention mechanism in intelligent fault diagnosis of machinery: A review of technique and application",
      "id": "17970566394936146777",
      "url": "https://www.sciencedirect.com/science/article/pii/S0263224122008077",
      "title": "Attention mechanism in intelligent fault diagnosis of machinery: A review of technique and application",
      "authors": "H Lv, J Chen, T Pan, T Zhang, Y Feng, S Liu",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17970566394936146777&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Retrieval augmented classification for long-tail visual recognition",
      "id": "1797517254712068026",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Long_Retrieval_Augmented_Classification_for_Long-Tail_Visual_Recognition_CVPR_2022_paper.html",
      "title": "Retrieval augmented classification for long-tail visual recognition",
      "authors": "A Long, W Yin, T Ajanthan, V Nguyen\u2026",
      "year": "2022",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1797517254712068026&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Mil-vt: Multiple instance learning enhanced vision transformer for fundus image classification",
      "id": "2971359940394370469",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-87237-3_5",
      "title": "Mil-vt: Multiple instance learning enhanced vision transformer for fundus image classification",
      "authors": "S Yu, K Ma, Q Bi, C Bian, M Ning, N He, Y Li\u2026",
      "year": "2021",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2971359940394370469&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "A robust volumetric transformer for accurate 3D tumor segmentation",
      "id": "13482994153555216848",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-16443-9_16",
      "title": "A robust volumetric transformer for accurate 3D tumor segmentation",
      "authors": "H Peiris, M Hayat, Z Chen, G Egan\u2026",
      "year": "2022",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13482994153555216848&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "End-to-end deep learning framework for printed circuit board manufacturing defect classification",
      "id": "3062420136055973965",
      "url": "https://www.nature.com/articles/s41598-022-16302-3",
      "title": "End-to-end deep learning framework for printed circuit board manufacturing defect classification",
      "authors": "A Bhattacharya, SG Cloutier",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3062420136055973965&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Convolution-free medical image segmentation using transformers",
      "id": "12187111677452062889",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-87193-2_8",
      "title": "Convolution-free medical image segmentation using transformers",
      "authors": "D Karimi, SD Vasylechko, A Gholipour",
      "year": "2021",
      "cited_by": 80,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12187111677452062889&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Facial expression recognition with grid-wise attention and visual transformer",
      "id": "9999087805969499080",
      "url": "https://www.sciencedirect.com/science/article/pii/S0020025521008495",
      "title": "Facial expression recognition with grid-wise attention and visual transformer",
      "authors": "Q Huang, C Huang, X Wang, F Jiang",
      "year": "2021",
      "cited_by": 63,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9999087805969499080&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Translation between molecules and natural language",
      "id": "3774217736601927222",
      "url": "https://arxiv.org/abs/2204.11817",
      "title": "Translation between molecules and natural language",
      "authors": "C Edwards, T Lai, K Ros, G Honke, K Cho\u2026",
      "year": "2022",
      "cited_by": 41,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3774217736601927222&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Transzero: Attribute-guided transformer for zero-shot learning",
      "id": "12443165844301288148",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/19909",
      "title": "Transzero: Attribute-guided transformer for zero-shot learning",
      "authors": "S Chen, Z Hong, Y Liu, GS Xie, B Sun, H Li\u2026",
      "year": "2022",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12443165844301288148&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Online continual learning with contrastive vision transformer",
      "id": "8750779121680802066",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20044-1_36",
      "title": "Online continual learning with contrastive vision transformer",
      "authors": "Z Wang, L Liu, Y Kong, J Guo, D Tao",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8750779121680802066&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "EGDE-Net: A building change detection method for high-resolution remote sensing imagery based on edge guidance and differential enhancement",
      "id": "8737500900907252911",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271622001940",
      "title": "EGDE-Net: A building change detection method for high-resolution remote sensing imagery based on edge guidance and differential enhancement",
      "authors": "Z Chen, Y Zhou, B Wang, X Xu, N He, S Jin\u2026",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8737500900907252911&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "IL-MCAM: An interactive learning and multi-channel attention mechanism-based weakly supervised colorectal histopathology image classification approach",
      "id": "15425036751013855629",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482522000579",
      "title": "IL-MCAM: An interactive learning and multi-channel attention mechanism-based weakly supervised colorectal histopathology image classification approach",
      "authors": "H Chen, C Li, X Li, MM Rahaman, W Hu, Y Li\u2026",
      "year": "2022",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15425036751013855629&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "UTRAD: Anomaly detection and localization with U-transformer",
      "id": "6637879260771394229",
      "url": "https://www.sciencedirect.com/science/article/pii/S0893608021004810",
      "title": "UTRAD: Anomaly detection and localization with U-transformer",
      "authors": "L Chen, Z You, N Zhang, J Xi, X Le",
      "year": "2022",
      "cited_by": 40,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6637879260771394229&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Towards the fully automated monitoring of ecological communities",
      "id": "17981792349028675992",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/ele.14123",
      "title": "Towards the fully automated monitoring of ecological communities",
      "authors": "M Besson, J Alison, K Bjerge, TE Gorochowski\u2026",
      "year": "2022",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17981792349028675992&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Robustifying token attention for vision transformers",
      "id": "18080630766028543102",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Guo_Robustifying_Token_Attention_for_Vision_Transformers_ICCV_2023_paper.html",
      "title": "Robustifying token attention for vision transformers",
      "authors": "Y Guo, D Stutz, B Schiele",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18080630766028543102&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Istr: End-to-end instance segmentation with transformers",
      "id": "15758326914658017418",
      "url": "https://arxiv.org/abs/2105.00637",
      "title": "Istr: End-to-end instance segmentation with transformers",
      "authors": "J Hu, L Cao, Y Lu, SC Zhang, Y Wang, K Li\u2026",
      "year": "2021",
      "cited_by": 72,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15758326914658017418&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Pointmixer: Mlp-mixer for point cloud understanding",
      "id": "12478683589701856519",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19812-0_36",
      "title": "Pointmixer: Mlp-mixer for point cloud understanding",
      "authors": "J Choe, C Park, F Rameau, J Park\u2026",
      "year": "2022",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12478683589701856519&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Countering malicious deepfakes: Survey, battleground, and horizon",
      "id": "8623435992513029102",
      "url": "https://link.springer.com/article/10.1007/s11263-022-01606-8",
      "title": "Countering malicious deepfakes: Survey, battleground, and horizon",
      "authors": "F Juefei-Xu, R Wang, Y Huang, Q Guo, L Ma\u2026",
      "year": "2022",
      "cited_by": 65,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8623435992513029102&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "On improving adversarial transferability of vision transformers",
      "id": "9927551479269048485",
      "url": "https://arxiv.org/abs/2106.04169",
      "title": "On improving adversarial transferability of vision transformers",
      "authors": "M Naseer, K Ranasinghe, S Khan, FS Khan\u2026",
      "year": "2021",
      "cited_by": 58,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9927551479269048485&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Deep hierarchical vision transformer for hyperspectral and LiDAR data classification",
      "id": "6583545798277065500",
      "url": "https://ieeexplore.ieee.org/abstract/document/9755059/",
      "title": "Deep hierarchical vision transformer for hyperspectral and LiDAR data classification",
      "authors": "Z Xue, X Tan, X Yu, B Liu, A Yu\u2026",
      "year": "2022",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6583545798277065500&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Avoiding negative transfer for semantic segmentation of remote sensing images",
      "id": "2547364804279732726",
      "url": "https://ieeexplore.ieee.org/abstract/document/9866807/",
      "title": "Avoiding negative transfer for semantic segmentation of remote sensing images",
      "authors": "H Wang, C Tao, J Qi, R Xiao, H Li",
      "year": "2022",
      "cited_by": 67,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2547364804279732726&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Federated split task-agnostic vision transformer for COVID-19 CXR diagnosis",
      "id": "3241342143336277180",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/ceb0595112db2513b9325a85761b7310-Abstract.html",
      "title": "Federated split task-agnostic vision transformer for COVID-19 CXR diagnosis",
      "authors": "S Park, G Kim, J Kim, B Kim\u2026",
      "year": "2021",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3241342143336277180&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Image harmonization with transformer",
      "id": "1309943264288419550",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Guo_Image_Harmonization_With_Transformer_ICCV_2021_paper.html",
      "title": "Image harmonization with transformer",
      "authors": "Z Guo, D Guo, H Zheng, Z Gu\u2026",
      "year": "2021",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1309943264288419550&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Visual attention methods in deep learning: An in-depth survey",
      "id": "10901034885667795659",
      "url": "https://arxiv.org/abs/2204.07756",
      "title": "Visual attention methods in deep learning: An in-depth survey",
      "authors": "M Hassanin, S Anwar, I Radwan, FS Khan\u2026",
      "year": "2022",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10901034885667795659&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Video transformers: A survey",
      "id": "15926311935982020340",
      "url": "https://ieeexplore.ieee.org/abstract/document/10041724/",
      "title": "Video transformers: A survey",
      "authors": "J Selva, AS Johansen, S Escalera\u2026",
      "year": "2023",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15926311935982020340&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer",
      "id": "5301766735590672032",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Liu_FlatFormer_Flattened_Window_Attention_for_Efficient_Point_Cloud_Transformer_CVPR_2023_paper.html",
      "title": "FlatFormer: Flattened Window Attention for Efficient Point Cloud Transformer",
      "authors": "Z Liu, X Yang, H Tang, S Yang\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5301766735590672032&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Wildfire segmentation using deep vision transformers",
      "id": "16583630453825645332",
      "url": "https://www.mdpi.com/2072-4292/13/17/3527",
      "title": "Wildfire segmentation using deep vision transformers",
      "authors": "R Ghali, MA Akhloufi, M Jmal, W Souidene Mseddi\u2026",
      "year": "2021",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16583630453825645332&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Transformers in remote sensing: A survey",
      "id": "3738295254278174876",
      "url": "https://www.mdpi.com/2072-4292/15/7/1860",
      "title": "Transformers in remote sensing: A survey",
      "authors": "AA Aleissaee, A Kumar, RM Anwer, S Khan\u2026",
      "year": "2023",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3738295254278174876&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "A survey of self-supervised and few-shot object detection",
      "id": "9591435289724766439",
      "url": "https://ieeexplore.ieee.org/abstract/document/9860087/",
      "title": "A survey of self-supervised and few-shot object detection",
      "authors": "G Huang, I Laradji, D Vazquez\u2026",
      "year": "2022",
      "cited_by": 45,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9591435289724766439&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A hybrid explainable ensemble transformer encoder for pneumonia identification from chest X-ray images",
      "id": "3333668025330401477",
      "url": "https://www.sciencedirect.com/science/article/pii/S2090123222002028",
      "title": "A hybrid explainable ensemble transformer encoder for pneumonia identification from chest X-ray images",
      "authors": "CC Ukwuoma, Z Qin, MBB Heyat, F Akhtar\u2026",
      "year": "2023",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3333668025330401477&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Keypoint transformer: Solving joint identification in challenging hands and object interactions for accurate 3d pose estimation",
      "id": "5952922111315863760",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.html",
      "title": "Keypoint transformer: Solving joint identification in challenging hands and object interactions for accurate 3d pose estimation",
      "authors": "S Hampali, SD Sarkar, M Rad\u2026",
      "year": "2022",
      "cited_by": 56,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5952922111315863760&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "AMMU: a survey of transformer-based biomedical pretrained language models",
      "id": "1101546884380916291",
      "url": "https://www.sciencedirect.com/science/article/pii/S1532046421003117",
      "title": "AMMU: a survey of transformer-based biomedical pretrained language models",
      "authors": "KS Kalyan, A Rajasekharan, S Sangeetha",
      "year": "2022",
      "cited_by": 58,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1101546884380916291&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "CCTNet: Coupled CNN and transformer network for crop segmentation of remote sensing images",
      "id": "8994048266291075499",
      "url": "https://www.mdpi.com/2072-4292/14/9/1956",
      "title": "CCTNet: Coupled CNN and transformer network for crop segmentation of remote sensing images",
      "authors": "H Wang, X Chen, T Zhang, Z Xu, J Li",
      "year": "2022",
      "cited_by": 32,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8994048266291075499&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "M3T: three-dimensional Medical image classifier using Multi-plane and Multi-slice Transformer",
      "id": "15220408395767693757",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Jang_M3T_Three-Dimensional_Medical_Image_Classifier_Using_Multi-Plane_and_Multi-Slice_Transformer_CVPR_2022_paper.html",
      "title": "M3T: three-dimensional Medical image classifier using Multi-plane and Multi-slice Transformer",
      "authors": "J Jang, D Hwang",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15220408395767693757&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Few-shot class-incremental learning by sampling multi-phase tasks",
      "id": "5423828611786306174",
      "url": "https://ieeexplore.ieee.org/abstract/document/9864267/",
      "title": "Few-shot class-incremental learning by sampling multi-phase tasks",
      "authors": "DW Zhou, HJ Ye, L Ma, D Xie, S Pu\u2026",
      "year": "2022",
      "cited_by": 31,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5423828611786306174&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Uniform masking: Enabling mae pre-training for pyramid-based vision transformers with locality",
      "id": "5888510936612783579",
      "url": "https://arxiv.org/abs/2205.10063",
      "title": "Uniform masking: Enabling mae pre-training for pyramid-based vision transformers with locality",
      "authors": "X Li, W Wang, L Yang, J Yang",
      "year": "2022",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5888510936612783579&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Searching the search space of vision transformer",
      "id": "17171842121702147403",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/48e95c45c8217961bf6cd7696d80d238-Abstract.html",
      "title": "Searching the search space of vision transformer",
      "authors": "M Chen, K Wu, B Ni, H Peng, B Liu\u2026",
      "year": "2021",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17171842121702147403&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "Deep learning based computer vision approaches for smart agricultural applications",
      "id": "8071202295861113716",
      "url": "https://www.sciencedirect.com/science/article/pii/S2589721722000174",
      "title": "Deep learning based computer vision approaches for smart agricultural applications",
      "authors": "VG Dhanya, A Subeesh, NL Kushwaha\u2026",
      "year": "2022",
      "cited_by": 40,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8071202295861113716&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 9
    },
    {
      "label": "A survey on image data augmentation for deep learning",
      "id": "4041041901496425203",
      "url": "https://journalofbigdata.springeropen.com/track/pdf/10.1186/s40537-019-0197-0.pdf",
      "title": "A survey on image data augmentation for deep learning",
      "authors": "C Shorten, TM Khoshgoftaar",
      "year": "2019",
      "cited_by": 7767,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4041041901496425203&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Review of deep learning: Concepts, CNN architectures, challenges, applications, future directions",
      "id": "8136644755673586417",
      "url": "https://link.springer.com/article/10.1186/s40537-021-00444-8",
      "title": "Review of deep learning: Concepts, CNN architectures, challenges, applications, future directions",
      "authors": "L Alzubaidi, J Zhang, AJ Humaidi, A Al-Dujaili\u2026",
      "year": "2021",
      "cited_by": 2459,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8136644755673586417&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Review on Convolutional Neural Networks (CNN) in vegetation remote sensing",
      "id": "6141939658324331542",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271620303488",
      "title": "Review on Convolutional Neural Networks (CNN) in vegetation remote sensing",
      "authors": "T Kattenborn, J Leitloff, F Schiefer, S Hinz",
      "year": "2021",
      "cited_by": 615,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6141939658324331542&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation",
      "id": "7770442917120891581",
      "url": "https://proceedings.mlr.press/v162/li22n.html",
      "title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation",
      "authors": "J Li, D Li, C Xiong, S Hoi",
      "year": "2022",
      "cited_by": 835,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7770442917120891581&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions",
      "id": "8793029896395507010",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Wang_Pyramid_Vision_Transformer_A_Versatile_Backbone_for_Dense_Prediction_Without_ICCV_2021_paper.html",
      "title": "Pyramid vision transformer: A versatile backbone for dense prediction without convolutions",
      "authors": "W Wang, E Xie, X Li, DP Fan, K Song\u2026",
      "year": "2021",
      "cited_by": 2381,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8793029896395507010&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "On the opportunities and risks of foundation models",
      "id": "9595110325981705564",
      "url": "https://arxiv.org/abs/2108.07258",
      "title": "On the opportunities and risks of foundation models",
      "authors": "R Bommasani, DA Hudson, E Adeli, R Altman\u2026",
      "year": "2021",
      "cited_by": 1551,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9595110325981705564&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Vilt: Vision-and-language transformer without convolution or region supervision",
      "id": "12987945369444025427",
      "url": "https://proceedings.mlr.press/v139/kim21k.html",
      "title": "Vilt: Vision-and-language transformer without convolution or region supervision",
      "authors": "W Kim, B Son, I Kim",
      "year": "2021",
      "cited_by": 851,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12987945369444025427&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A survey of uncertainty in deep neural networks",
      "id": "16770513324417061228",
      "url": "https://link.springer.com/article/10.1007/s10462-023-10562-9",
      "title": "A survey of uncertainty in deep neural networks",
      "authors": "J Gawlikowski, CRN Tassi, M Ali, J Lee, M Humt\u2026",
      "year": "2023",
      "cited_by": 450,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16770513324417061228&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Training generative adversarial networks with limited data",
      "id": "9063880872255850171",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/8d30aa96e72440759f74bd2306c1fa3d-Abstract.html",
      "title": "Training generative adversarial networks with limited data",
      "authors": "T Karras, M Aittala, J Hellsten, S Laine\u2026",
      "year": "2020",
      "cited_by": 1343,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9063880872255850171&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Simple copy-paste is a strong data augmentation method for instance segmentation",
      "id": "2321980635951558135",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/html/Ghiasi_Simple_Copy-Paste_Is_a_Strong_Data_Augmentation_Method_for_Instance_CVPR_2021_paper.html?ref=https://githubhelp.com",
      "title": "Simple copy-paste is a strong data augmentation method for instance segmentation",
      "authors": "G Ghiasi, Y Cui, A Srinivas, R Qian\u2026",
      "year": "2021",
      "cited_by": 684,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2321980635951558135&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A survey of data augmentation approaches for NLP",
      "id": "862169174991977666",
      "url": "https://arxiv.org/abs/2105.03075",
      "title": "A survey of data augmentation approaches for NLP",
      "authors": "SY Feng, V Gangal, J Wei, S Chandar\u2026",
      "year": "2021",
      "cited_by": 496,
      "cited_by_url": "https://scholar.google.com/scholar?cites=862169174991977666&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Generalizing to unseen domains: A survey on domain generalization",
      "id": "7227117659365205945",
      "url": "https://ieeexplore.ieee.org/abstract/document/9782500/",
      "title": "Generalizing to unseen domains: A survey on domain generalization",
      "authors": "J Wang, C Lan, C Liu, Y Ouyang, T Qin\u2026",
      "year": "2022",
      "cited_by": 498,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7227117659365205945&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Learning from noisy labels with deep neural networks: A survey",
      "id": "16564777441869762048",
      "url": "https://ieeexplore.ieee.org/abstract/document/9729424/",
      "title": "Learning from noisy labels with deep neural networks: A survey",
      "authors": "H Song, M Kim, D Park, Y Shin\u2026",
      "year": "2022",
      "cited_by": 608,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16564777441869762048&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Machine learning: new ideas and tools in environmental science and engineering",
      "id": "9003206964118171143",
      "url": "https://pubs.acs.org/doi/abs/10.1021/acs.est.1c01339",
      "title": "Machine learning: new ideas and tools in environmental science and engineering",
      "authors": "S Zhong, K Zhang, M Bagheri, JG Burken\u2026",
      "year": "2021",
      "cited_by": 280,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9003206964118171143&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Out-of-distribution generalization via risk extrapolation (rex)",
      "id": "10054528338033032937",
      "url": "http://proceedings.mlr.press/v139/krueger21a.html",
      "title": "Out-of-distribution generalization via risk extrapolation (rex)",
      "authors": "D Krueger, E Caballero, JH Jacobsen\u2026",
      "year": "2021",
      "cited_by": 545,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10054528338033032937&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Multi-sensor information fusion based on machine learning for real applications in human activity recognition: State-of-the-art and research challenges",
      "id": "7358070883597795569",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253521002311",
      "title": "Multi-sensor information fusion based on machine learning for real applications in human activity recognition: State-of-the-art and research challenges",
      "authors": "S Qiu, H Zhao, N Jiang, Z Wang, L Liu, Y An, H Zhao\u2026",
      "year": "2022",
      "cited_by": 224,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7358070883597795569&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Albumentations: fast and flexible image augmentations",
      "id": "13927538846757401282",
      "url": "https://www.mdpi.com/2078-2489/11/2/125?ref=https://coder.social",
      "title": "Albumentations: fast and flexible image augmentations",
      "authors": "A Buslaev, VI Iglovikov, E Khvedchenya, A Parinov\u2026",
      "year": "2020",
      "cited_by": 1446,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13927538846757401282&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Embracing imperfect datasets: A review of deep learning solutions for medical image segmentation",
      "id": "11310550941481896506",
      "url": "https://www.sciencedirect.com/science/article/pii/S136184152030058X",
      "title": "Embracing imperfect datasets: A review of deep learning solutions for medical image segmentation",
      "authors": "N Tajbakhsh, L Jeyaseelan, Q Li, JN Chiang, Z Wu\u2026",
      "year": "2020",
      "cited_by": 609,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11310550941481896506&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A novel transfer learning based approach for pneumonia detection in chest X-ray images",
      "id": "13436034306365145381",
      "url": "https://www.mdpi.com/2076-3417/10/2/559",
      "title": "A novel transfer learning based approach for pneumonia detection in chest X-ray images",
      "authors": "V Chouhan, SK Singh, A Khamparia, D Gupta\u2026",
      "year": "2020",
      "cited_by": 549,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13436034306365145381&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A review of medical image data augmentation techniques for deep learning applications",
      "id": "11885254696629287118",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/1754-9485.13261",
      "title": "A review of medical image data augmentation techniques for deep learning applications",
      "authors": "P Chlap, H Min, N Vandenberg\u2026",
      "year": "2021",
      "cited_by": 292,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11885254696629287118&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Deep long-tailed learning: A survey",
      "id": "7309961819207216748",
      "url": "https://ieeexplore.ieee.org/abstract/document/10105457/",
      "title": "Deep long-tailed learning: A survey",
      "authors": "Y Zhang, B Kang, B Hooi, S Yan\u2026",
      "year": "2023",
      "cited_by": 237,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7309961819207216748&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Deep semantic segmentation of natural and medical images: a review",
      "id": "4984340879175316146",
      "url": "https://link.springer.com/article/10.1007/s10462-020-09854-1",
      "title": "Deep semantic segmentation of natural and medical images: a review",
      "authors": "S Asgari Taghanaki, K Abhishek, JP Cohen\u2026",
      "year": "2021",
      "cited_by": 534,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4984340879175316146&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Time series data augmentation for deep learning: A survey",
      "id": "8302576934258228524",
      "url": "https://arxiv.org/abs/2002.12478",
      "title": "Time series data augmentation for deep learning: A survey",
      "authors": "Q Wen, L Sun, F Yang, X Song, J Gao, X Wang\u2026",
      "year": "2020",
      "cited_by": 502,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8302576934258228524&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "An empirical survey of data augmentation for time series classification with neural networks",
      "id": "10911957018595078026",
      "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0254841",
      "title": "An empirical survey of data augmentation for time series classification with neural networks",
      "authors": "BK Iwana, S Uchida",
      "year": "2021",
      "cited_by": 356,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10911957018595078026&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Deep Learning applications for COVID-19",
      "id": "17777612268280748847",
      "url": "https://link.springer.com/article/10.1186/s40537-020-00392-9%23auth-Taghi_M_-Khoshgoftaar",
      "title": "Deep Learning applications for COVID-19",
      "authors": "C Shorten, TM Khoshgoftaar, B Furht",
      "year": "2021",
      "cited_by": 253,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17777612268280748847&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Continual test-time domain adaptation",
      "id": "4325500781447230872",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wang_Continual_Test-Time_Domain_Adaptation_CVPR_2022_paper.html",
      "title": "Continual test-time domain adaptation",
      "authors": "Q Wang, O Fink, L Van Gool\u2026",
      "year": "2022",
      "cited_by": 135,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4325500781447230872&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Text data augmentation for deep learning",
      "id": "13909256571563279522",
      "url": "https://link.springer.com/article/10.1186/s40537-021-00492-0",
      "title": "Text data augmentation for deep learning",
      "authors": "C Shorten, TM Khoshgoftaar, B Furht",
      "year": "2021",
      "cited_by": 218,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13909256571563279522&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "CNN-based transfer learning\u2013BiLSTM network: A novel approach for COVID-19 infection detection",
      "id": "14260054837347093009",
      "url": "https://www.sciencedirect.com/science/article/pii/S1568494620308504",
      "title": "CNN-based transfer learning\u2013BiLSTM network: A novel approach for COVID-19 infection detection",
      "authors": "MF Aslan, MF Unlersen, K Sabanci, A Durdu",
      "year": "2021",
      "cited_by": 275,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14260054837347093009&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "AI applications to medical images: From machine learning to deep learning",
      "id": "2022703968544749835",
      "url": "https://www.sciencedirect.com/science/article/pii/S1120179721000946",
      "title": "AI applications to medical images: From machine learning to deep learning",
      "authors": "I Castiglioni, L Rundo, M Codari, G Di Leo, C Salvatore\u2026",
      "year": "2021",
      "cited_by": 254,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2022703968544749835&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Label-only membership inference attacks",
      "id": "18421653793757811360",
      "url": "https://proceedings.mlr.press/v139/choquette-choo21a.html",
      "title": "Label-only membership inference attacks",
      "authors": "CA Choquette-Choo, F Tramer\u2026",
      "year": "2021",
      "cited_by": 278,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18421653793757811360&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Designing deep learning studies in cancer diagnostics",
      "id": "639736007842008588",
      "url": "https://www.nature.com/articles/s41568-020-00327-9",
      "title": "Designing deep learning studies in cancer diagnostics",
      "authors": "A Kleppe, OJ Skrede, S De Raedt, K Liest\u00f8l\u2026",
      "year": "2021",
      "cited_by": 178,
      "cited_by_url": "https://scholar.google.com/scholar?cites=639736007842008588&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Data augmentation approaches in natural language processing: A survey",
      "id": "11748945572016694012",
      "url": "https://www.sciencedirect.com/science/article/pii/S2666651022000080",
      "title": "Data augmentation approaches in natural language processing: A survey",
      "authors": "B Li, Y Hou, W Che",
      "year": "2022",
      "cited_by": 119,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11748945572016694012&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A survey of deep learning techniques for weed detection from images",
      "id": "18253746969450725752",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169921000855",
      "title": "A survey of deep learning techniques for weed detection from images",
      "authors": "ASMM Hasan, F Sohel, D Diepeveen, H Laga\u2026",
      "year": "2021",
      "cited_by": 207,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18253746969450725752&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Openood: Benchmarking generalized out-of-distribution detection",
      "id": "1091474511097006762",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/d201587e3a84fc4761eadc743e9b3f35-Abstract-Datasets_and_Benchmarks.html",
      "title": "Openood: Benchmarking generalized out-of-distribution detection",
      "authors": "J Yang, P Wang, D Zou, Z Zhou\u2026",
      "year": "2022",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1091474511097006762&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "A survey on data augmentation for text classification",
      "id": "3667217905602891315",
      "url": "https://dl.acm.org/doi/abs/10.1145/3544558",
      "title": "A survey on data augmentation for text classification",
      "authors": "M Bayer, MA Kaufhold, C Reuter",
      "year": "2022",
      "cited_by": 165,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3667217905602891315&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "An enhanced technique of skin cancer classification using deep convolutional neural network with transfer learning models",
      "id": "12913547344242152073",
      "url": "https://www.sciencedirect.com/science/article/pii/S2666827021000177",
      "title": "An enhanced technique of skin cancer classification using deep convolutional neural network with transfer learning models",
      "authors": "MS Ali, MS Miah, J Haque, MM Rahman\u2026",
      "year": "2021",
      "cited_by": 184,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12913547344242152073&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Enhanced data security of communication system using combined encryption and steganography",
      "id": "10803661783624345607",
      "url": "https://www.academia.edu/download/81991120/9765.pdf",
      "title": "Enhanced data security of communication system using combined encryption and steganography",
      "authors": "HTS ALRikabi, HT Hazim",
      "year": "2021",
      "cited_by": 135,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10803661783624345607&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Predictive maintenance enabled by machine learning: Use cases and challenges in the automotive industry",
      "id": "6953811760252391041",
      "url": "https://www.sciencedirect.com/science/article/pii/S0951832021003835",
      "title": "Predictive maintenance enabled by machine learning: Use cases and challenges in the automotive industry",
      "authors": "A Theissler, J P\u00e9rez-Vel\u00e1zquez, M Kettelgerdes\u2026",
      "year": "2021",
      "cited_by": 164,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6953811760252391041&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A survey on deep learning in medicine: Why, how and when?",
      "id": "7183832294030210754",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253520303651",
      "title": "A survey on deep learning in medicine: Why, how and when?",
      "authors": "F Piccialli, V Di Somma, F Giampaolo, S Cuomo\u2026",
      "year": "2021",
      "cited_by": 236,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7183832294030210754&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Data augmentation for graph neural networks",
      "id": "7119350279654084346",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/17315",
      "title": "Data augmentation for graph neural networks",
      "authors": "T Zhao, Y Liu, L Neves, O Woodford, M Jiang\u2026",
      "year": "2021",
      "cited_by": 263,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7119350279654084346&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "COVID-19 open source data sets: a comprehensive survey",
      "id": "4506444976781600964",
      "url": "https://link.springer.com/article/10.1007/s10489-020-01862-6",
      "title": "COVID-19 open source data sets: a comprehensive survey",
      "authors": "J Shuja, E Alanazi, W Alasmary, A Alashaikh",
      "year": "2021",
      "cited_by": 250,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4506444976781600964&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A scoping review of transfer learning research on medical image analysis using ImageNet",
      "id": "10215776754955167080",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482520304467",
      "title": "A scoping review of transfer learning research on medical image analysis using ImageNet",
      "authors": "MA Morid, A Borjali, G Del Fiol",
      "year": "2021",
      "cited_by": 263,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10215776754955167080&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Transparency and reproducibility in artificial intelligence",
      "id": "6018697739026892882",
      "url": "https://www.nature.com/articles/s41586-020-2766-y",
      "title": "Transparency and reproducibility in artificial intelligence",
      "authors": "B Haibe-Kains, GA Adam, A Hosny, F Khodakarami\u2026",
      "year": "2020",
      "cited_by": 269,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6018697739026892882&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Memo: Test time robustness via adaptation and augmentation",
      "id": "14158261027181687094",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/fc28053a08f59fccb48b11f2e31e81c7-Abstract-Conference.html",
      "title": "Memo: Test time robustness via adaptation and augmentation",
      "authors": "M Zhang, S Levine, C Finn",
      "year": "2022",
      "cited_by": 89,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14158261027181687094&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Deblurring by realistic blurring",
      "id": "5892850021726448686",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_Deblurring_by_Realistic_Blurring_CVPR_2020_paper.html",
      "title": "Deblurring by realistic blurring",
      "authors": "K Zhang, W Luo, Y Zhong, L Ma\u2026",
      "year": "2020",
      "cited_by": 250,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5892850021726448686&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Deep learning tools for the measurement of animal behavior in neuroscience",
      "id": "14228395058672942618",
      "url": "https://www.sciencedirect.com/science/article/pii/S0959438819301151",
      "title": "Deep learning tools for the measurement of animal behavior in neuroscience",
      "authors": "MW Mathis, A Mathis",
      "year": "2020",
      "cited_by": 298,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14228395058672942618&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Data augmentation for deep-learning-based electroencephalography",
      "id": "18043841524050979844",
      "url": "https://www.sciencedirect.com/science/article/pii/S0165027020303083",
      "title": "Data augmentation for deep-learning-based electroencephalography",
      "authors": "E Lashgari, D Liang, U Maoz",
      "year": "2020",
      "cited_by": 210,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18043841524050979844&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "The risks of invariant risk minimization",
      "id": "16629143072867731417",
      "url": "https://arxiv.org/abs/2010.05761",
      "title": "The risks of invariant risk minimization",
      "authors": "E Rosenfeld, P Ravikumar, A Risteski",
      "year": "2020",
      "cited_by": 209,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16629143072867731417&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Graph neural networks: foundation, frontiers and applications",
      "id": "370769816745103063",
      "url": "https://dl.acm.org/doi/abs/10.1145/3534678.3542609",
      "title": "Graph neural networks: foundation, frontiers and applications",
      "authors": "L Wu, P Cui, J Pei, L Zhao, X Guo",
      "year": "2022",
      "cited_by": 140,
      "cited_by_url": "https://scholar.google.com/scholar?cites=370769816745103063&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A machine learning-based framework for diagnosis of COVID-19 from chest X-ray images",
      "id": "1555581554615315719",
      "url": "https://link.springer.com/article/10.1007/s12539-020-00403-6",
      "title": "A machine learning-based framework for diagnosis of COVID-19 from chest X-ray images",
      "authors": "J Rasheed, AA Hameed, C Djeddi, A Jamil\u2026",
      "year": "2021",
      "cited_by": 168,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1555581554615315719&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "[CITATION][C]",
      "id": "7294969416203662369",
      "title": "[CITATION][C]",
      "authors": "HA Khan, W Jue, M Mushtaq, MU Mushtaq",
      "year": "2021",
      "cited_by": 225,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7294969416203662369&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Data augmentation for deep graph learning: A survey",
      "id": "9634990485617283026",
      "url": "https://dl.acm.org/doi/abs/10.1145/3575637.3575646",
      "title": "Data augmentation for deep graph learning: A survey",
      "authors": "K Ding, Z Xu, H Tong, H Liu",
      "year": "2022",
      "cited_by": 92,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9634990485617283026&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "An enhanced deep learning approach for brain cancer MRI images classification using residual networks",
      "id": "5055262884129010690",
      "url": "https://www.sciencedirect.com/science/article/pii/S0933365719306177",
      "title": "An enhanced deep learning approach for brain cancer MRI images classification using residual networks",
      "authors": "SAA Ismael, A Mohammed, H Hefny",
      "year": "2020",
      "cited_by": 259,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5055262884129010690&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Humble teachers teach better students for semi-supervised object detection",
      "id": "3398859238063529749",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Tang_Humble_Teachers_Teach_Better_Students_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.html",
      "title": "Humble teachers teach better students for semi-supervised object detection",
      "authors": "Y Tang, W Chen, Y Luo\u2026",
      "year": "2021",
      "cited_by": 112,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3398859238063529749&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "3d human action representation learning via cross-view consistency pursuit",
      "id": "14585779787909883755",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Li_3D_Human_Action_Representation_Learning_via_Cross-View_Consistency_Pursuit_CVPR_2021_paper.html",
      "title": "3d human action representation learning via cross-view consistency pursuit",
      "authors": "L Li, M Wang, B Ni, H Wang, J Yang\u2026",
      "year": "2021",
      "cited_by": 116,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14585779787909883755&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "State-of-the-art augmented NLP transformer models for direct and single-step retrosynthesis",
      "id": "4956847805201710311",
      "url": "https://www.nature.com/articles/s41467-020-19266-y",
      "title": "State-of-the-art augmented NLP transformer models for direct and single-step retrosynthesis",
      "authors": "IV Tetko, P Karpov, R Van Deursen, G Godin",
      "year": "2020",
      "cited_by": 203,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4956847805201710311&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A comprehensive survey of recent trends in deep learning for digital images augmentation",
      "id": "6542176543643613250",
      "url": "https://link.springer.com/article/10.1007/s10462-021-10066-4",
      "title": "A comprehensive survey of recent trends in deep learning for digital images augmentation",
      "authors": "NE Khalifa, M Loey, S Mirjalili",
      "year": "2022",
      "cited_by": 119,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6542176543643613250&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Variability and reproducibility in deep learning for medical image segmentation",
      "id": "13844417272486663442",
      "url": "https://www.nature.com/articles/s41598-020-69920-0",
      "title": "Variability and reproducibility in deep learning for medical image segmentation",
      "authors": "F Renard, S Guedria, ND Palma, N Vuillerme",
      "year": "2020",
      "cited_by": 148,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13844417272486663442&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A survey of public datasets for computer vision tasks in precision agriculture",
      "id": "1995042310766600523",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169920312709",
      "title": "A survey of public datasets for computer vision tasks in precision agriculture",
      "authors": "Y Lu, S Young",
      "year": "2020",
      "cited_by": 168,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1995042310766600523&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Statistical and machine learning models in credit scoring: A systematic literature survey",
      "id": "17455667949400521995",
      "url": "https://www.sciencedirect.com/science/article/pii/S1568494620302039",
      "title": "Statistical and machine learning models in credit scoring: A systematic literature survey",
      "authors": "X Dastile, T Celik, M Potsane",
      "year": "2020",
      "cited_by": 219,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17455667949400521995&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Generative adversarial networks (GANs) for image augmentation in agriculture: A systematic review",
      "id": "1824518314930278626",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922005233",
      "title": "Generative adversarial networks (GANs) for image augmentation in agriculture: A systematic review",
      "authors": "Y Lu, D Chen, E Olaniyi, Y Huang",
      "year": "2022",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1824518314930278626&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Detection of coronavirus (COVID-19) associated pneumonia based on generative adversarial networks and a fine-tuned deep transfer learning model using chest X\u00a0\u2026",
      "id": "16973471166771569958",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20601-6_22",
      "title": "Detection of coronavirus (COVID-19) associated pneumonia based on generative adversarial networks and a fine-tuned deep transfer learning model using chest X\u00a0\u2026",
      "authors": "NEM Khalifa, MHN Taha, AE Hassanien\u2026",
      "year": "2022",
      "cited_by": 205,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16973471166771569958&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Data augmentation for brain-tumor segmentation: a review",
      "id": "11854062718992351025",
      "url": "https://www.frontiersin.org/articles/10.3389/fncom.2019.00083/full",
      "title": "Data augmentation for brain-tumor segmentation: a review",
      "authors": "J Nalepa, M Marcinkiewicz, M Kawulok",
      "year": "2019",
      "cited_by": 229,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11854062718992351025&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Machine learning in aerodynamic shape optimization",
      "id": "14217745962583788184",
      "url": "https://www.sciencedirect.com/science/article/pii/S0376042122000410",
      "title": "Machine learning in aerodynamic shape optimization",
      "authors": "J Li, X Du, JRRA Martins",
      "year": "2022",
      "cited_by": 59,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14217745962583788184&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Deep learning in medical imaging",
      "id": "5951026065039086409",
      "url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6945006/",
      "title": "Deep learning in medical imaging",
      "authors": "M Kim, J Yun, Y Cho, K Shin, R Jang, H Bae, N Kim",
      "year": "2019",
      "cited_by": 225,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5951026065039086409&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Advances in data preprocessing for biomedical data fusion: An overview of the methods, challenges, and prospects",
      "id": "7826621618102468948",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253521001354",
      "title": "Advances in data preprocessing for biomedical data fusion: An overview of the methods, challenges, and prospects",
      "authors": "S Wang, ME Celebi, YD Zhang, X Yu, S Lu, X Yao\u2026",
      "year": "2021",
      "cited_by": 98,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7826621618102468948&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A survey of generalisation in deep reinforcement learning",
      "id": "7802246301550866837",
      "url": "https://ui.adsabs.harvard.edu/abs/2021arXiv211109794K/abstract",
      "title": "A survey of generalisation in deep reinforcement learning",
      "authors": "R Kirk, A Zhang, E Grefenstette\u2026",
      "year": "2021",
      "cited_by": 157,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7802246301550866837&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "COVID-19 detection and disease progression visualization: Deep learning on chest X-rays for classification and coarse localization",
      "id": "10296237619596505984",
      "url": "https://link.springer.com/article/10.1007/s10489-020-01867-1",
      "title": "COVID-19 detection and disease progression visualization: Deep learning on chest X-rays for classification and coarse localization",
      "authors": "T Zebin, S Rezvy",
      "year": "2021",
      "cited_by": 171,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10296237619596505984&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Deep building footprint update network: A semi-supervised method for updating existing building footprint from bi-temporal remote sensing images",
      "id": "2178700053782973603",
      "url": "https://www.sciencedirect.com/science/article/pii/S0034425721003096",
      "title": "Deep building footprint update network: A semi-supervised method for updating existing building footprint from bi-temporal remote sensing images",
      "authors": "H Guo, Q Shi, A Marinoni, B Du, L Zhang",
      "year": "2021",
      "cited_by": 88,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2178700053782973603&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Artificial intelligence and machine learning for medical imaging: A technology review",
      "id": "10604152332073933497",
      "url": "https://www.sciencedirect.com/science/article/pii/S1120179721001733",
      "title": "Artificial intelligence and machine learning for medical imaging: A technology review",
      "authors": "A Barrag\u00e1n-Montero, U Javaid, G Vald\u00e9s, D Nguyen\u2026",
      "year": "2021",
      "cited_by": 128,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10604152332073933497&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Models genesis",
      "id": "7188590031243869377",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841520302048",
      "title": "Models genesis",
      "authors": "Z Zhou, V Sodha, J Pang, MB Gotway, J Liang",
      "year": "2021",
      "cited_by": 184,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7188590031243869377&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "IoT and interpretable machine learning based framework for disease prediction in pearl millet",
      "id": "15803341694212540345",
      "url": "https://www.mdpi.com/1424-8220/21/16/5386",
      "title": "IoT and interpretable machine learning based framework for disease prediction in pearl millet",
      "authors": "N Kundu, G Rani, VS Dhaka, K Gupta, SC Nayak\u2026",
      "year": "2021",
      "cited_by": 107,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15803341694212540345&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Directional graph networks",
      "id": "6256455976929564913",
      "url": "https://proceedings.mlr.press/v139/beaini21a.html",
      "title": "Directional graph networks",
      "authors": "D Beaini, S Passaro, V L\u00e9tourneau\u2026",
      "year": "2021",
      "cited_by": 120,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6256455976929564913&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A comprehensive survey of image augmentation techniques for deep learning",
      "id": "15580172266410736369",
      "url": "https://www.sciencedirect.com/science/article/pii/S0031320323000481",
      "title": "A comprehensive survey of image augmentation techniques for deep learning",
      "authors": "M Xu, S Yoon, A Fuentes, DS Park",
      "year": "2023",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15580172266410736369&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Avoiding overfitting: A survey on regularization methods for convolutional neural networks",
      "id": "6628585655867076014",
      "url": "https://dl.acm.org/doi/abs/10.1145/3510413",
      "title": "Avoiding overfitting: A survey on regularization methods for convolutional neural networks",
      "authors": "CFGD Santos, JP Papa",
      "year": "2022",
      "cited_by": 70,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6628585655867076014&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "COVID-19 salivary Raman fingerprint: innovative approach for the detection of current and past SARS-CoV-2 infections",
      "id": "8885814579435600701",
      "url": "https://www.nature.com/articles/s41598-021-84565-3",
      "title": "COVID-19 salivary Raman fingerprint: innovative approach for the detection of current and past SARS-CoV-2 infections",
      "authors": "C Carlomagno, D Bertazioli, A Gualerzi, S Picciolini\u2026",
      "year": "2021",
      "cited_by": 96,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8885814579435600701&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "The effects of regularization and data augmentation are class dependent",
      "id": "1656744800823975080",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/f73c04538a5e1cad40ba5586b4b517d3-Abstract-Conference.html",
      "title": "The effects of regularization and data augmentation are class dependent",
      "authors": "R Balestriero, L Bottou\u2026",
      "year": "2022",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1656744800823975080&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A survey on deep learning-based change detection from high-resolution remote sensing images",
      "id": "10374132085208051787",
      "url": "https://www.mdpi.com/2072-4292/14/7/1552",
      "title": "A survey on deep learning-based change detection from high-resolution remote sensing images",
      "authors": "H Jiang, M Peng, Y Zhong, H Xie, Z Hao, J Lin, X Ma\u2026",
      "year": "2022",
      "cited_by": 67,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10374132085208051787&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "How variability shapes learning and generalization",
      "id": "10940775338620708972",
      "url": "https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(22)00065-1",
      "title": "How variability shapes learning and generalization",
      "authors": "L Raviv, G Lupyan, SC Green",
      "year": "2022",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10940775338620708972&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "CovidXrayNet: Optimizing data augmentation and CNN hyperparameters for improved COVID-19 detection from CXR",
      "id": "17945544379535649211",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482521001694",
      "title": "CovidXrayNet: Optimizing data augmentation and CNN hyperparameters for improved COVID-19 detection from CXR",
      "authors": "MMA Monshi, J Poon, V Chung, FM Monshi",
      "year": "2021",
      "cited_by": 94,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17945544379535649211&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Insect classification and detection in field crops using modern machine learning techniques",
      "id": "16412654433518658547",
      "url": "https://www.sciencedirect.com/science/article/pii/S2214317320302067",
      "title": "Insect classification and detection in field crops using modern machine learning techniques",
      "authors": "T Kasinathan, D Singaraju, SR Uyyala",
      "year": "2021",
      "cited_by": 142,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16412654433518658547&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A survey on data\u2010efficient algorithms in big data era",
      "id": "804636322301015973",
      "url": "https://link.springer.com/article/10.1186/s40537-021-00419-9",
      "title": "A survey on data\u2010efficient algorithms in big data era",
      "authors": "A Adadi",
      "year": "2021",
      "cited_by": 132,
      "cited_by_url": "https://scholar.google.com/scholar?cites=804636322301015973&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Stabilizing deep q-learning with convnets and vision transformers under data augmentation",
      "id": "6794503273897899990",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/1e0f65eb20acbfb27ee05ddc000b50ec-Abstract.html",
      "title": "Stabilizing deep q-learning with convnets and vision transformers under data augmentation",
      "authors": "N Hansen, H Su, X Wang",
      "year": "2021",
      "cited_by": 63,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6794503273897899990&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Applications of explainable artificial intelligence in diagnosis and surgery",
      "id": "5744336008744333374",
      "url": "https://www.mdpi.com/2075-4418/12/2/237",
      "title": "Applications of explainable artificial intelligence in diagnosis and surgery",
      "authors": "Y Zhang, Y Weng, J Lund",
      "year": "2022",
      "cited_by": 94,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5744336008744333374&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Channel augmented joint learning for visible-infrared recognition",
      "id": "11739296977766500505",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Ye_Channel_Augmented_Joint_Learning_for_Visible-Infrared_Recognition_ICCV_2021_paper.html",
      "title": "Channel augmented joint learning for visible-infrared recognition",
      "authors": "M Ye, W Ruan, B Du, MZ Shou",
      "year": "2021",
      "cited_by": 79,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11739296977766500505&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "An efficient CNN model for COVID-19 disease detection based on X-ray image classification",
      "id": "9595578074718261885",
      "url": "https://www.hindawi.com/journals/complexity/2021/6621607/",
      "title": "An efficient CNN model for COVID-19 disease detection based on X-ray image classification",
      "authors": "AA Reshi, F Rustam, A Mehmood, A Alhossan\u2026",
      "year": "2021",
      "cited_by": 107,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9595578074718261885&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Plant diseases recognition on images using convolutional neural networks: A systematic review",
      "id": "7437652212406869439",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169921001435",
      "title": "Plant diseases recognition on images using convolutional neural networks: A systematic review",
      "authors": "A Abade, PA Ferreira, F de Barros Vidal",
      "year": "2021",
      "cited_by": 121,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7437652212406869439&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Comprehensive survey of recent drug discovery using deep learning",
      "id": "14190759885589230911",
      "url": "https://www.mdpi.com/1422-0067/22/18/9983",
      "title": "Comprehensive survey of recent drug discovery using deep learning",
      "authors": "J Kim, S Park, D Min, W Kim",
      "year": "2021",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14190759885589230911&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "A literature review on one-class classification and its potential applications in big data",
      "id": "15052277191896050356",
      "url": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00514-x",
      "title": "A literature review on one-class classification and its potential applications in big data",
      "authors": "N Seliya, A Abdollah Zadeh\u2026",
      "year": "2021",
      "cited_by": 67,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15052277191896050356&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Differentiable biology: using deep learning for biophysics-based and data-driven modeling of molecular mechanisms",
      "id": "8770863820400864485",
      "url": "https://www.nature.com/articles/s41592-021-01283-4",
      "title": "Differentiable biology: using deep learning for biophysics-based and data-driven modeling of molecular mechanisms",
      "authors": "M AlQuraishi, PK Sorger",
      "year": "2021",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8770863820400864485&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Cassava disease recognition from low\u2010quality images using enhanced data augmentation model and deep learning",
      "id": "11914760532013868738",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.12746",
      "title": "Cassava disease recognition from low\u2010quality images using enhanced data augmentation model and deep learning",
      "authors": "OO Abayomi\u2010Alli, R Dama\u0161evi\u010dius, S Misra\u2026",
      "year": "2021",
      "cited_by": 84,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11914760532013868738&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Unlocking high-accuracy differentially private image classification through scale",
      "id": "8884460723513624148",
      "url": "https://arxiv.org/abs/2204.13650",
      "title": "Unlocking high-accuracy differentially private image classification through scale",
      "authors": "S De, L Berrada, J Hayes, SL Smith, B Balle",
      "year": "2022",
      "cited_by": 77,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8884460723513624148&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Avoiding a replication crisis in deep-learning-based bioimage analysis",
      "id": "16779378878512616320",
      "url": "https://www.nature.com/articles/s41592-021-01284-3",
      "title": "Avoiding a replication crisis in deep-learning-based bioimage analysis",
      "authors": "RF Laine, I Arganda-Carreras, R Henriques\u2026",
      "year": "2021",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16779378878512616320&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Machine learning for metal additive manufacturing: Towards a physics-informed data-driven paradigm",
      "id": "17666447766930405698",
      "url": "https://www.sciencedirect.com/science/article/pii/S0278612521002259",
      "title": "Machine learning for metal additive manufacturing: Towards a physics-informed data-driven paradigm",
      "authors": "S Guo, M Agarwal, C Cooper, Q Tian, RX Gao\u2026",
      "year": "2022",
      "cited_by": 66,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17666447766930405698&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Image data augmentation for deep learning: A survey",
      "id": "18148219906827393870",
      "url": "https://arxiv.org/abs/2204.08610",
      "title": "Image data augmentation for deep learning: A survey",
      "authors": "S Yang, W Xiao, M Zhang, S Guo, J Zhao\u2026",
      "year": "2022",
      "cited_by": 101,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18148219906827393870&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Augmenting organizational decision-making with deep learning algorithms: Principles, promises, and challenges",
      "id": "2194257343717484563",
      "url": "https://www.sciencedirect.com/science/article/pii/S0148296320306512",
      "title": "Augmenting organizational decision-making with deep learning algorithms: Principles, promises, and challenges",
      "authors": "YR Shrestha, V Krishna, G von Krogh",
      "year": "2021",
      "cited_by": 115,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2194257343717484563&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Towards a better understanding of transfer learning for medical imaging: a case study",
      "id": "9750378231570611023",
      "url": "https://www.mdpi.com/2076-3417/10/13/4523",
      "title": "Towards a better understanding of transfer learning for medical imaging: a case study",
      "authors": "L Alzubaidi, MA Fadhel, O Al-Shamma, J Zhang\u2026",
      "year": "2020",
      "cited_by": 152,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9750378231570611023&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Hyperspectral image classification\u2014Traditional to deep models: A survey for future prospects",
      "id": "8336676790606133743",
      "url": "https://ieeexplore.ieee.org/abstract/document/9645266/",
      "title": "Hyperspectral image classification\u2014Traditional to deep models: A survey for future prospects",
      "authors": "M Ahmad, S Shabbir, SK Roy, D Hong\u2026",
      "year": "2021",
      "cited_by": 107,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8336676790606133743&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "Real time pear fruit detection and counting using YOLOv4 models and deep SORT",
      "id": "9023365447299077306",
      "url": "https://www.mdpi.com/1424-8220/21/14/4803",
      "title": "Real time pear fruit detection and counting using YOLOv4 models and deep SORT",
      "authors": "AIB Parico, T Ahamed",
      "year": "2021",
      "cited_by": 96,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9023365447299077306&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A comprehensive study on classification of COVID-19 on computed tomography with pretrained convolutional neural networks",
      "id": "448552700743310645",
      "url": "https://www.nature.com/articles/s41598-020-74164-z",
      "title": "A comprehensive study on classification of COVID-19 on computed tomography with pretrained convolutional neural networks",
      "authors": "TD Pham",
      "year": "2020",
      "cited_by": 137,
      "cited_by_url": "https://scholar.google.com/scholar?cites=448552700743310645&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 5
    },
    {
      "label": "YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors",
      "id": "2026726248513085794",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wang_YOLOv7_Trainable_Bag-of-Freebies_Sets_New_State-of-the-Art_for_Real-Time_Object_Detectors_CVPR_2023_paper.html",
      "title": "YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors",
      "authors": "CY Wang, A Bochkovskiy\u2026",
      "year": "2023",
      "cited_by": 1921,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2026726248513085794&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Object detection in 20 years: A survey",
      "id": "9850512646184180167",
      "url": "https://ieeexplore.ieee.org/abstract/document/10028728/",
      "title": "Object detection in 20 years: A survey",
      "authors": "Z Zou, K Chen, Z Shi, Y Guo, J Ye",
      "year": "2023",
      "cited_by": 1626,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9850512646184180167&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Bytetrack: Multi-object tracking by associating every detection box",
      "id": "14638466021176544465",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20047-2_1",
      "title": "Bytetrack: Multi-object tracking by associating every detection box",
      "authors": "Y Zhang, P Sun, Y Jiang, D Yu, F Weng, Z Yuan\u2026",
      "year": "2022",
      "cited_by": 538,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14638466021176544465&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "YOLOv6: A single-stage object detection framework for industrial applications",
      "id": "13702720529764835843",
      "url": "https://arxiv.org/abs/2209.02976",
      "title": "YOLOv6: A single-stage object detection framework for industrial applications",
      "authors": "C Li, L Li, H Jiang, K Weng, Y Geng, L Li, Z Ke\u2026",
      "year": "2022",
      "cited_by": 477,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13702720529764835843&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Optimization strategies of fruit detection to overcome the challenge of unstructured background in field orchard environment: A review",
      "id": "17646032300901507453",
      "url": "https://link.springer.com/article/10.1007/s11119-023-10009-9",
      "title": "Optimization strategies of fruit detection to overcome the challenge of unstructured background in field orchard environment: A review",
      "authors": "Y Tang, J Qiu, Y Zhang, D Wu, Y Cao, K Zhao\u2026",
      "year": "2023",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17646032300901507453&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "YOLOWeeds: a novel benchmark of YOLO object detectors for multi-class weed detection in cotton production systems",
      "id": "17127958062872744853",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169923000431",
      "title": "YOLOWeeds: a novel benchmark of YOLO object detectors for multi-class weed detection in cotton production systems",
      "authors": "F Dang, D Chen, Y Lu, Z Li",
      "year": "2023",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17127958062872744853&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "An attention mechanism-improved YOLOv7 object detection algorithm for hemp duck count estimation",
      "id": "13222462680960111198",
      "url": "https://www.mdpi.com/2077-0472/12/10/1659",
      "title": "An attention mechanism-improved YOLOv7 object detection algorithm for hemp duck count estimation",
      "authors": "K Jiang, T Xie, R Yan, X Wen, D Li, H Jiang, N Jiang\u2026",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13222462680960111198&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Zenseact open dataset: A large-scale and diverse multimodal dataset for autonomous driving",
      "id": "8594852448598418616",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Alibeigi_Zenseact_Open_Dataset_A_Large-Scale_and_Diverse_Multimodal_Dataset_for_ICCV_2023_paper.html",
      "title": "Zenseact open dataset: A large-scale and diverse multimodal dataset for autonomous driving",
      "authors": "M Alibeigi, W Ljungbergh, A Tonderski\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8594852448598418616&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Sf-yolov5: A lightweight small object detection algorithm based on improved feature fusion mode",
      "id": "16827683962441657873",
      "url": "https://www.mdpi.com/1424-8220/22/15/5817",
      "title": "Sf-yolov5: A lightweight small object detection algorithm based on improved feature fusion mode",
      "authors": "H Liu, F Sun, J Gu, L Deng",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16827683962441657873&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Detection of Camellia oleifera Fruit in Complex Scenes by Using YOLOv7 and Data Augmentation",
      "id": "11112203079270473115",
      "url": "https://www.mdpi.com/2076-3417/12/22/11318",
      "title": "Detection of Camellia oleifera Fruit in Complex Scenes by Using YOLOv7 and Data Augmentation",
      "authors": "D Wu, S Jiang, E Zhao, Y Liu, H Zhu, W Wang\u2026",
      "year": "2022",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11112203079270473115&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Adaptive Active Positioning of Camellia oleifera Fruit Picking Points: Classical Image Processing and YOLOv7 Fusion Algorithm",
      "id": "17690753104303819861",
      "url": "https://www.mdpi.com/2076-3417/12/24/12959",
      "title": "Adaptive Active Positioning of Camellia oleifera Fruit Picking Points: Classical Image Processing and YOLOv7 Fusion Algorithm",
      "authors": "Y Zhou, Y Tang, X Zou, M Wu, W Tang, F Meng\u2026",
      "year": "2022",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17690753104303819861&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Domain feature mapping with YOLOv7 for automated edge-based pallet racking inspections",
      "id": "10264464849626080964",
      "url": "https://www.mdpi.com/1424-8220/22/18/6927",
      "title": "Domain feature mapping with YOLOv7 for automated edge-based pallet racking inspections",
      "authors": "M Hussain, H Al-Aqrabi, M Munawar, R Hill, T Alsboui",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10264464849626080964&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Rtmdet: An empirical study of designing real-time object detectors",
      "id": "17785166320928157068",
      "url": "https://arxiv.org/abs/2212.07784",
      "title": "Rtmdet: An empirical study of designing real-time object detectors",
      "authors": "C Lyu, W Zhang, H Huang, Y Zhou, Y Wang\u2026",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17785166320928157068&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Target detection method of UAV aerial imagery based on improved YOLOv5",
      "id": "7665772481323515367",
      "url": "https://www.mdpi.com/2072-4292/14/19/5063",
      "title": "Target detection method of UAV aerial imagery based on improved YOLOv5",
      "authors": "X Luo, Y Wu, F Wang",
      "year": "2022",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7665772481323515367&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Hybrid-YOLO for classification of insulators defects in transmission lines based on UAV",
      "id": "5875186414038374408",
      "url": "https://www.sciencedirect.com/science/article/pii/S014206152300039X",
      "title": "Hybrid-YOLO for classification of insulators defects in transmission lines based on UAV",
      "authors": "BJ Souza, SF Stefenon, G Singh, RZ Freire",
      "year": "2023",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5875186414038374408&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Real-time multi-class helmet violation detection using few-shot data sampling technique and yolov8",
      "id": "9420485880557840183",
      "url": "https://openaccess.thecvf.com/content/CVPR2023W/AICity/html/Aboah_Real-Time_Multi-Class_Helmet_Violation_Detection_Using_Few-Shot_Data_Sampling_Technique_CVPRW_2023_paper.html",
      "title": "Real-time multi-class helmet violation detection using few-shot data sampling technique and yolov8",
      "authors": "A Aboah, B Wang, U Bagci\u2026",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9420485880557840183&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Deep learning for detecting macroplastic litter in water bodies: A review",
      "id": "14658447611882211088",
      "url": "https://www.sciencedirect.com/science/article/pii/S0043135423000672",
      "title": "Deep learning for detecting macroplastic litter in water bodies: A review",
      "authors": "T Jia, Z Kapelan, R de Vries, P Vriend, EC Peereboom\u2026",
      "year": "2023",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14658447611882211088&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Lite DETR: An interleaved multi-scale encoder for efficient detr",
      "id": "10221363205500346797",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Li_Lite_DETR_An_Interleaved_Multi-Scale_Encoder_for_Efficient_DETR_CVPR_2023_paper.html",
      "title": "Lite DETR: An interleaved multi-scale encoder for efficient detr",
      "authors": "F Li, A Zeng, S Liu, H Zhang, H Li\u2026",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10221363205500346797&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A multiscale lightweight and efficient model based on YOLOv7: Applied to citrus orchard",
      "id": "16559564215385655731",
      "url": "https://www.mdpi.com/2223-7747/11/23/3260",
      "title": "A multiscale lightweight and efficient model based on YOLOv7: Applied to citrus orchard",
      "authors": "J Chen, H Liu, Y Zhang, D Zhang, H Ouyang, X Chen",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16559564215385655731&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Yolov6 v3. 0: A full-scale reloading",
      "id": "958587697277086390",
      "url": "https://arxiv.org/abs/2301.05586",
      "title": "Yolov6 v3. 0: A full-scale reloading",
      "authors": "C Li, L Li, Y Geng, H Jiang, M Cheng, B Zhang\u2026",
      "year": "2023",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=958587697277086390&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Deep object detection of crop weeds: Performance of YOLOv7 on a real case dataset from UAV images",
      "id": "17898472391686934449",
      "url": "https://www.mdpi.com/2072-4292/15/2/539?ref=blog.roboflow.com",
      "title": "Deep object detection of crop weeds: Performance of YOLOv7 on a real case dataset from UAV images",
      "authors": "I Gallo, AU Rehman, RH Dehkordi, N Landro\u2026",
      "year": "2023",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17898472391686934449&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Deepsegmenter: Temporal action localization for detecting anomalies in untrimmed naturalistic driving videos",
      "id": "6352382094902298941",
      "url": "https://openaccess.thecvf.com/content/CVPR2023W/AICity/html/Aboah_DeepSegmenter_Temporal_Action_Localization_for_Detecting_Anomalies_in_Untrimmed_Naturalistic_CVPRW_2023_paper.html",
      "title": "Deepsegmenter: Temporal action localization for detecting anomalies in untrimmed naturalistic driving videos",
      "authors": "A Aboah, U Bagci, AR Mussah\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6352382094902298941&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Improved YOLOv3 model with feature map cropping for multi-scale road object detection",
      "id": "14183845217069566705",
      "url": "https://iopscience.iop.org/article/10.1088/1361-6501/acb075/meta",
      "title": "Improved YOLOv3 model with feature map cropping for multi-scale road object detection",
      "authors": "L Shen, H Tao, Y Ni, Y Wang\u2026",
      "year": "2023",
      "cited_by": 40,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14183845217069566705&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Development of YOLOv5-based real-time smart monitoring system for increasing lab safety awareness in educational institutions",
      "id": "14052692408086479292",
      "url": "https://www.mdpi.com/1424-8220/22/22/8820",
      "title": "Development of YOLOv5-based real-time smart monitoring system for increasing lab safety awareness in educational institutions",
      "authors": "L Ali, F Alnajjar, MMA Parambil, MI Younes\u2026",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14052692408086479292&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Stall number detection of cow teats key frames",
      "id": "16133934620382970642",
      "url": "https://arxiv.org/abs/2303.10444",
      "title": "Stall number detection of cow teats key frames",
      "authors": "Y Zhang",
      "year": "2023",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16133934620382970642&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Adversarial patch attack on multi-scale object detection for uav remote sensing images",
      "id": "15271212594475018431",
      "url": "https://www.mdpi.com/2072-4292/14/21/5298",
      "title": "Adversarial patch attack on multi-scale object detection for uav remote sensing images",
      "authors": "Y Zhang, Y Zhang, J Qi, K Bin, H Wen, X Tong\u2026",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15271212594475018431&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A comprehensive review of YOLO: From YOLOv1 to YOLOv8 and beyond",
      "id": "8819196546794680544",
      "url": "https://arxiv.org/abs/2304.00501",
      "title": "A comprehensive review of YOLO: From YOLOv1 to YOLOv8 and beyond",
      "authors": "J Terven, D Cordova-Esparza",
      "year": "2023",
      "cited_by": 92,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8819196546794680544&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Insulator-defect detection algorithm based on improved YOLOv7",
      "id": "12345969996209231071",
      "url": "https://www.mdpi.com/1424-8220/22/22/8801",
      "title": "Insulator-defect detection algorithm based on improved YOLOv7",
      "authors": "J Zheng, H Wu, H Zhang, Z Wang, W Xu",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12345969996209231071&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "1st workshop on maritime computer vision (macvi) 2023: Challenge results",
      "id": "13723544815291086075",
      "url": "https://openaccess.thecvf.com/content/WACV2023W/MaCVi/html/Kiefer_1st_Workshop_on_Maritime_Computer_Vision_MaCVi_2023_Challenge_Results_WACVW_2023_paper.html",
      "title": "1st workshop on maritime computer vision (macvi) 2023: Challenge results",
      "authors": "B Kiefer, M Kristan, J Per\u0161, L \u017dust\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13723544815291086075&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Mislaying behavior detection in cage-free hens with deep learning technologies",
      "id": "7938131059737931281",
      "url": "https://www.sciencedirect.com/science/article/pii/S0032579123002511",
      "title": "Mislaying behavior detection in cage-free hens with deep learning technologies",
      "authors": "RB Bist, X Yang, S Subedi, L Chai",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7938131059737931281&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Yolov7-sea: Object detection of maritime uav images based on improved yolov7",
      "id": "4384676216153265937",
      "url": "https://openaccess.thecvf.com/content/WACV2023W/MaCVi/html/Zhao_YOLOv7-Sea_Object_Detection_of_Maritime_UAV_Images_Based_on_Improved_WACVW_2023_paper.html",
      "title": "Yolov7-sea: Object detection of maritime uav images based on improved yolov7",
      "authors": "H Zhao, H Zhang, Y Zhao",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4384676216153265937&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Gbh-yolov5: Ghost convolution with bottleneckcsp and tiny target prediction head incorporating yolov5 for pv panel defect detection",
      "id": "10116304010765610972",
      "url": "https://www.mdpi.com/2079-9292/12/3/561",
      "title": "Gbh-yolov5: Ghost convolution with bottleneckcsp and tiny target prediction head incorporating yolov5 for pv panel defect detection",
      "authors": "L Li, Z Wang, T Zhang",
      "year": "2023",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10116304010765610972&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A reinforcement learning paradigm of configuring visual enhancement for object detection in underwater scenes",
      "id": "2663039362134560569",
      "url": "https://ieeexplore.ieee.org/abstract/document/10058092/",
      "title": "A reinforcement learning paradigm of configuring visual enhancement for object detection in underwater scenes",
      "authors": "H Wang, S Sun, X Bai, J Wang\u2026",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2663039362134560569&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "CEAM-YOLOv7: Improved YOLOv7 based on channel expansion and attention mechanism for driver distraction behavior detection",
      "id": "3281046445393215005",
      "url": "https://ieeexplore.ieee.org/abstract/document/9980374/",
      "title": "CEAM-YOLOv7: Improved YOLOv7 based on channel expansion and attention mechanism for driver distraction behavior detection",
      "authors": "S Liu, Y Wang, Q Yu, H Liu, Z Peng",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3281046445393215005&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "GGT-YOLO: a novel object detection algorithm for drone-based maritime cruising",
      "id": "176548951834254449",
      "url": "https://www.mdpi.com/2504-446X/6/11/335",
      "title": "GGT-YOLO: a novel object detection algorithm for drone-based maritime cruising",
      "authors": "Y Li, H Yuan, Y Wang, C Xiao",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=176548951834254449&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "One-to-Few Label Assignment for End-to-End Dense Detection",
      "id": "7090138214741207408",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Li_One-to-Few_Label_Assignment_for_End-to-End_Dense_Detection_CVPR_2023_paper.html",
      "title": "One-to-Few Label Assignment for End-to-End Dense Detection",
      "authors": "S Li, M Li, R Li, C He, L Zhang",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7090138214741207408&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Using lightweight deep learning algorithm for real-time detection of apple flowers in natural environments",
      "id": "14151669589159930339",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169923001539",
      "title": "Using lightweight deep learning algorithm for real-time detection of apple flowers in natural environments",
      "authors": "Y Shang, X Xu, Y Jiao, Z Wang, Z Hua\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14151669589159930339&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Efficient detection model of steel strip surface defects based on YOLO-V7",
      "id": "6535827589324635187",
      "url": "https://ieeexplore.ieee.org/abstract/document/9994733/",
      "title": "Efficient detection model of steel strip surface defects based on YOLO-V7",
      "authors": "Y Wang, H Wang, Z Xin",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6535827589324635187&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "TCPMFNet: An infrared and visible image fusion network with composite auto encoder and transformer\u2013convolutional parallel mixed fusion strategy",
      "id": "12472359179257688469",
      "url": "https://www.sciencedirect.com/science/article/pii/S1350449522003863",
      "title": "TCPMFNet: An infrared and visible image fusion network with composite auto encoder and transformer\u2013convolutional parallel mixed fusion strategy",
      "authors": "S Yi, G Jiang, X Liu, J Li, L Chen",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12472359179257688469&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "YOLOv5s-FP: a novel method for in-field pear detection using a transformer encoder and multi-scale collaboration perception",
      "id": "9925896961448568187",
      "url": "https://www.mdpi.com/1424-8220/23/1/30",
      "title": "YOLOv5s-FP: a novel method for in-field pear detection using a transformer encoder and multi-scale collaboration perception",
      "authors": "Y Li, Y Rao, X Jin, Z Jiang, Y Wang, T Wang, F Wang\u2026",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9925896961448568187&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "YOLO-HR: Improved YOLOv5 for Object Detection in High-Resolution Optical Remote Sensing Images",
      "id": "14205155098487362799",
      "url": "https://www.mdpi.com/2072-4292/15/3/614",
      "title": "YOLO-HR: Improved YOLOv5 for Object Detection in High-Resolution Optical Remote Sensing Images",
      "authors": "D Wan, R Lu, S Wang, S Shen, T Xu, X Lang",
      "year": "2023",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14205155098487362799&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Cross-modal text and visual generation: A systematic review. Part 1\u2014Image to text",
      "id": "7644674706913288304",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253523000143",
      "title": "Cross-modal text and visual generation: A systematic review. Part 1\u2014Image to text",
      "authors": "M \u017belaszczyk, J Ma\u0144dziuk",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7644674706913288304&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Automated optical inspection of FAST's reflector surface using drones and computer vision",
      "id": "15845207782709112329",
      "url": "https://www.light-am.com/article/doi/10.37188/lam.2023.001",
      "title": "Automated optical inspection of FAST's reflector surface using drones and computer vision",
      "authors": "J Li, S Jiang, L Song, P Peng, F Mu, H Li\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15845207782709112329&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Automated vehicle counting from pre-recorded video using you only look once (YOLO) object detection model",
      "id": "2749712196276682618",
      "url": "https://www.mdpi.com/2313-433X/9/7/131",
      "title": "Automated vehicle counting from pre-recorded video using you only look once (YOLO) object detection model",
      "authors": "M Majumder, C Wilmot",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2749712196276682618&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Research on safety helmet detection algorithm based on improved YOLOv5s",
      "id": "8263847837619800805",
      "url": "https://www.mdpi.com/1424-8220/23/13/5824",
      "title": "Research on safety helmet detection algorithm based on improved YOLOv5s",
      "authors": "Q An, Y Xu, J Yu, M Tang, T Liu, F Xu",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8263847837619800805&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Brain tumor detection based on deep learning approaches and magnetic resonance imaging",
      "id": "7690447212830750827",
      "url": "https://www.mdpi.com/2072-6694/15/16/4172",
      "title": "Brain tumor detection based on deep learning approaches and magnetic resonance imaging",
      "authors": "AB Abdusalomov, M Mukhiddinov, TK Whangbo",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7690447212830750827&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Multi-Scale Ship Detection Algorithm Based on YOLOv7 for Complex Scene SAR Images",
      "id": "10608878509050050554",
      "url": "https://www.mdpi.com/2072-4292/15/8/2071",
      "title": "Multi-Scale Ship Detection Algorithm Based on YOLOv7 for Complex Scene SAR Images",
      "authors": "Z Chen, C Liu, VF Filaretov, DA Yukhimets",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10608878509050050554&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Three-stage pavement crack localization and segmentation algorithm based on digital image processing and deep learning techniques",
      "id": "7076299391791953686",
      "url": "https://www.mdpi.com/1424-8220/22/21/8459",
      "title": "Three-stage pavement crack localization and segmentation algorithm based on digital image processing and deep learning techniques",
      "authors": "Z Yang, C Ni, L Li, W Luo, Y Qin",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7076299391791953686&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Machine learning in solar plants inspection automation",
      "id": "7291687913883151332",
      "url": "https://www.mdpi.com/1996-1073/15/16/5966",
      "title": "Machine learning in solar plants inspection automation",
      "authors": "J Starzy\u0144ski, P Zawadzki, D Hara\u0144czyk",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7291687913883151332&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A cooperative vehicle-infrastructure system for road hazards detection with edge intelligence",
      "id": "7099002288627031897",
      "url": "https://ieeexplore.ieee.org/abstract/document/10038653/",
      "title": "A cooperative vehicle-infrastructure system for road hazards detection with edge intelligence",
      "authors": "C Chen, G Yao, L Liu, Q Pei, H Song\u2026",
      "year": "2023",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7099002288627031897&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Classification of diabetic retinopathy severity in fundus images using the vision transformer and residual attention",
      "id": "15184762675201395065",
      "url": "https://www.hindawi.com/journals/cin/2023/1305583/",
      "title": "Classification of diabetic retinopathy severity in fundus images using the vision transformer and residual attention",
      "authors": "Z Gu, Y Li, Z Wang, J Kan, J Shu, Q Wang",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15184762675201395065&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "YOLOv7-RAR for Urban Vehicle Detection",
      "id": "6327480080772807927",
      "url": "https://www.mdpi.com/1424-8220/23/4/1801",
      "title": "YOLOv7-RAR for Urban Vehicle Detection",
      "authors": "Y Zhang, Y Sun, Z Wang, Y Jiang",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6327480080772807927&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Lightweight SM-YOLOv5 tomato fruit detection algorithm for plant factory",
      "id": "8866059787183806571",
      "url": "https://www.mdpi.com/1424-8220/23/6/3336",
      "title": "Lightweight SM-YOLOv5 tomato fruit detection algorithm for plant factory",
      "authors": "X Wang, Z Wu, M Jia, T Xu, C Pan, X Qi, M Zhao",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8866059787183806571&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Feature-enhanced centernet for small object detection in remote sensing images",
      "id": "13803925855903140317",
      "url": "https://www.mdpi.com/2072-4292/14/21/5488",
      "title": "Feature-enhanced centernet for small object detection in remote sensing images",
      "authors": "T Shi, J Gong, J Hu, X Zhi, W Zhang, Y Zhang\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13803925855903140317&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Video object tracking based on YOLOv7 and DeepSORT",
      "id": "16632032221621362841",
      "url": "https://arxiv.org/abs/2207.12202",
      "title": "Video object tracking based on YOLOv7 and DeepSORT",
      "authors": "F Yang, X Zhang, B Liu",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16632032221621362841&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Learning emotion representations from verbal and nonverbal communication",
      "id": "18391486949977622277",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Learning_Emotion_Representations_From_Verbal_and_Nonverbal_Communication_CVPR_2023_paper.html",
      "title": "Learning emotion representations from verbal and nonverbal communication",
      "authors": "S Zhang, Y Pan, JZ Wang",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18391486949977622277&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Two-stream regression network for dental implant position prediction",
      "id": "10392802398675002497",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417423016378",
      "title": "Two-stream regression network for dental implant position prediction",
      "authors": "X Yang, X Li, X Li, W Chen, L Shen, X Li\u2026",
      "year": "2024",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10392802398675002497&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Semantic scene understanding with large language models on unmanned aerial vehicles",
      "id": "9903488889701687950",
      "url": "https://www.mdpi.com/2504-446X/7/2/114",
      "title": "Semantic scene understanding with large language models on unmanned aerial vehicles",
      "authors": "J de Curt\u00f2, I de Zarz\u00e0, CT Calafate",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9903488889701687950&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Recognition and Counting of Apples in a Dynamic State Using a 3D Camera and Deep Learning Algorithms for Robotic Harvesting Systems",
      "id": "8851123877575968338",
      "url": "https://www.mdpi.com/1424-8220/23/8/3810",
      "title": "Recognition and Counting of Apples in a Dynamic State Using a 3D Camera and Deep Learning Algorithms for Robotic Harvesting Systems",
      "authors": "RMRD Abeyrathna, VM Nakaguchi, A Minn, T Ahamed",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8851123877575968338&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Neural Architecture Search Survey: A Computer Vision Perspective",
      "id": "1702973244756968520",
      "url": "https://www.mdpi.com/1424-8220/23/3/1713",
      "title": "Neural Architecture Search Survey: A Computer Vision Perspective",
      "authors": "JS Kang, JK Kang, JJ Kim, KW Jeon, HJ Chung\u2026",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1702973244756968520&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Comparison of pre-trained YOLO models on steel surface defects detector based on transfer learning with GPU-based embedded devices",
      "id": "14037392503982667044",
      "url": "https://www.mdpi.com/1424-8220/22/24/9926",
      "title": "Comparison of pre-trained YOLO models on steel surface defects detector based on transfer learning with GPU-based embedded devices",
      "authors": "HV Nguyen, JH Bae, YE Lee, HS Lee, KR Kwon",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14037392503982667044&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Road Damage Detection and Classification with YOLOv7",
      "id": "2410476445007210626",
      "url": "https://ieeexplore.ieee.org/abstract/document/10020856/",
      "title": "Road Damage Detection and Classification with YOLOv7",
      "authors": "V Pham, D Nguyen, C Donan",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2410476445007210626&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "IDOD-YOLOV7: Image-Dehazing YOLOV7 for Object Detection in Low-Light Foggy Traffic Environments",
      "id": "17386293721154871155",
      "url": "https://www.mdpi.com/1424-8220/23/3/1347",
      "title": "IDOD-YOLOV7: Image-Dehazing YOLOV7 for Object Detection in Low-Light Foggy Traffic Environments",
      "authors": "Y Qiu, Y Lu, Y Wang, H Jiang",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17386293721154871155&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Creating a dynamic quadrupedal robotic goalkeeper with reinforcement learning",
      "id": "9015347870265085472",
      "url": "https://arxiv.org/abs/2210.04435",
      "title": "Creating a dynamic quadrupedal robotic goalkeeper with reinforcement learning",
      "authors": "X Huang, Z Li, Y Xiang, Y Ni, Y Chi, Y Li, L Yang\u2026",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9015347870265085472&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Fire detection and notification method in ship areas using deep learning and computer vision approaches",
      "id": "12337878440731894992",
      "url": "https://www.mdpi.com/1424-8220/23/16/7078",
      "title": "Fire detection and notification method in ship areas using deep learning and computer vision approaches",
      "authors": "K Avazov, MK Jamil, B Muminov, AB Abdusalomov\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12337878440731894992&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results",
      "id": "6147088247534052612",
      "url": "https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/html/Dumitriu_Rip_Current_Segmentation_A_Novel_Benchmark_and_YOLOv8_Baseline_Results_CVPRW_2023_paper.html",
      "title": "Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results",
      "authors": "A Dumitriu, F Tatui, F Miron\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6147088247534052612&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Underwater Object Detection Using TC-YOLO with Attention Mechanisms",
      "id": "4526718419682475090",
      "url": "https://www.mdpi.com/1424-8220/23/5/2567",
      "title": "Underwater Object Detection Using TC-YOLO with Attention Mechanisms",
      "authors": "K Liu, L Peng, S Tang",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4526718419682475090&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Yolopv2: Better, faster, stronger for panoptic driving perception",
      "id": "6128611593700706618",
      "url": "https://arxiv.org/abs/2208.11434",
      "title": "Yolopv2: Better, faster, stronger for panoptic driving perception",
      "authors": "C Han, Q Zhao, S Zhang, Y Chen, Z Zhang\u2026",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6128611593700706618&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Towards Single Camera Human 3D-Kinematics",
      "id": "17237114188030762025",
      "url": "https://www.mdpi.com/1424-8220/23/1/341",
      "title": "Towards Single Camera Human 3D-Kinematics",
      "authors": "M Bittner, WT Yang, X Zhang, A Seth, J van Gemert\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17237114188030762025&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Improved ship detection algorithm from satellite images using YOLOv7 and graph neural network",
      "id": "15542278339082031875",
      "url": "https://www.mdpi.com/1999-4893/15/12/473",
      "title": "Improved ship detection algorithm from satellite images using YOLOv7 and graph neural network",
      "authors": "K Patel, C Bhatt, PL Mazzeo",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15542278339082031875&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Deformable convolution and coordinate attention for fast cattle detection",
      "id": "8569975234173607623",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169923003940",
      "title": "Deformable convolution and coordinate attention for fast cattle detection",
      "authors": "W Yang, J Wu, J Zhang, K Gao, R Du, Z Wu\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8569975234173607623&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Detection of Power Poles in Orchards Based on Improved Yolov5s Model",
      "id": "14110793700557908078",
      "url": "https://www.mdpi.com/2073-4395/13/7/1705",
      "title": "Detection of Power Poles in Orchards Based on Improved Yolov5s Model",
      "authors": "Y Zhang, X Lu, W Li, K Yan, Z Mo, Y Lan, L Wang",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14110793700557908078&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Yolo-former: Marrying yolo and transformer for foreign object detection",
      "id": "388784122271071816",
      "url": "https://ieeexplore.ieee.org/abstract/document/9953039/",
      "title": "Yolo-former: Marrying yolo and transformer for foreign object detection",
      "authors": "Y Dai, W Liu, H Wang, W Xie\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=388784122271071816&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Special Vehicle Detection from UAV Perspective via YOLO-GNS Based Deep Learning Network",
      "id": "8471323315563528709",
      "url": "https://www.mdpi.com/2504-446X/7/2/117",
      "title": "Special Vehicle Detection from UAV Perspective via YOLO-GNS Based Deep Learning Network",
      "authors": "Z Qiu, H Bai, T Chen",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8471323315563528709&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "DynamicDet: A Unified Dynamic Architecture for Object Detection",
      "id": "13825486577349279839",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Lin_DynamicDet_A_Unified_Dynamic_Architecture_for_Object_Detection_CVPR_2023_paper.html",
      "title": "DynamicDet: A Unified Dynamic Architecture for Object Detection",
      "authors": "Z Lin, Y Wang, J Zhang, X Chu",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13825486577349279839&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "KPE-YOLOv5: An Improved Small Target Detection Algorithm Based on YOLOv5",
      "id": "4419171281200457557",
      "url": "https://www.mdpi.com/2079-9292/12/4/817",
      "title": "KPE-YOLOv5: An Improved Small Target Detection Algorithm Based on YOLOv5",
      "authors": "R Yang, W Li, X Shang, D Zhu, X Man",
      "year": "2023",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4419171281200457557&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Dense Text-to-Image Generation with Attention Modulation",
      "id": "4043189257734549657",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.html",
      "title": "Dense Text-to-Image Generation with Attention Modulation",
      "authors": "Y Kim, J Lee, JH Kim, JW Ha\u2026",
      "year": "2023",
      "modularity": 1
    },
    {
      "label": "3d-net: Monocular 3d object recognition for traffic monitoring",
      "id": "12115561072014802341",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417423007558",
      "title": "3d-net: Monocular 3d object recognition for traffic monitoring",
      "authors": "M Rezaei, M Azarmi, FMP Mir",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12115561072014802341&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Damage Detection and Localization of Bridge Deck Pavement Based on Deep Learning",
      "id": "5444293888769597917",
      "url": "https://www.mdpi.com/1424-8220/23/11/5138",
      "title": "Damage Detection and Localization of Bridge Deck Pavement Based on Deep Learning",
      "authors": "Y Ni, J Mao, Y Fu, H Wang, H Zong, K Luo",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5444293888769597917&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "SafeFac: Video-based smart safety monitoring for preventing industrial work accidents",
      "id": "13381092205432192534",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417422024150",
      "title": "SafeFac: Video-based smart safety monitoring for preventing industrial work accidents",
      "authors": "J Ahn, JY Park, SS Lee, KH Lee, H Do, JG Ko",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13381092205432192534&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "SegLoc: Learning Segmentation-Based Representations for Privacy-Preserving Visual Localization",
      "id": "14213127820813811957",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Pietrantoni_SegLoc_Learning_Segmentation-Based_Representations_for_Privacy-Preserving_Visual_Localization_CVPR_2023_paper.html",
      "title": "SegLoc: Learning Segmentation-Based Representations for Privacy-Preserving Visual Localization",
      "authors": "M Pietrantoni, M Humenberger\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14213127820813811957&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "RGB-D datasets for robotic perception in site-specific agricultural operations\u2014A survey",
      "id": "3527582028524441499",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169923004234",
      "title": "RGB-D datasets for robotic perception in site-specific agricultural operations\u2014A survey",
      "authors": "P Kurtser, S Lowry",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3527582028524441499&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "SegDetector: A Deep Learning Model for Detecting Small and Overlapping Damaged Buildings in Satellite Images",
      "id": "310549142066083798",
      "url": "https://www.mdpi.com/2072-4292/14/23/6136",
      "title": "SegDetector: A Deep Learning Model for Detecting Small and Overlapping Damaged Buildings in Satellite Images",
      "authors": "Z Yu, Z Chen, Z Sun, H Guo, B Leng, Z He, J Yang\u2026",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=310549142066083798&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Instruction-vit: Multi-modal prompts for instruction learning in vit",
      "id": "2795686517415303571",
      "url": "https://arxiv.org/abs/2305.00201",
      "title": "Instruction-vit: Multi-modal prompts for instruction learning in vit",
      "authors": "Z Xiao, Y Chen, L Zhang, J Yao, Z Wu, X Yu\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2795686517415303571&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Deep Learning Based Object Detection for Resource Constrained Devices-Systematic Review, Future Trends and Challenges Ahead",
      "id": "12602640083300493507",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231223001388",
      "title": "Deep Learning Based Object Detection for Resource Constrained Devices-Systematic Review, Future Trends and Challenges Ahead",
      "authors": "V Kamath, A Renuka",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12602640083300493507&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism",
      "id": "2199006774138818312",
      "url": "https://arxiv.org/abs/2301.10051",
      "title": "Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism",
      "authors": "Z Tong, Y Chen, Z Xu, R Yu",
      "year": "2023",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2199006774138818312&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Deep-worm-tracker: Deep learning methods for accurate detection and tracking for behavioral studies in C. elegans",
      "id": "1068983787928302396",
      "url": "https://www.sciencedirect.com/science/article/pii/S016815912300196X",
      "title": "Deep-worm-tracker: Deep learning methods for accurate detection and tracking for behavioral studies in C. elegans",
      "authors": "SC Banerjee, KA Khan, R Sharma",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1068983787928302396&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Study on Lightweight Model of Maize Seedling Object Detection Based on YOLOv7",
      "id": "13704777355910523310",
      "url": "https://www.mdpi.com/2076-3417/13/13/7731",
      "title": "Study on Lightweight Model of Maize Seedling Object Detection Based on YOLOv7",
      "authors": "K Zhao, L Zhao, Y Zhao, H Deng",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13704777355910523310&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "TIA-YOLOv5: An improved YOLOv5 network for real-time detection of crop and weed in the field",
      "id": "8849990741625315400",
      "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.1091655/full",
      "title": "TIA-YOLOv5: An improved YOLOv5 network for real-time detection of crop and weed in the field",
      "authors": "A Wang, T Peng, H Cao, Y Xu, X Wei\u2026",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8849990741625315400&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Deep Learning-Based Pine Nematode Trees' Identification Using Multispectral and Visible UAV Imagery",
      "id": "14014258077591706555",
      "url": "https://www.mdpi.com/2504-446X/7/3/183",
      "title": "Deep Learning-Based Pine Nematode Trees' Identification Using Multispectral and Visible UAV Imagery",
      "authors": "B Qin, F Sun, W Shen, B Dong, S Ma, X Huo, P Lan",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14014258077591706555&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A Lightweight Object Detection Algorithm for Remote Sensing Images Based on Attention Mechanism and YOLOv5s",
      "id": "10603972393777456896",
      "url": "https://www.mdpi.com/2072-4292/15/9/2429",
      "title": "A Lightweight Object Detection Algorithm for Remote Sensing Images Based on Attention Mechanism and YOLOv5s",
      "authors": "P Liu, Q Wang, H Zhang, J Mi, Y Liu",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10603972393777456896&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Predicting highly dynamic traffic noise using rotating mobile monitoring and machine learning method",
      "id": "5046561428623654374",
      "url": "https://www.sciencedirect.com/science/article/pii/S0013935123006886",
      "title": "Predicting highly dynamic traffic noise using rotating mobile monitoring and machine learning method",
      "authors": "Y Zhang, H Zhao, Y Li, Y Long, W Liang",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5046561428623654374&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Edge AI-based tree trunk detection for forestry monitoring robotics",
      "id": "3550218616048655433",
      "url": "https://www.mdpi.com/2218-6581/11/6/136",
      "title": "Edge AI-based tree trunk detection for forestry monitoring robotics",
      "authors": "DQ da Silva, FN dos Santos, V Filipe, AJ Sousa\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3550218616048655433&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Fast-Yolo-Rec: incorporating yolo-base detection and recurrent-base prediction networks for fast vehicle detection in consecutive images",
      "id": "5900725104936277094",
      "url": "https://ieeexplore.ieee.org/abstract/document/9950239/",
      "title": "Fast-Yolo-Rec: incorporating yolo-base detection and recurrent-base prediction networks for fast vehicle detection in consecutive images",
      "authors": "N Zarei, P Moallem, M Shams",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5900725104936277094&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Advanced crack detection and segmentation on bridge decks using deep learning",
      "id": "12974822052652996066",
      "url": "https://www.sciencedirect.com/science/article/pii/S0950061823025552",
      "title": "Advanced crack detection and segmentation on bridge decks using deep learning",
      "authors": "TS Tran, SD Nguyen, HJ Lee, VP Tran",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12974822052652996066&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Object Detection With Self-Supervised Scene Adaptation",
      "id": "f2PZtE-BhD0J",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Object_Detection_With_Self-Supervised_Scene_Adaptation_CVPR_2023_paper.html",
      "title": "Object Detection With Self-Supervised Scene Adaptation",
      "authors": "Z Zhang, M Hoai",
      "year": "2023",
      "modularity": 1
    },
    {
      "label": "Crowdsensing-based Road Damage Detection Challenge (CRDDC'2022)",
      "id": "2868755694884485530",
      "url": "https://ieeexplore.ieee.org/abstract/document/10021040/",
      "title": "Crowdsensing-based Road Damage Detection Challenge (CRDDC'2022)",
      "authors": "D Arya, H Maeda, SK Ghosh\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2868755694884485530&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Swin-Transformer-Based YOLOv5 for Small-Object Detection in Remote Sensing Images",
      "id": "5981499027157381733",
      "url": "https://www.mdpi.com/1424-8220/23/7/3634",
      "title": "Swin-Transformer-Based YOLOv5 for Small-Object Detection in Remote Sensing Images",
      "authors": "X Cao, Y Zhang, S Lang, Y Gong",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5981499027157381733&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Sim-YOLOv5s: A method for detecting defects on the end face of lithium battery steel shells",
      "id": "16205265336717732975",
      "url": "https://www.sciencedirect.com/science/article/pii/S1474034622002828",
      "title": "Sim-YOLOv5s: A method for detecting defects on the end face of lithium battery steel shells",
      "authors": "H Hu, Z Zhu",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16205265336717732975&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A Survey on Waste Detection and Classification Using Deep Learning",
      "id": "7572686774487370911",
      "url": "https://ieeexplore.ieee.org/abstract/document/9970346/",
      "title": "A Survey on Waste Detection and Classification Using Deep Learning",
      "authors": "H Abdu, MHM Noor",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7572686774487370911&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Skew class-balanced re-weighting for unbiased scene graph generation",
      "id": "3244016085706305630",
      "url": "https://www.mdpi.com/2504-4990/5/1/18",
      "title": "Skew class-balanced re-weighting for unbiased scene graph generation",
      "authors": "H Kang, CD Yoo",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3244016085706305630&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Yolox: Exceeding yolo series in 2021",
      "id": "11531242419091815801",
      "url": "https://arxiv.org/abs/2107.08430",
      "title": "Yolox: Exceeding yolo series in 2021",
      "authors": "Z Ge, S Liu, F Wang, Z Li, J Sun",
      "year": "2021",
      "cited_by": 2281,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11531242419091815801&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "TPH-YOLOv5: Improved YOLOv5 based on transformer prediction head for object detection on drone-captured scenarios",
      "id": "18210588638302847093",
      "url": "https://openaccess.thecvf.com/content/ICCV2021W/VisDrone/html/Zhu_TPH-YOLOv5_Improved_YOLOv5_Based_on_Transformer_Prediction_Head_for_Object_ICCVW_2021_paper.html",
      "title": "TPH-YOLOv5: Improved YOLOv5 based on transformer prediction head for object detection on drone-captured scenarios",
      "authors": "X Zhu, S Lyu, X Wang, Q Zhao",
      "year": "2021",
      "cited_by": 683,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18210588638302847093&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Diffusiondet: Diffusion model for object detection",
      "id": "11452477192554017570",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Chen_DiffusionDet_Diffusion_Model_for_Object_Detection_ICCV_2023_paper.html",
      "title": "Diffusiondet: Diffusion model for object detection",
      "authors": "S Chen, P Sun, Y Song, P Luo",
      "year": "2023",
      "cited_by": 90,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11452477192554017570&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Dino: Detr with improved denoising anchor boxes for end-to-end object detection",
      "id": "7039269942427062691",
      "url": "https://arxiv.org/abs/2203.03605",
      "title": "Dino: Detr with improved denoising anchor boxes for end-to-end object detection",
      "authors": "H Zhang, F Li, S Liu, L Zhang, H Su, J Zhu\u2026",
      "year": "2022",
      "cited_by": 361,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7039269942427062691&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Comparing YOLOv3, YOLOv4 and YOLOv5 for autonomous landing spot detection in faulty UAVs",
      "id": "4488471448867589825",
      "url": "https://www.mdpi.com/1424-8220/22/2/464",
      "title": "Comparing YOLOv3, YOLOv4 and YOLOv5 for autonomous landing spot detection in faulty UAVs",
      "authors": "U Nepal, H Eslamiat",
      "year": "2022",
      "cited_by": 271,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4488471448867589825&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Key technologies of machine vision for weeding robots: A review and benchmark",
      "id": "5295462520886771746",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922001971",
      "title": "Key technologies of machine vision for weeding robots: A review and benchmark",
      "authors": "Y Li, Z Guo, F Shuang, M Zhang, X Li",
      "year": "2022",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5295462520886771746&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Observation-centric sort: Rethinking sort for robust multi-object tracking",
      "id": "2093389731615411975",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Cao_Observation-Centric_SORT_Rethinking_SORT_for_Robust_Multi-Object_Tracking_CVPR_2023_paper.html",
      "title": "Observation-centric sort: Rethinking sort for robust multi-object tracking",
      "authors": "J Cao, J Pang, X Weng\u2026",
      "year": "2023",
      "cited_by": 142,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2093389731615411975&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Deep learning methods for object detection in smart manufacturing: A survey",
      "id": "11789051068432887660",
      "url": "https://www.sciencedirect.com/science/article/pii/S0278612522001066",
      "title": "Deep learning methods for object detection in smart manufacturing: A survey",
      "authors": "HM Ahmad, A Rahimi",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11789051068432887660&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Dab-detr: Dynamic anchor boxes are better queries for detr",
      "id": "11838073149065061192",
      "url": "https://arxiv.org/abs/2201.12329",
      "title": "Dab-detr: Dynamic anchor boxes are better queries for detr",
      "authors": "S Liu, F Li, H Zhang, X Yang, X Qi, H Su, J Zhu\u2026",
      "year": "2022",
      "cited_by": 266,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11838073149065061192&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Focal and global knowledge distillation for detectors",
      "id": "14151291256828319904",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yang_Focal_and_Global_Knowledge_Distillation_for_Detectors_CVPR_2022_paper.html",
      "title": "Focal and global knowledge distillation for detectors",
      "authors": "Z Yang, Z Li, X Jiang, Y Gong, Z Yuan\u2026",
      "year": "2022",
      "cited_by": 116,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14151291256828319904&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "In defense of online models for video instance segmentation",
      "id": "16069829188377130053",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19815-1_34",
      "title": "In defense of online models for video instance segmentation",
      "authors": "J Wu, Q Liu, Y Jiang, S Bai, A Yuille, X Bai",
      "year": "2022",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16069829188377130053&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Towards grand unification of object tracking",
      "id": "14300935760162828522",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19803-8_43",
      "title": "Towards grand unification of object tracking",
      "authors": "B Yan, Y Jiang, P Sun, D Wang, Z Yuan, P Luo\u2026",
      "year": "2022",
      "cited_by": 72,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14300935760162828522&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Group detr: Fast detr training with group-wise one-to-many assignment",
      "id": "7664894228759942842",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Chen_Group_DETR_Fast_DETR_Training_with_Group-Wise_One-to-Many_Assignment_ICCV_2023_paper.html",
      "title": "Group detr: Fast detr training with group-wise one-to-many assignment",
      "authors": "Q Chen, X Chen, J Wang, S Zhang\u2026",
      "year": "2023",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7664894228759942842&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Strongsort: Make deepsort great again",
      "id": "14167857935364818481",
      "url": "https://ieeexplore.ieee.org/abstract/document/10032656/",
      "title": "Strongsort: Make deepsort great again",
      "authors": "Y Du, Z Zhao, Y Song, Y Zhao, F Su\u2026",
      "year": "2023",
      "cited_by": 150,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14167857935364818481&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Alphapose: Whole-body regional multi-person pose estimation and tracking in real-time",
      "id": "13684672788136223420",
      "url": "https://ieeexplore.ieee.org/abstract/document/9954214/",
      "title": "Alphapose: Whole-body regional multi-person pose estimation and tracking in real-time",
      "authors": "HS Fang, J Li, H Tang, C Xu, H Zhu\u2026",
      "year": "2022",
      "cited_by": 89,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13684672788136223420&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Memot: Multi-object tracking with memory",
      "id": "5598971766222052345",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Cai_MeMOT_Multi-Object_Tracking_With_Memory_CVPR_2022_paper.html",
      "title": "Memot: Multi-object tracking with memory",
      "authors": "J Cai, M Xu, W Li, Y Xiong, W Xia\u2026",
      "year": "2022",
      "cited_by": 63,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5598971766222052345&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Dancetrack: Multi-object tracking in uniform appearance and diverse motion",
      "id": "9529319158101525799",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Sun_DanceTrack_Multi-Object_Tracking_in_Uniform_Appearance_and_Diverse_Motion_CVPR_2022_paper.html",
      "title": "Dancetrack: Multi-object tracking in uniform appearance and diverse motion",
      "authors": "P Sun, J Cao, Y Jiang, Z Yuan, S Bai\u2026",
      "year": "2022",
      "cited_by": 72,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9529319158101525799&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "YOLOv5-Tassel: Detecting tassels in RGB UAV imagery with improved YOLOv5 based on transfer learning",
      "id": "7104781172538541114",
      "url": "https://ieeexplore.ieee.org/abstract/document/9889182/",
      "title": "YOLOv5-Tassel: Detecting tassels in RGB UAV imagery with improved YOLOv5 based on transfer learning",
      "authors": "W Liu, K Quijano, MM Crawford",
      "year": "2022",
      "cited_by": 121,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7104781172538541114&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Cbnet: A composite backbone network architecture for object detection",
      "id": "3501401895928296969",
      "url": "https://ieeexplore.ieee.org/abstract/document/9932281/",
      "title": "Cbnet: A composite backbone network architecture for object detection",
      "authors": "T Liang, X Chu, Y Liu, Y Wang, Z Tang\u2026",
      "year": "2022",
      "cited_by": 119,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3501401895928296969&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Equalized focal loss for dense long-tailed object detection",
      "id": "3753161556540928995",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_Equalized_Focal_Loss_for_Dense_Long-Tailed_Object_Detection_CVPR_2022_paper.html",
      "title": "Equalized focal loss for dense long-tailed object detection",
      "authors": "B Li, Y Yao, J Tan, G Zhang, F Yu\u2026",
      "year": "2022",
      "cited_by": 55,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3753161556540928995&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Msft-yolo: Improved yolov5 based on transformer for detecting defects of steel surface",
      "id": "4241401890946035983",
      "url": "https://www.mdpi.com/1424-8220/22/9/3467",
      "title": "Msft-yolo: Improved yolov5 based on transformer for detecting defects of steel surface",
      "authors": "Z Guo, C Wang, G Yang, Z Huang, G Li",
      "year": "2022",
      "cited_by": 70,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4241401890946035983&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Tracking objects as pixel-wise distributions",
      "id": "10239175441885037567",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20047-2_5",
      "title": "Tracking objects as pixel-wise distributions",
      "authors": "Z Zhao, Z Wu, Y Zhuang, B Li, J Jia",
      "year": "2022",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10239175441885037567&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Clrnet: Cross layer refinement network for lane detection",
      "id": "11442601300141569813",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zheng_CLRNet_Cross_Layer_Refinement_Network_for_Lane_Detection_CVPR_2022_paper.html",
      "title": "Clrnet: Cross layer refinement network for lane detection",
      "authors": "T Zheng, Y Huang, Y Liu, W Tang\u2026",
      "year": "2022",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11442601300141569813&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "PP-YOLOE: An evolved version of YOLO",
      "id": "12358278621343852999",
      "url": "https://arxiv.org/abs/2203.16250",
      "title": "PP-YOLOE: An evolved version of YOLO",
      "authors": "S Xu, X Wang, W Lv, Q Chang, C Cui, K Deng\u2026",
      "year": "2022",
      "cited_by": 89,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12358278621343852999&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Motrv2: Bootstrapping end-to-end multi-object tracking by pretrained object detectors",
      "id": "14575314968965851624",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_MOTRv2_Bootstrapping_End-to-End_Multi-Object_Tracking_by_Pretrained_Object_Detectors_CVPR_2023_paper.html",
      "title": "Motrv2: Bootstrapping end-to-end multi-object tracking by pretrained object detectors",
      "authors": "Y Zhang, T Wang, X Zhang",
      "year": "2023",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14575314968965851624&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Fast forest fire smoke detection using MVMNet",
      "id": "8851003302500796244",
      "url": "https://www.sciencedirect.com/science/article/pii/S0950705122000612",
      "title": "Fast forest fire smoke detection using MVMNet",
      "authors": "Y Hu, J Zhan, G Zhou, A Chen, W Cai, K Guo\u2026",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8851003302500796244&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Extendable multiple nodes recurrent tracking framework with RTU++",
      "id": "10246639746398567269",
      "url": "https://ieeexplore.ieee.org/abstract/document/9841421/",
      "title": "Extendable multiple nodes recurrent tracking framework with RTU++",
      "authors": "S Wang, H Sheng, D Yang, Y Zhang\u2026",
      "year": "2022",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10246639746398567269&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Qdtrack: Quasi-dense similarity learning for appearance-only multiple object tracking",
      "id": "9808171637715574951",
      "url": "https://ieeexplore.ieee.org/abstract/document/10209207/",
      "title": "Qdtrack: Quasi-dense similarity learning for appearance-only multiple object tracking",
      "authors": "T Fischer, TE Huang, J Pang, L Qiu\u2026",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9808171637715574951&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "BoT-SORT: Robust associations multi-pedestrian tracking",
      "id": "3318911338829069796",
      "url": "https://arxiv.org/abs/2206.14651",
      "title": "BoT-SORT: Robust associations multi-pedestrian tracking",
      "authors": "N Aharon, R Orfaig, BZ Bobrovsky",
      "year": "2022",
      "cited_by": 91,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3318911338829069796&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Real-time object detection for streaming perception",
      "id": "10139464426827633103",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yang_Real-Time_Object_Detection_for_Streaming_Perception_CVPR_2022_paper.html",
      "title": "Real-time object detection for streaming perception",
      "authors": "J Yang, S Liu, Z Li, X Li, J Sun",
      "year": "2022",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10139464426827633103&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "PP-PicoDet: A better real-time object detector on mobile devices",
      "id": "5177357115845082072",
      "url": "https://arxiv.org/abs/2111.00902",
      "title": "PP-PicoDet: A better real-time object detector on mobile devices",
      "authors": "G Yu, Q Chang, W Lv, C Xu, C Cui, W Ji\u2026",
      "year": "2021",
      "cited_by": 72,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5177357115845082072&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Yolo-pose: Enhancing yolo for multi person pose estimation using object keypoint similarity loss",
      "id": "503273143199070187",
      "url": "http://openaccess.thecvf.com/content/CVPR2022W/ECV/html/Maji_YOLO-Pose_Enhancing_YOLO_for_Multi_Person_Pose_Estimation_Using_Object_CVPRW_2022_paper.html",
      "title": "Yolo-pose: Enhancing yolo for multi person pose estimation using object keypoint similarity loss",
      "authors": "D Maji, S Nagori, M Mathew\u2026",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=503273143199070187&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Universal instance perception as object discovery and retrieval",
      "id": "17928092202816562244",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Yan_Universal_Instance_Perception_As_Object_Discovery_and_Retrieval_CVPR_2023_paper.html",
      "title": "Universal instance perception as object discovery and retrieval",
      "authors": "B Yan, Y Jiang, J Wu, D Wang, P Luo\u2026",
      "year": "2023",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17928092202816562244&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Simple multi-dataset detection",
      "id": "17207953557216789132",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Simple_Multi-Dataset_Detection_CVPR_2022_paper.html",
      "title": "Simple multi-dataset detection",
      "authors": "X Zhou, V Koltun, P Kr\u00e4henb\u00fchl",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17207953557216789132&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "High-accuracy detection of maize leaf diseases CNN based on multi-pathway activation function module",
      "id": "1858398396401784628",
      "url": "https://www.mdpi.com/2072-4292/13/21/4218",
      "title": "High-accuracy detection of maize leaf diseases CNN based on multi-pathway activation function module",
      "authors": "Y Zhang, S Wa, Y Liu, X Zhou, P Sun, Q Ma",
      "year": "2021",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1858398396401784628&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Soccernet-tracking: Multiple object tracking dataset and benchmark in soccer videos",
      "id": "12280368052734223898",
      "url": "http://openaccess.thecvf.com/content/CVPR2022W/CVSports/html/Cioppa_SoccerNet-Tracking_Multiple_Object_Tracking_Dataset_and_Benchmark_in_Soccer_Videos_CVPRW_2022_paper.html",
      "title": "Soccernet-tracking: Multiple object tracking dataset and benchmark in soccer videos",
      "authors": "A Cioppa, S Giancola, A Deliege\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12280368052734223898&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Surface defect detection of steel strips based on improved YOLOv4",
      "id": "5901510358391583323",
      "url": "https://www.sciencedirect.com/science/article/pii/S0045790622004499",
      "title": "Surface defect detection of steel strips based on improved YOLOv4",
      "authors": "M Li, H Wang, Z Wan",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5901510358391583323&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Autoalignv2: Deformable feature aggregation for dynamic multi-modal 3d object detection",
      "id": "7280187709203663599",
      "url": "https://arxiv.org/abs/2207.10316",
      "title": "Autoalignv2: Deformable feature aggregation for dynamic multi-modal 3d object detection",
      "authors": "Z Chen, Z Li, S Zhang, L Fang, Q Jiang\u2026",
      "year": "2022",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7280187709203663599&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "TRACE: 5D temporal regression of avatars with dynamic cameras in 3D environments",
      "id": "8918294861982063782",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Sun_TRACE_5D_Temporal_Regression_of_Avatars_With_Dynamic_Cameras_in_CVPR_2023_paper.html",
      "title": "TRACE: 5D temporal regression of avatars with dynamic cameras in 3D environments",
      "authors": "Y Sun, Q Bao, W Liu, T Mei\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8918294861982063782&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Regioncl: exploring contrastive region pairs for self-supervised representation learning",
      "id": "9002295544688722648",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19827-4_28",
      "title": "Regioncl: exploring contrastive region pairs for self-supervised representation learning",
      "authors": "Y Xu, Q Zhang, J Zhang, D Tao",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9002295544688722648&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "ECAP-YOLO: Efficient channel attention pyramid YOLO for small object detection in aerial image",
      "id": "4172110649540745529",
      "url": "https://www.mdpi.com/2072-4292/13/23/4851",
      "title": "ECAP-YOLO: Efficient channel attention pyramid YOLO for small object detection in aerial image",
      "authors": "M Kim, J Jeong, S Kim",
      "year": "2021",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4172110649540745529&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Fully convolutional one-stage 3d object detection on lidar range images",
      "id": "1182214878703167432",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/e1f418450107c4a0ddc16d008d131573-Abstract-Conference.html",
      "title": "Fully convolutional one-stage 3d object detection on lidar range images",
      "authors": "Z Tian, X Chu, X Wang, X Wei\u2026",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1182214878703167432&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Efficientvit: Enhanced linear attention for high-resolution low-computation visual recognition",
      "id": "5085325784414234300",
      "url": "https://arxiv.org/abs/2205.14756",
      "title": "Efficientvit: Enhanced linear attention for high-resolution low-computation visual recognition",
      "authors": "H Cai, C Gan, S Han",
      "year": "2022",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5085325784414234300&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Bop challenge 2022 on detection, segmentation and pose estimation of specific rigid objects",
      "id": "8537681662983932237",
      "url": "https://openaccess.thecvf.com/content/CVPR2023W/CV4MR/html/Sundermeyer_BOP_Challenge_2022_on_Detection_Segmentation_and_Pose_Estimation_of_CVPRW_2023_paper.html",
      "title": "Bop challenge 2022 on detection, segmentation and pose estimation of specific rigid objects",
      "authors": "M Sundermeyer, T Hoda\u0148, Y Labbe\u2026",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8537681662983932237&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Improved ship detection algorithm based on YOLOX for SAR outline enhancement image",
      "id": "1803748338102694409",
      "url": "https://www.mdpi.com/2072-4292/14/16/4070",
      "title": "Improved ship detection algorithm based on YOLOX for SAR outline enhancement image",
      "authors": "S Li, X Fu, J Dong",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1803748338102694409&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Active teacher for semi-supervised object detection",
      "id": "16254437278639517990",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Mi_Active_Teacher_for_Semi-Supervised_Object_Detection_CVPR_2022_paper.html",
      "title": "Active teacher for semi-supervised object detection",
      "authors": "P Mi, J Lin, Y Zhou, Y Shen, G Luo\u2026",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16254437278639517990&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "A real-time apple targets detection method for picking robot based on ShufflenetV2-YOLOX",
      "id": "9097004020017827588",
      "url": "https://www.mdpi.com/2077-0472/12/6/856",
      "title": "A real-time apple targets detection method for picking robot based on ShufflenetV2-YOLOX",
      "authors": "W Ji, Y Pan, B Xu, J Wang",
      "year": "2022",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9097004020017827588&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "No more strided convolutions or pooling: A new CNN building block for low-resolution images and small objects",
      "id": "12877767864993853066",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-26409-2_27",
      "title": "No more strided convolutions or pooling: A new CNN building block for low-resolution images and small objects",
      "authors": "R Sunkara, T Luo",
      "year": "2022",
      "cited_by": 58,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12877767864993853066&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Automated bridge surface crack detection and segmentation using computer vision-based deep learning model",
      "id": "2089165535494063327",
      "url": "https://www.sciencedirect.com/science/article/pii/S0952197622003050",
      "title": "Automated bridge surface crack detection and segmentation using computer vision-based deep learning model",
      "authors": "J Zhang, S Qian, C Tan",
      "year": "2022",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2089165535494063327&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Vision-based anti-uav detection and tracking",
      "id": "3119590478708025935",
      "url": "https://ieeexplore.ieee.org/abstract/document/9785379/",
      "title": "Vision-based anti-uav detection and tracking",
      "authors": "J Zhao, J Zhang, D Li, D Wang",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3119590478708025935&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Pear defect detection method based on resnet and dcgan",
      "id": "679650553160689765",
      "url": "https://www.mdpi.com/2078-2489/12/10/397",
      "title": "Pear defect detection method based on resnet and dcgan",
      "authors": "Y Zhang, S Wa, P Sun, Y Wang",
      "year": "2021",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=679650553160689765&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "{RECL}: Responsive {Resource-Efficient} Continuous Learning for Video Analytics",
      "id": "1907607333359949293",
      "url": "https://www.usenix.org/conference/nsdi23/presentation/khani",
      "title": "{RECL}: Responsive {Resource-Efficient} Continuous Learning for Video Analytics",
      "authors": "M Khani, G Ananthanarayanan, K Hsieh\u2026",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1907607333359949293&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "SwinGD: A robust grape bunch detection model based on swin transformer in complex vineyard environment",
      "id": "18256102101708736597",
      "url": "https://www.mdpi.com/2311-7524/7/11/492",
      "title": "SwinGD: A robust grape bunch detection model based on swin transformer in complex vineyard environment",
      "authors": "J Wang, Z Zhang, L Luo, W Zhu, J Chen, W Wang",
      "year": "2021",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18256102101708736597&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "An improved apple object detection method based on lightweight YOLOv4 in complex backgrounds",
      "id": "9917302194767651380",
      "url": "https://www.mdpi.com/2072-4292/14/17/4150",
      "title": "An improved apple object detection method based on lightweight YOLOv4 in complex backgrounds",
      "authors": "C Zhang, F Kang, Y Wang",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9917302194767651380&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Mum: Mix image tiles and unmix feature tiles for semi-supervised object detection",
      "id": "7439091361445822478",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Kim_MUM_Mix_Image_Tiles_and_UnMix_Feature_Tiles_for_Semi-Supervised_CVPR_2022_paper.html",
      "title": "Mum: Mix image tiles and unmix feature tiles for semi-supervised object detection",
      "authors": "JM Kim, JY Jang, S Seo, J Jeong\u2026",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7439091361445822478&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Intelligent edge-enabled efficient multi-source data fusion for autonomous surface vehicles in maritime internet of things",
      "id": "13668398880115037252",
      "url": "https://ieeexplore.ieee.org/abstract/document/9731523/",
      "title": "Intelligent edge-enabled efficient multi-source data fusion for autonomous surface vehicles in maritime internet of things",
      "authors": "RW Liu, Y Guo, J Nie, Q Hu, Z Xiong\u2026",
      "year": "2022",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13668398880115037252&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Adversarially-aware robust object detector",
      "id": "9399655475680081198",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_18",
      "title": "Adversarially-aware robust object detector",
      "authors": "Z Dong, P Wei, L Lin",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9399655475680081198&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Low-cost mobile mapping system solution for traffic sign segmentation using Azure Kinect",
      "id": "3905038671402584496",
      "url": "https://www.sciencedirect.com/science/article/pii/S1569843222000978",
      "title": "Low-cost mobile mapping system solution for traffic sign segmentation using Azure Kinect",
      "authors": "Z Qiu, J Mart\u00ednez-S\u00e1nchez, VM Brea, P L\u00f3pez\u2026",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3905038671402584496&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Semi-DETR: Semi-Supervised Object Detection With Detection Transformers",
      "id": "4526443549077206496",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Semi-DETR_Semi-Supervised_Object_Detection_With_Detection_Transformers_CVPR_2023_paper.html",
      "title": "Semi-DETR: Semi-Supervised Object Detection With Detection Transformers",
      "authors": "J Zhang, X Lin, W Zhang, K Wang\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4526443549077206496&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Yolov: Making still image object detectors great at video object detection",
      "id": "7753649110726260014",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25320",
      "title": "Yolov: Making still image object detectors great at video object detection",
      "authors": "Y Shi, N Wang, X Guo",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7753649110726260014&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Improved Mask R-CNN for obstacle detection of rail transit",
      "id": "48995825530336826",
      "url": "https://www.sciencedirect.com/science/article/pii/S026322412200032X",
      "title": "Improved Mask R-CNN for obstacle detection of rail transit",
      "authors": "D He, Y Qiu, J Miao, Z Zou, K Li, C Ren, G Shen",
      "year": "2022",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=48995825530336826&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Cross-modality attentive feature fusion for object detection in multispectral remote sensing imagery",
      "id": "16929187721477555329",
      "url": "https://www.sciencedirect.com/science/article/pii/S0031320322002679",
      "title": "Cross-modality attentive feature fusion for object detection in multispectral remote sensing imagery",
      "authors": "F Qingyun, W Zhaokui",
      "year": "2022",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16929187721477555329&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Centralized feature pyramid for object detection",
      "id": "13672856354810391005",
      "url": "https://ieeexplore.ieee.org/abstract/document/10194544/",
      "title": "Centralized feature pyramid for object detection",
      "authors": "Y Quan, D Zhang, L Zhang\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13672856354810391005&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "You should look at all objects",
      "id": "7436725887660345544",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_20",
      "title": "You should look at all objects",
      "authors": "Z Jin, D Yu, L Song, Z Yuan, L Yu",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7436725887660345544&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Normalizing flows for human pose anomaly detection",
      "id": "8487537285655290697",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Hirschorn_Normalizing_Flows_for_Human_Pose_Anomaly_Detection_ICCV_2023_paper.html",
      "title": "Normalizing flows for human pose anomaly detection",
      "authors": "O Hirschorn, S Avidan",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8487537285655290697&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "TransVCL: attention-enhanced video copy localization network with flexible supervision",
      "id": "5327297247516466432",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25158",
      "title": "TransVCL: attention-enhanced video copy localization network with flexible supervision",
      "authors": "S He, Y He, M Lu, C Jiang, X Yang, F Qian\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5327297247516466432&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "A lightweight position-enhanced anchor-free algorithm for SAR ship detection",
      "id": "1845681316412466465",
      "url": "https://www.mdpi.com/2072-4292/14/8/1908",
      "title": "A lightweight position-enhanced anchor-free algorithm for SAR ship detection",
      "authors": "Y Feng, J Chen, Z Huang, H Wan, R Xia, B Wu, L Sun\u2026",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1845681316412466465&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "TraCon: A novel dataset for real-time traffic cones detection using deep learning",
      "id": "15573361464256666532",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-17601-2_37",
      "title": "TraCon: A novel dataset for real-time traffic cones detection using deep learning",
      "authors": "I Katsamenis, EE Karolou, A Davradou\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15573361464256666532&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "UTM: A Unified Multiple Object Tracking Model With Identity-Aware Feature Enhancement",
      "id": "1380225769636433327",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/You_UTM_A_Unified_Multiple_Object_Tracking_Model_With_Identity-Aware_Feature_CVPR_2023_paper.html",
      "title": "UTM: A Unified Multiple Object Tracking Model With Identity-Aware Feature Enhancement",
      "authors": "S You, H Yao, BK Bao, C Xu",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1380225769636433327&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Hard to track objects with irregular motions and similar appearances? make it easier by buffering the matching space",
      "id": "17206319611652371856",
      "url": "https://openaccess.thecvf.com/content/WACV2023/html/Yang_Hard_To_Track_Objects_With_Irregular_Motions_and_Similar_Appearances_WACV_2023_paper.html",
      "title": "Hard to track objects with irregular motions and similar appearances? make it easier by buffering the matching space",
      "authors": "F Yang, S Odashima, S Masui\u2026",
      "year": "2023",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17206319611652371856&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Lightweight detection algorithm of kiwifruit based on improved YOLOX-s",
      "id": "410585140321607722",
      "url": "https://www.mdpi.com/2077-0472/12/7/993",
      "title": "Lightweight detection algorithm of kiwifruit based on improved YOLOX-s",
      "authors": "J Zhou, W Hu, A Zou, S Zhai, T Liu, W Yang, P Jiang",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=410585140321607722&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "A vision-based detection and spatial localization scheme for forest fire inspection from uav",
      "id": "2499885218349084470",
      "url": "https://www.mdpi.com/1999-4907/13/3/383",
      "title": "A vision-based detection and spatial localization scheme for forest fire inspection from uav",
      "authors": "K Lu, R Xu, J Li, Y Lv, H Lin, Y Liu",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2499885218349084470&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Improved MobileNetV2-SSDLite for automatic fabric defect detection system based on cloud-edge computing",
      "id": "15199713057680873086",
      "url": "https://www.sciencedirect.com/science/article/pii/S0263224122008739",
      "title": "Improved MobileNetV2-SSDLite for automatic fabric defect detection system based on cloud-edge computing",
      "authors": "J Zhang, J Jing, P Lu, S Song",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15199713057680873086&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "A New Approach for Detecting Fundus Lesions Using Image Processing and Deep Neural Network Architecture Based on YOLO Model",
      "id": "5063651843298506539",
      "url": "https://www.mdpi.com/1424-8220/22/17/6441",
      "title": "A New Approach for Detecting Fundus Lesions Using Image Processing and Deep Neural Network Architecture Based on YOLO Model",
      "authors": "C Santos, M Aguiar, D Welfer, B Belloni",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5063651843298506539&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Sap-detr: Bridging the gap between salient points and queries-based transformer detector for fast model convergency",
      "id": "17116877368626144169",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Liu_SAP-DETR_Bridging_the_Gap_Between_Salient_Points_and_Queries-Based_Transformer_CVPR_2023_paper.html",
      "title": "Sap-detr: Bridging the gap between salient points and queries-based transformer detector for fast model convergency",
      "authors": "Y Liu, Y Zhang, Y Wang, Y Zhang\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17116877368626144169&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "CenterNet++ for object detection",
      "id": "11206281819202318260",
      "url": "https://arxiv.org/abs/2204.08394",
      "title": "CenterNet++ for object detection",
      "authors": "K Duan, S Bai, L Xie, H Qi, Q Huang, Q Tian",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11206281819202318260&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "A review of convolutional neural network architectures and their optimizations",
      "id": "12932718969286495303",
      "url": "https://link.springer.com/article/10.1007/s10462-022-10213-5",
      "title": "A review of convolutional neural network architectures and their optimizations",
      "authors": "S Cong, Y Zhou",
      "year": "2023",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12932718969286495303&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Dense Oil Tank Detection and Classification via YOLOX-TR Network in Large-Scale SAR Images",
      "id": "3883959449895642650",
      "url": "https://www.mdpi.com/2072-4292/14/14/3246",
      "title": "Dense Oil Tank Detection and Classification via YOLOX-TR Network in Large-Scale SAR Images",
      "authors": "Q Wu, B Zhang, C Xu, H Zhang, C Wang",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3883959449895642650&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Field-matching attention network for object detection",
      "id": "1435298664216281195",
      "url": "https://www.sciencedirect.com/science/article/pii/S092523122300262X",
      "title": "Field-matching attention network for object detection",
      "authors": "Y Dong, L Shen, Y Pei, H Yang, X Li",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1435298664216281195&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "PDAM\u2013STPNNet: A small target detection approach for wildland fire smoke through remote sensing images",
      "id": "5279305686836034362",
      "url": "https://www.mdpi.com/2073-8994/13/12/2260",
      "title": "PDAM\u2013STPNNet: A small target detection approach for wildland fire smoke through remote sensing images",
      "authors": "J Zhan, Y Hu, W Cai, G Zhou, L Li",
      "year": "2021",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5279305686836034362&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Dist-YOLO: fast object detection with distance estimation",
      "id": "2900647541574704523",
      "url": "https://www.mdpi.com/2076-3417/12/3/1354",
      "title": "Dist-YOLO: fast object detection with distance estimation",
      "authors": "M Vajgl, P Hurtik, T Nejezchleba",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2900647541574704523&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Detection of river plastic using UAV sensor data and deep learning",
      "id": "9358192350302074225",
      "url": "https://www.mdpi.com/2072-4292/14/13/3049",
      "title": "Detection of river plastic using UAV sensor data and deep learning",
      "authors": "N Maharjan, H Miyazaki, BM Pati, MN Dailey\u2026",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9358192350302074225&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "RegionCL: Can simple region swapping contribute to contrastive learning?",
      "id": "7333075876299418187",
      "url": "https://arxiv.org/abs/2111.12309",
      "title": "RegionCL: Can simple region swapping contribute to contrastive learning?",
      "authors": "Y Xu, Q Zhang, J Zhang, D Tao",
      "year": "2021",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7333075876299418187&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Pcbnet: A lightweight convolutional neural network for defect inspection in surface mount technology",
      "id": "41036872912386481",
      "url": "https://ieeexplore.ieee.org/abstract/document/9837457/",
      "title": "Pcbnet: A lightweight convolutional neural network for defect inspection in surface mount technology",
      "authors": "H Wu, R Lei, Y Peng",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=41036872912386481&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "A domestic trash detection model based on improved YOLOX",
      "id": "3142941948497874730",
      "url": "https://www.mdpi.com/1424-8220/22/18/6974",
      "title": "A domestic trash detection model based on improved YOLOX",
      "authors": "C Liu, N Xie, X Yang, R Chen, X Chang, RY Zhong\u2026",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3142941948497874730&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Efficient one-stage video object detection by exploiting temporal consistency",
      "id": "12459243040456605693",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19833-5_1",
      "title": "Efficient one-stage video object detection by exploiting temporal consistency",
      "authors": "G Sun, Y Hua, G Hu, N Robertson",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12459243040456605693&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "YOLOv5 with convMixer prediction heads for precise object detection in drone imagery",
      "id": "6585235751137549645",
      "url": "https://www.mdpi.com/1424-8220/22/21/8424",
      "title": "YOLOv5 with convMixer prediction heads for precise object detection in drone imagery",
      "authors": "R Baidya, H Jeong",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6585235751137549645&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "A systematic review of drone based road traffic monitoring system",
      "id": "16425348670839745439",
      "url": "https://ieeexplore.ieee.org/abstract/document/9893814/",
      "title": "A systematic review of drone based road traffic monitoring system",
      "authors": "I Bisio, C Garibotto, H Haleem, F Lavagetto\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16425348670839745439&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "YOLOD: A target detection method for UAV aerial imagery",
      "id": "16435089417528679481",
      "url": "https://www.mdpi.com/2072-4292/14/14/3240",
      "title": "YOLOD: A target detection method for UAV aerial imagery",
      "authors": "X Luo, Y Wu, L Zhao",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16435089417528679481&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Fbnetv5: Neural architecture search for multiple tasks in one run",
      "id": "7917884940240812522",
      "url": "https://arxiv.org/abs/2111.10007",
      "title": "Fbnetv5: Neural architecture search for multiple tasks in one run",
      "authors": "B Wu, C Li, H Zhang, X Dai, P Zhang, M Yu\u2026",
      "year": "2021",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7917884940240812522&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Object detection in autonomous vehicles: Status and open challenges",
      "id": "14459465598979164145",
      "url": "https://arxiv.org/abs/2201.07706",
      "title": "Object detection in autonomous vehicles: Status and open challenges",
      "authors": "A Balasubramaniam, S Pasricha",
      "year": "2022",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14459465598979164145&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 15
    },
    {
      "label": "Exploring plain vision transformer backbones for object detection",
      "id": "4490918786976048296",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_17",
      "title": "Exploring plain vision transformer backbones for object detection",
      "authors": "Y Li, H Mao, R Girshick, K He",
      "year": "2022",
      "cited_by": 294,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4490918786976048296&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Transforming medical imaging with Transformers? A comparative review of key properties, current progresses, and future perspectives",
      "id": "6243645967630982889",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841523000233",
      "title": "Transforming medical imaging with Transformers? A comparative review of key properties, current progresses, and future perspectives",
      "authors": "J Li, J Chen, Y Tang, C Wang, BA Landman\u2026",
      "year": "2023",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6243645967630982889&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Adding conditional control to text-to-image diffusion models",
      "id": "9370947851501467347",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html",
      "title": "Adding conditional control to text-to-image diffusion models",
      "authors": "L Zhang, A Rao, M Agrawala",
      "year": "2023",
      "cited_by": 314,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9370947851501467347&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Segment anything",
      "id": "15741444728855576863",
      "url": "https://arxiv.org/abs/2304.02643",
      "title": "Segment anything",
      "authors": "A Kirillov, E Mintun, N Ravi, H Mao, C Rolland\u2026",
      "year": "2023",
      "cited_by": 703,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15741444728855576863&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Eva: Exploring the limits of masked visual representation learning at scale",
      "id": "10588342779298269046",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Fang_EVA_Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_CVPR_2023_paper.html",
      "title": "Eva: Exploring the limits of masked visual representation learning at scale",
      "authors": "Y Fang, W Wang, B Xie, Q Sun, L Wu\u2026",
      "year": "2023",
      "cited_by": 114,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10588342779298269046&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Internimage: Exploring large-scale vision foundation models with deformable convolutions",
      "id": "6118595289890500680",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wang_InternImage_Exploring_Large-Scale_Vision_Foundation_Models_With_Deformable_Convolutions_CVPR_2023_paper.html",
      "title": "Internimage: Exploring large-scale vision foundation models with deformable convolutions",
      "authors": "W Wang, J Dai, Z Chen, Z Huang, Z Li\u2026",
      "year": "2023",
      "cited_by": 128,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6118595289890500680&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Mixformer: End-to-end tracking with iterative mixed attention",
      "id": "17997891498068622933",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Cui_MixFormer_End-to-End_Tracking_With_Iterative_Mixed_Attention_CVPR_2022_paper.html",
      "title": "Mixformer: End-to-end tracking with iterative mixed attention",
      "authors": "Y Cui, C Jiang, L Wang, G Wu",
      "year": "2022",
      "cited_by": 170,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17997891498068622933&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Vitpose: Simple vision transformer baselines for human pose estimation",
      "id": "9439766841533136382",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/fbb10d319d44f8c3b4720873e4177c65-Abstract-Conference.html",
      "title": "Vitpose: Simple vision transformer baselines for human pose estimation",
      "authors": "Y Xu, J Zhang, Q Zhang, D Tao",
      "year": "2022",
      "cited_by": 140,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9439766841533136382&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Hornet: Efficient high-order spatial interactions with recursive gated convolutions",
      "id": "12938213222665733645",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/436d042b2dd81214d23ae43eb196b146-Abstract-Conference.html",
      "title": "Hornet: Efficient high-order spatial interactions with recursive gated convolutions",
      "authors": "Y Rao, W Zhao, Y Tang, J Zhou\u2026",
      "year": "2022",
      "cited_by": 102,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12938213222665733645&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Vision transformer adapter for dense predictions",
      "id": "14316138733173377966",
      "url": "https://arxiv.org/abs/2205.08534",
      "title": "Vision transformer adapter for dense predictions",
      "authors": "Z Chen, Y Duan, W Wang, J He, T Lu, J Dai\u2026",
      "year": "2022",
      "cited_by": 172,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14316138733173377966&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Detrs with hybrid matching",
      "id": "12550135891789567985",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Jia_DETRs_With_Hybrid_Matching_CVPR_2023_paper.html",
      "title": "Detrs with hybrid matching",
      "authors": "D Jia, Y Yuan, H He, X Wu, H Yu\u2026",
      "year": "2023",
      "cited_by": 59,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12550135891789567985&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Convmae: Masked convolution meets masked autoencoders",
      "id": "4555711365675635781",
      "url": "https://arxiv.org/abs/2205.03892",
      "title": "Convmae: Masked convolution meets masked autoencoders",
      "authors": "P Gao, T Ma, H Li, Z Lin, J Dai, Y Qiao",
      "year": "2022",
      "cited_by": 69,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4555711365675635781&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "A unified sequence interface for vision tasks",
      "id": "14680303082655356082",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/cb0f9020c00fc52a9f6c9dbfacc6ac58-Abstract-Conference.html",
      "title": "A unified sequence interface for vision tasks",
      "authors": "T Chen, S Saxena, L Li, TY Lin\u2026",
      "year": "2022",
      "cited_by": 45,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14680303082655356082&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Segment anything model for medical image analysis: an experimental study",
      "id": "640071900436442539",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841523001780",
      "title": "Segment anything model for medical image analysis: an experimental study",
      "authors": "MA Mazurowski, H Dong, H Gu, J Yang, N Konz\u2026",
      "year": "2023",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=640071900436442539&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Siamese image modeling for self-supervised vision representation learning",
      "id": "9830572971874050892",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Tao_Siamese_Image_Modeling_for_Self-Supervised_Vision_Representation_Learning_CVPR_2023_paper.html",
      "title": "Siamese image modeling for self-supervised vision representation learning",
      "authors": "C Tao, X Zhu, W Su, G Huang, B Li\u2026",
      "year": "2023",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9830572971874050892&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Detrs with collaborative hybrid assignments training",
      "id": "18387677115510147109",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.html",
      "title": "Detrs with collaborative hybrid assignments training",
      "authors": "Z Zong, G Song, Y Liu",
      "year": "2023",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18387677115510147109&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "MCMAE: Masked convolution meets masked autoencoders",
      "id": "7734774232157964979",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/e7938ede51225b490bb69f7b361a9259-Abstract-Conference.html",
      "title": "MCMAE: Masked convolution meets masked autoencoders",
      "authors": "P Gao, T Ma, H Li, Z Lin, J Dai\u2026",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7734774232157964979&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Advancing plain vision transformer toward remote sensing foundation model",
      "id": "14613261815949086918",
      "url": "https://ieeexplore.ieee.org/abstract/document/9956816/",
      "title": "Advancing plain vision transformer toward remote sensing foundation model",
      "authors": "D Wang, Q Zhang, Y Xu, J Zhang, B Du\u2026",
      "year": "2022",
      "cited_by": 47,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14613261815949086918&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Decoupling human and camera motion from videos in the wild",
      "id": "6979440938086217563",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Ye_Decoupling_Human_and_Camera_Motion_From_Videos_in_the_Wild_CVPR_2023_paper.html",
      "title": "Decoupling human and camera motion from videos in the wild",
      "authors": "V Ye, G Pavlakos, J Malik\u2026",
      "year": "2023",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6979440938086217563&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Towards all-in-one pre-training via maximizing multi-modal mutual information",
      "id": "5337226914153811562",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Su_Towards_All-in-One_Pre-Training_via_Maximizing_Multi-Modal_Mutual_Information_CVPR_2023_paper.html",
      "title": "Towards all-in-one pre-training via maximizing multi-modal mutual information",
      "authors": "W Su, X Zhu, C Tao, L Lu, B Li\u2026",
      "year": "2023",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5337226914153811562&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Vsa: Learning varied-size window attention in vision transformers",
      "id": "7134900495559356797",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19806-9_27",
      "title": "Vsa: Learning varied-size window attention in vision transformers",
      "authors": "Q Zhang, Y Xu, J Zhang, D Tao",
      "year": "2022",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7134900495559356797&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Masked autoencoders enable efficient knowledge distillers",
      "id": "5030683813836303943",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Bai_Masked_Autoencoders_Enable_Efficient_Knowledge_Distillers_CVPR_2023_paper.html",
      "title": "Masked autoencoders enable efficient knowledge distillers",
      "authors": "Y Bai, Z Wang, J Xiao, C Wei, H Wang\u2026",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5030683813836303943&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Unleashing vanilla vision transformer with masked image modeling for object detection",
      "id": "11522546362437060713",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.html",
      "title": "Unleashing vanilla vision transformer with masked image modeling for object detection",
      "authors": "Y Fang, S Yang, S Wang, Y Ge\u2026",
      "year": "2023",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11522546362437060713&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Hydra attention: Efficient attention with many heads",
      "id": "12195536569534646845",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-25082-8_3",
      "title": "Hydra attention: Efficient attention with many heads",
      "authors": "D Bolya, CY Fu, X Dai, P Zhang, J Hoffman",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12195536569534646845&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Understanding masked image modeling via learning occlusion invariant feature",
      "id": "5962552400166695847",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Kong_Understanding_Masked_Image_Modeling_via_Learning_Occlusion_Invariant_Feature_CVPR_2023_paper.html",
      "title": "Understanding masked image modeling via learning occlusion invariant feature",
      "authors": "X Kong, X Zhang",
      "year": "2023",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5962552400166695847&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Flatten transformer: Vision transformer using focused linear attention",
      "id": "14300246766552093616",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Han_FLatten_Transformer_Vision_Transformer_using_Focused_Linear_Attention_ICCV_2023_paper.html",
      "title": "Flatten transformer: Vision transformer using focused linear attention",
      "authors": "D Han, X Pan, Y Han, S Song\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14300246766552093616&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "F-vlm: Open-vocabulary object detection upon frozen vision and language models",
      "id": "8055277125890470910",
      "url": "https://arxiv.org/abs/2209.15639",
      "title": "F-vlm: Open-vocabulary object detection upon frozen vision and language models",
      "authors": "W Kuo, Y Cui, X Gu, AJ Piergiovanni\u2026",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8055277125890470910&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Vision transformers are good mask auto-labelers",
      "id": "7111056020821706590",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Lan_Vision_Transformers_Are_Good_Mask_Auto-Labelers_CVPR_2023_paper.html",
      "title": "Vision transformers are good mask auto-labelers",
      "authors": "S Lan, X Yang, Z Yu, Z Wu\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7111056020821706590&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Paco: Parts and attributes of common objects",
      "id": "1052062078621162321",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Ramanathan_PACO_Parts_and_Attributes_of_Common_Objects_CVPR_2023_paper.html",
      "title": "Paco: Parts and attributes of common objects",
      "authors": "V Ramanathan, A Kalia, V Petrovic\u2026",
      "year": "2023",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1052062078621162321&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Resformer: Scaling vits with multi-resolution training",
      "id": "7380604299331262465",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Tian_ResFormer_Scaling_ViTs_With_Multi-Resolution_Training_CVPR_2023_paper.html",
      "title": "Resformer: Scaling vits with multi-resolution training",
      "authors": "R Tian, Z Wu, Q Dai, H Hu, Y Qiao\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7380604299331262465&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Better plain ViT baselines for ImageNet-1k",
      "id": "17776221386292352341",
      "url": "https://arxiv.org/abs/2205.01580",
      "title": "Better plain ViT baselines for ImageNet-1k",
      "authors": "L Beyer, X Zhai, A Kolesnikov",
      "year": "2022",
      "cited_by": 31,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17776221386292352341&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Stare at what you see: Masked image modeling without reconstruction",
      "id": "8429597570092570925",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Xue_Stare_at_What_You_See_Masked_Image_Modeling_Without_Reconstruction_CVPR_2023_paper.html",
      "title": "Stare at what you see: Masked image modeling without reconstruction",
      "authors": "H Xue, P Gao, H Li, Y Qiao, H Sun\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8429597570092570925&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Dilated neighborhood attention transformer",
      "id": "8815839713273959723",
      "url": "https://arxiv.org/abs/2209.15001",
      "title": "Dilated neighborhood attention transformer",
      "authors": "A Hassani, H Shi",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8815839713273959723&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "BiFormer: Vision Transformer with Bi-Level Routing Attention",
      "id": "4731455256244956465",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhu_BiFormer_Vision_Transformer_With_Bi-Level_Routing_Attention_CVPR_2023_paper.html",
      "title": "BiFormer: Vision Transformer with Bi-Level Routing Attention",
      "authors": "L Zhu, X Wang, Z Ke, W Zhang\u2026",
      "year": "2023",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4731455256244956465&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Bridgetower: Building bridges between encoders in vision-language representation learning",
      "id": "8388230239628727224",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/26263",
      "title": "Bridgetower: Building bridges between encoders in vision-language representation learning",
      "authors": "X Xu, C Wu, S Rosenman, V Lal, W Che\u2026",
      "year": "2023",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8388230239628727224&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Lightvit: Towards light-weight convolution-free vision transformers",
      "id": "13876321258274905912",
      "url": "https://arxiv.org/abs/2207.05557",
      "title": "Lightvit: Towards light-weight convolution-free vision transformers",
      "authors": "T Huang, L Huang, S You, F Wang, C Qian\u2026",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13876321258274905912&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Expediting large-scale vision transformer for dense prediction without fine-tuning",
      "id": "3429308917664707403",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/e6c2e85db1f1039177c4495ccd399ac4-Abstract-Conference.html",
      "title": "Expediting large-scale vision transformer for dense prediction without fine-tuning",
      "authors": "W Liang, Y Yuan, H Ding, X Luo\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3429308917664707403&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion",
      "id": "16202141712210963294",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/16e71d1a24b98a02c17b1be1f634f979-Abstract-Conference.html",
      "title": "CroCo: Self-Supervised Pre-training for 3D Vision Tasks by Cross-View Completion",
      "authors": "P Weinzaepfel, V Leroy, T Lucas\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16202141712210963294&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Grit: A generative region-to-text transformer for object understanding",
      "id": "3360913791146424633",
      "url": "https://arxiv.org/abs/2212.00280",
      "title": "Grit: A generative region-to-text transformer for object understanding",
      "authors": "J Wu, J Wang, Z Yang, Z Gan, Z Liu, J Yuan\u2026",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3360913791146424633&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "SAM Fails to Segment Anything?--SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More",
      "id": "11213926060739194818",
      "url": "https://arxiv.org/abs/2304.09148",
      "title": "SAM Fails to Segment Anything?--SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More",
      "authors": "T Chen, L Zhu, C Ding, R Cao, S Zhang\u2026",
      "year": "2023",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11213926060739194818&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Affordance grounding from demonstration video to target image",
      "id": "352322076591852020",
      "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Affordance_Grounding_From_Demonstration_Video_To_Target_Image_CVPR_2023_paper.html",
      "title": "Affordance grounding from demonstration video to target image",
      "authors": "J Chen, D Gao, KQ Lin\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=352322076591852020&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Language adaptive weight generation for multi-task visual grounding",
      "id": "13906564416939487459",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Su_Language_Adaptive_Weight_Generation_for_Multi-Task_Visual_Grounding_CVPR_2023_paper.html",
      "title": "Language adaptive weight generation for multi-task visual grounding",
      "authors": "W Su, P Miao, H Dou, G Wang\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13906564416939487459&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Region-aware pretraining for open-vocabulary object detection with vision transformers",
      "id": "12626688018988097647",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Kim_Region-Aware_Pretraining_for_Open-Vocabulary_Object_Detection_With_Vision_Transformers_CVPR_2023_paper.html",
      "title": "Region-aware pretraining for open-vocabulary object detection with vision transformers",
      "authors": "D Kim, A Angelova, W Kuo",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12626688018988097647&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "2D and 3D object detection algorithms from images: A Survey",
      "id": "15264491751168338591",
      "url": "https://www.sciencedirect.com/science/article/pii/S2590005623000309",
      "title": "2D and 3D object detection algorithms from images: A Survey",
      "authors": "W Chen, Y Li, Z Tian, F Zhang",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15264491751168338591&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Cat: Localization and identification cascade detection transformer for open-world object detection",
      "id": "1684205177621612046",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Ma_CAT_LoCalization_and_IdentificAtion_Cascade_Detection_Transformer_for_Open-World_Object_CVPR_2023_paper.html",
      "title": "Cat: Localization and identification cascade detection transformer for open-world object detection",
      "authors": "S Ma, Y Wang, Y Wei, J Fan, TH Li\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1684205177621612046&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "A closer look at self-supervised lightweight vision transformers",
      "id": "9289927810203044884",
      "url": "https://proceedings.mlr.press/v202/wang23e.html",
      "title": "A closer look at self-supervised lightweight vision transformers",
      "authors": "S Wang, J Gao, Z Li, X Zhang\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9289927810203044884&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "The effectiveness of MAE pre-pretraining for billion-scale pretraining",
      "id": "4028732696004816605",
      "url": "https://arxiv.org/abs/2303.13496",
      "title": "The effectiveness of MAE pre-pretraining for billion-scale pretraining",
      "authors": "M Singh, Q Duval, KV Alwala, H Fan\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4028732696004816605&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "BiViT: Extremely Compressed Binary Vision Transformers",
      "id": "2922049850680781929",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/He_BiViT_Extremely_Compressed_Binary_Vision_Transformers_ICCV_2023_paper.html",
      "title": "BiViT: Extremely Compressed Binary Vision Transformers",
      "authors": "Y He, Z Lou, L Zhang, J Liu, W Wu\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2922049850680781929&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Hivit: A simpler and more efficient design of hierarchical vision transformer",
      "id": "6877116560747276387",
      "url": "https://openreview.net/forum?id=3F6I-0-57SC",
      "title": "Hivit: A simpler and more efficient design of hierarchical vision transformer",
      "authors": "X Zhang, Y Tian, L Xie, W Huang, Q Dai\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6877116560747276387&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Vitkd: Practical guidelines for vit feature knowledge distillation",
      "id": "4504943264737055020",
      "url": "https://arxiv.org/abs/2209.02432",
      "title": "Vitkd: Practical guidelines for vit feature knowledge distillation",
      "authors": "Z Yang, Z Li, A Zeng, Z Li, C Yuan, Y Li",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4504943264737055020&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Efficient self-supervised vision pretraining with local masked reconstruction",
      "id": "8057404930177375775",
      "url": "https://arxiv.org/abs/2206.00790",
      "title": "Efficient self-supervised vision pretraining with local masked reconstruction",
      "authors": "J Chen, M Hu, B Li, M Elhoseiny",
      "year": "2022",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8057404930177375775&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Eva-02: A visual representation for neon genesis",
      "id": "8100725342405011358",
      "url": "https://arxiv.org/abs/2303.11331",
      "title": "Eva-02: A visual representation for neon genesis",
      "authors": "Y Fang, Q Sun, X Wang, T Huang, X Wang\u2026",
      "year": "2023",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8100725342405011358&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Less is More: Focus Attention for Efficient DETR",
      "id": "1673777623717824835",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.html",
      "title": "Less is More: Focus Attention for Efficient DETR",
      "authors": "D Zheng, W Dong, H Hu, X Chen\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1673777623717824835&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "More than encoder: Introducing transformer decoder to upsample",
      "id": "526538470553837028",
      "url": "https://ieeexplore.ieee.org/abstract/document/9995378/",
      "title": "More than encoder: Introducing transformer decoder to upsample",
      "authors": "Y Li, W Cai, Y Gao, C Li, X Hu",
      "year": "2022",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=526538470553837028&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Group detr v2: Strong object detector with encoder-decoder pretraining",
      "id": "11594648656724394854",
      "url": "https://arxiv.org/abs/2211.03594",
      "title": "Group detr v2: Strong object detector with encoder-decoder pretraining",
      "authors": "Q Chen, J Wang, C Han, S Zhang, Z Li, X Chen\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11594648656724394854&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "UniHCP: A Unified Model for Human-Centric Perceptions",
      "id": "4578573813216045589",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Ci_UniHCP_A_Unified_Model_for_Human-Centric_Perceptions_CVPR_2023_paper.html",
      "title": "UniHCP: A Unified Model for Human-Centric Perceptions",
      "authors": "Y Ci, Y Wang, M Chen, S Tang, L Bai\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4578573813216045589&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Swin-Transformer-YOLOv5 for real-time wine grape bunch detection",
      "id": "9793040987893379450",
      "url": "https://www.mdpi.com/2072-4292/14/22/5853",
      "title": "Swin-Transformer-YOLOv5 for real-time wine grape bunch detection",
      "authors": "S Lu, X Liu, Z He, X Zhang, W Liu, M Karkee",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9793040987893379450&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Exploring long-sequence masked autoencoders",
      "id": "10898983420399357710",
      "url": "https://arxiv.org/abs/2210.07224",
      "title": "Exploring long-sequence masked autoencoders",
      "authors": "R Hu, S Debnath, S Xie, X Chen",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10898983420399357710&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "STMixer: A One-Stage Sparse Action Detector",
      "id": "11821895939908774894",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wu_STMixer_A_One-Stage_Sparse_Action_Detector_CVPR_2023_paper.html",
      "title": "STMixer: A One-Stage Sparse Action Detector",
      "authors": "T Wu, M Cao, Z Gao, G Wu\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11821895939908774894&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Good helper is around you: Attention-driven masked image modeling",
      "id": "10214171113959087100",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25269",
      "title": "Good helper is around you: Attention-driven masked image modeling",
      "authors": "Z Liu, J Gui, H Luo",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10214171113959087100&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Pidray: A large-scale x-ray benchmark for real-world prohibited item detection",
      "id": "6493028014197162041",
      "url": "https://link.springer.com/article/10.1007/s11263-023-01855-1",
      "title": "Pidray: A large-scale x-ray benchmark for real-world prohibited item detection",
      "authors": "L Zhang, L Jiang, R Ji, H Fan",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6493028014197162041&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "A domain specific knowledge extraction transformer method for multisource satellite-borne SAR images ship detection",
      "id": "14312905429445779769",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271623000515",
      "title": "A domain specific knowledge extraction transformer method for multisource satellite-borne SAR images ship detection",
      "authors": "S Zhao, Y Luo, T Zhang, W Guo, Z Zhang",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14312905429445779769&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Mvsformer: Learning robust image representations via transformers and temperature-based depth for multi-view stereo",
      "id": "4706041545647768300",
      "url": "https://arxiv.org/abs/2208.02541",
      "title": "Mvsformer: Learning robust image representations via transformers and temperature-based depth for multi-view stereo",
      "authors": "C Cao, X Ren, Y Fu",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4706041545647768300&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Streaming Video Model",
      "id": "11889722873208015946",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Streaming_Video_Model_CVPR_2023_paper.html",
      "title": "Streaming Video Model",
      "authors": "Y Zhao, C Luo, C Tang, D Chen\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11889722873208015946&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Improving CLIP Fine-tuning Performance",
      "id": "RR4ndOlcdmUJ",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Improving_CLIP_Fine-tuning_Performance_ICCV_2023_paper.html",
      "title": "Improving CLIP Fine-tuning Performance",
      "authors": "Y Wei, H Hu, Z Xie, Z Liu, Z Zhang\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Transvg++: End-to-end visual grounding with language conditioned vision transformer",
      "id": "7490603673765775284",
      "url": "https://ieeexplore.ieee.org/abstract/document/10187690/",
      "title": "Transvg++: End-to-end visual grounding with language conditioned vision transformer",
      "authors": "J Deng, Z Yang, D Liu, T Chen, W Zhou\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7490603673765775284&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks",
      "id": "117882505525518941",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wang_Image_as_a_Foreign_Language_BEiT_Pretraining_for_Vision_and_CVPR_2023_paper.html",
      "title": "Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks",
      "authors": "W Wang, H Bao, L Dong, J Bjorck\u2026",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=117882505525518941&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Castling-ViT: Compressing Self-Attention via Switching Towards Linear-Angular Attention at Vision Transformer Inference",
      "id": "16343611144020544659",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/You_Castling-ViT_Compressing_Self-Attention_via_Switching_Towards_Linear-Angular_Attention_at_Vision_CVPR_2023_paper.html",
      "title": "Castling-ViT: Compressing Self-Attention via Switching Towards Linear-Angular Attention at Vision Transformer Inference",
      "authors": "H You, Y Xiong, X Dai, B Wu, P Zhang\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16343611144020544659&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Cascade-DETR: Delving into High-Quality Universal Object Detection",
      "id": "11178483353620714191",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_Cascade-DETR_Delving_into_High-Quality_Universal_Object_Detection_ICCV_2023_paper.html",
      "title": "Cascade-DETR: Delving into High-Quality Universal Object Detection",
      "authors": "M Ye, L Ke, S Li, YW Tai, CK Tang\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection",
      "id": "vTRbp0ZWND4J",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Integrally_Migrating_Pre-trained_Transformer_Encoder-decoders_for_Visual_Object_Detection_ICCV_2023_paper.html",
      "title": "Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection",
      "authors": "F Liu, X Zhang, Z Peng, Z Guo\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer",
      "id": "17890971807751741818",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Chen_SparseViT_Revisiting_Activation_Sparsity_for_Efficient_High-Resolution_Vision_Transformer_CVPR_2023_paper.html",
      "title": "SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer",
      "authors": "X Chen, Z Liu, H Tang, L Yi\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17890971807751741818&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Mammut: A simple architecture for joint learning for multimodal tasks",
      "id": "7816124690949941974",
      "url": "https://arxiv.org/abs/2303.16839",
      "title": "Mammut: A simple architecture for joint learning for multimodal tasks",
      "authors": "W Kuo, AJ Piergiovanni, D Kim, X Luo, B Caine\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7816124690949941974&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Vision transformer with quadrangle attention",
      "id": "7897280292740363837",
      "url": "https://arxiv.org/abs/2303.15105",
      "title": "Vision transformer with quadrangle attention",
      "authors": "Q Zhang, J Zhang, Y Xu, D Tao",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7897280292740363837&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Budgeted Training for Vision Transformer",
      "id": "306282026774466293",
      "url": "https://openreview.net/forum?id=sVzBN-DlJRi",
      "title": "Budgeted Training for Vision Transformer",
      "authors": "X Pan, X Jin, Y He, S Song, G Huang",
      "year": "2022",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=306282026774466293&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Where should i spend my flops? efficiency evaluations of visual pre-training methods",
      "id": "3818577016458576609",
      "url": "https://arxiv.org/abs/2209.15589",
      "title": "Where should i spend my flops? efficiency evaluations of visual pre-training methods",
      "authors": "S Koppula, Y Li, E Shelhamer, A Jaegle\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3818577016458576609&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Contrastive Feature Masking Open-Vocabulary Vision Transformer",
      "id": "2272102423598794653",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Kim_Contrastive_Feature_Masking_Open-Vocabulary_Vision_Transformer_ICCV_2023_paper.html",
      "title": "Contrastive Feature Masking Open-Vocabulary Vision Transformer",
      "authors": "D Kim, A Angelova, W Kuo",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Self-distillation augmented masked autoencoders for histopathological image classification",
      "id": "15646051846564298047",
      "url": "https://arxiv.org/abs/2203.16983",
      "title": "Self-distillation augmented masked autoencoders for histopathological image classification",
      "authors": "Y Luo, Z Chen, S Zhou, X Gao",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15646051846564298047&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "How can objects help action recognition?",
      "id": "647200095634493159",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhou_How_Can_Objects_Help_Action_Recognition_CVPR_2023_paper.html",
      "title": "How can objects help action recognition?",
      "authors": "X Zhou, A Arnab, C Sun\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=647200095634493159&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Integrally Pre-Trained Transformer Pyramid Networks",
      "id": "8153900683485623660",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Tian_Integrally_Pre-Trained_Transformer_Pyramid_Networks_CVPR_2023_paper.html",
      "title": "Integrally Pre-Trained Transformer Pyramid Networks",
      "authors": "Y Tian, L Xie, Z Wang, L Wei, X Zhang\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8153900683485623660&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "RILS: Masked Visual Reconstruction in Language Semantic Space",
      "id": "mT3lyH5QtvIJ",
      "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Yang_RILS_Masked_Visual_Reconstruction_in_Language_Semantic_Space_CVPR_2023_paper.html",
      "title": "RILS: Masked Visual Reconstruction in Language Semantic Space",
      "authors": "S Yang, Y Ge, K Yi, D Li, Y Shan\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Vitpose+: Vision transformer foundation model for generic body pose estimation",
      "id": "15577220087848933491",
      "url": "https://arxiv.org/abs/2212.04246",
      "title": "Vitpose+: Vision transformer foundation model for generic body pose estimation",
      "authors": "Y Xu, J Zhang, Q Zhang, D Tao",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15577220087848933491&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Learning Geometric-Aware Properties in 2D Representation Using Lightweight CAD Models, or Zero Real 3D Pairs",
      "id": "cTJB_-Obg3YJ",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Arsomngern_Learning_Geometric-Aware_Properties_in_2D_Representation_Using_Lightweight_CAD_Models_CVPR_2023_paper.html",
      "title": "Learning Geometric-Aware Properties in 2D Representation Using Lightweight CAD Models, or Zero Real 3D Pairs",
      "authors": "P Arsomngern, S Nutanong\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "A billion-scale foundation model for remote sensing images",
      "id": "5523520554880035051",
      "url": "https://arxiv.org/abs/2304.05215",
      "title": "A billion-scale foundation model for remote sensing images",
      "authors": "K Cha, J Seo, T Lee",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5523520554880035051&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Cumulative Spatial Knowledge Distillation for Vision Transformers",
      "id": "7501011475036280832",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Cumulative_Spatial_Knowledge_Distillation_for_Vision_Transformers_ICCV_2023_paper.html",
      "title": "Cumulative Spatial Knowledge Distillation for Vision Transformers",
      "authors": "B Zhao, R Song, J Liang",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine Perception",
      "id": "7424513001270707708",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Aria_Digital_Twin_A_New_Benchmark_Dataset_for_Egocentric_3D_ICCV_2023_paper.html",
      "title": "Aria Digital Twin: A New Benchmark Dataset for Egocentric 3D Machine Perception",
      "authors": "X Pan, N Charron, Y Yang, S Peters\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "SparseMAE: Sparse Training Meets Masked Autoencoders",
      "id": "10014472325439300361",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SparseMAE_Sparse_Training_Meets_Masked_Autoencoders_ICCV_2023_paper.html",
      "title": "SparseMAE: Sparse Training Meets Masked Autoencoders",
      "authors": "A Zhou, Y Li, Z Qin, J Liu, J Pan\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "UnLoc: A Unified Framework for Video Localization Tasks",
      "id": "16089508268500048635",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Yan_UnLoc_A_Unified_Framework_for_Video_Localization_Tasks_ICCV_2023_paper.html",
      "title": "UnLoc: A Unified Framework for Video Localization Tasks",
      "authors": "S Yan, X Xiong, A Nagrani, A Arnab\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Improving Pixel-based MIM by Reducing Wasted Modeling Capability",
      "id": "14381170671853204535",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Liu_Improving_Pixel-based_MIM_by_Reducing_Wasted_Modeling_Capability_ICCV_2023_paper.html",
      "title": "Improving Pixel-based MIM by Reducing Wasted Modeling Capability",
      "authors": "Y Liu, S Zhang, J Chen, Z Yu\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Generic-to-Specific Distillation of Masked Autoencoders",
      "id": "7564591903506430655",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Huang_Generic-to-Specific_Distillation_of_Masked_Autoencoders_CVPR_2023_paper.html",
      "title": "Generic-to-Specific Distillation of Masked Autoencoders",
      "authors": "W Huang, Z Peng, L Dong, F Wei\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7564591903506430655&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Learning Distortion Invariant Representation for Image Restoration from A Causality Perspective",
      "id": "16928381517970009960",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Li_Learning_Distortion_Invariant_Representation_for_Image_Restoration_From_a_Causality_CVPR_2023_paper.html",
      "title": "Learning Distortion Invariant Representation for Image Restoration from A Causality Perspective",
      "authors": "X Li, B Li, X Jin, C Lan, Z Chen",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16928381517970009960&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Vision Transformer Adapters for Generalizable Multitask Learning",
      "id": "11996337183205116538",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Bhattacharjee_Vision_Transformer_Adapters_for_Generalizable_Multitask_Learning_ICCV_2023_paper.html",
      "title": "Vision Transformer Adapters for Generalizable Multitask Learning",
      "authors": "D Bhattacharjee, S S\u00fcsstrunk\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Stitchable Neural Networks",
      "id": "18182863446124159795",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Pan_Stitchable_Neural_Networks_CVPR_2023_paper.html",
      "title": "Stitchable Neural Networks",
      "authors": "Z Pan, J Cai, B Zhuang",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18182863446124159795&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "DETR Does Not Need Multi-Scale or Locality Design",
      "id": "56664849184651828",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_DETR_Does_Not_Need_Multi-Scale_or_Locality_Design_ICCV_2023_paper.html",
      "title": "DETR Does Not Need Multi-Scale or Locality Design",
      "authors": "Y Lin, Y Yuan, Z Zhang, C Li\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "End-to-end object detection with transformers",
      "id": "1672665553767281734",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58452-8_13",
      "title": "End-to-end object detection with transformers",
      "authors": "N Carion, F Massa, G Synnaeve, N Usunier\u2026",
      "year": "2020",
      "cited_by": 7987,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1672665553767281734&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Flamingo: a visual language model for few-shot learning",
      "id": "2325917221075842848",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html",
      "title": "Flamingo: a visual language model for few-shot learning",
      "authors": "JB Alayrac, J Donahue, P Luc\u2026",
      "year": "2022",
      "cited_by": 807,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2325917221075842848&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "SegFormer: Simple and efficient design for semantic segmentation with transformers",
      "id": "11165298458048562314",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/64f1f27bf1b4ec22924fd0acb550c235-Abstract.html",
      "title": "SegFormer: Simple and efficient design for semantic segmentation with transformers",
      "authors": "E Xie, W Wang, Z Yu, A Anandkumar\u2026",
      "year": "2021",
      "cited_by": 1809,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11165298458048562314&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Swinir: Image restoration using swin transformer",
      "id": "15816136068893942524",
      "url": "https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.html",
      "title": "Swinir: Image restoration using swin transformer",
      "authors": "J Liang, J Cao, G Sun, K Zhang\u2026",
      "year": "2021",
      "cited_by": 1295,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15816136068893942524&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Swin transformer: Hierarchical vision transformer using shifted windows",
      "id": "3458396398389387877",
      "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper",
      "title": "Swin transformer: Hierarchical vision transformer using shifted windows",
      "authors": "Z Liu, Y Lin, Y Cao, H Hu, Y Wei\u2026",
      "year": "2021",
      "cited_by": 10712,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3458396398389387877&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Multiscale vision transformers",
      "id": "7329647594369932315",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Fan_Multiscale_Vision_Transformers_ICCV_2021_paper.html",
      "title": "Multiscale vision transformers",
      "authors": "H Fan, B Xiong, K Mangalam, Y Li\u2026",
      "year": "2021",
      "cited_by": 1670,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7329647594369932315&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Training data-efficient image transformers & distillation through attention",
      "id": "16235705232339507184",
      "url": "https://proceedings.mlr.press/v139/touvron21a",
      "title": "Training data-efficient image transformers & distillation through attention",
      "authors": "H Touvron, M Cord, M Douze, F Massa\u2026",
      "year": "2021",
      "cited_by": 4101,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16235705232339507184&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers",
      "id": "2013933719074368496",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html",
      "title": "Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers",
      "authors": "S Zheng, J Lu, H Zhao, X Zhu, Z Luo\u2026",
      "year": "2021",
      "cited_by": 2077,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2013933719074368496&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Cvt: Introducing convolutions to vision transformers",
      "id": "11517447940529951525",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Wu_CvT_Introducing_Convolutions_to_Vision_Transformers_ICCV_2021_paper.html",
      "title": "Cvt: Introducing convolutions to vision transformers",
      "authors": "H Wu, B Xiao, N Codella, M Liu, X Dai\u2026",
      "year": "2021",
      "cited_by": 1237,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11517447940529951525&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Swin-unet: Unet-like pure transformer for medical image segmentation",
      "id": "4461602603986165987",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-25066-8_9",
      "title": "Swin-unet: Unet-like pure transformer for medical image segmentation",
      "authors": "H Cao, Y Wang, J Chen, D Jiang, X Zhang\u2026",
      "year": "2022",
      "cited_by": 1219,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4461602603986165987&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Vivit: A video vision transformer",
      "id": "1788827408361087894",
      "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Arnab_ViViT_A_Video_Vision_Transformer_ICCV_2021_paper.html?ref=https://githubhelp.com",
      "title": "Vivit: A video vision transformer",
      "authors": "A Arnab, M Dehghani, G Heigold\u2026",
      "year": "2021",
      "cited_by": 1222,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1788827408361087894&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Tokens-to-token vit: Training vision transformers from scratch on imagenet",
      "id": "3844087685498854388",
      "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Yuan_Tokens-to-Token_ViT_Training_Vision_Transformers_From_Scratch_on_ImageNet_ICCV_2021_paper.html?ref=https://githubhelp.com",
      "title": "Tokens-to-token vit: Training vision transformers from scratch on imagenet",
      "authors": "L Yuan, Y Chen, T Wang, W Yu, Y Shi\u2026",
      "year": "2021",
      "cited_by": 1397,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3844087685498854388&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Masked-attention mask transformer for universal image segmentation",
      "id": "10375739191012965737",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Masked-Attention_Mask_Transformer_for_Universal_Image_Segmentation_CVPR_2022_paper.html",
      "title": "Masked-attention mask transformer for universal image segmentation",
      "authors": "B Cheng, I Misra, AG Schwing\u2026",
      "year": "2022",
      "cited_by": 652,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10375739191012965737&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Segmenter: Transformer for semantic segmentation",
      "id": "17465500328468068642",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Strudel_Segmenter_Transformer_for_Semantic_Segmentation_ICCV_2021_paper.html",
      "title": "Segmenter: Transformer for semantic segmentation",
      "authors": "R Strudel, R Garcia, I Laptev\u2026",
      "year": "2021",
      "cited_by": 886,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17465500328468068642&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Deformable detr: Deformable transformers for end-to-end object detection",
      "id": "7911999856845003856",
      "url": "https://arxiv.org/abs/2010.04159",
      "title": "Deformable detr: Deformable transformers for end-to-end object detection",
      "authors": "X Zhu, W Su, L Lu, B Li, X Wang, J Dai",
      "year": "2020",
      "cited_by": 2795,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7911999856845003856&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Per-pixel classification is not all you need for semantic segmentation",
      "id": "8508636578765152299",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/950a4152c2b4aa3ad78bdd6b366cc179-Abstract.html",
      "title": "Per-pixel classification is not all you need for semantic segmentation",
      "authors": "B Cheng, A Schwing, A Kirillov",
      "year": "2021",
      "cited_by": 666,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8508636578765152299&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Is space-time attention all you need for video understanding?",
      "id": "6828425192739736056",
      "url": "http://proceedings.mlr.press/v139/bertasius21a/bertasius21a-supp.pdf",
      "title": "Is space-time attention all you need for video understanding?",
      "authors": "G Bertasius, H Wang, L Torresani",
      "year": "2021",
      "cited_by": 1190,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6828425192739736056&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Do vision transformers see like convolutional neural networks?",
      "id": "1018521690946850362",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/652cf38361a209088302ba2b8b7f51e0-Abstract.html",
      "title": "Do vision transformers see like convolutional neural networks?",
      "authors": "M Raghu, T Unterthiner, S Kornblith\u2026",
      "year": "2021",
      "cited_by": 535,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1018521690946850362&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Transformer in transformer",
      "id": "15154755818357511167",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/854d9fca60b4bd07f9bb215d59ef5561-Abstract.html",
      "title": "Transformer in transformer",
      "authors": "K Han, A Xiao, E Wu, J Guo, C Xu\u2026",
      "year": "2021",
      "cited_by": 931,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15154755818357511167&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Decision transformer: Reinforcement learning via sequence modeling",
      "id": "7704492432415173786",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/7f489f642a0ddb10272b5c31057f0663-Abstract.html",
      "title": "Decision transformer: Reinforcement learning via sequence modeling",
      "authors": "L Chen, K Lu, A Rajeswaran, K Lee\u2026",
      "year": "2021",
      "cited_by": 718,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7704492432415173786&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Unsupervised learning of visual features by contrasting cluster assignments",
      "id": "13209348926291080860",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html",
      "title": "Unsupervised learning of visual features by contrasting cluster assignments",
      "authors": "M Caron, I Misra, J Mairal, P Goyal\u2026",
      "year": "2020",
      "cited_by": 2695,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13209348926291080860&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Pre-trained image processing transformer",
      "id": "5512802662340022027",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Chen_Pre-Trained_Image_Processing_Transformer_CVPR_2021_paper.html",
      "title": "Pre-trained image processing transformer",
      "authors": "H Chen, Y Wang, T Guo, C Xu\u2026",
      "year": "2021",
      "cited_by": 1152,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5512802662340022027&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Visual prompt tuning",
      "id": "14421942083121350206",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19827-4_41",
      "title": "Visual prompt tuning",
      "authors": "M Jia, L Tang, BC Chen, C Cardie, S Belongie\u2026",
      "year": "2022",
      "cited_by": 405,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14421942083121350206&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Scaling vision transformers",
      "id": "13501013621324561884",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhai_Scaling_Vision_Transformers_CVPR_2022_paper.html",
      "title": "Scaling vision transformers",
      "authors": "X Zhai, A Kolesnikov, N Houlsby\u2026",
      "year": "2022",
      "cited_by": 590,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13501013621324561884&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Going deeper with image transformers",
      "id": "13810965122904729211",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Touvron_Going_Deeper_With_Image_Transformers_ICCV_2021_paper.html",
      "title": "Going deeper with image transformers",
      "authors": "H Touvron, M Cord, A Sablayrolles\u2026",
      "year": "2021",
      "cited_by": 689,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13810965122904729211&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Twins: Revisiting the design of spatial attention in vision transformers",
      "id": "5060121065165184210",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/4e0928de075538c593fbdabb0c5ef2c3-Abstract.html",
      "title": "Twins: Revisiting the design of spatial attention in vision transformers",
      "authors": "X Chu, Z Tian, Y Wang, B Zhang\u2026",
      "year": "2021",
      "cited_by": 592,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5060121065165184210&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Bottleneck transformers for visual recognition",
      "id": "15783325521916683415",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Srinivas_Bottleneck_Transformers_for_Visual_Recognition_CVPR_2021_paper.html",
      "title": "Bottleneck transformers for visual recognition",
      "authors": "A Srinivas, TY Lin, N Parmar, J Shlens\u2026",
      "year": "2021",
      "cited_by": 795,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15783325521916683415&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Transformer tracking",
      "id": "10722665686456251008",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Chen_Transformer_Tracking_CVPR_2021_paper.html",
      "title": "Transformer tracking",
      "authors": "X Chen, B Yan, J Zhu, D Wang\u2026",
      "year": "2021",
      "cited_by": 677,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10722665686456251008&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training",
      "id": "8140812159859442226",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/416f9cb3276121c42eebb86352a4354a-Abstract-Conference.html",
      "title": "Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training",
      "authors": "Z Tong, Y Song, J Wang\u2026",
      "year": "2022",
      "cited_by": 321,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8140812159859442226&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Unetr: Transformers for 3d medical image segmentation",
      "id": "4072300244718161964",
      "url": "http://openaccess.thecvf.com/content/WACV2022/html/Hatamizadeh_UNETR_Transformers_for_3D_Medical_Image_Segmentation_WACV_2022_paper.html",
      "title": "Unetr: Transformers for 3d medical image segmentation",
      "authors": "A Hatamizadeh, Y Tang, V Nath\u2026",
      "year": "2022",
      "cited_by": 756,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4072300244718161964&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Bevformer: Learning bird's-eye-view representation from multi-camera images via spatiotemporal transformers",
      "id": "5447961710166142858",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_1",
      "title": "Bevformer: Learning bird's-eye-view representation from multi-camera images via spatiotemporal transformers",
      "authors": "Z Li, W Wang, H Li, E Xie, C Sima, T Lu, Y Qiao\u2026",
      "year": "2022",
      "cited_by": 347,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5447961710166142858&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Pct: Point cloud transformer",
      "id": "12908708535020454138",
      "url": "https://link.springer.com/article/10.1007/s41095-021-0229-5",
      "title": "Pct: Point cloud transformer",
      "authors": "MH Guo, JX Cai, ZN Liu, TJ Mu, RR Martin\u2026",
      "year": "2021",
      "cited_by": 867,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12908708535020454138&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Convit: Improving vision transformers with soft convolutional inductive biases",
      "id": "817698272872287436",
      "url": "https://proceedings.mlr.press/v139/d-ascoli21a",
      "title": "Convit: Improving vision transformers with soft convolutional inductive biases",
      "authors": "S d'Ascoli, H Touvron, ML Leavitt\u2026",
      "year": "2021",
      "cited_by": 533,
      "cited_by_url": "https://scholar.google.com/scholar?cites=817698272872287436&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Perceiver: General perception with iterative attention",
      "id": "8704237515510088771",
      "url": "http://proceedings.mlr.press/v139/jaegle21a.html",
      "title": "Perceiver: General perception with iterative attention",
      "authors": "A Jaegle, F Gimeno, A Brock\u2026",
      "year": "2021",
      "cited_by": 531,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8704237515510088771&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Cswin transformer: A general vision transformer backbone with cross-shaped windows",
      "id": "4431453089685809340",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Dong_CSWin_Transformer_A_General_Vision_Transformer_Backbone_With_Cross-Shaped_Windows_CVPR_2022_paper.html",
      "title": "Cswin transformer: A general vision transformer backbone with cross-shaped windows",
      "authors": "X Dong, J Bao, D Chen, W Zhang\u2026",
      "year": "2022",
      "cited_by": 512,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4431453089685809340&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Sparse r-cnn: End-to-end object detection with learnable proposals",
      "id": "2104521862399993019",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Sun_Sparse_R-CNN_End-to-End_Object_Detection_With_Learnable_Proposals_CVPR_2021_paper.html",
      "title": "Sparse r-cnn: End-to-end object detection with learnable proposals",
      "authors": "P Sun, R Zhang, Y Jiang, T Kong\u2026",
      "year": "2021",
      "cited_by": 730,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2104521862399993019&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Conversational agents in therapeutic interventions for neurodevelopmental disorders: a survey",
      "id": "14911027486580949315",
      "url": "https://dl.acm.org/doi/abs/10.1145/3564269",
      "title": "Conversational agents in therapeutic interventions for neurodevelopmental disorders: a survey",
      "authors": "F Catania, M Spitale, F Garzotto",
      "year": "2023",
      "cited_by": 798,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14911027486580949315&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "A survey on vision transformer",
      "id": "4278610892084589339",
      "url": "https://ieeexplore.ieee.org/abstract/document/9716741/",
      "title": "A survey on vision transformer",
      "authors": "K Han, Y Wang, H Chen, X Chen, J Guo\u2026",
      "year": "2022",
      "cited_by": 724,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4278610892084589339&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "LoFTR: Detector-free local feature matching with transformers",
      "id": "3868256673952367025",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Sun_LoFTR_Detector-Free_Local_Feature_Matching_With_Transformers_CVPR_2021_paper.html",
      "title": "LoFTR: Detector-free local feature matching with transformers",
      "authors": "J Sun, Z Shen, Y Wang, H Bao\u2026",
      "year": "2021",
      "cited_by": 528,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3868256673952367025&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Mdetr-modulated detection for end-to-end multi-modal understanding",
      "id": "915917310659134030",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Kamath_MDETR_-_Modulated_Detection_for_End-to-End_Multi-Modal_Understanding_ICCV_2021_paper.html",
      "title": "Mdetr-modulated detection for end-to-end multi-modal understanding",
      "authors": "A Kamath, M Singh, Y LeCun\u2026",
      "year": "2021",
      "cited_by": 462,
      "cited_by_url": "https://scholar.google.com/scholar?cites=915917310659134030&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Grounded language-image pre-training",
      "id": "6004268348151288098",
      "url": "https://openaccess.thecvf.com/content/CVPR2022/html/Li_Grounded_Language-Image_Pre-Training_CVPR_2022_paper.html?ref=blog.roboflow.com",
      "title": "Grounded language-image pre-training",
      "authors": "LH Li, P Zhang, H Zhang, J Yang, C Li\u2026",
      "year": "2022",
      "cited_by": 332,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6004268348151288098&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text",
      "id": "7327595990658945420",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/cb3213ada48302953cb0f166464ab356-Abstract.html",
      "title": "Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text",
      "authors": "H Akbari, L Yuan, R Qian\u2026",
      "year": "2021",
      "cited_by": 412,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7327595990658945420&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Metaformer is actually what you need for vision",
      "id": "7623662567011711547",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yu_MetaFormer_Is_Actually_What_You_Need_for_Vision_CVPR_2022_paper.html",
      "title": "Metaformer is actually what you need for vision",
      "authors": "W Yu, M Luo, P Zhou, C Si, Y Zhou\u2026",
      "year": "2022",
      "cited_by": 371,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7623662567011711547&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "End-to-end video instance segmentation with transformers",
      "id": "10424310778620231784",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Wang_End-to-End_Video_Instance_Segmentation_With_Transformers_CVPR_2021_paper.html",
      "title": "End-to-end video instance segmentation with transformers",
      "authors": "Y Wang, Z Xu, X Wang, C Shen\u2026",
      "year": "2021",
      "cited_by": 584,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10424310778620231784&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "You only look one-level feature",
      "id": "8367071398417962813",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Chen_You_Only_Look_One-Level_Feature_CVPR_2021_paper.html",
      "title": "You only look one-level feature",
      "authors": "Q Chen, Y Wang, T Yang, X Zhang\u2026",
      "year": "2021",
      "cited_by": 437,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8367071398417962813&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "An end-to-end transformer model for 3d object detection",
      "id": "5445650339708387168",
      "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Misra_An_End-to-End_Transformer_Model_for_3D_Object_Detection_ICCV_2021_paper.html?ref=https://githubhelp.com",
      "title": "An end-to-end transformer model for 3d object detection",
      "authors": "I Misra, R Girdhar, A Joulin",
      "year": "2021",
      "cited_by": 302,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5445650339708387168&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Pay attention to mlps",
      "id": "8639836755629224484",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/4cc05b35c2f937c5bd9e7d41d3686fff-Abstract.html",
      "title": "Pay attention to mlps",
      "authors": "H Liu, Z Dai, D So, QV Le",
      "year": "2021",
      "cited_by": 334,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8639836755629224484&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Flava: A foundational language and vision alignment model",
      "id": "1440121271646678581",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Singh_FLAVA_A_Foundational_Language_and_Vision_Alignment_Model_CVPR_2022_paper.html",
      "title": "Flava: A foundational language and vision alignment model",
      "authors": "A Singh, R Hu, V Goswami\u2026",
      "year": "2022",
      "cited_by": 268,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1440121271646678581&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Rethinking spatial dimensions of vision transformers",
      "id": "3380151090492446607",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Heo_Rethinking_Spatial_Dimensions_of_Vision_Transformers_ICCV_2021_paper.html",
      "title": "Rethinking spatial dimensions of vision transformers",
      "authors": "B Heo, S Yun, D Han, S Chun\u2026",
      "year": "2021",
      "cited_by": 399,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3380151090492446607&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Learning spatio-temporal transformer for visual tracking",
      "id": "17454749727813031882",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Yan_Learning_Spatio-Temporal_Transformer_for_Visual_Tracking_ICCV_2021_paper.html",
      "title": "Learning spatio-temporal transformer for visual tracking",
      "authors": "B Yan, H Peng, J Fu, D Wang\u2026",
      "year": "2021",
      "cited_by": 427,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17454749727813031882&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Frozen in time: A joint video and image encoder for end-to-end retrieval",
      "id": "11808828478262249051",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Bain_Frozen_in_Time_A_Joint_Video_and_Image_Encoder_for_ICCV_2021_paper.html",
      "title": "Frozen in time: A joint video and image encoder for end-to-end retrieval",
      "authors": "M Bain, A Nagrani, G Varol\u2026",
      "year": "2021",
      "cited_by": 415,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11808828478262249051&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Trackformer: Multi-object tracking with transformers",
      "id": "11460907858590036405",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Meinhardt_TrackFormer_Multi-Object_Tracking_With_Transformers_CVPR_2022_paper.html",
      "title": "Trackformer: Multi-object tracking with transformers",
      "authors": "T Meinhardt, A Kirillov, L Leal-Taixe\u2026",
      "year": "2022",
      "cited_by": 467,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11460907858590036405&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Inception transformer",
      "id": "610621467807251926",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/94e85561a342de88b559b72c9b29f638-Abstract-Conference.html",
      "title": "Inception transformer",
      "authors": "C Si, W Yu, P Zhou, Y Zhou\u2026",
      "year": "2022",
      "cited_by": 153,
      "cited_by_url": "https://scholar.google.com/scholar?cites=610621467807251926&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Transformer meets tracker: Exploiting temporal context for robust visual tracking",
      "id": "9233219793813194550",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Wang_Transformer_Meets_Tracker_Exploiting_Temporal_Context_for_Robust_Visual_Tracking_CVPR_2021_paper.html",
      "title": "Transformer meets tracker: Exploiting temporal context for robust visual tracking",
      "authors": "N Wang, W Zhou, J Wang, H Li",
      "year": "2021",
      "cited_by": 405,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9233219793813194550&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Ego4d: Around the world in 3,000 hours of egocentric video",
      "id": "17780356579077510129",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.html",
      "title": "Ego4d: Around the world in 3,000 hours of egocentric video",
      "authors": "K Grauman, A Westbury, E Byrne\u2026",
      "year": "2022",
      "cited_by": 301,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17780356579077510129&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Cmt: Convolutional neural networks meet vision transformers",
      "id": "18216985783540724512",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Guo_CMT_Convolutional_Neural_Networks_Meet_Vision_Transformers_CVPR_2022_paper.html",
      "title": "Cmt: Convolutional neural networks meet vision transformers",
      "authors": "J Guo, K Han, H Wu, Y Tang, X Chen\u2026",
      "year": "2022",
      "cited_by": 344,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18216985783540724512&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Conditional detr for fast training convergence",
      "id": "10842331006678867208",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Meng_Conditional_DETR_for_Fast_Training_Convergence_ICCV_2021_paper.html",
      "title": "Conditional detr for fast training convergence",
      "authors": "D Meng, X Chen, Z Fan, G Zeng, H Li\u2026",
      "year": "2021",
      "cited_by": 299,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10842331006678867208&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Conformer: Local features coupling global representations for visual recognition",
      "id": "3320528631702187603",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Peng_Conformer_Local_Features_Coupling_Global_Representations_for_Visual_Recognition_ICCV_2021_paper.html",
      "title": "Conformer: Local features coupling global representations for visual recognition",
      "authors": "Z Peng, W Huang, S Gu, L Xie\u2026",
      "year": "2021",
      "cited_by": 356,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3320528631702187603&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Visual attention network",
      "id": "4773463079530656035",
      "url": "https://link.springer.com/article/10.1007/s41095-023-0364-2",
      "title": "Visual attention network",
      "authors": "MH Guo, CZ Lu, ZN Liu, MM Cheng, SM Hu",
      "year": "2023",
      "cited_by": 252,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4773463079530656035&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Petr: Position embedding transformation for multi-view 3d object detection",
      "id": "3799744009906269739",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19812-0_31",
      "title": "Petr: Position embedding transformation for multi-view 3d object detection",
      "authors": "Y Liu, T Wang, X Zhang, J Sun",
      "year": "2022",
      "cited_by": 183,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3799744009906269739&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Adabins: Depth estimation using adaptive bins",
      "id": "11112701312974631954",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Bhat_AdaBins_Depth_Estimation_Using_Adaptive_Bins_CVPR_2021_paper.html",
      "title": "Adabins: Depth estimation using adaptive bins",
      "authors": "SF Bhat, I Alhashim, P Wonka",
      "year": "2021",
      "cited_by": 483,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11112701312974631954&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Transfusion: Robust lidar-camera fusion for 3d object detection with transformers",
      "id": "12911220675230413174",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.html",
      "title": "Transfusion: Robust lidar-camera fusion for 3d object detection with transformers",
      "authors": "X Bai, Z Hu, X Zhu, Q Huang, Y Chen\u2026",
      "year": "2022",
      "cited_by": 228,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12911220675230413174&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Dynamicvit: Efficient vision transformers with dynamic token sparsification",
      "id": "14185047449981394536",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/747d3443e319a22747fbb873e8b2f9f2-Abstract.html",
      "title": "Dynamicvit: Efficient vision transformers with dynamic token sparsification",
      "authors": "Y Rao, W Zhao, B Liu, J Lu, J Zhou\u2026",
      "year": "2021",
      "cited_by": 316,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14185047449981394536&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Incorporating convolution designs into visual transformers",
      "id": "9393703958705125224",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Yuan_Incorporating_Convolution_Designs_Into_Visual_Transformers_ICCV_2021_paper.html",
      "title": "Incorporating convolution designs into visual transformers",
      "authors": "K Yuan, S Guo, Z Liu, A Zhou\u2026",
      "year": "2021",
      "cited_by": 354,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9393703958705125224&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Bevdepth: Acquisition of reliable depth for multi-view 3d object detection",
      "id": "14030709993426908081",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25233",
      "title": "Bevdepth: Acquisition of reliable depth for multi-view 3d object detection",
      "authors": "Y Li, Z Ge, G Yu, J Yang, Z Wang, Y Shi\u2026",
      "year": "2023",
      "cited_by": 162,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14030709993426908081&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "End-to-end human pose and mesh reconstruction with transformers",
      "id": "12956114412627599893",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Lin_End-to-End_Human_Pose_and_Mesh_Reconstruction_with_Transformers_CVPR_2021_paper.html",
      "title": "End-to-end human pose and mesh reconstruction with transformers",
      "authors": "K Lin, L Wang, Z Liu",
      "year": "2021",
      "cited_by": 434,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12956114412627599893&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Clip-adapter: Better vision-language models with feature adapters",
      "id": "17712252571307454824",
      "url": "https://link.springer.com/article/10.1007/s11263-023-01891-x",
      "title": "Clip-adapter: Better vision-language models with feature adapters",
      "authors": "P Gao, S Geng, R Zhang, T Ma, R Fang\u2026",
      "year": "2023",
      "cited_by": 265,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17712252571307454824&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Dn-detr: Accelerate detr training by introducing query denoising",
      "id": "9646853108847192407",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_DN-DETR_Accelerate_DETR_Training_by_Introducing_Query_DeNoising_CVPR_2022_paper.html",
      "title": "Dn-detr: Accelerate detr training by introducing query denoising",
      "authors": "F Li, H Zhang, S Liu, J Guo, LM Ni\u2026",
      "year": "2022",
      "cited_by": 227,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9646853108847192407&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Max-deeplab: End-to-end panoptic segmentation with mask transformers",
      "id": "5792560058636996973",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Wang_MaX-DeepLab_End-to-End_Panoptic_Segmentation_With_Mask_Transformers_CVPR_2021_paper.html",
      "title": "Max-deeplab: End-to-end panoptic segmentation with mask transformers",
      "authors": "H Wang, Y Zhu, H Adam, A Yuille\u2026",
      "year": "2021",
      "cited_by": 399,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5792560058636996973&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Voxel transformer for 3d object detection",
      "id": "7843478121381660661",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Mao_Voxel_Transformer_for_3D_Object_Detection_ICCV_2021_paper.html",
      "title": "Voxel transformer for 3d object detection",
      "authors": "J Mao, Y Xue, M Niu, H Bai, J Feng\u2026",
      "year": "2021",
      "cited_by": 252,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7843478121381660661&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Transformer interpretability beyond attention visualization",
      "id": "8730617665338917129",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Chefer_Transformer_Interpretability_Beyond_Attention_Visualization_CVPR_2021_paper.html",
      "title": "Transformer interpretability beyond attention visualization",
      "authors": "H Chefer, S Gur, L Wolf",
      "year": "2021",
      "cited_by": 393,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8730617665338917129&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Up-detr: Unsupervised pre-training for object detection with transformers",
      "id": "10828507269261066901",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Dai_UP-DETR_Unsupervised_Pre-Training_for_Object_Detection_With_Transformers_CVPR_2021_paper.html",
      "title": "Up-detr: Unsupervised pre-training for object detection with transformers",
      "authors": "Z Dai, B Cai, Y Lin, J Chen",
      "year": "2021",
      "cited_by": 393,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10828507269261066901&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Detr3d: 3d object detection from multi-view images via 3d-to-2d queries",
      "id": "1986765630077984342",
      "url": "https://proceedings.mlr.press/v164/wang22b.html",
      "title": "Detr3d: 3d object detection from multi-view images via 3d-to-2d queries",
      "authors": "Y Wang, VC Guizilini, T Zhang\u2026",
      "year": "2022",
      "cited_by": 286,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1986765630077984342&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Dynamic head: Unifying object detection heads with attentions",
      "id": "1319826694668830613",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Dai_Dynamic_Head_Unifying_Object_Detection_Heads_With_Attentions_CVPR_2021_paper.html",
      "title": "Dynamic head: Unifying object detection heads with attentions",
      "authors": "X Dai, Y Chen, B Xiao, D Chen, M Liu\u2026",
      "year": "2021",
      "cited_by": 282,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1319826694668830613&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Localvit: Bringing locality to vision transformers",
      "id": "4416527254888837916",
      "url": "https://arxiv.org/abs/2104.05707",
      "title": "Localvit: Bringing locality to vision transformers",
      "authors": "Y Li, K Zhang, J Cao, R Timofte, L Van Gool",
      "year": "2021",
      "cited_by": 347,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4416527254888837916&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Object-centric learning with slot attention",
      "id": "12372357504406827550",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/8511df98c02ab60aea1b2356c013bc0f-Abstract.html",
      "title": "Object-centric learning with slot attention",
      "authors": "F Locatello, D Weissenborn\u2026",
      "year": "2020",
      "cited_by": 483,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12372357504406827550&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "You only learn one representation: Unified network for multiple tasks",
      "id": "14889255110023347971",
      "url": "https://arxiv.org/abs/2105.04206",
      "title": "You only learn one representation: Unified network for multiple tasks",
      "authors": "CY Wang, IH Yeh, HYM Liao",
      "year": "2021",
      "cited_by": 377,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14889255110023347971&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Deepvit: Towards deeper vision transformer",
      "id": "8562591691593838404",
      "url": "https://arxiv.org/abs/2103.11886",
      "title": "Deepvit: Towards deeper vision transformer",
      "authors": "D Zhou, B Kang, X Jin, L Yang, X Lian, Z Jiang\u2026",
      "year": "2021",
      "cited_by": 383,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8562591691593838404&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Conditional positional encodings for vision transformers",
      "id": "17870066505440679476",
      "url": "https://arxiv.org/abs/2102.10882",
      "title": "Conditional positional encodings for vision transformers",
      "authors": "X Chu, Z Tian, B Zhang, X Wang, X Wei, H Xia\u2026",
      "year": "2021",
      "cited_by": 380,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17870066505440679476&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Mobile-former: Bridging mobilenet and transformer",
      "id": "14766365221923861675",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Chen_Mobile-Former_Bridging_MobileNet_and_Transformer_CVPR_2022_paper.html",
      "title": "Mobile-former: Bridging mobilenet and transformer",
      "authors": "Y Chen, X Dai, D Chen, M Liu\u2026",
      "year": "2022",
      "cited_by": 262,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14766365221923861675&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Pre-trained models: Past, present and future",
      "id": "966567457136989804",
      "url": "https://www.sciencedirect.com/science/article/pii/S2666651021000231",
      "title": "Pre-trained models: Past, present and future",
      "authors": "X Han, Z Zhang, N Ding, Y Gu, X Liu, Y Huo, J Qiu\u2026",
      "year": "2021",
      "cited_by": 369,
      "cited_by_url": "https://scholar.google.com/scholar?cites=966567457136989804&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Video transformer network",
      "id": "14768862339001694574",
      "url": "http://openaccess.thecvf.com/content/ICCV2021W/CVEU/html/Neimark_Video_Transformer_Network_ICCVW_2021_paper.html",
      "title": "Video transformer network",
      "authors": "D Neimark, O Bar, M Zohar\u2026",
      "year": "2021",
      "cited_by": 343,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14768862339001694574&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Remote sensing image change detection with transformers",
      "id": "3435520687143059291",
      "url": "https://ieeexplore.ieee.org/abstract/document/9491802/",
      "title": "Remote sensing image change detection with transformers",
      "authors": "H Chen, Z Qi, Z Shi",
      "year": "2021",
      "cited_by": 368,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3435520687143059291&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 16
    },
    {
      "label": "Scaled-yolov4: Scaling cross stage partial network",
      "id": "12563424232401784595",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.html?ref=",
      "title": "Scaled-yolov4: Scaling cross stage partial network",
      "authors": "CY Wang, A Bochkovskiy\u2026",
      "year": "2021",
      "cited_by": 1152,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12563424232401784595&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Review of image classification algorithms based on convolutional neural networks",
      "id": "1747429016739752835",
      "url": "https://www.mdpi.com/2072-4292/13/22/4712",
      "title": "Review of image classification algorithms based on convolutional neural networks",
      "authors": "L Chen, S Li, Q Bai, J Yang, S Jiang, Y Miao",
      "year": "2021",
      "cited_by": 164,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1747429016739752835&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "You only look at one sequence: Rethinking transformer in vision through object detection",
      "id": "8455459026871994587",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/dc912a253d1e9ba40e2c597ed2376640-Abstract.html",
      "title": "You only look at one sequence: Rethinking transformer in vision through object detection",
      "authors": "Y Fang, B Liao, X Wang, J Fang, J Qi\u2026",
      "year": "2021",
      "cited_by": 163,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8455459026871994587&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Probabilistic two-stage detection",
      "id": "1529894457156192581",
      "url": "https://arxiv.org/abs/2103.07461",
      "title": "Probabilistic two-stage detection",
      "authors": "X Zhou, V Koltun, P Kr\u00e4henb\u00fchl",
      "year": "2021",
      "cited_by": 185,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1529894457156192581&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Detection and tracking meet drones challenge",
      "id": "3460125397015656161",
      "url": "https://ieeexplore.ieee.org/abstract/document/9573394/",
      "title": "Detection and tracking meet drones challenge",
      "authors": "P Zhu, L Wen, D Du, X Bian, H Fan\u2026",
      "year": "2021",
      "cited_by": 242,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3460125397015656161&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "The 7th AI City Challenge",
      "id": "17632693958287984620",
      "url": "https://openaccess.thecvf.com/content/CVPR2023W/AICity/html/Naphade_The_7th_AI_City_Challenge_CVPRW_2023_paper.html",
      "title": "The 7th AI City Challenge",
      "authors": "M Naphade, S Wang, DC Anastasiu\u2026",
      "year": "2023",
      "cited_by": 189,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17632693958287984620&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Non-deep networks",
      "id": "12528683203894514853",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/2d52879ef2ba487445ca2e143b104c3b-Abstract-Conference.html",
      "title": "Non-deep networks",
      "authors": "A Goyal, A Bochkovskiy, J Deng\u2026",
      "year": "2022",
      "cited_by": 46,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12528683203894514853&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Deep learning-based waste detection in natural and urban environments",
      "id": "7857274260714324520",
      "url": "https://www.sciencedirect.com/science/article/pii/S0956053X21006474",
      "title": "Deep learning-based waste detection in natural and urban environments",
      "authors": "S Majchrowska, A Miko\u0142ajczyk, M Ferlin\u2026",
      "year": "2022",
      "cited_by": 65,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7857274260714324520&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Yolop: You only look once for panoptic driving perception",
      "id": "14032891689439695129",
      "url": "https://link.springer.com/article/10.1007/s11633-022-1339-y",
      "title": "Yolop: You only look once for panoptic driving perception",
      "authors": "D Wu, MW Liao, WT Zhang, XG Wang, X Bai\u2026",
      "year": "2022",
      "cited_by": 122,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14032891689439695129&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A robust real-time deep learning based automatic polyp detection system",
      "id": "14685699400456064504",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482521003139",
      "title": "A robust real-time deep learning based automatic polyp detection system",
      "authors": "I Pacal, D Karaboga",
      "year": "2021",
      "cited_by": 73,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14685699400456064504&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Lightweight underwater object detection based on yolo v4 and multi-scale attentional feature fusion",
      "id": "1836634166646364702",
      "url": "https://www.mdpi.com/2072-4292/13/22/4706",
      "title": "Lightweight underwater object detection based on yolo v4 and multi-scale attentional feature fusion",
      "authors": "M Zhang, S Xu, W Song, Q He, Q Wei",
      "year": "2021",
      "cited_by": 69,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1836634166646364702&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Detection of objects in the images: From likelihood relationships towards scalable and efficient neural networks",
      "id": "9800203968264557275",
      "url": "https://www.computeroptics.ru/eng/KO/Annot/KO46-1/460117e.html",
      "title": "Detection of objects in the images: From likelihood relationships towards scalable and efficient neural networks",
      "authors": "NA Andriyanov, VE Dementiev, AG Tashlinskii",
      "year": "2022",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9800203968264557275&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "An efficient real-time colonic polyp detection with YOLO algorithms trained by using negative samples and large datasets",
      "id": "4801397296227909937",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482521008258",
      "title": "An efficient real-time colonic polyp detection with YOLO algorithms trained by using negative samples and large datasets",
      "authors": "I Pacal, A Karaman, D Karaboga, B Akay\u2026",
      "year": "2022",
      "cited_by": 59,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4801397296227909937&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Assessment of state-of-the-art deep learning based citrus disease detection techniques using annotated optical leaf images",
      "id": "17733214079678161609",
      "url": "https://www.sciencedirect.com/science/article/pii/S016816992100675X",
      "title": "Assessment of state-of-the-art deep learning based citrus disease detection techniques using annotated optical leaf images",
      "authors": "S Dananjayan, Y Tang, J Zhuang, C Hou\u2026",
      "year": "2022",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17733214079678161609&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A novel apple fruit detection and counting methodology based on deep learning and trunk tracking in modern orchard",
      "id": "17275460023441273996",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922003179",
      "title": "A novel apple fruit detection and counting methodology based on deep learning and trunk tracking in modern orchard",
      "authors": "F Gao, W Fang, X Sun, Z Wu, G Zhao, G Li, R Li\u2026",
      "year": "2022",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17275460023441273996&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Swin-transformer-enabled YOLOv5 with attention mechanism for small object detection on satellite images",
      "id": "9099615620722636165",
      "url": "https://www.mdpi.com/2072-4292/14/12/2861",
      "title": "Swin-transformer-enabled YOLOv5 with attention mechanism for small object detection on satellite images",
      "authors": "H Gong, T Mu, Q Li, H Dai, C Li, Z He, W Wang, F Han\u2026",
      "year": "2022",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9099615620722636165&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Slim-neck by GSConv: A better design paradigm of detector architectures for autonomous vehicles",
      "id": "15832601975079045141",
      "url": "https://arxiv.org/abs/2206.02424",
      "title": "Slim-neck by GSConv: A better design paradigm of detector architectures for autonomous vehicles",
      "authors": "H Li, J Li, H Wei, Z Liu, Z Zhan, Q Ren",
      "year": "2022",
      "cited_by": 70,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15832601975079045141&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Machine learning for microcontroller-class hardware-a review",
      "id": "501800524296721407",
      "url": "https://ieeexplore.ieee.org/abstract/document/9912325/",
      "title": "Machine learning for microcontroller-class hardware-a review",
      "authors": "SS Saha, SS Sandha, M Srivastava",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=501800524296721407&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Designing network design strategies through gradient path analysis",
      "id": "13429408729973378271",
      "url": "https://arxiv.org/abs/2211.04800",
      "title": "Designing network design strategies through gradient path analysis",
      "authors": "CY Wang, HYM Liao, IH Yeh",
      "year": "2022",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13429408729973378271&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Rethinking keypoint representations: Modeling keypoints and poses as objects for multi-person human pose estimation",
      "id": "16749039856030657986",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20068-7_3",
      "title": "Rethinking keypoint representations: Modeling keypoints and poses as objects for multi-person human pose estimation",
      "authors": "W McNally, K Vats, A Wong, J McPhee",
      "year": "2022",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16749039856030657986&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A real-time table grape detection method based on improved YOLOv4-tiny network in complex background",
      "id": "11425593478470212697",
      "url": "https://www.sciencedirect.com/science/article/pii/S1537511021002786",
      "title": "A real-time table grape detection method based on improved YOLOv4-tiny network in complex background",
      "authors": "H Li, C Li, G Li, L Chen",
      "year": "2021",
      "cited_by": 47,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11425593478470212697&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Disentangle your dense object detector",
      "id": "11107660116184346387",
      "url": "https://dl.acm.org/doi/abs/10.1145/3474085.3475351",
      "title": "Disentangle your dense object detector",
      "authors": "Z Chen, C Yang, Q Li, F Zhao, ZJ Zha\u2026",
      "year": "2021",
      "cited_by": 56,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11107660116184346387&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Cross-domain object detection for autonomous driving: A stepwise domain adaptative YOLO approach",
      "id": "12615305976817605176",
      "url": "https://ieeexplore.ieee.org/abstract/document/9750853/",
      "title": "Cross-domain object detection for autonomous driving: A stepwise domain adaptative YOLO approach",
      "authors": "G Li, Z Ji, X Qu, R Zhou, D Cao",
      "year": "2022",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12615305976817605176&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Application of deep learning and machine learning models to detect COVID-19 face masks-A review",
      "id": "15647727552153509563",
      "url": "https://www.sciencedirect.com/science/article/pii/S2666412721000325",
      "title": "Application of deep learning and machine learning models to detect COVID-19 face masks-A review",
      "authors": "E Mbunge, S Simelane, SG Fashoto\u2026",
      "year": "2021",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15647727552153509563&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Towards goal-oriented semantic signal processing: Applications and future challenges",
      "id": "15014850471536980328",
      "url": "https://www.sciencedirect.com/science/article/pii/S1051200421001731",
      "title": "Towards goal-oriented semantic signal processing: Applications and future challenges",
      "authors": "M Kalfa, M Gok, A Atalik, B Tegin, TM Duman\u2026",
      "year": "2021",
      "cited_by": 40,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15014850471536980328&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Cat: Cross attention in vision transformer",
      "id": "6434716222653444990",
      "url": "https://ieeexplore.ieee.org/abstract/document/9859720/",
      "title": "Cat: Cross attention in vision transformer",
      "authors": "H Lin, X Cheng, X Wu, D Shen",
      "year": "2022",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6434716222653444990&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Robust multi-object tracking by marginal inference",
      "id": "17859848890141888541",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20047-2_2",
      "title": "Robust multi-object tracking by marginal inference",
      "authors": "Y Zhang, C Wang, X Wang, W Zeng, W Liu",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17859848890141888541&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Small object detection method based on adaptive spatial parallel convolution and fast multi-scale fusion",
      "id": "3847442534681122442",
      "url": "https://www.mdpi.com/2072-4292/14/2/420",
      "title": "Small object detection method based on adaptive spatial parallel convolution and fast multi-scale fusion",
      "authors": "G Qi, Y Zhang, K Wang, N Mazur, Y Liu, D Malaviya",
      "year": "2022",
      "cited_by": 35,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3847442534681122442&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Confidence score: The forgotten dimension of object detection performance evaluation",
      "id": "3175561385815325856",
      "url": "https://www.mdpi.com/1424-8220/21/13/4350",
      "title": "Confidence score: The forgotten dimension of object detection performance evaluation",
      "authors": "S Wenkel, K Alhazmi, T Liiv, S Alrshoud, M Simon",
      "year": "2021",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3175561385815325856&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Autonomous, onboard vision-based trash and litter detection in low altitude aerial images collected by an unmanned aerial vehicle",
      "id": "6897858680399954297",
      "url": "https://www.mdpi.com/2072-4292/13/5/965",
      "title": "Autonomous, onboard vision-based trash and litter detection in low altitude aerial images collected by an unmanned aerial vehicle",
      "authors": "M Kraft, M Piechocki, B Ptak, K Walas",
      "year": "2021",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6897858680399954297&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Giaotracker: A comprehensive framework for mcmot with global information and optimizing strategies in visdrone 2021",
      "id": "17212634534495365627",
      "url": "https://openaccess.thecvf.com/content/ICCV2021W/VisDrone/html/Du_GIAOTracker_A_Comprehensive_Framework_for_MCMOT_With_Global_Information_and_ICCVW_2021_paper.html",
      "title": "Giaotracker: A comprehensive framework for mcmot with global information and optimizing strategies in visdrone 2021",
      "authors": "Y Du, J Wan, Y Zhao, B Zhang\u2026",
      "year": "2021",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17212634534495365627&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Generalized focal loss: Towards efficient representation learning for dense object detection",
      "id": "5912943256082429583",
      "url": "https://ieeexplore.ieee.org/abstract/document/9792391/",
      "title": "Generalized focal loss: Towards efficient representation learning for dense object detection",
      "authors": "X Li, C Lv, W Wang, G Li, L Yang\u2026",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5912943256082429583&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "CF2PN: A cross-scale feature fusion pyramid network based remote sensing target detection",
      "id": "16607894208431157893",
      "url": "https://www.mdpi.com/2072-4292/13/5/847",
      "title": "CF2PN: A cross-scale feature fusion pyramid network based remote sensing target detection",
      "authors": "W Huang, G Li, Q Chen, M Ju, J Qu",
      "year": "2021",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16607894208431157893&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "ES-Net: Efficient scale-aware network for tiny defect detection",
      "id": "14615147074360053768",
      "url": "https://ieeexplore.ieee.org/abstract/document/9760388/",
      "title": "ES-Net: Efficient scale-aware network for tiny defect detection",
      "authors": "X Yu, W Lyu, D Zhou, C Wang\u2026",
      "year": "2022",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14615147074360053768&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Tensorrt-based framework and optimization methodology for deep learning inference on jetson boards",
      "id": "8195426956859072339",
      "url": "https://dl.acm.org/doi/abs/10.1145/3508391",
      "title": "Tensorrt-based framework and optimization methodology for deep learning inference on jetson boards",
      "authors": "EJ Jeong, J Kim, S Ha",
      "year": "2022",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8195426956859072339&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "K-Radar: 4D radar object detection for autonomous driving in various weather conditions",
      "id": "3657623424699616492",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/185fdf627eaae2abab36205dcd19b817-Abstract-Datasets_and_Benchmarks.html",
      "title": "K-Radar: 4D radar object detection for autonomous driving in various weather conditions",
      "authors": "DH Paek, SH Kong, KT Wijaya",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3657623424699616492&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "EAutoDet: Efficient architecture search for object detection",
      "id": "7400981380759084546",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20044-1_38",
      "title": "EAutoDet: Efficient architecture search for object detection",
      "authors": "X Wang, J Lin, J Zhao, X Yang, J Yan",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7400981380759084546&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Autonomous path planning with obstacle avoidance for smart assistive systems",
      "id": "3490367220831301861",
      "url": "https://www.sciencedirect.com/science/article/pii/S095741742202067X",
      "title": "Autonomous path planning with obstacle avoidance for smart assistive systems",
      "authors": "C Ntakolia, S Moustakidis, A Siouras",
      "year": "2023",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3490367220831301861&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Hyper-parameter optimization of deep learning architectures using artificial bee colony (ABC) algorithm for high performance real-time automatic colorectal cancer\u00a0\u2026",
      "id": "15727602987444865635",
      "url": "https://link.springer.com/article/10.1007/s10489-022-04299-1",
      "title": "Hyper-parameter optimization of deep learning architectures using artificial bee colony (ABC) algorithm for high performance real-time automatic colorectal cancer\u00a0\u2026",
      "authors": "A Karaman, D Karaboga, I Pacal, B Akay, A Basturk\u2026",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15727602987444865635&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Boxer: Box-attention for 2d and 3d transformers",
      "id": "1805226328438105949",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_BoxeR_Box-Attention_for_2D_and_3D_Transformers_CVPR_2022_paper.html",
      "title": "Boxer: Box-attention for 2d and 3d transformers",
      "authors": "DK Nguyen, J Ju, O Booij\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1805226328438105949&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Bigdetection: A large-scale benchmark for improved object detector pre-training",
      "id": "14442074394232253245",
      "url": "http://openaccess.thecvf.com/content/CVPR2022W/VDU/html/Cai_BigDetection_A_Large-Scale_Benchmark_for_Improved_Object_Detector_Pre-Training_CVPRW_2022_paper.html",
      "title": "Bigdetection: A large-scale benchmark for improved object detector pre-training",
      "authors": "L Cai, Z Zhang, Y Zhu, L Zhang\u2026",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14442074394232253245&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Helmet wearing detection of motorcycle drivers using deep learning network with residual transformer-spatial attention",
      "id": "15900202697333596864",
      "url": "https://www.mdpi.com/2504-446X/6/12/415",
      "title": "Helmet wearing detection of motorcycle drivers using deep learning network with residual transformer-spatial attention",
      "authors": "S Chen, J Lan, H Liu, C Chen, X Wang",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15900202697333596864&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Fast detection and location of longan fruits using UAV images",
      "id": "3843578070760729914",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169921004828",
      "title": "Fast detection and location of longan fruits using UAV images",
      "authors": "D Li, X Sun, H Elkhouchlaa, Y Jia, Z Yao, P Lin\u2026",
      "year": "2021",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3843578070760729914&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Deep learning-based detection of aluminum casting defects and their types",
      "id": "7176502249404124990",
      "url": "https://www.sciencedirect.com/science/article/pii/S0952197622006261",
      "title": "Deep learning-based detection of aluminum casting defects and their types",
      "authors": "IE Parlak, E Emel",
      "year": "2023",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7176502249404124990&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Improved YOLOv4-tiny network for real-time electronic component detection",
      "id": "1170441202157905831",
      "url": "https://www.nature.com/articles/s41598-021-02225-y",
      "title": "Improved YOLOv4-tiny network for real-time electronic component detection",
      "authors": "C Guo, X Lv, Y Zhang, M Zhang",
      "year": "2021",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1170441202157905831&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "YOLO-G: A lightweight network model for improving the performance of military targets detection",
      "id": "12063573584218762374",
      "url": "https://ieeexplore.ieee.org/abstract/document/9780377/",
      "title": "YOLO-G: A lightweight network model for improving the performance of military targets detection",
      "authors": "L Kong, J Wang, P Zhao",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12063573584218762374&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Real-time citywide reconstruction of traffic flow from moving cameras on lightweight edge devices",
      "id": "2762494041692657615",
      "url": "https://www.sciencedirect.com/science/article/pii/S092427162200199X",
      "title": "Real-time citywide reconstruction of traffic flow from moving cameras on lightweight edge devices",
      "authors": "A Kumar, T Kashiyama, H Maeda, H Omata\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2762494041692657615&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Identification and classification of mechanical damage during continuous harvesting of root crops using computer vision methods",
      "id": "5067198574099017621",
      "url": "https://ieeexplore.ieee.org/abstract/document/9729819/",
      "title": "Identification and classification of mechanical damage during continuous harvesting of root crops using computer vision methods",
      "authors": "A Osipov, V Shumaev, A Ekielski, T Gataullin\u2026",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5067198574099017621&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Identifying images of dead chickens with a chicken removal system integrated with a deep learning algorithm",
      "id": "10920476727045815687",
      "url": "https://www.mdpi.com/1424-8220/21/11/3579",
      "title": "Identifying images of dead chickens with a chicken removal system integrated with a deep learning algorithm",
      "authors": "HW Liu, CH Chen, YC Tsai, KW Hsieh, HT Lin",
      "year": "2021",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10920476727045815687&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Research on recognition method of electrical components based on FEYOLOv4-tiny",
      "id": "618726556668923706",
      "url": "https://link.springer.com/article/10.1007/s42835-022-01124-0",
      "title": "Research on recognition method of electrical components based on FEYOLOv4-tiny",
      "authors": "J Gao, H Sun, J Han, Q Sun, T Zhong",
      "year": "2022",
      "cited_by": 31,
      "cited_by_url": "https://scholar.google.com/scholar?cites=618726556668923706&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Rail transit obstacle detection based on improved CNN",
      "id": "10392290641755897502",
      "url": "https://ieeexplore.ieee.org/abstract/document/9552593/",
      "title": "Rail transit obstacle detection based on improved CNN",
      "authors": "D He, Z Zou, Y Chen, B Liu\u2026",
      "year": "2021",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10392290641755897502&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Deep visual social distancing monitoring to combat COVID-19: A comprehensive survey",
      "id": "16867947394585746384",
      "url": "https://www.sciencedirect.com/science/article/pii/S2210670722003821",
      "title": "Deep visual social distancing monitoring to combat COVID-19: A comprehensive survey",
      "authors": "Y Himeur, S Al-Maadeed, N Almaadeed\u2026",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16867947394585746384&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Multi-level knowledge distillation for low-resolution object detection and facial expression recognition",
      "id": "7958224277211121064",
      "url": "https://www.sciencedirect.com/science/article/pii/S0950705122000144",
      "title": "Multi-level knowledge distillation for low-resolution object detection and facial expression recognition",
      "authors": "T Ma, W Tian, Y Xie",
      "year": "2022",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7958224277211121064&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A robust traffic-aware city-scale multi-camera vehicle tracking of vehicles",
      "id": "14994183852412960494",
      "url": "http://openaccess.thecvf.com/content/CVPR2022W/AICity/html/Tran_A_Robust_Traffic-Aware_City-Scale_Multi-Camera_Vehicle_Tracking_of_Vehicles_CVPRW_2022_paper.html",
      "title": "A robust traffic-aware city-scale multi-camera vehicle tracking of vehicles",
      "authors": "DNN Tran, LH Pham, HJ Jeon\u2026",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14994183852412960494&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "An improved YOLOv5 method for large objects detection with multi-scale feature cross-layer fusion network",
      "id": "8743963594325005332",
      "url": "https://www.sciencedirect.com/science/article/pii/S0262885622001470",
      "title": "An improved YOLOv5 method for large objects detection with multi-scale feature cross-layer fusion network",
      "authors": "Z Qu, L Gao, S Wang, H Yin, T Yi",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8743963594325005332&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "YOLO-ReT: Towards high accuracy real-time object detection on edge GPUs",
      "id": "3716397009677337300",
      "url": "https://openaccess.thecvf.com/content/WACV2022/html/Ganesh_YOLO-ReT_Towards_High_Accuracy_Real-Time_Object_Detection_on_Edge_GPUs_WACV_2022_paper.html?ref=https://githubhelp.com",
      "title": "YOLO-ReT: Towards high accuracy real-time object detection on edge GPUs",
      "authors": "P Ganesh, Y Chen, Y Yang, D Chen\u2026",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3716397009677337300&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Fast and accurate multi-class geospatial object detection with large-size remote sensing imagery using CNN and Truncated NMS",
      "id": "11651296702682936875",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271622001976",
      "title": "Fast and accurate multi-class geospatial object detection with large-size remote sensing imagery using CNN and Truncated NMS",
      "authors": "Y Shen, D Liu, F Zhang, Q Zhang",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11651296702682936875&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Real-time monitoring for manual operations with machine vision in smart manufacturing",
      "id": "491588394875958513",
      "url": "https://www.sciencedirect.com/science/article/pii/S0278612522001868",
      "title": "Real-time monitoring for manual operations with machine vision in smart manufacturing",
      "authors": "P Lou, J Li, YH Zeng, B Chen, X Zhang",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=491588394875958513&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Conformer: Local features coupling global representations for recognition and detection",
      "id": "2613459347497379531",
      "url": "https://ieeexplore.ieee.org/abstract/document/10040235/",
      "title": "Conformer: Local features coupling global representations for recognition and detection",
      "authors": "Z Peng, Z Guo, W Huang, Y Wang, L Xie\u2026",
      "year": "2023",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2613459347497379531&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Deep learning-based weed detection in turf: a review",
      "id": "6340122554340223367",
      "url": "https://www.mdpi.com/2073-4395/12/12/3051",
      "title": "Deep learning-based weed detection in turf: a review",
      "authors": "X Jin, T Liu, Y Chen, J Yu",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6340122554340223367&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Fall prevention from scaffolding using computer vision and IoT-based monitoring",
      "id": "6724179115405406423",
      "url": "https://ascelibrary.org/doi/full/10.1061/(ASCE)CO.1943-7862.0002278",
      "title": "Fall prevention from scaffolding using computer vision and IoT-based monitoring",
      "authors": "M Khan, R Khalid, S Anjum, SVT Tran\u2026",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6724179115405406423&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Automatic weld type classification, tacked spot recognition and weld ROI determination for robotic welding based on modified YOLOv5",
      "id": "14372476051154245137",
      "url": "https://www.sciencedirect.com/science/article/pii/S0736584522001727",
      "title": "Automatic weld type classification, tacked spot recognition and weld ROI determination for robotic welding based on modified YOLOv5",
      "authors": "S Chen, D Yang, J Liu, Q Tian, F Zhou",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14372476051154245137&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Interspace pruning: Using adaptive filter representations to improve training of sparse cnns",
      "id": "18310514353510448588",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wimmer_Interspace_Pruning_Using_Adaptive_Filter_Representations_To_Improve_Training_of_CVPR_2022_paper.html",
      "title": "Interspace pruning: Using adaptive filter representations to improve training of sparse cnns",
      "authors": "P Wimmer, J Mehnert\u2026",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18310514353510448588&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Location-sensitive visual recognition with cross-iou loss",
      "id": "14757740639617181116",
      "url": "https://arxiv.org/abs/2104.04899",
      "title": "Location-sensitive visual recognition with cross-iou loss",
      "authors": "K Duan, L Xie, H Qi, S Bai, Q Huang, Q Tian",
      "year": "2021",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14757740639617181116&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "AIR-YOLOv3: Aerial infrared pedestrian detection via an improved YOLOv3 with network pruning",
      "id": "3625588465481963755",
      "url": "https://www.mdpi.com/2076-3417/12/7/3627",
      "title": "AIR-YOLOv3: Aerial infrared pedestrian detection via an improved YOLOv3 with network pruning",
      "authors": "Y Shao, X Zhang, H Chu, X Zhang, D Zhang, Y Rao",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3625588465481963755&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Detectorguard: Provably securing object detectors against localized patch hiding attacks",
      "id": "1358307963221369570",
      "url": "https://dl.acm.org/doi/abs/10.1145/3460120.3484757",
      "title": "Detectorguard: Provably securing object detectors against localized patch hiding attacks",
      "authors": "C Xiang, P Mittal",
      "year": "2021",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1358307963221369570&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "MITNET: a novel dataset and a two-stage deep learning approach for mitosis recognition in whole slide images of breast cancer tissue",
      "id": "17729334233569922217",
      "url": "https://link.springer.com/article/10.1007/s00521-022-07441-9",
      "title": "MITNET: a novel dataset and a two-stage deep learning approach for mitosis recognition in whole slide images of breast cancer tissue",
      "authors": "S \u00c7ay\u0131r, G Solmaz, H Kusetogullari, F Tokat\u2026",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17729334233569922217&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Detection of bird species related to transmission line faults based on lightweight convolutional neural network",
      "id": "5997947092271436772",
      "url": "https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/gtd2.12333",
      "title": "Detection of bird species related to transmission line faults based on lightweight convolutional neural network",
      "authors": "Z Qiu, X Zhu, C Liao, D Shi, Y Kuang\u2026",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5997947092271436772&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Nms strikes back",
      "id": "10928542084451319450",
      "url": "https://arxiv.org/abs/2212.06137",
      "title": "Nms strikes back",
      "authors": "J Ouyang-Zhang, JH Cho, X Zhou\u2026",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10928542084451319450&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Liver tumor segmentation using 2.5 D UV-Net with multi-scale convolution",
      "id": "14498566121599741556",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482521002183",
      "title": "Liver tumor segmentation using 2.5 D UV-Net with multi-scale convolution",
      "authors": "C Zhang, Q Hua, Y Chu, P Wang",
      "year": "2021",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14498566121599741556&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "SHOMY: Detection of Small Hazardous Objects using the You Only Look Once Algorithm.",
      "id": "10132132318136226957",
      "url": "http://itiis.org/journals/tiis/digital-library/manuscript/file/25914/TIIS%20Vol%2016,%20No%208-12.pdf",
      "title": "SHOMY: Detection of Small Hazardous Objects using the You Only Look Once Algorithm.",
      "authors": "E Kim, J Lee, H Jo, K Na, E Moon, G Gweon\u2026",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10132132318136226957&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A fast aircraft detection method for SAR images based on efficient bidirectional path aggregated attention network",
      "id": "4082625592026884096",
      "url": "https://www.mdpi.com/2072-4292/13/15/2940",
      "title": "A fast aircraft detection method for SAR images based on efficient bidirectional path aggregated attention network",
      "authors": "R Luo, L Chen, J Xing, Z Yuan, S Tan, X Cai, J Wang",
      "year": "2021",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4082625592026884096&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Revitalizing optimization for 3d human pose and shape estimation: A sparse constrained formulation",
      "id": "6948486903139323825",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Fan_Revitalizing_Optimization_for_3D_Human_Pose_and_Shape_Estimation_A_ICCV_2021_paper.html",
      "title": "Revitalizing optimization for 3d human pose and shape estimation: A sparse constrained formulation",
      "authors": "T Fan, KV Alwala, D Xiang, W Xu\u2026",
      "year": "2021",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6948486903139323825&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Augmentative contrastive learning for one-shot object detection",
      "id": "18135864541368653593",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231222012152",
      "title": "Augmentative contrastive learning for one-shot object detection",
      "authors": "Y Du, F Liu, L Jiao, Z Hao, S Li, X Liu, J Liu",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18135864541368653593&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "LES-YOLO: A lightweight pinecone detection algorithm based on improved YOLOv4-Tiny network",
      "id": "7748241482703179571",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169923000017",
      "title": "LES-YOLO: A lightweight pinecone detection algorithm based on improved YOLOv4-Tiny network",
      "authors": "M Cui, Y Lou, Y Ge, K Wang",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7748241482703179571&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A learning-based crack defect detection and 3D localization framework for automated fluorescent magnetic particle inspection",
      "id": "3294374866555392652",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417422019844",
      "title": "A learning-based crack defect detection and 3D localization framework for automated fluorescent magnetic particle inspection",
      "authors": "Q Wu, X Qin, K Dong, A Shi, Z Hu",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3294374866555392652&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "ssFPN: Scale Sequence (S2) Feature-Based Feature Pyramid Network for Object Detection",
      "id": "5386784097479583414",
      "url": "https://www.mdpi.com/1424-8220/23/9/4432",
      "title": "ssFPN: Scale Sequence (S2) Feature-Based Feature Pyramid Network for Object Detection",
      "authors": "HJ Park, JW Kang, BG Kim",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5386784097479583414&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "TRC\u2010YOLO: A real\u2010time detection method for lightweight targets based on mobile devices",
      "id": "6661086806896725511",
      "url": "https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/cvi2.12072",
      "title": "TRC\u2010YOLO: A real\u2010time detection method for lightweight targets based on mobile devices",
      "authors": "G Wang, H Ding, Z Yang, B Li, Y Wang\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6661086806896725511&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Automatic Vehicle Identification and Classification Model Using the YOLOv3 Algorithm for a Toll Management System",
      "id": "15115558022538513237",
      "url": "https://www.mdpi.com/2071-1050/14/15/9163",
      "title": "Automatic Vehicle Identification and Classification Model Using the YOLOv3 Algorithm for a Toll Management System",
      "authors": "SK Rajput, JC Patni, SS Alshamrani, V Chaudhari\u2026",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15115558022538513237&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A lightweight framework for obstacle detection in the railway image based on fast region proposal and improved YOLO-tiny network",
      "id": "14159121989210618633",
      "url": "https://ieeexplore.ieee.org/abstract/document/9715050/",
      "title": "A lightweight framework for obstacle detection in the railway image based on fast region proposal and improved YOLO-tiny network",
      "authors": "L Guan, L Jia, Z Xie, C Yin",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14159121989210618633&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A comprehensive survey of few-shot learning: Evolution, applications, challenges, and opportunities",
      "id": "15045952046135698930",
      "url": "https://dl.acm.org/doi/abs/10.1145/3582688",
      "title": "A comprehensive survey of few-shot learning: Evolution, applications, challenges, and opportunities",
      "authors": "Y Song, T Wang, P Cai, SK Mondal\u2026",
      "year": "2023",
      "cited_by": 46,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15045952046135698930&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A lightweight vehicles detection network model based on YOLOv5",
      "id": "1223563817431199857",
      "url": "https://www.sciencedirect.com/science/article/pii/S0952197622001415",
      "title": "A lightweight vehicles detection network model based on YOLOv5",
      "authors": "X Dong, S Yan, C Duan",
      "year": "2022",
      "cited_by": 80,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1223563817431199857&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Improved yolov5: Efficient object detection using drone images under various conditions",
      "id": "3743433833463586545",
      "url": "https://www.mdpi.com/2076-3417/12/14/7255",
      "title": "Improved yolov5: Efficient object detection using drone images under various conditions",
      "authors": "HK Jung, GS Choi",
      "year": "2022",
      "cited_by": 62,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3743433833463586545&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Underwater target detection algorithm based on improved YOLOv5",
      "id": "2805320302601413924",
      "url": "https://www.mdpi.com/2077-1312/10/3/310",
      "title": "Underwater target detection algorithm based on improved YOLOv5",
      "authors": "F Lei, F Tang, S Li",
      "year": "2022",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2805320302601413924&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Deep learning-based object detection techniques for remote sensing images: A survey",
      "id": "12502648671025662060",
      "url": "https://www.mdpi.com/2072-4292/14/10/2385",
      "title": "Deep learning-based object detection techniques for remote sensing images: A survey",
      "authors": "Z Li, Y Wang, N Zhang, Y Zhang, Z Zhao, D Xu, G Ben\u2026",
      "year": "2022",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12502648671025662060&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Concrete dam damage detection and localisation based on YOLOv5s-HSC and photogrammetric 3D reconstruction",
      "id": "11992929173642808953",
      "url": "https://www.sciencedirect.com/science/article/pii/S0926580522004253",
      "title": "Concrete dam damage detection and localisation based on YOLOv5s-HSC and photogrammetric 3D reconstruction",
      "authors": "S Zhao, F Kang, J Li",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11992929173642808953&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A deep learning model for detecting cage-free hens on the litter floor",
      "id": "6429502500328305488",
      "url": "https://www.mdpi.com/2076-2615/12/15/1983",
      "title": "A deep learning model for detecting cage-free hens on the litter floor",
      "authors": "X Yang, L Chai, RB Bist, S Subedi, Z Wu",
      "year": "2022",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6429502500328305488&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Research on the coordinate attention mechanism fuse in a YOLOv5 deep learning detector for the SAR ship detection task",
      "id": "4628199491611022446",
      "url": "https://www.mdpi.com/1424-8220/22/9/3370",
      "title": "Research on the coordinate attention mechanism fuse in a YOLOv5 deep learning detector for the SAR ship detection task",
      "authors": "F Xie, B Lin, Y Liu",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4628199491611022446&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "YOLOv5-Fog: A multiobjective visual detection algorithm for fog driving scenes based on improved YOLOv5",
      "id": "17059844040400317816",
      "url": "https://ieeexplore.ieee.org/abstract/document/9851677/",
      "title": "YOLOv5-Fog: A multiobjective visual detection algorithm for fog driving scenes based on improved YOLOv5",
      "authors": "H Wang, Y Xu, Y He, Y Cai, L Chen, Y Li\u2026",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17059844040400317816&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An improved Yolov5 for multi-rotor UAV detection",
      "id": "2901021971175385417",
      "url": "https://www.mdpi.com/2079-9292/11/15/2330",
      "title": "An improved Yolov5 for multi-rotor UAV detection",
      "authors": "B Liu, H Luo",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2901021971175385417&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Real-time detection of cracks in tiled sidewalks using YOLO-based method applied to unmanned aerial vehicle (UAV) images",
      "id": "5838860470680827023",
      "url": "https://www.sciencedirect.com/science/article/pii/S0926580523000055",
      "title": "Real-time detection of cracks in tiled sidewalks using YOLO-based method applied to unmanned aerial vehicle (UAV) images",
      "authors": "Q Qiu, D Lau",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5838860470680827023&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Research on tiny target detection technology of fabric defects based on improved Yolo",
      "id": "16864394826962881925",
      "url": "https://www.mdpi.com/2076-3417/12/13/6823",
      "title": "Research on tiny target detection technology of fabric defects based on improved Yolo",
      "authors": "X Yue, Q Wang, L He, Y Li, D Tang",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16864394826962881925&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A region-based deep learning approach to automated retail checkout",
      "id": "7269756958028651926",
      "url": "https://openaccess.thecvf.com/content/CVPR2022W/AICity/html/Shoman_A_Region-Based_Deep_Learning_Approach_to_Automated_Retail_Checkout_CVPRW_2022_paper.html",
      "title": "A region-based deep learning approach to automated retail checkout",
      "authors": "M Shoman, A Aboah, A Morehead\u2026",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7269756958028651926&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An end-to-end smart IoT-driven navigation for social distancing enforcement",
      "id": "6832920879012580854",
      "url": "https://ieeexplore.ieee.org/abstract/document/9834931/",
      "title": "An end-to-end smart IoT-driven navigation for social distancing enforcement",
      "authors": "H Friji, A Khanfor, H Ghazzai, Y Massoud",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6832920879012580854&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Boosting target-level infrared and visible image fusion with regional information coordination",
      "id": "12145681576382105820",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253522002536",
      "title": "Boosting target-level infrared and visible image fusion with regional information coordination",
      "authors": "M Han, K Yu, J Qiu, H Li, D Wu, Y Rao, Y Yang, L Xing\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12145681576382105820&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Recognition of terminal buds of densely-planted Chinese fir seedlings using improved YOLOv5 by integrating attention mechanism",
      "id": "18188852084265258548",
      "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.991929/full",
      "title": "Recognition of terminal buds of densely-planted Chinese fir seedlings using improved YOLOv5 by integrating attention mechanism",
      "authors": "Z Ye, Q Guo, J Wei, J Zhang, H Zhang, L Bian\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18188852084265258548&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Solar cell surface defect detection based on improved YOLO v5",
      "id": "795370128396508846",
      "url": "https://ieeexplore.ieee.org/abstract/document/9847242/",
      "title": "Solar cell surface defect detection based on improved YOLO v5",
      "authors": "M Zhang, L Yin",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=795370128396508846&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Detection of norway spruce trees (Picea Abies) infested by bark beetle in UAV images using YOLOs architectures",
      "id": "17094049497238104059",
      "url": "https://ieeexplore.ieee.org/abstract/document/9684880/",
      "title": "Detection of norway spruce trees (Picea Abies) infested by bark beetle in UAV images using YOLOs architectures",
      "authors": "A Safonova, Y Hamad, A Alekhina, D Kaplun",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17094049497238104059&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Object detection of road assets using transformer-based YOLOX with feature pyramid decoder on thai highway panorama",
      "id": "8167187293724692556",
      "url": "https://www.mdpi.com/2078-2489/13/1/5",
      "title": "Object detection of road assets using transformer-based YOLOX with feature pyramid decoder on thai highway panorama",
      "authors": "T Panboonyuen, S Thongbai, W Wongweeranimit\u2026",
      "year": "2021",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8167187293724692556&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Automatic estimation of apple orchard blooming levels using the improved YOLOv5",
      "id": "1708442884848326195",
      "url": "https://www.mdpi.com/2073-4395/12/10/2483",
      "title": "Automatic estimation of apple orchard blooming levels using the improved YOLOv5",
      "authors": "Z Chen, R Su, Y Wang, G Chen, Z Wang, P Yin, J Wang",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1708442884848326195&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Explainable Multitask Shapley Explanation Networks for Real-time Polyp Diagnosis in Videos",
      "id": "10621171041712014560",
      "url": "https://ieeexplore.ieee.org/abstract/document/9896998/",
      "title": "Explainable Multitask Shapley Explanation Networks for Real-time Polyp Diagnosis in Videos",
      "authors": "D Wang, X Wang, S Wang, Y Yin",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10621171041712014560&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Last decade in vehicle detection and classification: a comprehensive survey",
      "id": "282841756216791105",
      "url": "https://link.springer.com/article/10.1007/s11831-022-09764-1",
      "title": "Last decade in vehicle detection and classification: a comprehensive survey",
      "authors": "S Maity, A Bhattacharyya, PK Singh, M Kumar\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=282841756216791105&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An improved YOLOv5 crack detection method combined with transformer",
      "id": "1020146708014614449",
      "url": "https://ieeexplore.ieee.org/abstract/document/9794770/",
      "title": "An improved YOLOv5 crack detection method combined with transformer",
      "authors": "X Xiang, Z Wang, Y Qiao",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1020146708014614449&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Transvisdrone: Spatio-temporal transformer for vision-based drone-to-drone detection in aerial videos",
      "id": "10294172557164487522",
      "url": "https://ieeexplore.ieee.org/abstract/document/10161433/",
      "title": "Transvisdrone: Spatio-temporal transformer for vision-based drone-to-drone detection in aerial videos",
      "authors": "T Sangam, IR Dave, W Sultani\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10294172557164487522&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Lightweight detection network for arbitrary-oriented vehicles in UAV imagery via global attentive relation and multi-path fusion",
      "id": "14493401188532558995",
      "url": "https://www.mdpi.com/2504-446X/6/5/108",
      "title": "Lightweight detection network for arbitrary-oriented vehicles in UAV imagery via global attentive relation and multi-path fusion",
      "authors": "J Feng, C Yi",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14493401188532558995&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Detection of river floating garbage based on improved YOLOv5",
      "id": "915175193869878529",
      "url": "https://www.mdpi.com/2227-7390/10/22/4366",
      "title": "Detection of river floating garbage based on improved YOLOv5",
      "authors": "X Yang, J Zhao, L Zhao, H Zhang, L Li, Z Ji, I Ganchev",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=915175193869878529&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "FiFoNet: Fine-Grained Target Focusing Network for Object Detection in UAV Images",
      "id": "4712339159260231874",
      "url": "https://www.mdpi.com/2072-4292/14/16/3919",
      "title": "FiFoNet: Fine-Grained Target Focusing Network for Object Detection in UAV Images",
      "authors": "Y Xi, W Jia, Q Miao, X Liu, X Fan, H Li",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4712339159260231874&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Research on crack detection method of wind turbine blade based on a deep learning method",
      "id": "10634144542916924319",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306261922014982",
      "title": "Research on crack detection method of wind turbine blade based on a deep learning method",
      "authors": "Z Xiaoxun, H Xinyu, G Xiaoxia, Y Xing, X Zixu, W Yu\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10634144542916924319&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Drone Detection Using YOLOv5",
      "id": "15151751976029410131",
      "url": "https://www.mdpi.com/2673-4117/4/1/25",
      "title": "Drone Detection Using YOLOv5",
      "authors": "B Aydin, S Singha",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15151751976029410131&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Pareto refocusing for drone-view object detection",
      "id": "3619283013073038983",
      "url": "https://ieeexplore.ieee.org/abstract/document/9905640/",
      "title": "Pareto refocusing for drone-view object detection",
      "authors": "J Leng, M Mo, Y Zhou, C Gao, W Li\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3619283013073038983&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Adverse Weather Target Detection Algorithm Based on Adaptive Color Levels and Improved YOLOv5",
      "id": "14298330466237469464",
      "url": "https://www.mdpi.com/1424-8220/22/21/8577",
      "title": "Adverse Weather Target Detection Algorithm Based on Adaptive Color Levels and Improved YOLOv5",
      "authors": "J Yao, X Fan, B Li, W Qin",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14298330466237469464&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "TPH-YOLOv5++: Boosting Object Detection on Drone-Captured Scenarios with Cross-Layer Asymmetric Transformer",
      "id": "17746736907900692263",
      "url": "https://www.mdpi.com/2072-4292/15/6/1687",
      "title": "TPH-YOLOv5++: Boosting Object Detection on Drone-Captured Scenarios with Cross-Layer Asymmetric Transformer",
      "authors": "Q Zhao, B Liu, S Lyu, C Wang, H Zhang",
      "year": "2023",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17746736907900692263&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "EfficientLiteDet: a real-time pedestrian and vehicle detection algorithm",
      "id": "7490525040340169893",
      "url": "https://link.springer.com/article/10.1007/s00138-022-01293-y",
      "title": "EfficientLiteDet: a real-time pedestrian and vehicle detection algorithm",
      "authors": "CB Murthy, MF Hashmi, AG Keskar",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7490525040340169893&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "SCFNet: Semantic correction and focus network for remote sensing image object detection",
      "id": "1646852206964174022",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417423004827",
      "title": "SCFNet: Semantic correction and focus network for remote sensing image object detection",
      "authors": "C Yue, J Yan, Y Zhang, Z Luo, Y Liu, P Guo",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1646852206964174022&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An Efficient YOLO Algorithm with an Attention Mechanism for Vision-Based Defect Inspection Deployed on FPGA",
      "id": "3566720882072534084",
      "url": "https://www.mdpi.com/2072-666X/13/7/1058",
      "title": "An Efficient YOLO Algorithm with an Attention Mechanism for Vision-Based Defect Inspection Deployed on FPGA",
      "authors": "L Yu, J Zhu, Q Zhao, Z Wang",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3566720882072534084&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Underwater Target Detection Lightweight Algorithm Based on Multi-Scale Feature Fusion",
      "id": "6060221142406415982",
      "url": "https://www.mdpi.com/2077-1312/11/2/320",
      "title": "Underwater Target Detection Lightweight Algorithm Based on Multi-Scale Feature Fusion",
      "authors": "L Chen, Y Yang, Z Wang, J Zhang, S Zhou\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6060221142406415982&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Research on the Application of Visual Recognition in the Engine Room of Intelligent Ships",
      "id": "7686098348117464607",
      "url": "https://www.mdpi.com/1424-8220/22/19/7261",
      "title": "Research on the Application of Visual Recognition in the Engine Room of Intelligent Ships",
      "authors": "D Shang, J Zhang, K Zhou, T Wang, J Qi",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7686098348117464607&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "MR-YOLO: an improved YOLOv5 network for detecting magnetic ring surface defects",
      "id": "10112787672038528081",
      "url": "https://www.mdpi.com/1424-8220/22/24/9897",
      "title": "MR-YOLO: an improved YOLOv5 network for detecting magnetic ring surface defects",
      "authors": "X Lang, Z Ren, D Wan, Y Zhang, S Shu",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10112787672038528081&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A pedestrian detection network model based on improved YOLOv5",
      "id": "12467383398842524346",
      "url": "https://www.mdpi.com/1099-4300/25/2/381",
      "title": "A pedestrian detection network model based on improved YOLOv5",
      "authors": "ML Li, GB Sun, JX Yu",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12467383398842524346&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Small vessel detection based on adaptive dual-polarimetric feature fusion and sea\u2013land segmentation in SAR images",
      "id": "17781373599130948810",
      "url": "https://ieeexplore.ieee.org/abstract/document/9735422/",
      "title": "Small vessel detection based on adaptive dual-polarimetric feature fusion and sea\u2013land segmentation in SAR images",
      "authors": "Y Zhou, F Zhang, F Ma, D Xiang\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17781373599130948810&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Deep learning in spatial transcriptomics: Learning from the next next-generation sequencing",
      "id": "10321528843008389282",
      "url": "https://www.biorxiv.org/content/10.1101/2022.02.28.482392.abstract",
      "title": "Deep learning in spatial transcriptomics: Learning from the next next-generation sequencing",
      "authors": "AA Heydari, SS Sindi",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10321528843008389282&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Safety helmet detection using deep learning: Implementation and comparative study using YOLOv5, YOLOv6, and YOLOv7",
      "id": "3073101641983057594",
      "url": "https://ieeexplore.ieee.org/abstract/document/10010490/",
      "title": "Safety helmet detection using deep learning: Implementation and comparative study using YOLOv5, YOLOv6, and YOLOv7",
      "authors": "NDT Yung, WK Wong, FH Juwono\u2026",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3073101641983057594&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Rd-yolo: An effective and efficient object detector for roadside perception system",
      "id": "15258815906138889567",
      "url": "https://www.mdpi.com/1424-8220/22/21/8097",
      "title": "Rd-yolo: An effective and efficient object detector for roadside perception system",
      "authors": "L Huang, W Huang",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15258815906138889567&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Hidden dangerous object recognition in terahertz images using deep learning methods",
      "id": "12958131567968188905",
      "url": "https://www.mdpi.com/2076-3417/12/15/7354",
      "title": "Hidden dangerous object recognition in terahertz images using deep learning methods",
      "authors": "SA Danso, L Shang, D Hu, J Odoom, Q Liu\u2026",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12958131567968188905&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Classification of Tomato Fruit Using Yolov5 and Convolutional Neural Network Models",
      "id": "11183708110410802287",
      "url": "https://www.mdpi.com/2223-7747/12/4/790",
      "title": "Classification of Tomato Fruit Using Yolov5 and Convolutional Neural Network Models",
      "authors": "QH Phan, VT Nguyen, CH Lien, TP Duong, MTK Hou\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11183708110410802287&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Research on Chengdu Ma goat recognition based on computer vison",
      "id": "14682032714717312533",
      "url": "https://www.mdpi.com/2076-2615/12/14/1746",
      "title": "Research on Chengdu Ma goat recognition based on computer vison",
      "authors": "J Pu, C Yu, X Chen, Y Zhang, X Yang, J Li",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14682032714717312533&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Fruit ripeness identification using transformers",
      "id": "11101126821023653833",
      "url": "https://link.springer.com/article/10.1007/s10489-023-04799-8",
      "title": "Fruit ripeness identification using transformers",
      "authors": "B Xiao, M Nguyen, WQ Yan",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11101126821023653833&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An Improved YOLOv5 Crack Detection Method Combined with a Bottleneck Transformer",
      "id": "2547097814727899492",
      "url": "https://www.mdpi.com/2227-7390/11/10/2377",
      "title": "An Improved YOLOv5 Crack Detection Method Combined with a Bottleneck Transformer",
      "authors": "G Yu, X Zhou",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2547097814727899492&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "YOLOSR-IST: A deep learning method for small target detection in infrared remote sensing images based on super-resolution and YOLO",
      "id": "9478150375568593008",
      "url": "https://www.sciencedirect.com/science/article/pii/S0165168423000361",
      "title": "YOLOSR-IST: A deep learning method for small target detection in infrared remote sensing images based on super-resolution and YOLO",
      "authors": "R Li, Y Shen",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9478150375568593008&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A video analytics system for person detection combined with edge computing",
      "id": "1144856546777335713",
      "url": "https://www.mdpi.com/2079-3197/10/3/35",
      "title": "A video analytics system for person detection combined with edge computing",
      "authors": "E Maltezos, P Lioupis, A Dadoukis, L Karagiannidis\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1144856546777335713&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Tiny vehicle detection for mid-to-high altitude UAV images based on visual attention and spatial-temporal information",
      "id": "5373184172069649878",
      "url": "https://www.mdpi.com/1424-8220/22/6/2354",
      "title": "Tiny vehicle detection for mid-to-high altitude UAV images based on visual attention and spatial-temporal information",
      "authors": "R Yu, H Li, Y Jiang, B Zhang, Y Wang",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5373184172069649878&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Research on car license plate recognition based on improved YOLOv5m and LPRNet",
      "id": "1630814355216789856",
      "url": "https://ieeexplore.ieee.org/abstract/document/9874789/",
      "title": "Research on car license plate recognition based on improved YOLOv5m and LPRNet",
      "authors": "S Luo, J Liu",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1630814355216789856&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "HematoNet: expert level classification of bone marrow cytology morphology in hematological malignancy with deep learning",
      "id": "5480963051895971527",
      "url": "https://www.sciencedirect.com/science/article/pii/S2667318522000137",
      "title": "HematoNet: expert level classification of bone marrow cytology morphology in hematological malignancy with deep learning",
      "authors": "S Tripathi, AI Augustin, R Sukumaran, S Dheer\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5480963051895971527&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Integrating Multi-Scale Remote-Sensing Data to Monitor Severe Forest Infestation in Response to Pine Wilt Disease",
      "id": "14031173575587899194",
      "url": "https://www.mdpi.com/2072-4292/14/20/5164",
      "title": "Integrating Multi-Scale Remote-Sensing Data to Monitor Severe Forest Infestation in Response to Pine Wilt Disease",
      "authors": "X Li, Y Liu, P Huang, T Tong, L Li, Y Chen, T Hou\u2026",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14031173575587899194&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A detection approach for late-autumn shoots of litchi based on unmanned aerial vehicle (UAV) remote sensing",
      "id": "16620415112774447142",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922008432",
      "title": "A detection approach for late-autumn shoots of litchi based on unmanned aerial vehicle (UAV) remote sensing",
      "authors": "J Liang, X Chen, C Liang, T Long, X Tang, Z Shi\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16620415112774447142&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Automatic Mapping of Karez in Turpan Basin Based on Google Earth Images and the YOLOv5 Model",
      "id": "16166479600523370143",
      "url": "https://www.mdpi.com/2072-4292/14/14/3318",
      "title": "Automatic Mapping of Karez in Turpan Basin Based on Google Earth Images and the YOLOv5 Model",
      "authors": "Q Li, H Guo, L Luo, X Wang",
      "year": "2022",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16166479600523370143&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Novel Recursive BiFPN Combining with Swin Transformer for Wildland Fire Smoke Detection",
      "id": "12327522076345093055",
      "url": "https://www.mdpi.com/1999-4907/13/12/2032",
      "title": "Novel Recursive BiFPN Combining with Swin Transformer for Wildland Fire Smoke Detection",
      "authors": "A Li, Y Zhao, Z Zheng",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12327522076345093055&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An Improved YOLOv5-Based Underwater Object-Detection Framework",
      "id": "14339464007846837517",
      "url": "https://www.mdpi.com/1424-8220/23/7/3693",
      "title": "An Improved YOLOv5-Based Underwater Object-Detection Framework",
      "authors": "J Zhang, J Zhang, K Zhou, Y Zhang, H Chen, X Yan",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14339464007846837517&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Coupled Global\u2013Local object detection for large VHR aerial images",
      "id": "7455995568870583888",
      "url": "https://www.sciencedirect.com/science/article/pii/S0950705122011935",
      "title": "Coupled Global\u2013Local object detection for large VHR aerial images",
      "authors": "X Chen, C Wang, Z Li, M Liu, Q Li, H Qi, D Ma\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7455995568870583888&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "YOLOv5s-CBAM-DMLHead: A lightweight identification algorithm for weedy rice (Oryza sativa f. spontanea) based on improved YOLOv5",
      "id": "3242865566534850692",
      "url": "https://www.sciencedirect.com/science/article/pii/S0261219423001655",
      "title": "YOLOv5s-CBAM-DMLHead: A lightweight identification algorithm for weedy rice (Oryza sativa f. spontanea) based on improved YOLOv5",
      "authors": "C Yuan, T Liu, F Gao, R Zhang, X Seng",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3242865566534850692&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "ARSD: An Adaptive Region Selection Object Detection Framework for UAV Images",
      "id": "10190720705683005400",
      "url": "https://www.mdpi.com/2504-446X/6/9/228",
      "title": "ARSD: An Adaptive Region Selection Object Detection Framework for UAV Images",
      "authors": "Y Wan, Y Zhong, Y Huang, Y Han, Y Cui, Q Yang, Z Li\u2026",
      "year": "2022",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10190720705683005400&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Improved YOLOX Foreign Object Detection Algorithm for Transmission Lines",
      "id": "3066843940507119154",
      "url": "https://www.hindawi.com/journals/wcmc/2022/5835693/",
      "title": "Improved YOLOX Foreign Object Detection Algorithm for Transmission Lines",
      "authors": "M Wu, L Guo, R Chen, W Du, J Wang, M Liu\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3066843940507119154&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Artificial intelligence\u2013based method for the rapid detection of fish parasites (Ichthyophthirius multifiliis, Gyrodactylus kobayashii, and Argulus japonicus)",
      "id": "6332829983840302405",
      "url": "https://www.sciencedirect.com/science/article/pii/S0044848622009073",
      "title": "Artificial intelligence\u2013based method for the rapid detection of fish parasites (Ichthyophthirius multifiliis, Gyrodactylus kobayashii, and Argulus japonicus)",
      "authors": "J Li, Z Lian, Z Wu, L Zeng, L Mu, Y Yuan, H Bai, Z Guo\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6332829983840302405&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Towards efficient detection for small objects via attention-guided detection network and data augmentation",
      "id": "13500090513888098729",
      "url": "https://www.mdpi.com/1424-8220/22/19/7663",
      "title": "Towards efficient detection for small objects via attention-guided detection network and data augmentation",
      "authors": "X Wang, D Zhu, Y Yan",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13500090513888098729&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Differential evolution based dual adversarial camouflage: Fooling human eyes and object detectors",
      "id": "12621962626789350377",
      "url": "https://www.sciencedirect.com/science/article/pii/S0893608023001764",
      "title": "Differential evolution based dual adversarial camouflage: Fooling human eyes and object detectors",
      "authors": "J Sun, W Yao, T Jiang, D Wang, X Chen",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12621962626789350377&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Lightweight and efficient neural network with SPSA attention for wheat ear detection",
      "id": "16002571822077945928",
      "url": "https://peerj.com/articles/cs-931/",
      "title": "Lightweight and efficient neural network with SPSA attention for wheat ear detection",
      "authors": "Y Dong, Y Liu, H Kang, C Li, P Liu, Z Liu",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16002571822077945928&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Deep Crowd Anomaly Detection: State-of-the-Art, Challenges, and Future Research Directions",
      "id": "3232219129862852847",
      "url": "https://arxiv.org/abs/2210.13927",
      "title": "Deep Crowd Anomaly Detection: State-of-the-Art, Challenges, and Future Research Directions",
      "authors": "MH Sharif, L Jiao, CW Omlin",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3232219129862852847&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An improved YOLOv7 lightweight detection algorithm for obscured pedestrians",
      "id": "5354452319526960123",
      "url": "https://www.mdpi.com/1424-8220/23/13/5912",
      "title": "An improved YOLOv7 lightweight detection algorithm for obscured pedestrians",
      "authors": "C Li, Y Wang, X Liu",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5354452319526960123&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "YOLOv4 with Deformable-Embedding-Transformer Feature Extractor for Exact Object Detection in Aerial Imagery",
      "id": "14918519107862734365",
      "url": "https://www.mdpi.com/1424-8220/23/5/2522",
      "title": "YOLOv4 with Deformable-Embedding-Transformer Feature Extractor for Exact Object Detection in Aerial Imagery",
      "authors": "Y Wu, J Li",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14918519107862734365&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An Intelligent Weighted Object Detector for Feature Extraction to Enrich Global Image Information",
      "id": "17165120566620849856",
      "url": "https://www.mdpi.com/2076-3417/12/15/7825",
      "title": "An Intelligent Weighted Object Detector for Feature Extraction to Enrich Global Image Information",
      "authors": "L Yan, K Li, R Gao, C Wang, N Xiong",
      "year": "2022",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17165120566620849856&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "JR-TFViT: A Lightweight Efficient Radar Jamming Recognition Network Based on Global Representation of the Time\u2013Frequency Domain",
      "id": "4741106364027764952",
      "url": "https://www.mdpi.com/2079-9292/11/17/2794",
      "title": "JR-TFViT: A Lightweight Efficient Radar Jamming Recognition Network Based on Global Representation of the Time\u2013Frequency Domain",
      "authors": "B Lang, J Gong",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4741106364027764952&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "A Sidelobe-Aware Small Ship Detection Network for Synthetic Aperture Radar Imagery",
      "id": "11222483890632287401",
      "url": "https://ieeexplore.ieee.org/abstract/document/10091564/",
      "title": "A Sidelobe-Aware Small Ship Detection Network for Synthetic Aperture Radar Imagery",
      "authors": "Y Zhou, H Liu, F Ma, Z Pan\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11222483890632287401&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Object Detection for UAV Aerial Scenarios Based on Vectorized IOU",
      "id": "12142856329509817511",
      "url": "https://www.mdpi.com/1424-8220/23/6/3061",
      "title": "Object Detection for UAV Aerial Scenarios Based on Vectorized IOU",
      "authors": "S Lu, H Lu, J Dong, S Wu",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12142856329509817511&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "A deep-learning pipeline to diagnose pediatric intussusception and assess severity during ultrasound scanning: a multicenter retrospective-prospective study",
      "id": "11083218512495776976",
      "url": "https://www.nature.com/articles/s41746-023-00930-8",
      "title": "A deep-learning pipeline to diagnose pediatric intussusception and assess severity during ultrasound scanning: a multicenter retrospective-prospective study",
      "authors": "Y Pei, G Wang, H Cao, S Jiang, D Wang, H Wang\u2026",
      "year": "2023",
      "modularity": 1
    },
    {
      "label": "Data-driven model SSD-BSP for multi-target coal-gangue detection",
      "id": "3110755508632090464",
      "url": "https://www.sciencedirect.com/science/article/pii/S0263224123008084",
      "title": "Data-driven model SSD-BSP for multi-target coal-gangue detection",
      "authors": "L Wang, X Wang, B Li",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3110755508632090464&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An eye tracking and brain-computer Interface based human-environment interactive system for amyotrophic lateral sclerosis patients",
      "id": "4388463373166231389",
      "url": "https://ieeexplore.ieee.org/abstract/document/9966509/",
      "title": "An eye tracking and brain-computer Interface based human-environment interactive system for amyotrophic lateral sclerosis patients",
      "authors": "J Wang, S Xu, Y Dai, S Gao",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4388463373166231389&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "An Active Multi-Object Ultrafast Tracking System with CNN-Based Hybrid Object Detection",
      "id": "11986345078302880571",
      "url": "https://www.mdpi.com/1424-8220/23/8/4150",
      "title": "An Active Multi-Object Ultrafast Tracking System with CNN-Based Hybrid Object Detection",
      "authors": "Q Li, S Hu, K Shimasaki, I Ishii",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11986345078302880571&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "High-resolution concrete damage image synthesis using conditional generative adversarial network",
      "id": "943904167170865655",
      "url": "https://www.sciencedirect.com/science/article/pii/S0926580522006094",
      "title": "High-resolution concrete damage image synthesis using conditional generative adversarial network",
      "authors": "S Li, X Zhao",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=943904167170865655&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "DBF\u2010YOLO: UAV Small Targets Detection Based on Shallow Feature Fusion",
      "id": "5907315131746612745",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/tee.23758",
      "title": "DBF\u2010YOLO: UAV Small Targets Detection Based on Shallow Feature Fusion",
      "authors": "H Liu, X Duan, H Chen, H Lou\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5907315131746612745&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Efficient-Lightweight YOLO: Improving Small Object Detection in YOLO for Aerial Images",
      "id": "2505454209938753585",
      "url": "https://www.mdpi.com/1424-8220/23/14/6423",
      "title": "Efficient-Lightweight YOLO: Improving Small Object Detection in YOLO for Aerial Images",
      "authors": "M Hu, Z Li, J Yu, X Wan, H Tan, Z Lin",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2505454209938753585&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Object detection based approach for an efficient video summarization with system statistics over cloud",
      "id": "1928444155270241570",
      "url": "https://ieeexplore.ieee.org/abstract/document/9986376/",
      "title": "Object detection based approach for an efficient video summarization with system statistics over cloud",
      "authors": "A Negi, K Kumar, P Saini\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1928444155270241570&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 1
    },
    {
      "label": "Yolov4: Optimal speed and accuracy of object detection",
      "id": "4550423614333066109",
      "url": "https://arxiv.org/abs/2004.10934",
      "title": "Yolov4: Optimal speed and accuracy of object detection",
      "authors": "A Bochkovskiy, CY Wang, HYM Liao",
      "year": "2020",
      "cited_by": 11856,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4550423614333066109&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "All one needs to know about metaverse: A complete survey on technological singularity, virtual ecosystem, and research agenda",
      "id": "2143047335646200982",
      "url": "https://arxiv.org/abs/2110.05352",
      "title": "All one needs to know about metaverse: A complete survey on technological singularity, virtual ecosystem, and research agenda",
      "authors": "LH Lee, T Braud, P Zhou, L Wang, D Xu, Z Lin\u2026",
      "year": "2021",
      "cited_by": 962,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2143047335646200982&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Mish: A self regularized non-monotonic activation function",
      "id": "9374811277911686866",
      "url": "https://arxiv.org/abs/1908.08681",
      "title": "Mish: A self regularized non-monotonic activation function",
      "authors": "D Misra",
      "year": "2019",
      "cited_by": 1385,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9374811277911686866&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Detecting twenty-thousand classes using image-level supervision",
      "id": "2641915666092458000",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_21",
      "title": "Detecting twenty-thousand classes using image-level supervision",
      "authors": "X Zhou, R Girdhar, A Joulin, P Kr\u00e4henb\u00fchl\u2026",
      "year": "2022",
      "cited_by": 216,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2641915666092458000&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Sensor and sensor fusion technology in autonomous vehicles: A review",
      "id": "6847238147022651878",
      "url": "https://www.mdpi.com/1424-8220/21/6/2140",
      "title": "Sensor and sensor fusion technology in autonomous vehicles: A review",
      "authors": "DJ Yeong, G Velasco-Hernandez, J Barry, J Walsh",
      "year": "2021",
      "cited_by": 394,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6847238147022651878&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A Review of Yolo algorithm developments",
      "id": "15073015961806262305",
      "url": "https://www.sciencedirect.com/science/article/pii/S1877050922001363",
      "title": "A Review of Yolo algorithm developments",
      "authors": "P Jiang, D Ergu, F Liu, Y Cai, B Ma",
      "year": "2022",
      "cited_by": 445,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15073015961806262305&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A forest fire detection system based on ensemble learning",
      "id": "4893668343000496575",
      "url": "https://www.mdpi.com/1999-4907/12/2/217",
      "title": "A forest fire detection system based on ensemble learning",
      "authors": "R Xu, H Lin, K Lu, L Cao, Y Liu",
      "year": "2021",
      "cited_by": 359,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4893668343000496575&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Robustbench: a standardized adversarial robustness benchmark",
      "id": "2257115641228924434",
      "url": "https://arxiv.org/abs/2010.09670",
      "title": "Robustbench: a standardized adversarial robustness benchmark",
      "authors": "F Croce, M Andriushchenko, V Sehwag\u2026",
      "year": "2020",
      "cited_by": 370,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2257115641228924434&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A comparative analysis of object detection metrics with a companion open-source toolkit",
      "id": "8384042348747306199",
      "url": "https://www.mdpi.com/2079-9292/10/3/279",
      "title": "A comparative analysis of object detection metrics with a companion open-source toolkit",
      "authors": "R Padilla, WL Passos, TLB Dias, SL Netto\u2026",
      "year": "2021",
      "cited_by": 353,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8384042348747306199&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning in computer vision: A critical review of emerging techniques and application scenarios",
      "id": "2188347889974787509",
      "url": "https://www.sciencedirect.com/science/article/pii/S2666827021000670",
      "title": "Deep learning in computer vision: A critical review of emerging techniques and application scenarios",
      "authors": "J Chai, H Zeng, A Li, EWT Ngai",
      "year": "2021",
      "cited_by": 255,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2188347889974787509&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Using channel pruning-based YOLO v4 deep learning algorithm for the real-time and accurate detection of apple flowers in natural environments",
      "id": "4220770694777717094",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169920318986",
      "title": "Using channel pruning-based YOLO v4 deep learning algorithm for the real-time and accurate detection of apple flowers in natural environments",
      "authors": "D Wu, S Lv, M Jiang, H Song",
      "year": "2020",
      "cited_by": 309,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4220770694777717094&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Pointaugmenting: Cross-modal augmentation for 3d object detection",
      "id": "8949706078964164796",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PointAugmenting_Cross-Modal_Augmentation_for_3D_Object_Detection_CVPR_2021_paper.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%28ja%29&utm_medium=email&utm_source=Revue%20newsletter",
      "title": "Pointaugmenting: Cross-modal augmentation for 3d object detection",
      "authors": "C Wang, C Ma, M Zhu, X Yang",
      "year": "2021",
      "cited_by": 197,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8949706078964164796&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Inner monologue: Embodied reasoning through planning with language models",
      "id": "17957175255238019436",
      "url": "https://arxiv.org/abs/2207.05608",
      "title": "Inner monologue: Embodied reasoning through planning with language models",
      "authors": "W Huang, F Xia, T Xiao, H Chan, J Liang\u2026",
      "year": "2022",
      "cited_by": 199,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17957175255238019436&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "-IoU: A Family of Power Intersection over Union Losses for Bounding Box Regression",
      "id": "6960142602186458983",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/a8f15eda80c50adb0e71943adc8015cf-Abstract.html",
      "title": "-IoU: A Family of Power Intersection over Union Losses for Bounding Box Regression",
      "authors": "J He, S Erfani, X Ma, J Bailey\u2026",
      "year": "2021",
      "cited_by": 148,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6960142602186458983&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Face mask wearing detection algorithm based on improved YOLO-v4",
      "id": "14469340457726874491",
      "url": "https://www.mdpi.com/1424-8220/21/9/3263",
      "title": "Face mask wearing detection algorithm based on improved YOLO-v4",
      "authors": "J Yu, W Zhang",
      "year": "2021",
      "cited_by": 207,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14469340457726874491&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A small-sized object detection oriented multi-scale feature fusion approach with application to defect detection",
      "id": "1333110857552676288",
      "url": "https://ieeexplore.ieee.org/abstract/document/9720996/",
      "title": "A small-sized object detection oriented multi-scale feature fusion approach with application to defect detection",
      "authors": "N Zeng, P Wu, Z Wang, H Li, W Liu\u2026",
      "year": "2022",
      "cited_by": 166,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1333110857552676288&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Enhancing geometric factors in model learning and inference for object detection and instance segmentation",
      "id": "2870654243860368694",
      "url": "https://ieeexplore.ieee.org/abstract/document/9523600/",
      "title": "Enhancing geometric factors in model learning and inference for object detection and instance segmentation",
      "authors": "Z Zheng, P Wang, D Ren, W Liu, R Ye\u2026",
      "year": "2021",
      "cited_by": 367,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2870654243860368694&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "CNN variants for computer vision: History, architecture, application, challenges and future scope",
      "id": "14520782850205069410",
      "url": "https://www.mdpi.com/2079-9292/10/20/2470",
      "title": "CNN variants for computer vision: History, architecture, application, challenges and future scope",
      "authors": "D Bhatt, C Patel, H Talsania, J Patel, R Vaghela\u2026",
      "year": "2021",
      "cited_by": 222,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14520782850205069410&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Defrcn: Decoupled faster r-cnn for few-shot object detection",
      "id": "8856983795724243302",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Qiao_DeFRCN_Decoupled_Faster_R-CNN_for_Few-Shot_Object_Detection_ICCV_2021_paper.html",
      "title": "Defrcn: Decoupled faster r-cnn for few-shot object detection",
      "authors": "L Qiao, Y Zhao, Z Li, X Qiu, J Wu\u2026",
      "year": "2021",
      "cited_by": 138,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8856983795724243302&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Gdr-net: Geometry-guided direct regression network for monocular 6d object pose estimation",
      "id": "14463958793485183598",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Wang_GDR-Net_Geometry-Guided_Direct_Regression_Network_for_Monocular_6D_Object_Pose_CVPR_2021_paper.html",
      "title": "Gdr-net: Geometry-guided direct regression network for monocular 6d object pose estimation",
      "authors": "G Wang, F Manhardt, F Tombari\u2026",
      "year": "2021",
      "cited_by": 183,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14463958793485183598&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Gligen: Open-set grounded text-to-image generation",
      "id": "11047031223001120005",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Li_GLIGEN_Open-Set_Grounded_Text-to-Image_Generation_CVPR_2023_paper.html",
      "title": "Gligen: Open-set grounded text-to-image generation",
      "authors": "Y Li, H Liu, Q Wu, F Mu, J Yang\u2026",
      "year": "2023",
      "cited_by": 43,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11047031223001120005&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "YOLOv4-5D: An effective and efficient object detector for autonomous driving",
      "id": "10949414717109961618",
      "url": "https://ieeexplore.ieee.org/abstract/document/9374990/",
      "title": "YOLOv4-5D: An effective and efficient object detector for autonomous driving",
      "authors": "Y Cai, T Luan, H Gao, H Wang, L Chen\u2026",
      "year": "2021",
      "cited_by": 202,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10949414717109961618&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "SAR ship detection dataset (SSDD): Official release and comprehensive data analysis",
      "id": "10684080371797193170",
      "url": "https://www.mdpi.com/2072-4292/13/18/3690",
      "title": "SAR ship detection dataset (SSDD): Official release and comprehensive data analysis",
      "authors": "T Zhang, X Zhang, J Li, X Xu, B Wang, X Zhan, Y Xu\u2026",
      "year": "2021",
      "cited_by": 159,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10684080371797193170&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A fast accurate fine-grain object detection model based on YOLOv4 deep neural network",
      "id": "2381712952938130950",
      "url": "https://link.springer.com/article/10.1007/s00521-021-06651-x",
      "title": "A fast accurate fine-grain object detection model based on YOLOv4 deep neural network",
      "authors": "AM Roy, R Bose, J Bhaduri",
      "year": "2022",
      "cited_by": 132,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2381712952938130950&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Real-time object detection method based on improved YOLOv4-tiny",
      "id": "599070989090902392",
      "url": "https://arxiv.org/abs/2011.04244",
      "title": "Real-time object detection method based on improved YOLOv4-tiny",
      "authors": "Z Jiang, L Zhao, S Li, Y Jia",
      "year": "2020",
      "cited_by": 234,
      "cited_by_url": "https://scholar.google.com/scholar?cites=599070989090902392&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "State of the art in defect detection based on machine vision",
      "id": "8128999273420313759",
      "url": "https://link.springer.com/article/10.1007/s40684-021-00343-6",
      "title": "State of the art in defect detection based on machine vision",
      "authors": "Z Ren, F Fang, N Yan, Y Wu",
      "year": "2022",
      "cited_by": 174,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8128999273420313759&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Comparative analysis of deep learning image detection algorithms",
      "id": "6959485123048444799",
      "url": "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00434-w",
      "title": "Comparative analysis of deep learning image detection algorithms",
      "authors": "S Srivastava, AV Divekar\u2026",
      "year": "2021",
      "cited_by": 168,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6959485123048444799&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Real-time growth stage detection model for high degree of occultation using DenseNet-fused YOLOv4",
      "id": "15019162986849498399",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922000114",
      "title": "Real-time growth stage detection model for high degree of occultation using DenseNet-fused YOLOv4",
      "authors": "AM Roy, J Bhaduri",
      "year": "2022",
      "cited_by": 90,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15019162986849498399&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Activation functions in deep learning: A comprehensive survey and benchmark",
      "id": "14023415170451607918",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231222008426",
      "title": "Activation functions in deep learning: A comprehensive survey and benchmark",
      "authors": "SR Dubey, SK Singh, BB Chaudhuri",
      "year": "2022",
      "cited_by": 177,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14023415170451607918&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Medical image segmentation using deep learning: A survey",
      "id": "2956947656254895097",
      "url": "https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/ipr2.12419",
      "title": "Medical image segmentation using deep learning: A survey",
      "authors": "R Wang, T Lei, R Cui, B Zhang, H Meng\u2026",
      "year": "2022",
      "cited_by": 225,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2956947656254895097&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Instant-teaching: An end-to-end semi-supervised object detection framework",
      "id": "4134683771649593563",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Instant-Teaching_An_End-to-End_Semi-Supervised_Object_Detection_Framework_CVPR_2021_paper.html",
      "title": "Instant-teaching: An end-to-end semi-supervised object detection framework",
      "authors": "Q Zhou, C Yu, Z Wang, Q Qian\u2026",
      "year": "2021",
      "cited_by": 123,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4134683771649593563&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "PP-YOLO: An effective and efficient implementation of object detector",
      "id": "9683136153549357939",
      "url": "https://arxiv.org/abs/2007.12099",
      "title": "PP-YOLO: An effective and efficient implementation of object detector",
      "authors": "X Long, K Deng, G Wang, Y Zhang, Q Dang\u2026",
      "year": "2020",
      "cited_by": 226,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9683136153549357939&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A real-time detection algorithm for Kiwifruit defects based on YOLOv5",
      "id": "9631020688074423843",
      "url": "https://www.mdpi.com/2079-9292/10/14/1711",
      "title": "A real-time detection algorithm for Kiwifruit defects based on YOLOv5",
      "authors": "J Yao, J Qi, J Zhang, H Shao, J Yang, X Li",
      "year": "2021",
      "cited_by": 165,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9631020688074423843&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deepsocial: Social distancing monitoring and infection risk assessment in covid-19 pandemic",
      "id": "12262835944335888935",
      "url": "https://www.mdpi.com/2076-3417/10/21/7514",
      "title": "Deepsocial: Social distancing monitoring and infection risk assessment in covid-19 pandemic",
      "authors": "M Rezaei, M Azarmi",
      "year": "2020",
      "cited_by": 199,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12262835944335888935&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "SIoU loss: More powerful learning for bounding box regression",
      "id": "12301499295205287615",
      "url": "https://arxiv.org/abs/2205.12740",
      "title": "SIoU loss: More powerful learning for bounding box regression",
      "authors": "Z Gevorgyan",
      "year": "2022",
      "cited_by": 194,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12301499295205287615&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Real-time detection of uneaten feed pellets in underwater images for aquaculture using an improved YOLO-V4 network",
      "id": "4438492435191836535",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169921001538",
      "title": "Real-time detection of uneaten feed pellets in underwater images for aquaculture using an improved YOLO-V4 network",
      "authors": "X Hu, Y Liu, Z Zhao, J Liu, X Yang, C Sun\u2026",
      "year": "2021",
      "cited_by": 131,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4438492435191836535&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Pavement distress detection using convolutional neural networks with images captured via UAV",
      "id": "13337861536124971139",
      "url": "https://www.sciencedirect.com/science/article/pii/S0926580521004428",
      "title": "Pavement distress detection using convolutional neural networks with images captured via UAV",
      "authors": "J Zhu, J Zhong, T Ma, X Huang, W Zhang\u2026",
      "year": "2022",
      "cited_by": 90,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13337861536124971139&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Channel pruned YOLO V5s-based deep learning approach for rapid and accurate apple fruitlet detection before fruit thinning",
      "id": "12863020002569949671",
      "url": "https://www.sciencedirect.com/science/article/pii/S1537511021001999",
      "title": "Channel pruned YOLO V5s-based deep learning approach for rapid and accurate apple fruitlet detection before fruit thinning",
      "authors": "D Wang, D He",
      "year": "2021",
      "cited_by": 115,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12863020002569949671&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Object detection using YOLO: Challenges, architectural successors, datasets and applications",
      "id": "3656418176994524008",
      "url": "https://link.springer.com/article/10.1007/s11042-022-13644-y",
      "title": "Object detection using YOLO: Challenges, architectural successors, datasets and applications",
      "authors": "T Diwan, G Anirudh, JV Tembhurne",
      "year": "2023",
      "cited_by": 135,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3656418176994524008&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt",
      "id": "2452866517197292093",
      "url": "https://arxiv.org/abs/2302.09419",
      "title": "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt",
      "authors": "C Zhou, Q Li, C Li, J Yu, Y Liu, G Wang\u2026",
      "year": "2023",
      "cited_by": 118,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2452866517197292093&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "LLVIP: A visible-infrared paired dataset for low-light vision",
      "id": "15799285439221317870",
      "url": "http://openaccess.thecvf.com/content/ICCV2021W/RLQ/html/Jia_LLVIP_A_Visible-Infrared_Paired_Dataset_for_Low-Light_Vision_ICCVW_2021_paper.html",
      "title": "LLVIP: A visible-infrared paired dataset for low-light vision",
      "authors": "X Jia, C Zhu, M Li, W Tang\u2026",
      "year": "2021",
      "cited_by": 117,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15799285439221317870&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Point-cloud based 3D object detection and classification methods for self-driving applications: A survey and taxonomy",
      "id": "9207765007843851263",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253520304097",
      "title": "Point-cloud based 3D object detection and classification methods for self-driving applications: A survey and taxonomy",
      "authors": "D Fernandes, A Silva, R N\u00e9voa, C Sim\u00f5es\u2026",
      "year": "2021",
      "cited_by": 132,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9207765007843851263&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "CCTSDB 2021: a more comprehensive traffic sign detection benchmark",
      "id": "6026250830209566504",
      "url": "https://centaur.reading.ac.uk/106129",
      "title": "CCTSDB 2021: a more comprehensive traffic sign detection benchmark",
      "authors": "J Zhang, X Zou, LD Kuang, J Wang\u2026",
      "year": "2022",
      "cited_by": 69,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6026250830209566504&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Real-time polyp detection, localization and segmentation in colonoscopy using deep learning",
      "id": "11882550127852592683",
      "url": "https://ieeexplore.ieee.org/abstract/document/9369308/",
      "title": "Real-time polyp detection, localization and segmentation in colonoscopy using deep learning",
      "authors": "D Jha, S Ali, NK Tomar, HD Johansen\u2026",
      "year": "2021",
      "cited_by": 170,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11882550127852592683&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Automatic bunch detection in white grape varieties using YOLOv3, YOLOv4, and YOLOv5 deep learning algorithms",
      "id": "9014029637884314032",
      "url": "https://www.mdpi.com/2073-4395/12/2/319",
      "title": "Automatic bunch detection in white grape varieties using YOLOv3, YOLOv4, and YOLOv5 deep learning algorithms",
      "authors": "M Sozzi, S Cantalamessa, A Cogato, A Kayad\u2026",
      "year": "2022",
      "cited_by": 102,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9014029637884314032&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Twin adversarial contrastive learning for underwater image enhancement and beyond",
      "id": "3909123747085405380",
      "url": "https://ieeexplore.ieee.org/abstract/document/9832540/",
      "title": "Twin adversarial contrastive learning for underwater image enhancement and beyond",
      "authors": "R Liu, Z Jiang, S Yang, X Fan",
      "year": "2022",
      "cited_by": 82,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3909123747085405380&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Image-adaptive YOLO for object detection in adverse weather conditions",
      "id": "15281565077085720279",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/20072",
      "title": "Image-adaptive YOLO for object detection in adverse weather conditions",
      "authors": "W Liu, G Ren, R Yu, S Guo, J Zhu\u2026",
      "year": "2022",
      "cited_by": 115,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15281565077085720279&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "ViT-YOLO: Transformer-based YOLO for object detection",
      "id": "14672720829595281606",
      "url": "http://openaccess.thecvf.com/content/ICCV2021W/VisDrone/html/Zhang_ViT-YOLOTransformer-Based_YOLO_for_Object_Detection_ICCVW_2021_paper.html",
      "title": "ViT-YOLO: Transformer-based YOLO for object detection",
      "authors": "Z Zhang, X Lu, G Cao, Y Yang\u2026",
      "year": "2021",
      "cited_by": 87,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14672720829595281606&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A review on modern defect detection models using DCNNs\u2013Deep convolutional neural networks",
      "id": "7222787612695411352",
      "url": "https://www.sciencedirect.com/science/article/pii/S2090123221000643",
      "title": "A review on modern defect detection models using DCNNs\u2013Deep convolutional neural networks",
      "authors": "AA Tulbure, AA Tulbure, EH Dulf",
      "year": "2022",
      "cited_by": 118,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7222787612695411352&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning-based object detection in low-altitude UAV datasets: A survey",
      "id": "2241015688519496377",
      "url": "https://www.sciencedirect.com/science/article/pii/S0262885620301785",
      "title": "Deep learning-based object detection in low-altitude UAV datasets: A survey",
      "authors": "P Mittal, R Singh, A Sharma",
      "year": "2020",
      "cited_by": 150,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2241015688519496377&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Cddfuse: Correlation-driven dual-branch feature decomposition for multi-modality image fusion",
      "id": "15226748689642581218",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhao_CDDFuse_Correlation-Driven_Dual-Branch_Feature_Decomposition_for_Multi-Modality_Image_Fusion_CVPR_2023_paper.html",
      "title": "Cddfuse: Correlation-driven dual-branch feature decomposition for multi-modality image fusion",
      "authors": "Z Zhao, H Bai, J Zhang, Y Zhang, S Xu\u2026",
      "year": "2023",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15226748689642581218&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A vision-based social distancing and critical density detection system for COVID-19",
      "id": "16799196534333096171",
      "url": "https://www.mdpi.com/1424-8220/21/13/4608",
      "title": "A vision-based social distancing and critical density detection system for COVID-19",
      "authors": "D Yang, E Yurtsever, V Renganathan, KA Redmill\u2026",
      "year": "2021",
      "cited_by": 174,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16799196534333096171&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "YOLO5Face: why reinventing a face detector",
      "id": "9519448529520784463",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-25072-9_15",
      "title": "YOLO5Face: why reinventing a face detector",
      "authors": "D Qi, W Tan, Q Yao, J Liu",
      "year": "2022",
      "cited_by": 98,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9519448529520784463&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A detection algorithm for cherry fruits based on the improved YOLO-v4 model",
      "id": "8269996013982993565",
      "url": "https://link.springer.com/article/10.1007/s00521-021-06029-z",
      "title": "A detection algorithm for cherry fruits based on the improved YOLO-v4 model",
      "authors": "R Gai, N Chen, H Yuan",
      "year": "2023",
      "cited_by": 105,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8269996013982993565&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Computing systems for autonomous driving: State of the art and challenges",
      "id": "12292417492888691772",
      "url": "https://ieeexplore.ieee.org/abstract/document/9288755/",
      "title": "Computing systems for autonomous driving: State of the art and challenges",
      "authors": "L Liu, S Lu, R Zhong, B Wu, Y Yao\u2026",
      "year": "2020",
      "cited_by": 167,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12292417492888691772&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Detection of concealed cracks from ground penetrating radar images based on deep learning algorithm",
      "id": "3469053983010224891",
      "url": "https://www.sciencedirect.com/science/article/pii/S0950061820339532",
      "title": "Detection of concealed cracks from ground penetrating radar images based on deep learning algorithm",
      "authors": "S Li, X Gu, X Xu, D Xu, T Zhang, Z Liu\u2026",
      "year": "2021",
      "cited_by": 133,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3469053983010224891&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "VisDrone-DET2021: The vision meets drone object detection challenge results",
      "id": "15326684253758327032",
      "url": "https://openaccess.thecvf.com/content/ICCV2021W/VisDrone/html/Cao_VisDrone-DET2021_The_Vision_Meets_Drone_Object_Detection_Challenge_Results_ICCVW_2021_paper.html",
      "title": "VisDrone-DET2021: The vision meets drone object detection challenge results",
      "authors": "Y Cao, Z He, L Wang, W Wang\u2026",
      "year": "2021",
      "cited_by": 76,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15326684253758327032&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A wheat spike detection method in UAV images based on improved YOLOv5",
      "id": "11839204226610748442",
      "url": "https://www.mdpi.com/2072-4292/13/16/3095",
      "title": "A wheat spike detection method in UAV images based on improved YOLOv5",
      "authors": "J Zhao, X Zhang, J Yan, X Qiu, X Yao, Y Tian, Y Zhu\u2026",
      "year": "2021",
      "cited_by": 102,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11839204226610748442&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Improving YOLOv5 with attention mechanism for detecting boulders from planetary images",
      "id": "7244644999756957350",
      "url": "https://www.mdpi.com/2072-4292/13/18/3776",
      "title": "Improving YOLOv5 with attention mechanism for detecting boulders from planetary images",
      "authors": "L Zhu, X Geng, Z Li, C Liu",
      "year": "2021",
      "cited_by": 100,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7244644999756957350&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Occupant-density-detection based energy efficient ventilation system: Prevention of infection transmission",
      "id": "15430727510373100145",
      "url": "https://www.sciencedirect.com/science/article/pii/S0378778821001675",
      "title": "Occupant-density-detection based energy efficient ventilation system: Prevention of infection transmission",
      "authors": "J Wang, J Huang, Z Feng, SJ Cao, F Haghighat",
      "year": "2021",
      "cited_by": 113,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15430727510373100145&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A dual weighting label assignment scheme for object detection",
      "id": "2484140027818923745",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_A_Dual_Weighting_Label_Assignment_Scheme_for_Object_Detection_CVPR_2022_paper.html",
      "title": "A dual weighting label assignment scheme for object detection",
      "authors": "S Li, C He, R Li, L Zhang",
      "year": "2022",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2484140027818923745&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Hallucination improves few-shot object detection",
      "id": "10402998279197599439",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Hallucination_Improves_Few-Shot_Object_Detection_CVPR_2021_paper.html?ref=https://githubhelp.com",
      "title": "Hallucination improves few-shot object detection",
      "authors": "W Zhang, YX Wang",
      "year": "2021",
      "cited_by": 81,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10402998279197599439&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Implementing a real-time, AI-based, people detection and social distancing measuring system for Covid-19",
      "id": "16564571492344788038",
      "url": "https://link.springer.com/article/10.1007/s11554-021-01070-6",
      "title": "Implementing a real-time, AI-based, people detection and social distancing measuring system for Covid-19",
      "authors": "S Saponara, A Elhanashi, A Gagliardi",
      "year": "2021",
      "cited_by": 118,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16564571492344788038&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Cross\u2010scene pavement distress detection by a novel transfer learning framework",
      "id": "17634164049223670343",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12674",
      "title": "Cross\u2010scene pavement distress detection by a novel transfer learning framework",
      "authors": "Y Li, P Che, C Liu, D Wu, Y Du",
      "year": "2021",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17634164049223670343&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "WilDect-YOLO: An efficient and robust computer vision-based accurate object localization model for automated endangered wildlife detection",
      "id": "19561195188667465",
      "url": "https://www.sciencedirect.com/science/article/pii/S1574954122003697",
      "title": "WilDect-YOLO: An efficient and robust computer vision-based accurate object localization model for automated endangered wildlife detection",
      "authors": "AM Roy, J Bhaduri, T Kumar, K Raj",
      "year": "2023",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=19561195188667465&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A novel spatio-temporal synchronization method of roadside asynchronous MMW radar-camera for sensor fusion",
      "id": "15167698914301610121",
      "url": "https://ieeexplore.ieee.org/abstract/document/9590496/",
      "title": "A novel spatio-temporal synchronization method of roadside asynchronous MMW radar-camera for sensor fusion",
      "authors": "Y Du, B Qin, C Zhao, Y Zhu, J Cao\u2026",
      "year": "2021",
      "cited_by": 81,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15167698914301610121&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Advanced feature extraction and selection approach using deep learning and Aquila optimizer for IoT intrusion detection system",
      "id": "9817510568104192073",
      "url": "https://www.mdpi.com/1424-8220/22/1/140",
      "title": "Advanced feature extraction and selection approach using deep learning and Aquila optimizer for IoT intrusion detection system",
      "authors": "A Fatani, A Dahou, MAA Al-Qaness, S Lu, MA Elaziz",
      "year": "2021",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9817510568104192073&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "The lottery tickets hypothesis for supervised and self-supervised pre-training in computer vision models",
      "id": "9665171368816644761",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Chen_The_Lottery_Tickets_Hypothesis_for_Supervised_and_Self-Supervised_Pre-Training_in_CVPR_2021_paper.html",
      "title": "The lottery tickets hypothesis for supervised and self-supervised pre-training in computer vision models",
      "authors": "T Chen, J Frankle, S Chang, S Liu\u2026",
      "year": "2021",
      "cited_by": 101,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9665171368816644761&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A deep learning enabled multi-class plant disease detection model based on computer vision",
      "id": "15329030602586300416",
      "url": "https://www.mdpi.com/2673-2688/2/3/26",
      "title": "A deep learning enabled multi-class plant disease detection model based on computer vision",
      "authors": "AM Roy, J Bhaduri",
      "year": "2021",
      "cited_by": 83,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15329030602586300416&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "VisDrone-DET2019: The vision meets drone object detection in image challenge results",
      "id": "7085275218926344408",
      "url": "http://openaccess.thecvf.com/content_ICCVW_2019/html/VISDrone/Du_VisDrone-DET2019_The_Vision_Meets_Drone_Object_Detection_in_Image_Challenge_ICCVW_2019_paper.html",
      "title": "VisDrone-DET2019: The vision meets drone object detection in image challenge results",
      "authors": "D Du, P Zhu, L Wen, X Bian, H Lin\u2026",
      "year": "2019",
      "cited_by": 188,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7085275218926344408&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Automatic detection of pothole distress in asphalt pavement using improved convolutional neural networks",
      "id": "2700093867622300626",
      "url": "https://www.mdpi.com/2072-4292/14/16/3892",
      "title": "Automatic detection of pothole distress in asphalt pavement using improved convolutional neural networks",
      "authors": "D Wang, Z Liu, X Gu, W Wu, Y Chen, L Wang",
      "year": "2022",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2700093867622300626&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning-based detection from the perspective of small or tiny objects: A survey",
      "id": "12979999094083269078",
      "url": "https://www.sciencedirect.com/science/article/pii/S0262885622001007",
      "title": "Deep learning-based detection from the perspective of small or tiny objects: A survey",
      "authors": "K Tong, Y Wu",
      "year": "2022",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12979999094083269078&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Vision-based robotic grasping from object localization, object pose estimation to grasp estimation for parallel grippers: a review",
      "id": "12527627239009594881",
      "url": "https://link.springer.com/article/10.1007/s10462-020-09888-5",
      "title": "Vision-based robotic grasping from object localization, object pose estimation to grasp estimation for parallel grippers: a review",
      "authors": "G Du, K Wang, S Lian, K Zhao",
      "year": "2021",
      "cited_by": 259,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12527627239009594881&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "PP-YOLOv2: A practical object detector",
      "id": "16290848704501469564",
      "url": "https://arxiv.org/abs/2104.10419",
      "title": "PP-YOLOv2: A practical object detector",
      "authors": "X Huang, X Wang, W Lv, X Bai, X Long, K Deng\u2026",
      "year": "2021",
      "cited_by": 99,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16290848704501469564&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A survey of computer-aided diagnosis of lung nodules from CT scans using deep learning",
      "id": "9060832344926997444",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482521006004",
      "title": "A survey of computer-aided diagnosis of lung nodules from CT scans using deep learning",
      "authors": "Y Gu, J Chi, J Liu, L Yang, B Zhang, D Yu\u2026",
      "year": "2021",
      "cited_by": 74,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9060832344926997444&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Pvt v2: Improved baselines with pyramid vision transformer",
      "id": "1659700362637596040",
      "url": "https://link.springer.com/article/10.1007/s41095-022-0274-8",
      "title": "Pvt v2: Improved baselines with pyramid vision transformer",
      "authors": "W Wang, E Xie, X Li, DP Fan, K Song, D Liang\u2026",
      "year": "2022",
      "cited_by": 626,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1659700362637596040&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "A review on 2D instance segmentation based on deep neural networks",
      "id": "8662214348531793431",
      "url": "https://www.sciencedirect.com/science/article/pii/S0262885622000300",
      "title": "A review on 2D instance segmentation based on deep neural networks",
      "authors": "W Gu, S Bai, L Kong",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8662214348531793431&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Fairmot: On the fairness of detection and re-identification in multiple object tracking",
      "id": "17314410080623672897",
      "url": "https://link.springer.com/article/10.1007/s11263-021-01513-4",
      "title": "Fairmot: On the fairness of detection and re-identification in multiple object tracking",
      "authors": "Y Zhang, C Wang, X Wang, W Zeng, W Liu",
      "year": "2021",
      "cited_by": 810,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17314410080623672897&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Transtrack: Multiple object tracking with transformer",
      "id": "10274815087550872131",
      "url": "https://arxiv.org/abs/2012.15460",
      "title": "Transtrack: Multiple object tracking with transformer",
      "authors": "P Sun, J Cao, Y Jiang, R Zhang, E Xie, Z Yuan\u2026",
      "year": "2020",
      "cited_by": 361,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10274815087550872131&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Detco: Unsupervised contrastive learning for object detection",
      "id": "8124073977598762954",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Xie_DetCo_Unsupervised_Contrastive_Learning_for_Object_Detection_ICCV_2021_paper.html",
      "title": "Detco: Unsupervised contrastive learning for object detection",
      "authors": "E Xie, J Ding, W Wang, X Zhan, H Xu\u2026",
      "year": "2021",
      "cited_by": 257,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8124073977598762954&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Dynamic detr: End-to-end object detection with dynamic attention",
      "id": "14069730115218722114",
      "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.html?ref=https://githubhelp.com",
      "title": "Dynamic detr: End-to-end object detection with dynamic attention",
      "authors": "X Dai, Y Chen, J Yang, P Zhang\u2026",
      "year": "2021",
      "cited_by": 145,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14069730115218722114&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Anchor detr: Query design for transformer-based detector",
      "id": "977587388012773361",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/20158",
      "title": "Anchor detr: Query design for transformer-based detector",
      "authors": "Y Wang, X Zhang, T Yang, J Sun",
      "year": "2022",
      "cited_by": 171,
      "cited_by_url": "https://scholar.google.com/scholar?cites=977587388012773361&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Mpvit: Multi-path vision transformer for dense prediction",
      "id": "15814018180296500902",
      "url": "https://openaccess.thecvf.com/content/CVPR2022/html/Lee_MPViT_Multi-Path_Vision_Transformer_for_Dense_Prediction_CVPR_2022_paper.html?ref=https://githubhelp.com",
      "title": "Mpvit: Multi-path vision transformer for dense prediction",
      "authors": "Y Lee, J Kim, J Willette\u2026",
      "year": "2022",
      "cited_by": 114,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15814018180296500902&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Instances as queries",
      "id": "17436807480659026891",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Fang_Instances_As_Queries_ICCV_2021_paper.html",
      "title": "Instances as queries",
      "authors": "Y Fang, S Yang, X Wang, Y Li, C Fang\u2026",
      "year": "2021",
      "cited_by": 177,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17436807480659026891&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Global tracking transformers",
      "id": "7616713930375867128",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Global_Tracking_Transformers_CVPR_2022_paper.html",
      "title": "Global tracking transformers",
      "authors": "X Zhou, T Yin, V Koltun\u2026",
      "year": "2022",
      "cited_by": 65,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7616713930375867128&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Efficient training of visual transformers with small datasets",
      "id": "17891879498080154736",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/c81e155d85dae5430a8cee6f2242e82c-Abstract.html",
      "title": "Efficient training of visual transformers with small datasets",
      "authors": "Y Liu, E Sangineto, W Bi, N Sebe\u2026",
      "year": "2021",
      "cited_by": 111,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17891879498080154736&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Crossformer++: A versatile vision transformer hinging on cross-scale attention",
      "id": "8825090207674893811",
      "url": "https://arxiv.org/abs/2303.06908",
      "title": "Crossformer++: A versatile vision transformer hinging on cross-scale attention",
      "authors": "W Wang, W Chen, Q Qiu, L Chen, B Wu, B Lin\u2026",
      "year": "2023",
      "cited_by": 175,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8825090207674893811&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Visformer: The vision-friendly transformer",
      "id": "11825390691537168558",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Chen_Visformer_The_Vision-Friendly_Transformer_ICCV_2021_paper.html",
      "title": "Visformer: The vision-friendly transformer",
      "authors": "Z Chen, L Xie, J Niu, X Liu, L Wei\u2026",
      "year": "2021",
      "cited_by": 128,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11825390691537168558&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Shuffle transformer: Rethinking spatial shuffle for vision transformer",
      "id": "4586155361346152499",
      "url": "https://arxiv.org/abs/2106.03650",
      "title": "Shuffle transformer: Rethinking spatial shuffle for vision transformer",
      "authors": "Z Huang, Y Ben, G Luo, P Cheng, G Yu\u2026",
      "year": "2021",
      "cited_by": 131,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4586155361346152499&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Wave-vit: Unifying wavelet and transformers for visual representation learning",
      "id": "9894263145711509588",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19806-9_19",
      "title": "Wave-vit: Unifying wavelet and transformers for visual representation learning",
      "authors": "T Yao, Y Pan, Y Li, CW Ngo, T Mei",
      "year": "2022",
      "cited_by": 45,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9894263145711509588&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Cyclemlp: A mlp-like architecture for dense prediction",
      "id": "1322906163224921925",
      "url": "https://arxiv.org/abs/2107.10224",
      "title": "Cyclemlp: A mlp-like architecture for dense prediction",
      "authors": "S Chen, E Xie, C Ge, R Chen, D Liang\u2026",
      "year": "2021",
      "cited_by": 171,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1322906163224921925&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Adamixer: A fast-converging query-based object detector",
      "id": "10270081680505767341",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Gao_AdaMixer_A_Fast-Converging_Query-Based_Object_Detector_CVPR_2022_paper.html",
      "title": "Adamixer: A fast-converging query-based object detector",
      "authors": "Z Gao, L Wang, B Han, S Guo",
      "year": "2022",
      "cited_by": 56,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10270081680505767341&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "As-mlp: An axial shifted mlp architecture for vision",
      "id": "1534689713476232636",
      "url": "https://arxiv.org/abs/2107.08391",
      "title": "As-mlp: An axial shifted mlp architecture for vision",
      "authors": "D Lian, Z Yu, X Sun, S Gao",
      "year": "2021",
      "cited_by": 137,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1534689713476232636&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Oriented reppoints for aerial object detection",
      "id": "1528825781662204302",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_Oriented_RepPoints_for_Aerial_Object_Detection_CVPR_2022_paper.html",
      "title": "Oriented reppoints for aerial object detection",
      "authors": "W Li, Y Chen, K Hu, J Zhu",
      "year": "2022",
      "cited_by": 110,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1528825781662204302&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Solq: Segmenting objects by learning queries",
      "id": "1852377411269249881",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/b7087c1f4f89e63af8d46f3b20271153-Abstract.html",
      "title": "Solq: Segmenting objects by learning queries",
      "authors": "B Dong, F Zeng, T Wang, X Zhang\u2026",
      "year": "2021",
      "cited_by": 79,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1852377411269249881&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Sparse instance activation for real-time instance segmentation",
      "id": "2803945007747990107",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Cheng_Sparse_Instance_Activation_for_Real-Time_Instance_Segmentation_CVPR_2022_paper.html",
      "title": "Sparse instance activation for real-time instance segmentation",
      "authors": "T Cheng, X Wang, S Chen, W Zhang\u2026",
      "year": "2022",
      "cited_by": 50,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2803945007747990107&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Language as queries for referring video object segmentation",
      "id": "15824157200018556836",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wu_Language_As_Queries_for_Referring_Video_Object_Segmentation_CVPR_2022_paper.html",
      "title": "Language as queries for referring video object segmentation",
      "authors": "J Wu, Y Jiang, P Sun, Z Yuan\u2026",
      "year": "2022",
      "cited_by": 60,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15824157200018556836&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Grounding dino: Marrying dino with grounded pre-training for open-set object detection",
      "id": "16816930780976029141",
      "url": "https://arxiv.org/abs/2303.05499",
      "title": "Grounding dino: Marrying dino with grounded pre-training for open-set object detection",
      "authors": "S Liu, Z Zeng, T Ren, F Li, H Zhang, J Yang\u2026",
      "year": "2023",
      "cited_by": 91,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16816930780976029141&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Spatially consistent representation learning",
      "id": "9209014176820981155",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Roh_Spatially_Consistent_Representation_Learning_CVPR_2021_paper.html",
      "title": "Spatially consistent representation learning",
      "authors": "B Roh, W Shin, I Kim, S Kim",
      "year": "2021",
      "cited_by": 84,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9209014176820981155&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Dual cross-attention learning for fine-grained visual categorization and object re-identification",
      "id": "5598507831422168925",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Dual_Cross-Attention_Learning_for_Fine-Grained_Visual_Categorization_and_Object_Re-Identification_CVPR_2022_paper.html",
      "title": "Dual cross-attention learning for fine-grained visual categorization and object re-identification",
      "authors": "H Zhu, W Ke, D Li, J Liu, L Tian\u2026",
      "year": "2022",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5598507831422168925&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "What makes for end-to-end object detection?",
      "id": "17182921757850029040",
      "url": "https://proceedings.mlr.press/v139/sun21b.html?ref=https://githubhelp.com",
      "title": "What makes for end-to-end object detection?",
      "authors": "P Sun, Y Jiang, E Xie, W Shao, Z Yuan\u2026",
      "year": "2021",
      "cited_by": 94,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17182921757850029040&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Seqformer: Sequential transformer for video instance segmentation",
      "id": "17304148947425718239",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19815-1_32",
      "title": "Seqformer: Sequential transformer for video instance segmentation",
      "authors": "J Wu, Y Jiang, S Bai, W Zhang, X Bai",
      "year": "2022",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17304148947425718239&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Sgtr: End-to-end scene graph generation with transformer",
      "id": "9105314878135623559",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_SGTR_End-to-End_Scene_Graph_Generation_With_Transformer_CVPR_2022_paper.html",
      "title": "Sgtr: End-to-end scene graph generation with transformer",
      "authors": "R Li, S Zhang, X He",
      "year": "2022",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9105314878135623559&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "GraphFPN: Graph feature pyramid network for object detection",
      "id": "15674075284060635644",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zhao_GraphFPN_Graph_Feature_Pyramid_Network_for_Object_Detection_ICCV_2021_paper.html",
      "title": "GraphFPN: Graph feature pyramid network for object detection",
      "authors": "G Zhao, W Ge, Y Yu",
      "year": "2021",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15674075284060635644&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Dual vision transformer",
      "id": "5425241495538385765",
      "url": "https://ieeexplore.ieee.org/abstract/document/10105499/",
      "title": "Dual vision transformer",
      "authors": "T Yao, Y Li, Y Pan, Y Wang\u2026",
      "year": "2023",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5425241495538385765&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "An improved swin transformer-based model for remote sensing object detection and instance segmentation",
      "id": "8214441654299017644",
      "url": "https://www.mdpi.com/2072-4292/13/23/4779",
      "title": "An improved swin transformer-based model for remote sensing object detection and instance segmentation",
      "authors": "X Xu, Z Feng, C Cao, M Li, J Wu, Z Wu, Y Shang, S Ye",
      "year": "2021",
      "cited_by": 62,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8214441654299017644&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "RFLA: Gaussian receptive field based label assignment for tiny object detection",
      "id": "16490222600712608071",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_31",
      "title": "RFLA: Gaussian receptive field based label assignment for tiny object detection",
      "authors": "C Xu, J Wang, W Yang, H Yu, L Yu, GS Xia",
      "year": "2022",
      "cited_by": 31,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16490222600712608071&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Coda: A real-world road corner case dataset for object detection in autonomous driving",
      "id": "12517757346728435037",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19839-7_24",
      "title": "Coda: A real-world road corner case dataset for object detection in autonomous driving",
      "authors": "K Li, K Chen, H Wang, L Hong, C Ye, J Han\u2026",
      "year": "2022",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12517757346728435037&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Vision-centric bev perception: A survey",
      "id": "16726572534871887028",
      "url": "https://arxiv.org/abs/2208.02797",
      "title": "Vision-centric bev perception: A survey",
      "authors": "Y Ma, T Wang, X Bai, H Yang, Y Hou, Y Wang\u2026",
      "year": "2022",
      "cited_by": 40,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16726572534871887028&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Progressive end-to-end object detection in crowded scenes",
      "id": "17039945862035123188",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Progressive_End-to-End_Object_Detection_in_Crowded_Scenes_CVPR_2022_paper.html",
      "title": "Progressive end-to-end object detection in crowded scenes",
      "authors": "A Zheng, Y Zhang, X Zhang, X Qi\u2026",
      "year": "2022",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17039945862035123188&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Yolo-firi: Improved yolov5 for infrared image object detection",
      "id": "16118065418965645421",
      "url": "https://ieeexplore.ieee.org/abstract/document/9576741/",
      "title": "Yolo-firi: Improved yolov5 for infrared image object detection",
      "authors": "S Li, Y Li, Y Li, M Li, X Xu",
      "year": "2021",
      "cited_by": 85,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16118065418965645421&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "More convnets in the 2020s: Scaling up kernels beyond 51x51 using sparsity",
      "id": "10812290025544152705",
      "url": "https://arxiv.org/abs/2207.03620",
      "title": "More convnets in the 2020s: Scaling up kernels beyond 51x51 using sparsity",
      "authors": "S Liu, T Chen, X Chen, X Chen, Q Xiao, B Wu\u2026",
      "year": "2022",
      "cited_by": 54,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10812290025544152705&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Towards data-efficient detection transformers",
      "id": "18413127590718653617",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_6",
      "title": "Towards data-efficient detection transformers",
      "authors": "W Wang, J Zhang, Y Cao, Y Shen, D Tao",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18413127590718653617&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Swintextspotter: Scene text spotting via better synergy between text detection and text recognition",
      "id": "6989674085539462525",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Huang_SwinTextSpotter_Scene_Text_Spotting_via_Better_Synergy_Between_Text_Detection_CVPR_2022_paper.html",
      "title": "Swintextspotter: Scene text spotting via better synergy between text detection and text recognition",
      "authors": "M Huang, Y Liu, Z Peng, C Liu, D Lin\u2026",
      "year": "2022",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6989674085539462525&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Temporally efficient vision transformer for video instance segmentation",
      "id": "12121457393934602812",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.html",
      "title": "Temporally efficient vision transformer for video instance segmentation",
      "authors": "S Yang, X Wang, Y Li, Y Fang, J Fang\u2026",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12121457393934602812&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Dynamic graph message passing networks",
      "id": "4303557091610097560",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_Dynamic_Graph_Message_Passing_Networks_CVPR_2020_paper.html",
      "title": "Dynamic graph message passing networks",
      "authors": "L Zhang, D Xu, A Arnab\u2026",
      "year": "2020",
      "cited_by": 119,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4303557091610097560&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Efficient detr: improving end-to-end object detector with dense prior",
      "id": "932093633137744803",
      "url": "https://arxiv.org/abs/2104.01318",
      "title": "Efficient detr: improving end-to-end object detector with dense prior",
      "authors": "Z Yao, J Ai, B Li, C Zhang",
      "year": "2021",
      "cited_by": 65,
      "cited_by_url": "https://scholar.google.com/scholar?cites=932093633137744803&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Dense learning based semi-supervised object detection",
      "id": "3247052077202185212",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Chen_Dense_Learning_Based_Semi-Supervised_Object_Detection_CVPR_2022_paper.html",
      "title": "Dense learning based semi-supervised object detection",
      "authors": "B Chen, P Li, X Chen, B Wang\u2026",
      "year": "2022",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3247052077202185212&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "End-to-end video object detection with spatial-temporal transformers",
      "id": "4349671636320753508",
      "url": "https://dl.acm.org/doi/abs/10.1145/3474085.3475285",
      "title": "End-to-end video object detection with spatial-temporal transformers",
      "authors": "L He, Q Zhou, X Li, L Niu, G Cheng, X Li, W Liu\u2026",
      "year": "2021",
      "cited_by": 65,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4349671636320753508&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "TransVOD: end-to-end video object detection with spatial-temporal transformers",
      "id": "18249743012593625562",
      "url": "https://ieeexplore.ieee.org/abstract/document/9960850/",
      "title": "TransVOD: end-to-end video object detection with spatial-temporal transformers",
      "authors": "Q Zhou, X Li, L He, Y Yang, G Cheng\u2026",
      "year": "2022",
      "cited_by": 54,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18249743012593625562&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Panoptic-partformer: Learning a unified model for panoptic part segmentation",
      "id": "11513198882440237429",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19812-0_42",
      "title": "Panoptic-partformer: Learning a unified model for panoptic part segmentation",
      "authors": "X Li, S Xu, Y Yang, G Cheng, Y Tong, D Tao",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11513198882440237429&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Group detr: Fast training convergence with decoupled one-to-many label assignment",
      "id": "17487592973794344865",
      "url": "https://arxiv.org/abs/2207.13085",
      "title": "Group detr: Fast training convergence with decoupled one-to-many label assignment",
      "authors": "Q Chen, X Chen, G Zeng, J Wang",
      "year": "2022",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17487592973794344865&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Fashionformer: A simple, effective and unified baseline for human fashion segmentation and recognition",
      "id": "14517707013240558642",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19836-6_31",
      "title": "Fashionformer: A simple, effective and unified baseline for human fashion segmentation and recognition",
      "authors": "S Xu, X Li, J Wang, G Cheng, Y Tong, D Tao",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14517707013240558642&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Efficient video instance segmentation via tracklet query and proposal",
      "id": "17247852947552745742",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wu_Efficient_Video_Instance_Segmentation_via_Tracklet_Query_and_Proposal_CVPR_2022_paper.html",
      "title": "Efficient video instance segmentation via tracklet query and proposal",
      "authors": "J Wu, S Yarram, H Liang, T Lan\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17247852947552745742&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Watch only once: An end-to-end video action detection framework",
      "id": "10634998792902995201",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Chen_Watch_Only_Once_An_End-to-End_Video_Action_Detection_Framework_ICCV_2021_paper.html",
      "title": "Watch only once: An end-to-end video action detection framework",
      "authors": "S Chen, P Sun, E Xie, C Ge, J Wu\u2026",
      "year": "2021",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10634998792902995201&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Beyond self-attention: External attention using two linear layers for visual tasks",
      "id": "10884589459641707712",
      "url": "https://ieeexplore.ieee.org/abstract/document/9912362/",
      "title": "Beyond self-attention: External attention using two linear layers for visual tasks",
      "authors": "MH Guo, ZN Liu, TJ Mu, SM Hu",
      "year": "2022",
      "cited_by": 279,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10884589459641707712&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Conquer: Query contrast voxel-detr for 3d object detection",
      "id": "7760609266921230809",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhu_ConQueR_Query_Contrast_Voxel-DETR_for_3D_Object_Detection_CVPR_2023_paper.html",
      "title": "Conquer: Query contrast voxel-detr for 3d object detection",
      "authors": "B Zhu, Z Wang, S Shi, H Xu\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7760609266921230809&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Ship detection in SAR images based on multi-scale feature extraction and adaptive feature fusion",
      "id": "88270295968296053",
      "url": "https://www.mdpi.com/2072-4292/14/3/755",
      "title": "Ship detection in SAR images based on multi-scale feature extraction and adaptive feature fusion",
      "authors": "K Zhou, M Zhang, H Wang, J Tan",
      "year": "2022",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=88270295968296053&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Scan: Cross domain object detection with semantic conditioned adaptation",
      "id": "16950256669529671184",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/20031",
      "title": "Scan: Cross domain object detection with semantic conditioned adaptation",
      "authors": "W Li, X Liu, X Yao, Y Yuan",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16950256669529671184&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Towards weakly-supervised text spotting using a multi-task transformer",
      "id": "9968669049352955949",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Kittenplon_Towards_Weakly-Supervised_Text_Spotting_Using_a_Multi-Task_Transformer_CVPR_2022_paper.html",
      "title": "Towards weakly-supervised text spotting using a multi-task transformer",
      "authors": "Y Kittenplon, I Lavi, S Fogel, Y Bar\u2026",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9968669049352955949&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Boosting R-CNN: Reweighting R-CNN samples by RPN's error for underwater object detection",
      "id": "13477863999935708391",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231223001200",
      "title": "Boosting R-CNN: Reweighting R-CNN samples by RPN's error for underwater object detection",
      "authors": "P Song, P Li, L Dai, T Wang, Z Chen",
      "year": "2023",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13477863999935708391&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Scale-aware modulation meet transformer",
      "id": "17378883393050270914",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.html",
      "title": "Scale-aware modulation meet transformer",
      "authors": "W Lin, Z Wu, J Chen, J Huang\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17378883393050270914&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Effective adaptation in multi-task co-training for unified autonomous driving",
      "id": "9787590110579187483",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/7c319b62e2257b34cb0e1040ced2e007-Abstract-Conference.html",
      "title": "Effective adaptation in multi-task co-training for unified autonomous driving",
      "authors": "X Liang, Y Wu, J Han, H Xu, C Xu\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9787590110579187483&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Open vocabulary object detection with pseudo bounding-box labels",
      "id": "1851007110321536767",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20080-9_16",
      "title": "Open vocabulary object detection with pseudo bounding-box labels",
      "authors": "M Gao, C Xing, JC Niebles, J Li, R Xu, W Liu\u2026",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1851007110321536767&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Anchor DETR: Query design for transformer-based object detection",
      "id": "16309997597335697837",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/download/20158/version/18455/19917",
      "title": "Anchor DETR: Query design for transformer-based object detection",
      "authors": "Y Wang, X Zhang, T Yang, J Sun",
      "year": "2021",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16309997597335697837&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Continual object detection via prototypical task correlation guided gating mechanism",
      "id": "12695099468525271301",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yang_Continual_Object_Detection_via_Prototypical_Task_Correlation_Guided_Gating_Mechanism_CVPR_2022_paper.html",
      "title": "Continual object detection via prototypical task correlation guided gating mechanism",
      "authors": "B Yang, X Deng, H Shi, C Li, G Zhang\u2026",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12695099468525271301&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Inspro: Propagating instance query and proposal for online video instance segmentation",
      "id": "4296423219815701790",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/7ac19fdcdf4f311f3e3ef2e7ef4784d7-Abstract-Conference.html",
      "title": "Inspro: Propagating instance query and proposal for online video instance segmentation",
      "authors": "F He, H Zhang, N Gao, J Jia, Y Shan\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4296423219815701790&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Beyond fixation: Dynamic window visual transformer",
      "id": "3432971989735915692",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Ren_Beyond_Fixation_Dynamic_Window_Visual_Transformer_CVPR_2022_paper.html",
      "title": "Beyond fixation: Dynamic window visual transformer",
      "authors": "P Ren, C Li, G Wang, Y Xiao, Q Du\u2026",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3432971989735915692&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Dense Distinct Query for End-to-End Object Detection",
      "id": "1436259968817456407",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Dense_Distinct_Query_for_End-to-End_Object_Detection_CVPR_2023_paper.html",
      "title": "Dense Distinct Query for End-to-End Object Detection",
      "authors": "S Zhang, X Wang, J Wang, J Pang\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1436259968817456407&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Adapt: Efficient multi-agent trajectory prediction with adaptation",
      "id": "9723387705619955263",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Aydemir_ADAPT_Efficient_Multi-Agent_Trajectory_Prediction_with_Adaptation_ICCV_2023_paper.html",
      "title": "Adapt: Efficient multi-agent trajectory prediction with adaptation",
      "authors": "G Aydemir, AK Akan, F G\u00fcney",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9723387705619955263&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Polyphonicformer: unified query learning for depth-aware video panoptic segmentation",
      "id": "7127843590064680446",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19812-0_34",
      "title": "Polyphonicformer: unified query learning for depth-aware video panoptic segmentation",
      "authors": "H Yuan, X Li, Y Yang, G Cheng, J Zhang\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7127843590064680446&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Towards Efficient Use of Multi-Scale Features in Transformer-Based Object Detectors",
      "id": "10574929869960191427",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Towards_Efficient_Use_of_Multi-Scale_Features_in_Transformer-Based_Object_Detectors_CVPR_2023_paper.html",
      "title": "Towards Efficient Use of Multi-Scale Features in Transformer-Based Object Detectors",
      "authors": "G Zhang, Z Luo, Z Tian, J Zhang\u2026",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10574929869960191427&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Visual recognition by request",
      "id": "15062612983329704744",
      "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Tang_Visual_Recognition_by_Request_CVPR_2023_paper.html",
      "title": "Visual recognition by request",
      "authors": "C Tang, L Xie, X Zhang, X Hu\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15062612983329704744&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Lctr: On awakening the local continuity of transformer for weakly supervised object localization",
      "id": "15276230008077862137",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/19918",
      "title": "Lctr: On awakening the local continuity of transformer for weakly supervised object localization",
      "authors": "Z Chen, C Wang, Y Wang, G Jiang, Y Shen\u2026",
      "year": "2022",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15276230008077862137&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "An empirical study of adder neural networks for object detection",
      "id": "7534423418396554672",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/37693cfc748049e45d87b8c7d8b9aacd-Abstract.html",
      "title": "An empirical study of adder neural networks for object detection",
      "authors": "X Chen, C Xu, M Dong, C Xu\u2026",
      "year": "2021",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7534423418396554672&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Dynamic sparse r-cnn",
      "id": "2519052790779402959",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Hong_Dynamic_Sparse_R-CNN_CVPR_2022_paper.html",
      "title": "Dynamic sparse r-cnn",
      "authors": "Q Hong, F Liu, D Li, J Liu, L Tian\u2026",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2519052790779402959&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Ship detection based on deep learning using SAR imagery: a systematic literature review",
      "id": "4642654167987856293",
      "url": "https://link.springer.com/article/10.1007/s00500-022-07522-w",
      "title": "Ship detection based on deep learning using SAR imagery: a systematic literature review",
      "authors": "M Yasir, W Jianhua, X Mingming, S Hui, Z Zhe\u2026",
      "year": "2023",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4642654167987856293&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Unsupervised continual learning for gradually varying domains",
      "id": "12417942115314361068",
      "url": "http://openaccess.thecvf.com/content/CVPR2022W/CLVision/html/Taufique_Unsupervised_Continual_Learning_for_Gradually_Varying_Domains_CVPRW_2022_paper.html",
      "title": "Unsupervised continual learning for gradually varying domains",
      "authors": "AMN Taufique, CS Jahan\u2026",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12417942115314361068&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Structured sparse r-cnn for direct scene graph generation",
      "id": "3862789668091273745",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Teng_Structured_Sparse_R-CNN_for_Direct_Scene_Graph_Generation_CVPR_2022_paper.html",
      "title": "Structured sparse r-cnn for direct scene graph generation",
      "authors": "Y Teng, L Wang",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3862789668091273745&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 17
    },
    {
      "label": "Distance-IoU loss: Faster and better learning for bounding box regression",
      "id": "13055852169785823920",
      "url": "https://aaai.org/ojs/index.php/AAAI/article/view/6999",
      "title": "Distance-IoU loss: Faster and better learning for bounding box regression",
      "authors": "Z Zheng, P Wang, W Liu, J Li, R Ye, D Ren",
      "year": "2020",
      "cited_by": 2222,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13055852169785823920&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "SE-SSD: Self-ensembling single-stage object detector from point cloud",
      "id": "10191050231224943760",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Zheng_SE-SSD_Self-Ensembling_Single-Stage_Object_Detector_From_Point_Cloud_CVPR_2021_paper.html",
      "title": "SE-SSD: Self-ensembling single-stage object detector from point cloud",
      "authors": "W Zheng, W Tang, L Jiang\u2026",
      "year": "2021",
      "cited_by": 261,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10191050231224943760&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "R3det: Refined single-stage detector with feature refinement for rotating object",
      "id": "12829565963573040312",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/16426",
      "title": "R3det: Refined single-stage detector with feature refinement for rotating object",
      "authors": "X Yang, J Yan, Z Feng, T He",
      "year": "2021",
      "cited_by": 574,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12829565963573040312&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A survey and performance evaluation of deep learning methods for small object detection",
      "id": "17430652832439326106",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417421000439",
      "title": "A survey and performance evaluation of deep learning methods for small object detection",
      "authors": "Y Liu, P Sun, N Wergeles, Y Shang",
      "year": "2021",
      "cited_by": 262,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17430652832439326106&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Focal and efficient IOU loss for accurate bounding box regression",
      "id": "7988129384525076421",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231222009018",
      "title": "Focal and efficient IOU loss for accurate bounding box regression",
      "authors": "YF Zhang, W Ren, Z Zhang, Z Jia, L Wang, T Tan",
      "year": "2022",
      "cited_by": 359,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7988129384525076421&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Actionformer: Localizing moments of actions with transformers",
      "id": "7487171131395966182",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19772-7_29",
      "title": "Actionformer: Localizing moments of actions with transformers",
      "authors": "CL Zhang, J Wu, Y Li",
      "year": "2022",
      "cited_by": 130,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7487171131395966182&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Rethinking rotated object detection with gaussian wasserstein distance loss",
      "id": "9458084216549029781",
      "url": "https://proceedings.mlr.press/v139/yang21l",
      "title": "Rethinking rotated object detection with gaussian wasserstein distance loss",
      "authors": "X Yang, J Yan, Q Ming, W Wang\u2026",
      "year": "2021",
      "cited_by": 214,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9458084216549029781&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Learning high-precision bounding box for rotated object detection via kullback-leibler divergence",
      "id": "15795399494869889077",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/98f13708210194c475687be6106a3b84-Abstract.html",
      "title": "Learning high-precision bounding box for rotated object detection via kullback-leibler divergence",
      "authors": "X Yang, X Yang, J Yang, Q Ming\u2026",
      "year": "2021",
      "cited_by": 170,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15795399494869889077&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Imbalance problems in object detection: A review",
      "id": "8762454778937977659",
      "url": "https://ieeexplore.ieee.org/abstract/document/9042296/",
      "title": "Imbalance problems in object detection: A review",
      "authors": "K Oksuz, BC Cam, S Kalkan\u2026",
      "year": "2020",
      "cited_by": 373,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8762454778937977659&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Rethinking the competition between detection and reid in multiobject tracking",
      "id": "9575584799952236610",
      "url": "https://ieeexplore.ieee.org/abstract/document/9756236/",
      "title": "Rethinking the competition between detection and reid in multiobject tracking",
      "authors": "C Liang, Z Zhang, X Zhou, B Li, S Zhu\u2026",
      "year": "2022",
      "cited_by": 175,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9575584799952236610&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Automatic recognition of pavement cracks from combined GPR B-scan and C-scan images using multiscale feature fusion deep neural networks",
      "id": "13728347746290657939",
      "url": "https://www.sciencedirect.com/science/article/pii/S0926580522005684",
      "title": "Automatic recognition of pavement cracks from combined GPR B-scan and C-scan images using multiscale feature fusion deep neural networks",
      "authors": "Z Liu, X Gu, J Chen, D Wang, Y Chen, L Wang",
      "year": "2023",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13728347746290657939&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Artificial intelligence-assisted colorimetric lateral flow immunoassay for sensitive and quantitative detection of COVID-19 neutralizing antibody",
      "id": "13222542974410927057",
      "url": "https://www.sciencedirect.com/science/article/pii/S0956566322004894",
      "title": "Artificial intelligence-assisted colorimetric lateral flow immunoassay for sensitive and quantitative detection of COVID-19 neutralizing antibody",
      "authors": "H Tong, C Cao, M You, S Han, Z Liu, Y Xiao\u2026",
      "year": "2022",
      "cited_by": 43,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13222542974410927057&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Deep learning based online metallic surface defect detection method for wire and arc additive manufacturing",
      "id": "1654562328017701106",
      "url": "https://www.sciencedirect.com/science/article/pii/S0736584522001521",
      "title": "Deep learning based online metallic surface defect detection method for wire and arc additive manufacturing",
      "authors": "W Li, H Zhang, G Wang, G Xiong, M Zhao, G Li\u2026",
      "year": "2023",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1654562328017701106&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Real-time defects detection for apple sorting using NIR cameras with pruning-based YOLOV4 network",
      "id": "13553623797919213094",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922000321",
      "title": "Real-time defects detection for apple sorting using NIR cameras with pruning-based YOLOV4 network",
      "authors": "S Fan, X Liang, W Huang, VJ Zhang, Q Pang\u2026",
      "year": "2022",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13553623797919213094&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Real-time vehicle detection based on improved yolo v5",
      "id": "13816665854585781255",
      "url": "https://www.mdpi.com/2071-1050/14/19/12274",
      "title": "Real-time vehicle detection based on improved yolo v5",
      "authors": "Y Zhang, Z Guo, J Wu, Y Tian, H Tang, X Guo",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13816665854585781255&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "DCC-CenterNet: A rapid detection method for steel surface defects",
      "id": "5767715645618653984",
      "url": "https://www.sciencedirect.com/science/article/pii/S0263224121011210",
      "title": "DCC-CenterNet: A rapid detection method for steel surface defects",
      "authors": "R Tian, M Jia",
      "year": "2022",
      "cited_by": 58,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5767715645618653984&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Object detection from UAV thermal infrared images and videos using YOLO models",
      "id": "15818286087987627641",
      "url": "https://www.sciencedirect.com/science/article/pii/S1569843222001145",
      "title": "Object detection from UAV thermal infrared images and videos using YOLO models",
      "authors": "C Jiang, H Ren, X Ye, J Zhu, H Zeng, Y Nan\u2026",
      "year": "2022",
      "cited_by": 40,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15818286087987627641&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Improved YOLOv5 network for real-time multi-scale traffic sign detection",
      "id": "16403067771390791423",
      "url": "https://link.springer.com/article/10.1007/s00521-022-08077-5",
      "title": "Improved YOLOv5 network for real-time multi-scale traffic sign detection",
      "authors": "J Wang, Y Chen, Z Dong, M Gao",
      "year": "2023",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16403067771390791423&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A new spatial-oriented object detection framework for remote sensing images",
      "id": "5845461691817459977",
      "url": "https://ieeexplore.ieee.org/abstract/document/9611255/",
      "title": "A new spatial-oriented object detection framework for remote sensing images",
      "authors": "D Yu, S Ji",
      "year": "2021",
      "cited_by": 60,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5845461691817459977&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Improved YOLOv4 marine target detection combined with CBAM",
      "id": "14373500618604811887",
      "url": "https://www.mdpi.com/2073-8994/13/4/623",
      "title": "Improved YOLOv4 marine target detection combined with CBAM",
      "authors": "H Fu, G Song, Y Wang",
      "year": "2021",
      "cited_by": 87,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14373500618604811887&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Real-time railroad track components inspection based on the improved YOLOv4 framework",
      "id": "14509614284638697910",
      "url": "https://www.sciencedirect.com/science/article/pii/S0926580521000479",
      "title": "Real-time railroad track components inspection based on the improved YOLOv4 framework",
      "authors": "F Guo, Y Qian, Y Shi",
      "year": "2021",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14509614284638697910&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Interior attention-aware network for infrared small target detection",
      "id": "2822888602570219347",
      "url": "https://ieeexplore.ieee.org/abstract/document/9745054/",
      "title": "Interior attention-aware network for infrared small target detection",
      "authors": "K Wang, S Du, C Liu, Z Cao",
      "year": "2022",
      "cited_by": 58,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2822888602570219347&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A novel nonlocal-aware pyramid and multiscale multitask refinement detector for object detection in remote sensing images",
      "id": "2124912804095600023",
      "url": "https://ieeexplore.ieee.org/abstract/document/9364888/",
      "title": "A novel nonlocal-aware pyramid and multiscale multitask refinement detector for object detection in remote sensing images",
      "authors": "Z Huang, W Li, XG Xia, X Wu, Z Cai\u2026",
      "year": "2021",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2124912804095600023&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "BiFA-YOLO: A novel YOLO-based method for arbitrary-oriented ship detection in high-resolution SAR images",
      "id": "16401671466632432676",
      "url": "https://www.mdpi.com/2072-4292/13/21/4209",
      "title": "BiFA-YOLO: A novel YOLO-based method for arbitrary-oriented ship detection in high-resolution SAR images",
      "authors": "Z Sun, X Leng, Y Lei, B Xiong, K Ji, G Kuang",
      "year": "2021",
      "cited_by": 63,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16401671466632432676&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "VerSe: a vertebrae labelling and segmentation benchmark for multi-detector CT images",
      "id": "18286028574106509245",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841521002127",
      "title": "VerSe: a vertebrae labelling and segmentation benchmark for multi-detector CT images",
      "authors": "A Sekuboyina, ME Husseini, A Bayat, M L\u00f6ffler\u2026",
      "year": "2021",
      "cited_by": 123,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18286028574106509245&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Objectbox: From centers to boxes for anchor-free object detection",
      "id": "7167680945390018074",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20080-9_23",
      "title": "Objectbox: From centers to boxes for anchor-free object detection",
      "authors": "M Zand, A Etemad, M Greenspan",
      "year": "2022",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7167680945390018074&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Pillarnet: Real-time and high-performance pillar-based 3d object detection",
      "id": "4019899772206366950",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20080-9_3",
      "title": "Pillarnet: Real-time and high-performance pillar-based 3d object detection",
      "authors": "G Shi, R Li, C Ma",
      "year": "2022",
      "cited_by": 35,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4019899772206366950&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "An improved Yolov5 real-time detection method for small objects captured by UAV",
      "id": "3815706068371757718",
      "url": "https://link.springer.com/article/10.1007/s00500-021-06407-8",
      "title": "An improved Yolov5 real-time detection method for small objects captured by UAV",
      "authors": "W Zhan, C Sun, M Wang, J She, Y Zhang, Z Zhang\u2026",
      "year": "2022",
      "cited_by": 63,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3815706068371757718&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Multi-scale ship detection from SAR and optical imagery via a more accurate YOLOv3",
      "id": "3273783590798016013",
      "url": "https://ieeexplore.ieee.org/abstract/document/9448440/",
      "title": "Multi-scale ship detection from SAR and optical imagery via a more accurate YOLOv3",
      "authors": "Z Hong, T Yang, X Tong, Y Zhang\u2026",
      "year": "2021",
      "cited_by": 59,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3273783590798016013&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Sample and computation redistribution for efficient face detection",
      "id": "249972322094479786",
      "url": "https://arxiv.org/abs/2105.04714",
      "title": "Sample and computation redistribution for efficient face detection",
      "authors": "J Guo, J Deng, A Lattas, S Zafeiriou",
      "year": "2021",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=249972322094479786&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Learning to track objects from unlabeled videos",
      "id": "7697764778571254929",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zheng_Learning_To_Track_Objects_From_Unlabeled_Videos_ICCV_2021_paper.html",
      "title": "Learning to track objects from unlabeled videos",
      "authors": "J Zheng, C Ma, H Peng, X Yang",
      "year": "2021",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7697764778571254929&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A lightweight detector based on attention mechanism for aluminum strip surface defect detection",
      "id": "16919329449044452538",
      "url": "https://www.sciencedirect.com/science/article/pii/S0166361521001925",
      "title": "A lightweight detector based on attention mechanism for aluminum strip surface defect detection",
      "authors": "MA Zhuxi, Y Li, M Huang, Q Huang, J Cheng\u2026",
      "year": "2022",
      "cited_by": 41,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16919329449044452538&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Tinaface: Strong but simple baseline for face detection",
      "id": "6421431120514564979",
      "url": "https://arxiv.org/abs/2011.13183",
      "title": "Tinaface: Strong but simple baseline for face detection",
      "authors": "Y Zhu, H Cai, S Zhang, C Wang, Y Xiong",
      "year": "2020",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6421431120514564979&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Dbcface: Towards pure convolutional neural network face detection",
      "id": "13529499341139137951",
      "url": "https://ieeexplore.ieee.org/abstract/document/9438673/",
      "title": "Dbcface: Towards pure convolutional neural network face detection",
      "authors": "X Li, S Lai, X Qian",
      "year": "2021",
      "cited_by": 55,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13529499341139137951&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Optimized YOLOv3 algorithm and its application in traffic flow detections",
      "id": "15464155576948087293",
      "url": "https://www.mdpi.com/2076-3417/10/9/3079",
      "title": "Optimized YOLOv3 algorithm and its application in traffic flow detections",
      "authors": "YQ Huang, JC Zheng, SD Sun, CF Yang, J Liu",
      "year": "2020",
      "cited_by": 95,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15464155576948087293&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Multi-scale ship detection algorithm based on a lightweight neural network for spaceborne SAR images",
      "id": "14962706247913538159",
      "url": "https://www.mdpi.com/2072-4292/14/5/1149",
      "title": "Multi-scale ship detection algorithm based on a lightweight neural network for spaceborne SAR images",
      "authors": "S Liu, W Kong, X Chen, M Xu, M Yasir, L Zhao, J Li",
      "year": "2022",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14962706247913538159&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "DefectTR: End-to-end defect detection for sewage networks using a transformer",
      "id": "7855712559170638610",
      "url": "https://www.sciencedirect.com/science/article/pii/S0950061822002744",
      "title": "DefectTR: End-to-end defect detection for sewage networks using a transformer",
      "authors": "LM Dang, H Wang, Y Li, TN Nguyen, H Moon",
      "year": "2022",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7855712559170638610&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Refining yolov4 for vehicle detection",
      "id": "302515988675284467",
      "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3628439",
      "title": "Refining yolov4 for vehicle detection",
      "authors": "P Mahto, P Garg, P Seth, J Panda",
      "year": "2020",
      "cited_by": 79,
      "cited_by_url": "https://scholar.google.com/scholar?cites=302515988675284467&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Insulator faults detection in aerial images from high-voltage transmission lines based on deep learning model",
      "id": "17326028169687643062",
      "url": "https://www.mdpi.com/2076-3417/11/10/4647",
      "title": "Insulator faults detection in aerial images from high-voltage transmission lines based on deep learning model",
      "authors": "C Liu, Y Wu, J Liu, Z Sun, H Xu",
      "year": "2021",
      "cited_by": 50,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17326028169687643062&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "The KFIoU loss for rotated object detection",
      "id": "4612145705765974530",
      "url": "https://arxiv.org/abs/2201.12558",
      "title": "The KFIoU loss for rotated object detection",
      "authors": "X Yang, Y Zhou, G Zhang, J Yang, W Wang\u2026",
      "year": "2022",
      "cited_by": 56,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4612145705765974530&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Deep learning for SAR ship detection: Past, present and future",
      "id": "6077963581280858299",
      "url": "https://www.mdpi.com/2072-4292/14/11/2712",
      "title": "Deep learning for SAR ship detection: Past, present and future",
      "authors": "J Li, C Xu, H Su, L Gao, T Wang",
      "year": "2022",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6077963581280858299&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A deep learning-based hybrid framework for object detection and recognition in autonomous driving",
      "id": "6155236788302466355",
      "url": "https://ieeexplore.ieee.org/abstract/document/9238023/",
      "title": "A deep learning-based hybrid framework for object detection and recognition in autonomous driving",
      "authors": "Y Li, H Wang, LM Dang, TN Nguyen, D Han\u2026",
      "year": "2020",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6155236788302466355&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Deep learning for computational cytology: A survey",
      "id": "4790015723049709885",
      "url": "https://www.sciencedirect.com/science/article/pii/S136184152200319X",
      "title": "Deep learning for computational cytology: A survey",
      "authors": "H Jiang, Y Zhou, Y Lin, RCK Chan, J Liu, H Chen",
      "year": "2022",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4790015723049709885&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Drone vs. bird detection: Deep learning algorithms and results from a grand challenge",
      "id": "4059997502371762707",
      "url": "https://www.mdpi.com/1424-8220/21/8/2824",
      "title": "Drone vs. bird detection: Deep learning algorithms and results from a grand challenge",
      "authors": "A Coluccia, A Fascista, A Schumann, L Sommer\u2026",
      "year": "2021",
      "cited_by": 59,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4059997502371762707&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "A small attentional YOLO model for landslide detection from satellite remote sensing images",
      "id": "5682759315963442168",
      "url": "https://link.springer.com/article/10.1007/s10346-021-01694-6",
      "title": "A small attentional YOLO model for landslide detection from satellite remote sensing images",
      "authors": "L Cheng, J Li, P Duan, M Wang",
      "year": "2021",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5682759315963442168&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Vehicle detection from aerial images using deep learning: A comparative study",
      "id": "17354835527964479444",
      "url": "https://www.mdpi.com/2079-9292/10/7/820",
      "title": "Vehicle detection from aerial images using deep learning: A comparative study",
      "authors": "A Ammar, A Koubaa, M Ahmed, A Saad, B Benjdira",
      "year": "2021",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17354835527964479444&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Apple detection in complex scene using the improved YOLOv4 model",
      "id": "13938085636022527711",
      "url": "https://www.mdpi.com/2073-4395/11/3/476",
      "title": "Apple detection in complex scene using the improved YOLOv4 model",
      "authors": "L Wu, J Ma, Y Zhao, H Liu",
      "year": "2021",
      "cited_by": 50,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13938085636022527711&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "YOLO-ACN: Focusing on small target and occluded object detection",
      "id": "4094576052109847144",
      "url": "https://ieeexplore.ieee.org/abstract/document/9303478/",
      "title": "YOLO-ACN: Focusing on small target and occluded object detection",
      "authors": "Y Li, S Li, H Du, L Chen, D Zhang, Y Li",
      "year": "2020",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4094576052109847144&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Localization distillation for dense object detection",
      "id": "10745444013023171384",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.html",
      "title": "Localization distillation for dense object detection",
      "authors": "Z Zheng, R Ye, P Wang, D Ren\u2026",
      "year": "2022",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10745444013023171384&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Rethinking IoU-based optimization for single-stage 3D object detection",
      "id": "6927002374951805343",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_32",
      "title": "Rethinking IoU-based optimization for single-stage 3D object detection",
      "authors": "H Sheng, S Cai, N Zhao, B Deng, J Huang\u2026",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6927002374951805343&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 3
    },
    {
      "label": "Vision-language pre-training: Basics, recent advances, and future trends",
      "id": "5562955281835677624",
      "url": "https://www.nowpublishers.com/article/Details/CGV-105",
      "title": "Vision-language pre-training: Basics, recent advances, and future trends",
      "authors": "Z Gan, L Li, C Li, L Wang, Z Liu\u2026",
      "year": "2022",
      "cited_by": 56,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5562955281835677624&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Simple open-vocabulary object detection",
      "id": "8448388555539304854",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20080-9_42",
      "title": "Simple open-vocabulary object detection",
      "authors": "M Minderer, A Gritsenko, A Stone, M Neumann\u2026",
      "year": "2022",
      "cited_by": 120,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8448388555539304854&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Glipv2: Unifying localization and vision-language understanding",
      "id": "4160517527641475312",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/ea370419760b421ce12e3082eb2ae1a8-Abstract-Conference.html",
      "title": "Glipv2: Unifying localization and vision-language understanding",
      "authors": "H Zhang, P Zhang, X Hu, YC Chen\u2026",
      "year": "2022",
      "cited_by": 93,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4160517527641475312&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Large ai models in health informatics: Applications, challenges, and the future",
      "id": "2958442793928445860",
      "url": "https://ieeexplore.ieee.org/abstract/document/10261199/",
      "title": "Large ai models in health informatics: Applications, challenges, and the future",
      "authors": "J Qiu, L Li, J Sun, J Peng, P Shi\u2026",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2958442793928445860&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Bridging the gap between object and image-level representations for open-vocabulary detection",
      "id": "10156380014983934707",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/dabf612543b97ea9c8f46d058d33cf74-Abstract-Conference.html",
      "title": "Bridging the gap between object and image-level representations for open-vocabulary detection",
      "authors": "H Bangalath, M Maaz, MU Khattak\u2026",
      "year": "2022",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10156380014983934707&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Unified-io: A unified model for vision, language, and multi-modal tasks",
      "id": "1828958259233079068",
      "url": "https://arxiv.org/abs/2206.08916",
      "title": "Unified-io: A unified model for vision, language, and multi-modal tasks",
      "authors": "J Lu, C Clark, R Zellers, R Mottaghi\u2026",
      "year": "2022",
      "cited_by": 133,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1828958259233079068&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Generalized decoding for pixel, image, and language",
      "id": "9556534593478071448",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zou_Generalized_Decoding_for_Pixel_Image_and_Language_CVPR_2023_paper.html",
      "title": "Generalized decoding for pixel, image, and language",
      "authors": "X Zou, ZY Dou, J Yang, Z Gan, L Li\u2026",
      "year": "2023",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9556534593478071448&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Detclip: Dictionary-enriched visual-concept paralleled pre-training for open-world detection",
      "id": "2013709511789422934",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/3ba960559212691be13fa81d9e5e0047-Abstract-Conference.html",
      "title": "Detclip: Dictionary-enriched visual-concept paralleled pre-training for open-world detection",
      "authors": "L Yao, J Han, Y Wen, X Liang, D Xu\u2026",
      "year": "2022",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2013709511789422934&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Test-time prompt tuning for zero-shot generalization in vision-language models",
      "id": "213109028691722316",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/5bf2b802e24106064dc547ae9283bb0c-Abstract-Conference.html",
      "title": "Test-time prompt tuning for zero-shot generalization in vision-language models",
      "authors": "M Shu, W Nie, DA Huang, Z Yu\u2026",
      "year": "2022",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=213109028691722316&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Visual instruction tuning",
      "id": "9083483030705185424",
      "url": "https://arxiv.org/abs/2304.08485",
      "title": "Visual instruction tuning",
      "authors": "H Liu, C Li, Q Wu, YJ Lee",
      "year": "2023",
      "cited_by": 178,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9083483030705185424&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Open-vocabulary panoptic segmentation with text-to-image diffusion models",
      "id": "8163168166663635565",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Xu_Open-Vocabulary_Panoptic_Segmentation_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.html",
      "title": "Open-vocabulary panoptic segmentation with text-to-image diffusion models",
      "authors": "J Xu, S Liu, A Vahdat, W Byeon\u2026",
      "year": "2023",
      "cited_by": 43,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8163168166663635565&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "ULIP: Learning a unified representation of language, images, and point clouds for 3D understanding",
      "id": "477874232529254013",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Gao_ULIP_Learning_a_Unified_Representation_of_Language_Images_and_Point_CVPR_2023_paper.html",
      "title": "ULIP: Learning a unified representation of language, images, and point clouds for 3D understanding",
      "authors": "L Xue, M Gao, C Xing, R Mart\u00edn-Mart\u00edn\u2026",
      "year": "2023",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=477874232529254013&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Elevater: A benchmark and toolkit for evaluating language-augmented visual models",
      "id": "14173651844217137684",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/3c4688b6a76f25f2311daa0d75a58f1a-Abstract-Datasets_and_Benchmarks.html",
      "title": "Elevater: A benchmark and toolkit for evaluating language-augmented visual models",
      "authors": "C Li, H Liu, L Li, P Zhang, J Aneja\u2026",
      "year": "2022",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14173651844217137684&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Coarse-to-fine vision-language pre-training with fusion in the backbone",
      "id": "7539527092820284785",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/d4b6ccf3acd6ccbc1093e093df345ba2-Abstract-Conference.html",
      "title": "Coarse-to-fine vision-language pre-training with fusion in the backbone",
      "authors": "ZY Dou, A Kamath, Z Gan, P Zhang\u2026",
      "year": "2022",
      "cited_by": 45,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7539527092820284785&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Segclip: Patch aggregation with learnable centers for open-vocabulary semantic segmentation",
      "id": "10493115215078116970",
      "url": "https://proceedings.mlr.press/v202/luo23a.html",
      "title": "Segclip: Patch aggregation with learnable centers for open-vocabulary semantic segmentation",
      "authors": "H Luo, J Bao, Y Wu, X He, T Li",
      "year": "2023",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10493115215078116970&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Uni-perceiver v2: A generalist model for large-scale vision and vision-language tasks",
      "id": "2135826005582191986",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Li_Uni-Perceiver_v2_A_Generalist_Model_for_Large-Scale_Vision_and_Vision-Language_CVPR_2023_paper.html",
      "title": "Uni-perceiver v2: A generalist model for large-scale vision and vision-language tasks",
      "authors": "H Li, J Zhu, X Jiang, X Zhu, H Li\u2026",
      "year": "2023",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2135826005582191986&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Fine-grained semantically aligned vision-language pre-training",
      "id": "238317474783907025",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/2fb4be70fc9668e9ec2c71b34fb127d4-Abstract-Conference.html",
      "title": "Fine-grained semantically aligned vision-language pre-training",
      "authors": "J Li, X He, L Wei, L Qian, L Zhu, L Xie\u2026",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=238317474783907025&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "K-lite: Learning transferable visual models with external knowledge",
      "id": "5712399572413041920",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/63fef0802863f47775c3563e18cbba17-Abstract-Conference.html",
      "title": "K-lite: Learning transferable visual models with external knowledge",
      "authors": "S Shen, C Li, X Hu, Y Xie, J Yang\u2026",
      "year": "2022",
      "cited_by": 40,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5712399572413041920&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "A simple framework for open-vocabulary segmentation and detection",
      "id": "4463177057029404685",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Zhang_A_Simple_Framework_for_Open-Vocabulary_Segmentation_and_Detection_ICCV_2023_paper.html",
      "title": "A simple framework for open-vocabulary segmentation and detection",
      "authors": "H Zhang, F Li, X Zou, S Liu, C Li\u2026",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4463177057029404685&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Zero-shot temporal action detection via vision-language prompting",
      "id": "527701684105539342",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20062-5_39",
      "title": "Zero-shot temporal action detection via vision-language prompting",
      "authors": "S Nag, X Zhu, YZ Song, T Xiang",
      "year": "2022",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=527701684105539342&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Training-free structured diffusion guidance for compositional text-to-image synthesis",
      "id": "11009706863402152282",
      "url": "https://arxiv.org/abs/2212.05032",
      "title": "Training-free structured diffusion guidance for compositional text-to-image synthesis",
      "authors": "W Feng, X He, TJ Fu, V Jampani, A Akula\u2026",
      "year": "2022",
      "cited_by": 67,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11009706863402152282&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Multi-modal knowledge graph construction and application: A survey",
      "id": "427793634810618701",
      "url": "https://ieeexplore.ieee.org/abstract/document/9961954/",
      "title": "Multi-modal knowledge graph construction and application: A survey",
      "authors": "X Zhu, Z Li, X Wang, X Jiang, P Sun\u2026",
      "year": "2022",
      "cited_by": 62,
      "cited_by_url": "https://scholar.google.com/scholar?cites=427793634810618701&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Vid2seq: Large-scale pretraining of a visual language model for dense video captioning",
      "id": "3710797496089968926",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Yang_Vid2Seq_Large-Scale_Pretraining_of_a_Visual_Language_Model_for_Dense_CVPR_2023_paper.html",
      "title": "Vid2seq: Large-scale pretraining of a visual language model for dense video captioning",
      "authors": "A Yang, A Nagrani, PH Seo, A Miech\u2026",
      "year": "2023",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3710797496089968926&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Exploring clip for assessing the look and feel of images",
      "id": "16719721271879905477",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25353",
      "title": "Exploring clip for assessing the look and feel of images",
      "authors": "J Wang, KCK Chan, CC Loy",
      "year": "2023",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16719721271879905477&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Vipergpt: Visual inference via python execution for reasoning",
      "id": "4650814090908712272",
      "url": "https://arxiv.org/abs/2303.08128",
      "title": "Vipergpt: Visual inference via python execution for reasoning",
      "authors": "D Sur\u00eds, S Menon, C Vondrick",
      "year": "2023",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4650814090908712272&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Unitab: Unifying text and box outputs for grounded vision-language modeling",
      "id": "4803373243514933274",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20059-5_30",
      "title": "Unitab: Unifying text and box outputs for grounded vision-language modeling",
      "authors": "Z Yang, Z Gan, J Wang, X Hu, F Ahmed, Z Liu\u2026",
      "year": "2022",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4803373243514933274&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "The unreasonable effectiveness of CLIP features for image captioning: an experimental analysis",
      "id": "13480193018115242663",
      "url": "https://openaccess.thecvf.com/content/CVPR2022W/MULA/html/Barraco_The_Unreasonable_Effectiveness_of_CLIP_Features_for_Image_Captioning_An_CVPRW_2022_paper.html",
      "title": "The unreasonable effectiveness of CLIP features for image captioning: an experimental analysis",
      "authors": "M Barraco, M Cornia, S Cascianelli\u2026",
      "year": "2022",
      "cited_by": 32,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13480193018115242663&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "X-detr: A versatile architecture for instance-wise vision-language tasks",
      "id": "8802764110576830272",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20059-5_17",
      "title": "X-detr: A versatile architecture for instance-wise vision-language tasks",
      "authors": "Z Cai, G Kwon, A Ravichandran, E Bas, Z Tu\u2026",
      "year": "2022",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8802764110576830272&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Revive: Regional visual representation matters in knowledge-based visual question answering",
      "id": "15826539500910476875",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/44956951349095f74492a5471128a7e0-Abstract-Conference.html",
      "title": "Revive: Regional visual representation matters in knowledge-based visual question answering",
      "authors": "Y Lin, Y Xie, D Chen, Y Xu, C Zhu\u2026",
      "year": "2022",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15826539500910476875&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Rlip: Relational language-image pre-training for human-object interaction detection",
      "id": "15237439848602268466",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/f37347375d8b54e3203e5d24aeb6c58c-Abstract-Conference.html",
      "title": "Rlip: Relational language-image pre-training for human-object interaction detection",
      "authors": "H Yuan, J Jiang, S Albanie, T Feng\u2026",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15237439848602268466&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Multimodality helps unimodality: Cross-modal few-shot learning with multimodal models",
      "id": "11416070587823639118",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Lin_Multimodality_Helps_Unimodality_Cross-Modal_Few-Shot_Learning_With_Multimodal_Models_CVPR_2023_paper.html",
      "title": "Multimodality helps unimodality: Cross-modal few-shot learning with multimodal models",
      "authors": "Z Lin, S Yu, Z Kuang, D Pathak\u2026",
      "year": "2023",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11416070587823639118&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Learning open-vocabulary semantic segmentation models from natural language supervision",
      "id": "1637260800010177981",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Xu_Learning_Open-Vocabulary_Semantic_Segmentation_Models_From_Natural_Language_Supervision_CVPR_2023_paper.html",
      "title": "Learning open-vocabulary semantic segmentation models from natural language supervision",
      "authors": "J Xu, J Hou, Y Zhang, R Feng\u2026",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1637260800010177981&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Open-vocabulary panoptic segmentation with maskclip",
      "id": "10981280129508603338",
      "url": "https://arxiv.org/abs/2208.08984",
      "title": "Open-vocabulary panoptic segmentation with maskclip",
      "authors": "Z Ding, J Wang, Z Tu",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10981280129508603338&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Detecting everything in the open world: Towards universal object detection",
      "id": "4328967688191824247",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wang_Detecting_Everything_in_the_Open_World_Towards_Universal_Object_Detection_CVPR_2023_paper.html",
      "title": "Detecting everything in the open world: Towards universal object detection",
      "authors": "Z Wang, Y Li, X Chen, SN Lim\u2026",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4328967688191824247&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Aligning bag of regions for open-vocabulary object detection",
      "id": "7638029543193686772",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wu_Aligning_Bag_of_Regions_for_Open-Vocabulary_Object_Detection_CVPR_2023_paper.html",
      "title": "Aligning bag of regions for open-vocabulary object detection",
      "authors": "S Wu, W Zhang, S Jin, W Liu\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7638029543193686772&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Partslip: Low-shot part segmentation for 3d point clouds via pretrained image-language models",
      "id": "13377052506571091555",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Liu_PartSLIP_Low-Shot_Part_Segmentation_for_3D_Point_Clouds_via_Pretrained_CVPR_2023_paper.html",
      "title": "Partslip: Low-shot part segmentation for 3d point clouds via pretrained image-language models",
      "authors": "M Liu, Y Zhu, H Cai, S Han, Z Ling\u2026",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13377052506571091555&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Scenecomposer: Any-level semantic image synthesis",
      "id": "1437976452746021768",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zeng_SceneComposer_Any-Level_Semantic_Image_Synthesis_CVPR_2023_paper.html",
      "title": "Scenecomposer: Any-level semantic image synthesis",
      "authors": "Y Zeng, Z Lin, J Zhang, Q Liu\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1437976452746021768&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Tarvis: A unified approach for target-based video segmentation",
      "id": "6353566274637563919",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Athar_TarViS_A_Unified_Approach_for_Target-Based_Video_Segmentation_CVPR_2023_paper.html",
      "title": "Tarvis: A unified approach for target-based video segmentation",
      "authors": "A Athar, A Hermans, J Luiten\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6353566274637563919&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Coupalign: Coupling word-pixel with sentence-mask alignments for referring image segmentation",
      "id": "10393073040573897009",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/5e773d319e310f1e4d695159484143b8-Abstract-Conference.html",
      "title": "Coupalign: Coupling word-pixel with sentence-mask alignments for referring image segmentation",
      "authors": "Z Zhang, Y Zhu, J Liu, X Liang\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10393073040573897009&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Capdet: Unifying dense captioning and open-world detection pretraining",
      "id": "8912529817908967060",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Long_CapDet_Unifying_Dense_Captioning_and_Open-World_Detection_Pretraining_CVPR_2023_paper.html",
      "title": "Capdet: Unifying dense captioning and open-world detection pretraining",
      "authors": "Y Long, Y Wen, J Han, H Xu, P Ren\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8912529817908967060&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Mixgen: A new multi-modal data augmentation",
      "id": "6499513093496013030",
      "url": "https://openaccess.thecvf.com/content/WACV2023W/Pretrain/html/Hao_MixGen_A_New_Multi-Modal_Data_Augmentation_WACVW_2023_paper.html",
      "title": "Mixgen: A new multi-modal data augmentation",
      "authors": "X Hao, Y Zhu, S Appalaraju, A Zhang\u2026",
      "year": "2023",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6499513093496013030&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Detclipv2: Scalable open-vocabulary object detection pre-training via word-region alignment",
      "id": "12164426444376333064",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Yao_DetCLIPv2_Scalable_Open-Vocabulary_Object_Detection_Pre-Training_via_Word-Region_Alignment_CVPR_2023_paper.html",
      "title": "Detclipv2: Scalable open-vocabulary object detection pre-training via word-region alignment",
      "authors": "L Yao, J Han, X Liang, D Xu\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12164426444376333064&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Task residual for tuning vision-language models",
      "id": "12516751945568333636",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Yu_Task_Residual_for_Tuning_Vision-Language_Models_CVPR_2023_paper.html",
      "title": "Task residual for tuning vision-language models",
      "authors": "T Yu, Z Lu, X Jin, Z Chen\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12516751945568333636&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Policy Adaptation From Foundation Model Feedback",
      "id": "4093024291231214911",
      "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Ge_Policy_Adaptation_From_Foundation_Model_Feedback_CVPR_2023_paper.html",
      "title": "Policy Adaptation From Foundation Model Feedback",
      "authors": "Y Ge, A Macaluso, LE Li, P Luo\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4093024291231214911&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Large-scale multi-modal pre-trained models: A comprehensive survey",
      "id": "8402450993508627791",
      "url": "https://link.springer.com/article/10.1007/s11633-022-1410-8",
      "title": "Large-scale multi-modal pre-trained models: A comprehensive survey",
      "authors": "X Wang, G Chen, G Qian, P Gao, XY Wei\u2026",
      "year": "2023",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8402450993508627791&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual Grounding",
      "id": "17253288657998487561",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wu_EDA_Explicit_Text-Decoupling_and_Dense_Alignment_for_3D_Visual_Grounding_CVPR_2023_paper.html",
      "title": "EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual Grounding",
      "authors": "Y Wu, X Cheng, R Zhang, Z Cheng\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17253288657998487561&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Blind image quality assessment via vision-language correspondence: A multitask learning perspective",
      "id": "17311003549850461359",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Blind_Image_Quality_Assessment_via_Vision-Language_Correspondence_A_Multitask_Learning_CVPR_2023_paper.html",
      "title": "Blind image quality assessment via vision-language correspondence: A multitask learning perspective",
      "authors": "W Zhang, G Zhai, Y Wei, X Yang\u2026",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17311003549850461359&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning",
      "id": "12473981189594605407",
      "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Kamath_A_New_Path_Scaling_Vision-and-Language_Navigation_With_Synthetic_Instructions_and_CVPR_2023_paper.html",
      "title": "A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning",
      "authors": "A Kamath, P Anderson, S Wang\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12473981189594605407&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Bottom up top down detection transformers for language grounding in images and point clouds",
      "id": "5975344897755588707",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20059-5_24",
      "title": "Bottom up top down detection transformers for language grounding in images and point clouds",
      "authors": "A Jain, N Gkanatsios, I Mediratta\u2026",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5975344897755588707&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Distilling Large Vision-Language Model with Out-of-Distribution Generalizability",
      "id": "11304746998376087883",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Li_Distilling_Large_Vision-Language_Model_with_Out-of-Distribution_Generalizability_ICCV_2023_paper.html",
      "title": "Distilling Large Vision-Language Model with Out-of-Distribution Generalizability",
      "authors": "X Li, Y Fang, M Liu, Z Ling, Z Tu\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11304746998376087883&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Detection hub: Unifying object detection datasets via query adaptation on language embedding",
      "id": "347260239260204132",
      "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Meng_Detection_Hub_Unifying_Object_Detection_Datasets_via_Query_Adaptation_on_CVPR_2023_paper.html",
      "title": "Detection hub: Unifying object detection datasets via query adaptation on language embedding",
      "authors": "L Meng, X Dai, Y Chen, P Zhang\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=347260239260204132&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Internchat: Solving vision-centric tasks by interacting with chatbots beyond language",
      "id": "11224588046887428191",
      "url": "https://arxiv.org/abs/2305.05662",
      "title": "Internchat: Solving vision-centric tasks by interacting with chatbots beyond language",
      "authors": "Z Liu, Y He, W Wang, W Wang, Y Wang, S Chen\u2026",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11224588046887428191&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Review of large vision models and visual prompt engineering",
      "id": "6014107160773218396",
      "url": "https://arxiv.org/abs/2307.00855",
      "title": "Review of large vision models and visual prompt engineering",
      "authors": "J Wang, Z Liu, L Zhao, Z Wu, C Ma, S Yu, H Dai\u2026",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6014107160773218396&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Contrast with Reconstruct: Contrastive 3D Representation Learning Guided by Generative Pretraining",
      "id": "15281327127593550121",
      "url": "https://arxiv.org/abs/2302.02318",
      "title": "Contrast with Reconstruct: Contrastive 3D Representation Learning Guided by Generative Pretraining",
      "authors": "Z Qi, R Dong, G Fan, Z Ge, X Zhang, K Ma\u2026",
      "year": "2023",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15281327127593550121&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Learning object-language alignments for open-vocabulary object detection",
      "id": "2811646611673890603",
      "url": "https://arxiv.org/abs/2211.14843",
      "title": "Learning object-language alignments for open-vocabulary object detection",
      "authors": "C Lin, P Sun, Y Jiang, P Luo, L Qu, G Haffari\u2026",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2811646611673890603&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Write and paint: Generative vision-language models are unified modal learners",
      "id": "12439397764083500705",
      "url": "https://openreview.net/forum?id=HgQR0mXQ1_a",
      "title": "Write and paint: Generative vision-language models are unified modal learners",
      "authors": "S Diao, W Zhou, X Zhang, J Wang",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12439397764083500705&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "xGQA: Cross-lingual visual question answering",
      "id": "5897644011303594318",
      "url": "https://arxiv.org/abs/2109.06082",
      "title": "xGQA: Cross-lingual visual question answering",
      "authors": "J Pfeiffer, G Geigle, A Kamath, JMO Steitz\u2026",
      "year": "2021",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5897644011303594318&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Dq-detr: Dual query detection transformer for phrase extraction and grounding",
      "id": "8565593079230529362",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25261",
      "title": "Dq-detr: Dual query detection transformer for phrase extraction and grounding",
      "authors": "S Liu, S Huang, F Li, H Zhang, Y Liang, H Su\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8565593079230529362&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Transferable decoding with visual entities for zero-shot image captioning",
      "id": "3496963086485613469",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.html",
      "title": "Transferable decoding with visual entities for zero-shot image captioning",
      "authors": "J Fei, T Wang, J Zhang, Z He\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3496963086485613469&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Accelerating vision-language pretraining with free language modeling",
      "id": "7990405874739376119",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wang_Accelerating_Vision-Language_Pretraining_With_Free_Language_Modeling_CVPR_2023_paper.html",
      "title": "Accelerating vision-language pretraining with free language modeling",
      "authors": "T Wang, Y Ge, F Zheng, R Cheng\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7990405874739376119&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "CLIP the Gap: A Single Domain Generalization Approach for Object Detection",
      "id": "14743366429652248033",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Vidit_CLIP_the_Gap_A_Single_Domain_Generalization_Approach_for_Object_CVPR_2023_paper.html",
      "title": "CLIP the Gap: A Single Domain Generalization Approach for Object Detection",
      "authors": "V Vidit, M Engilberge\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14743366429652248033&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Medical image understanding with pretrained vision language models: A comprehensive study",
      "id": "10883123266865516659",
      "url": "https://arxiv.org/abs/2209.15517",
      "title": "Medical image understanding with pretrained vision language models: A comprehensive study",
      "authors": "Z Qin, H Yi, Q Lao, K Li",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10883123266865516659&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Zero-shot Generative Model Adaptation via Image-specific Prompt Learning",
      "id": "3817102158084191521",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Guo_Zero-Shot_Generative_Model_Adaptation_via_Image-Specific_Prompt_Learning_CVPR_2023_paper.html",
      "title": "Zero-shot Generative Model Adaptation via Image-specific Prompt Learning",
      "authors": "J Guo, C Wang, Y Wu, E Zhang\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3817102158084191521&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Regionplc: Regional point-language contrastive learning for open-world 3d scene understanding",
      "id": "17782492311519284315",
      "url": "https://arxiv.org/abs/2304.00962",
      "title": "Regionplc: Regional point-language contrastive learning for open-world 3d scene understanding",
      "authors": "J Yang, R Ding, Z Wang, X Qi",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17782492311519284315&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations",
      "id": "10132989367820823432",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Yang_Improving_Visual_Grounding_by_Encouraging_Consistent_Gradient-Based_Explanations_CVPR_2023_paper.html",
      "title": "Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations",
      "authors": "Z Yang, K Kafle, F Dernoncourt\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10132989367820823432&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving",
      "id": "13594362999251312694",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.html",
      "title": "Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving",
      "authors": "M Najibi, J Ji, Y Zhou, CR Qi, X Yan\u2026",
      "year": "2023",
      "modularity": 10
    },
    {
      "label": "Comclip: Training-free compositional image and text matching",
      "id": "5126083329506829425",
      "url": "https://arxiv.org/abs/2211.13854",
      "title": "Comclip: Training-free compositional image and text matching",
      "authors": "K Jiang, X He, R Xu, XE Wang",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5126083329506829425&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "V3det: Vast vocabulary visual detection dataset",
      "id": "841216030252728204",
      "url": "https://arxiv.org/abs/2304.03752",
      "title": "V3det: Vast vocabulary visual detection dataset",
      "authors": "J Wang, P Zhang, T Chu, Y Cao, Y Zhou, T Wu\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=841216030252728204&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Segment Every Reference Object in Spatial and Temporal Spaces",
      "id": "8BD3FPNAIHoJ",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Wu_Segment_Every_Reference_Object_in_Spatial_and_Temporal_Spaces_ICCV_2023_paper.html",
      "title": "Segment Every Reference Object in Spatial and Temporal Spaces",
      "authors": "J Wu, Y Jiang, B Yan, H Lu\u2026",
      "year": "2023",
      "modularity": 10
    },
    {
      "label": "You Need Multiple Exiting: Dynamic Early Exiting for Accelerating Unified Vision Language Model",
      "id": "12075572838672919294",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Tang_You_Need_Multiple_Exiting_Dynamic_Early_Exiting_for_Accelerating_Unified_CVPR_2023_paper.html",
      "title": "You Need Multiple Exiting: Dynamic Early Exiting for Accelerating Unified Vision Language Model",
      "authors": "S Tang, Y Wang, Z Kong, T Zhang\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12075572838672919294&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Punifiedner: a prompting-based unified ner system for diverse datasets",
      "id": "11630631256493667109",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/26564",
      "title": "Punifiedner: a prompting-based unified ner system for diverse datasets",
      "authors": "J Lu, R Zhao, B Mac Namee, F Tan",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11630631256493667109&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "A data-scalable transformer for medical image segmentation: architecture, model efficiency, and benchmark",
      "id": "8636762778479383554",
      "url": "https://arxiv.org/abs/2203.00131",
      "title": "A data-scalable transformer for medical image segmentation: architecture, model efficiency, and benchmark",
      "authors": "Y Gao, M Zhou, D Liu, Z Yan, S Zhang\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8636762778479383554&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "Are Multimodal Models Robust to Image and Text Perturbations?",
      "id": "8814192339048828786",
      "url": "https://arxiv.org/abs/2212.08044",
      "title": "Are Multimodal Models Robust to Image and Text Perturbations?",
      "authors": "J Qiu, Y Zhu, X Shi, F Wenzel, Z Tang, D Zhao\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8814192339048828786&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 10
    },
    {
      "label": "SLAN: Self-Locator Aided Network for Vision-Language Understanding",
      "id": "b5DIgD2ZqeQJ",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_SLAN_Self-Locator_Aided_Network_for_Vision-Language_Understanding_ICCV_2023_paper.html",
      "title": "SLAN: Self-Locator Aided Network for Vision-Language Understanding",
      "authors": "JT Zhai, Q Zhang, T Wu, XY Chen\u2026",
      "year": "2023",
      "modularity": 10
    },
    {
      "label": "Mvitv2: Improved multiscale vision transformers for classification and detection",
      "id": "1273811038957334386",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_MViTv2_Improved_Multiscale_Vision_Transformers_for_Classification_and_Detection_CVPR_2022_paper.html",
      "title": "Mvitv2: Improved multiscale vision transformers for classification and detection",
      "authors": "Y Li, CY Wu, H Fan, K Mangalam\u2026",
      "year": "2022",
      "cited_by": 310,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1273811038957334386&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Masked feature prediction for self-supervised visual pre-training",
      "id": "12617218192144474322",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.html",
      "title": "Masked feature prediction for self-supervised visual pre-training",
      "authors": "C Wei, H Fan, S Xie, CY Wu, A Yuille\u2026",
      "year": "2022",
      "cited_by": 357,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12617218192144474322&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Masked autoencoders as spatiotemporal learners",
      "id": "5215096183189163093",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/e97d1081481a4017df96b51be31001d3-Abstract-Conference.html",
      "title": "Masked autoencoders as spatiotemporal learners",
      "authors": "C Feichtenhofer, Y Li, K He",
      "year": "2022",
      "cited_by": 193,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5215096183189163093&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Volo: Vision outlooker for visual recognition",
      "id": "17757348919061164318",
      "url": "https://ieeexplore.ieee.org/abstract/document/9888055/",
      "title": "Volo: Vision outlooker for visual recognition",
      "authors": "L Yuan, Q Hou, Z Jiang, J Feng\u2026",
      "year": "2022",
      "cited_by": 192,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17757348919061164318&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Efficientformer: Vision transformers at mobilenet speed",
      "id": "12692106295877813680",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/5452ad8ee6ea6e7dc41db1cbd31ba0b8-Abstract-Conference.html",
      "title": "Efficientformer: Vision transformers at mobilenet speed",
      "authors": "Y Li, G Yuan, Y Wen, J Hu\u2026",
      "year": "2022",
      "cited_by": 90,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12692106295877813680&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Expanding language-image pretrained models for general video recognition",
      "id": "1144066736404687657",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19772-7_1",
      "title": "Expanding language-image pretrained models for general video recognition",
      "authors": "B Ni, H Peng, M Chen, S Zhang, G Meng, J Fu\u2026",
      "year": "2022",
      "cited_by": 93,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1144066736404687657&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Memvit: Memory-augmented multiscale vision transformer for efficient long-term video recognition",
      "id": "12972864106896201781",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wu_MeMViT_Memory-Augmented_Multiscale_Vision_Transformer_for_Efficient_Long-Term_Video_Recognition_CVPR_2022_paper.html",
      "title": "Memvit: Memory-augmented multiscale vision transformer for efficient long-term video recognition",
      "authors": "CY Wu, Y Li, K Mangalam, H Fan\u2026",
      "year": "2022",
      "cited_by": 86,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12972864106896201781&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "St-adapter: Parameter-efficient image-to-video transfer learning",
      "id": "15930910090552432609",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/a92e9165b22d4456fc6d87236e04c266-Abstract-Conference.html",
      "title": "St-adapter: Parameter-efficient image-to-video transfer learning",
      "authors": "J Pan, Z Lin, X Zhu, J Shao, H Li",
      "year": "2022",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15930910090552432609&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Frozen clip models are efficient video learners",
      "id": "16057670792750577500",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19833-5_23",
      "title": "Frozen clip models are efficient video learners",
      "authors": "Z Lin, S Geng, R Zhang, P Gao, G de Melo\u2026",
      "year": "2022",
      "cited_by": 63,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16057670792750577500&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Rethinking vision transformers for mobilenet size and speed",
      "id": "3876751087281584278",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Li_Rethinking_Vision_Transformers_for_MobileNet_Size_and_Speed_ICCV_2023_paper.html",
      "title": "Rethinking vision transformers for mobilenet size and speed",
      "authors": "Y Li, J Hu, Y Wen, G Evangelidis\u2026",
      "year": "2023",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3876751087281584278&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Benchmarking detection transfer learning with vision transformers",
      "id": "467066746241725706",
      "url": "https://arxiv.org/abs/2111.11429",
      "title": "Benchmarking detection transfer learning with vision transformers",
      "authors": "Y Li, S Xie, X Chen, P Dollar, K He\u2026",
      "year": "2021",
      "cited_by": 94,
      "cited_by_url": "https://scholar.google.com/scholar?cites=467066746241725706&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Videomae v2: Scaling video masked autoencoders with dual masking",
      "id": "5506925343943935516",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wang_VideoMAE_V2_Scaling_Video_Masked_Autoencoders_With_Dual_Masking_CVPR_2023_paper.html",
      "title": "Videomae v2: Scaling video masked autoencoders with dual masking",
      "authors": "L Wang, B Huang, Z Zhao, Z Tong\u2026",
      "year": "2023",
      "cited_by": 31,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5506925343943935516&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "CoBEVT: Cooperative bird's eye view semantic segmentation with sparse transformers",
      "id": "2000389979125404276",
      "url": "https://arxiv.org/abs/2207.02202",
      "title": "CoBEVT: Cooperative bird's eye view semantic segmentation with sparse transformers",
      "authors": "R Xu, Z Tu, H Xiang, W Shao, B Zhou, J Ma",
      "year": "2022",
      "cited_by": 66,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2000389979125404276&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Masked autoencoders that listen",
      "id": "17534197269359092183",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/b89d5e209990b19e33b418e14f323998-Abstract-Conference.html",
      "title": "Masked autoencoders that listen",
      "authors": "PY Huang, H Xu, J Li, A Baevski\u2026",
      "year": "2022",
      "cited_by": 45,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17534197269359092183&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Hitea: Hierarchical temporal-aware video-language pre-training",
      "id": "5763129354275940103",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Ye_HiTeA_Hierarchical_Temporal-Aware_Video-Language_Pre-training_ICCV_2023_paper.html",
      "title": "Hitea: Hierarchical temporal-aware video-language pre-training",
      "authors": "Q Ye, G Xu, M Yan, H Xu, Q Qian\u2026",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5763129354275940103&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Masked autoencoders that listen",
      "id": "13233494379811120690",
      "url": "https://arxiv.org/abs/2207.06405",
      "title": "Masked autoencoders that listen",
      "authors": "PY Huang, H Xu, J Li, A Baevski, M Auli\u2026",
      "year": "2022",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13233494379811120690&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Omnimae: Single model masked pretraining on images and videos",
      "id": "9867831262985002468",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Girdhar_OmniMAE_Single_Model_Masked_Pretraining_on_Images_and_Videos_CVPR_2023_paper.html",
      "title": "Omnimae: Single model masked pretraining on images and videos",
      "authors": "R Girdhar, A El-Nouby, M Singh\u2026",
      "year": "2023",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9867831262985002468&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Squeezeformer: An efficient transformer for automatic speech recognition",
      "id": "8988041508983958224",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/3ccf6da39eeb8fefc8bbb1b0124adbd1-Abstract-Conference.html",
      "title": "Squeezeformer: An efficient transformer for automatic speech recognition",
      "authors": "S Kim, A Gholami, A Shaw, N Lee\u2026",
      "year": "2022",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8988041508983958224&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Rethinking video vits: Sparse video tubes for joint image and video learning",
      "id": "13961698310318632817",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Piergiovanni_Rethinking_Video_ViTs_Sparse_Video_Tubes_for_Joint_Image_and_CVPR_2023_paper.html",
      "title": "Rethinking video vits: Sparse video tubes for joint image and video learning",
      "authors": "AJ Piergiovanni, W Kuo\u2026",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13961698310318632817&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Metaformer baselines for vision",
      "id": "17264780080323807782",
      "url": "https://arxiv.org/abs/2210.13452",
      "title": "Metaformer baselines for vision",
      "authors": "W Yu, C Si, P Zhou, M Luo, Y Zhou, J Feng\u2026",
      "year": "2022",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17264780080323807782&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Ted-spad: Temporal distinctiveness for self-supervised privacy-preservation for video anomaly detection",
      "id": "7521998026481226724",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Fioresi_TeD-SPAD_Temporal_Distinctiveness_for_Self-Supervised_Privacy-Preservation_for_Video_Anomaly_Detection_ICCV_2023_paper.html",
      "title": "Ted-spad: Temporal distinctiveness for self-supervised privacy-preservation for video anomaly detection",
      "authors": "J Fioresi, IR Dave, M Shah",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7521998026481226724&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Stargazer: A transformer-based driver action detection system for intelligent transportation",
      "id": "14292753405609492066",
      "url": "http://openaccess.thecvf.com/content/CVPR2022W/AICity/html/Liang_Stargazer_A_Transformer-Based_Driver_Action_Detection_System_for_Intelligent_Transportation_CVPRW_2022_paper.html",
      "title": "Stargazer: A transformer-based driver action detection system for intelligent transportation",
      "authors": "J Liang, H Zhu, E Zhang\u2026",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14292753405609492066&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Masked video distillation: Rethinking masked feature modeling for self-supervised video representation learning",
      "id": "15701650176909360920",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wang_Masked_Video_Distillation_Rethinking_Masked_Feature_Modeling_for_Self-Supervised_Video_CVPR_2023_paper.html",
      "title": "Masked video distillation: Rethinking masked feature modeling for self-supervised video representation learning",
      "authors": "R Wang, D Chen, Z Wu, Y Chen\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15701650176909360920&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Re2tal: Rewiring pretrained video backbones for reversible temporal action localization",
      "id": "7083069404926056970",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Re2TAL_Rewiring_Pretrained_Video_Backbones_for_Reversible_Temporal_Action_Localization_CVPR_2023_paper.html",
      "title": "Re2tal: Rewiring pretrained video backbones for reversible temporal action localization",
      "authors": "C Zhao, S Liu, K Mangalam\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7083069404926056970&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Conv2former: A simple transformer-style convnet for visual recognition",
      "id": "16345516296958117809",
      "url": "https://arxiv.org/abs/2211.11943",
      "title": "Conv2former: A simple transformer-style convnet for visual recognition",
      "authors": "Q Hou, CZ Lu, MM Cheng, J Feng",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16345516296958117809&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "MsSVT: Mixed-scale sparse voxel transformer for 3d object detection on point clouds",
      "id": "18352250779745802826",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/4bad7c27534efca029ca0d366c47c0e3-Abstract-Conference.html",
      "title": "MsSVT: Mixed-scale sparse voxel transformer for 3d object detection on point clouds",
      "authors": "S Dong, L Ding, H Wang, T Xu, X Xu\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18352250779745802826&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Mobilevitv3: Mobile-friendly vision transformer with simple and effective fusion of local, global and input features",
      "id": "12521341369829058727",
      "url": "https://arxiv.org/abs/2209.15159",
      "title": "Mobilevitv3: Mobile-friendly vision transformer with simple and effective fusion of local, global and input features",
      "authors": "SN Wadekar, A Chaurasia",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12521341369829058727&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Multi-dataset Training of Transformers for Robust Action Recognition",
      "id": "18278928779930263666",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/5d2e24df9cfaad3189833b819c40b392-Abstract-Conference.html",
      "title": "Multi-dataset Training of Transformers for Robust Action Recognition",
      "authors": "J Liang, E Zhang, J Zhang\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18278928779930263666&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Attention-based distributed deep learning model for air quality forecasting",
      "id": "11435180467185856094",
      "url": "https://www.mdpi.com/2071-1050/14/6/3269",
      "title": "Attention-based distributed deep learning model for air quality forecasting",
      "authors": "AG Mengara Mengara, E Park, J Jang, Y Yoo",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11435180467185856094&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Moat: Alternating mobile convolution and attention brings strong vision models",
      "id": "297116116872847031",
      "url": "https://arxiv.org/abs/2210.01820",
      "title": "Moat: Alternating mobile convolution and attention brings strong vision models",
      "authors": "C Yang, S Qiao, Q Yu, X Yuan, Y Zhu, A Yuille\u2026",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=297116116872847031&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Transformer-based visual segmentation: A survey",
      "id": "10401914588824198986",
      "url": "https://arxiv.org/abs/2304.09854",
      "title": "Transformer-based visual segmentation: A survey",
      "authors": "X Li, H Ding, W Zhang, H Yuan, J Pang\u2026",
      "year": "2023",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10401914588824198986&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Marlin: Masked autoencoder for facial video representation learning",
      "id": "1636570585907882285",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Cai_MARLIN_Masked_Autoencoder_for_Facial_Video_Representation_LearnINg_CVPR_2023_paper.html",
      "title": "Marlin: Masked autoencoder for facial video representation learning",
      "authors": "Z Cai, S Ghosh, K Stefanov, A Dhall\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1636570585907882285&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Learning Procedure-aware Video Representation from Instructional Videos and Their Narrations",
      "id": "12251423014012987213",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Yu_Learning_Procedure-Aware_Video_Representation_From_Instructional_Videos_and_Their_Narrations_CVPR_2023_paper.html",
      "title": "Learning Procedure-aware Video Representation from Instructional Videos and Their Narrations",
      "authors": "Y Zhong, L Yu, Y Bai, S Li, X Yan\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12251423014012987213&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "HumanBench: Towards General Human-centric Perception with Projector Assisted Pretraining",
      "id": "16223923155940056199",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Tang_HumanBench_Towards_General_Human-Centric_Perception_With_Projector_Assisted_Pretraining_CVPR_2023_paper.html",
      "title": "HumanBench: Towards General Human-centric Perception with Projector Assisted Pretraining",
      "authors": "S Tang, C Chen, Q Xie, M Chen\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16223923155940056199&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Prune spatio-temporal tokens by semantic-aware temporal accumulation",
      "id": "1475939297738772704",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Ding_Prune_Spatio-temporal_Tokens_by_Semantic-aware_Temporal_Accumulation_ICCV_2023_paper.html",
      "title": "Prune spatio-temporal tokens by semantic-aware temporal accumulation",
      "authors": "S Ding, P Zhao, X Zhang, R Qian\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1475939297738772704&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Transformers meet visual learning understanding: A comprehensive review",
      "id": "163853940069191532",
      "url": "https://arxiv.org/abs/2203.12944",
      "title": "Transformers meet visual learning understanding: A comprehensive review",
      "authors": "Y Yang, L Jiao, X Liu, F Liu, S Yang, Z Feng\u2026",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=163853940069191532&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Unmasked teacher: Towards training-efficient video foundation models",
      "id": "17353513126312288026",
      "url": "https://arxiv.org/abs/2303.16058",
      "title": "Unmasked teacher: Towards training-efficient video foundation models",
      "authors": "K Li, Y Wang, Y Li, Y Wang, Y He, L Wang\u2026",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17353513126312288026&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Revisiting temporal modeling for clip-based image-to-video knowledge transferring",
      "id": "4553933449540878013",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Liu_Revisiting_Temporal_Modeling_for_CLIP-Based_Image-to-Video_Knowledge_Transferring_CVPR_2023_paper.html",
      "title": "Revisiting temporal modeling for clip-based image-to-video knowledge transferring",
      "authors": "R Liu, J Huang, G Li, J Feng\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4553933449540878013&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Rethinking attention mechanism in time series classification",
      "id": "7548052650525629965",
      "url": "https://www.sciencedirect.com/science/article/pii/S0020025523000968",
      "title": "Rethinking attention mechanism in time series classification",
      "authors": "B Zhao, H Xing, X Wang, F Song, Z Xiao",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7548052650525629965&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Mar: Masked autoencoders for efficient action recognition",
      "id": "13374404244463301147",
      "url": "https://ieeexplore.ieee.org/abstract/document/10089159/",
      "title": "Mar: Masked autoencoders for efficient action recognition",
      "authors": "Z Qing, S Zhang, Z Huang, X Wang\u2026",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13374404244463301147&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Vision Transformer with Super Token Sampling",
      "id": "11917368591479581577",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Huang_Vision_Transformer_With_Super_Token_Sampling_CVPR_2023_paper.html",
      "title": "Vision Transformer with Super Token Sampling",
      "authors": "H Huang, X Zhou, J Cao, R He\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11917368591479581577&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "HierVL: Learning Hierarchical Video-Language Embeddings",
      "id": "18135230557293693450",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Ashutosh_HierVL_Learning_Hierarchical_Video-Language_Embeddings_CVPR_2023_paper.html",
      "title": "HierVL: Learning Hierarchical Video-Language Embeddings",
      "authors": "K Ashutosh, R Girdhar, L Torresani\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18135230557293693450&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "D3Former: Debiased Dual Distilled Transformer for Incremental Learning",
      "id": "2687678320604906488",
      "url": "https://openaccess.thecvf.com/content/CVPR2023W/CLVision/html/Mohamed_D3Former_Debiased_Dual_Distilled_Transformer_for_Incremental_Learning_CVPRW_2023_paper.html",
      "title": "D3Former: Debiased Dual Distilled Transformer for Incremental Learning",
      "authors": "A Mohamed, R Grandhe, KJ Joseph\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2687678320604906488&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Inceptionnext: When inception meets convnext",
      "id": "7457602010468600062",
      "url": "https://arxiv.org/abs/2303.16900",
      "title": "Inceptionnext: When inception meets convnext",
      "authors": "W Yu, P Zhou, S Yan, X Wang",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7457602010468600062&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Dual-domain attention for image deblurring",
      "id": "14160811618017343674",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25122",
      "title": "Dual-domain attention for image deblurring",
      "authors": "Y Cui, Y Tao, W Ren, A Knoll",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14160811618017343674&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Design and Application of a UAV Autonomous Inspection System for High-Voltage Power Transmission Lines",
      "id": "7586367217993538099",
      "url": "https://www.mdpi.com/2072-4292/15/3/865",
      "title": "Design and Application of a UAV Autonomous Inspection System for High-Voltage Power Transmission Lines",
      "authors": "Z Li, Y Zhang, H Wu, S Suzuki, A Namiki, W Wang",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7586367217993538099&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Ego-Only: Egocentric Action Detection without Exocentric Transferring",
      "id": "k2InbV7B6EkJ",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Ego-Only_Egocentric_Action_Detection_without_Exocentric_Transferring_ICCV_2023_paper.html",
      "title": "Ego-Only: Egocentric Action Detection without Exocentric Transferring",
      "authors": "H Wang, MK Singh, L Torresani",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "Adapool: Exponential adaptive pooling for information-retaining downsampling",
      "id": "8672277335438437194",
      "url": "https://ieeexplore.ieee.org/abstract/document/9982650/",
      "title": "Adapool: Exponential adaptive pooling for information-retaining downsampling",
      "authors": "A Stergiou, R Poppe",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8672277335438437194&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Bringing image scene structure to video via frame-clip consistency of object tokens",
      "id": "8783919417057800696",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/abc1943857a42935ceacff03c524bb44-Abstract-Conference.html",
      "title": "Bringing image scene structure to video via frame-clip consistency of object tokens",
      "authors": "E Ben Avraham, R Herzig\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8783919417057800696&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Promptonomyvit: Multi-task prompt learning improves video transformers using synthetic scene data",
      "id": "17020241982343048724",
      "url": "https://arxiv.org/abs/2212.04821",
      "title": "Promptonomyvit: Multi-task prompt learning improves video transformers using synthetic scene data",
      "authors": "R Herzig, O Abramovich, E Ben-Avraham\u2026",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17020241982343048724&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Relational Space-Time Query in Long-Form Videos",
      "id": "6135323271371562232",
      "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Relational_Space-Time_Query_in_Long-Form_Videos_CVPR_2023_paper.html",
      "title": "Relational Space-Time Query in Long-Form Videos",
      "authors": "X Yang, FJ Chu, M Feiszli, R Goyal\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6135323271371562232&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "On the Benefits of 3D Pose and Tracking for Human Action Recognition",
      "id": "9897568004629027598",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Rajasegaran_On_the_Benefits_of_3D_Pose_and_Tracking_for_Human_CVPR_2023_paper.html",
      "title": "On the Benefits of 3D Pose and Tracking for Human Action Recognition",
      "authors": "J Rajasegaran, G Pavlakos\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9897568004629027598&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "UniFormerV2: Unlocking the Potential of Image ViTs for Video Understanding",
      "id": "iPZOpP141k4J",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.html",
      "title": "UniFormerV2: Unlocking the Potential of Image ViTs for Video Understanding",
      "authors": "K Li, Y Wang, Y He, Y Li, Y Wang\u2026",
      "year": "2023",
      "modularity": 2
    },
    {
      "label": "TransCNN: Hybrid CNN and transformer mechanism for surveillance anomaly detection",
      "id": "5346646808921915555",
      "url": "https://www.sciencedirect.com/science/article/pii/S0952197623003573",
      "title": "TransCNN: Hybrid CNN and transformer mechanism for surveillance anomaly detection",
      "authors": "W Ullah, T Hussain, FUM Ullah, MY Lee\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5346646808921915555&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "Latency Matters: Real-Time Action Forecasting Transformer",
      "id": "14765226393767823271",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Girase_Latency_Matters_Real-Time_Action_Forecasting_Transformer_CVPR_2023_paper.html",
      "title": "Latency Matters: Real-Time Action Forecasting Transformer",
      "authors": "H Girase, N Agarwal, C Choi\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14765226393767823271&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "MAViL: Masked Audio-Video Learners",
      "id": "5678901956168261131",
      "url": "https://arxiv.org/abs/2212.08071",
      "title": "MAViL: Masked Audio-Video Learners",
      "authors": "PY Huang, V Sharma, H Xu, C Ryali, H Fan, Y Li\u2026",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5678901956168261131&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 2
    },
    {
      "label": "A comprehensive survey on graph neural networks",
      "id": "1431633311194488622",
      "url": "https://ieeexplore.ieee.org/abstract/document/9046288/",
      "title": "A comprehensive survey on graph neural networks",
      "authors": "Z Wu, S Pan, F Chen, G Long, C Zhang\u2026",
      "year": "2020",
      "cited_by": 6447,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1431633311194488622&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Diffusion models: A comprehensive survey of methods and applications",
      "id": "17457133269069328267",
      "url": "https://dl.acm.org/doi/abs/10.1145/3626235",
      "title": "Diffusion models: A comprehensive survey of methods and applications",
      "authors": "L Yang, Z Zhang, Y Song, S Hong, R Xu, Y Zhao\u2026",
      "year": "2022",
      "cited_by": 257,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17457133269069328267&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A comprehensive survey on graph anomaly detection with deep learning",
      "id": "5640775539800892593",
      "url": "https://ieeexplore.ieee.org/abstract/document/9565320/",
      "title": "A comprehensive survey on graph anomaly detection with deep learning",
      "authors": "X Ma, J Wu, S Xue, J Yang, C Zhou\u2026",
      "year": "2021",
      "cited_by": 486,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5640775539800892593&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Deep learning--based text classification: a comprehensive review",
      "id": "17228116273163901194",
      "url": "https://dl.acm.org/doi/abs/10.1145/3439726",
      "title": "Deep learning--based text classification: a comprehensive review",
      "authors": "S Minaee, N Kalchbrenner, E Cambria\u2026",
      "year": "2021",
      "cited_by": 1136,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17228116273163901194&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "How attentive are graph attention networks?",
      "id": "5656297883023258429",
      "url": "https://arxiv.org/abs/2105.14491",
      "title": "How attentive are graph attention networks?",
      "authors": "S Brody, U Alon, E Yahav",
      "year": "2021",
      "cited_by": 471,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5656297883023258429&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph neural networks: A review of methods and applications",
      "id": "2381021153585051804",
      "url": "https://www.sciencedirect.com/science/article/pii/S2666651021000012",
      "title": "Graph neural networks: A review of methods and applications",
      "authors": "J Zhou, G Cui, S Hu, Z Zhang, C Yang, Z Liu, L Wang\u2026",
      "year": "2020",
      "cited_by": 4126,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2381021153585051804&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Contrastive multi-view representation learning on graphs",
      "id": "11131425815493661687",
      "url": "http://proceedings.mlr.press/v119/hassani20a.html",
      "title": "Contrastive multi-view representation learning on graphs",
      "authors": "K Hassani, AH Khasahmadi",
      "year": "2020",
      "cited_by": 850,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11131425815493661687&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph neural networks in recommender systems: a survey",
      "id": "16559789848821467555",
      "url": "https://dl.acm.org/doi/abs/10.1145/3535101",
      "title": "Graph neural networks in recommender systems: a survey",
      "authors": "S Wu, F Sun, W Zhang, X Xie, B Cui",
      "year": "2022",
      "cited_by": 516,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16559789848821467555&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Neural ordinary differential equations",
      "id": "13748354740225969894",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2018/hash/69386f6bb1dfed68692a24c8686939b9-Abstract.html",
      "title": "Neural ordinary differential equations",
      "authors": "RTQ Chen, Y Rubanova\u2026",
      "year": "2018",
      "cited_by": 3698,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13748354740225969894&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Simplifying graph convolutional networks",
      "id": "17348071344751182786",
      "url": "https://proceedings.mlr.press/v97/wu19e.html",
      "title": "Simplifying graph convolutional networks",
      "authors": "F Wu, A Souza, T Zhang, C Fifty, T Yu\u2026",
      "year": "2019",
      "cited_by": 2379,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17348071344751182786&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Deep learning for generic object detection: A survey",
      "id": "2846334625875347669",
      "url": "https://link.springer.com/article/10.1007/s11263-019-01247-4",
      "title": "Deep learning for generic object detection: A survey",
      "authors": "L Liu, W Ouyang, X Wang, P Fieguth, J Chen\u2026",
      "year": "2020",
      "cited_by": 2510,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2846334625875347669&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Graph neural network for traffic forecasting: A survey",
      "id": "7012076773417880547",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417422011654",
      "title": "Graph neural network for traffic forecasting: A survey",
      "authors": "W Jiang, J Luo",
      "year": "2022",
      "cited_by": 408,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7012076773417880547&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Disentangling and unifying graph convolutions for skeleton-based action recognition",
      "id": "14188108076981434930",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Liu_Disentangling_and_Unifying_Graph_Convolutions_for_Skeleton-Based_Action_Recognition_CVPR_2020_paper.html",
      "title": "Disentangling and unifying graph convolutions for skeleton-based action recognition",
      "authors": "Z Liu, H Zhang, Z Chen, Z Wang\u2026",
      "year": "2020",
      "cited_by": 691,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14188108076981434930&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Gman: A graph multi-attention network for traffic prediction",
      "id": "10560769186027812935",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/5477",
      "title": "Gman: A graph multi-attention network for traffic prediction",
      "authors": "C Zheng, X Fan, C Wang, J Qi",
      "year": "2020",
      "cited_by": 806,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10560769186027812935&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Deep graph library: A graph-centric, highly-performant package for graph neural networks",
      "id": "17598489487193491440",
      "url": "https://arxiv.org/abs/1909.01315",
      "title": "Deep graph library: A graph-centric, highly-performant package for graph neural networks",
      "authors": "M Wang, D Zheng, Z Ye, Q Gan, M Li, X Song\u2026",
      "year": "2019",
      "cited_by": 817,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17598489487193491440&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph convolutional networks: a comprehensive review",
      "id": "824590046745083591",
      "url": "https://computationalsocialnetworks.springeropen.com/articles/10.1186/s40649-019-0069-y?ref=https://githubhelp.com",
      "title": "Graph convolutional networks: a comprehensive review",
      "authors": "S Zhang, H Tong, J Xu\u2026",
      "year": "2019",
      "cited_by": 714,
      "cited_by_url": "https://scholar.google.com/scholar?cites=824590046745083591&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Point-gnn: Graph neural network for 3d object detection in a point cloud",
      "id": "3987152815255001944",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Shi_Point-GNN_Graph_Neural_Network_for_3D_Object_Detection_in_a_CVPR_2020_paper.html",
      "title": "Point-gnn: Graph neural network for 3d object detection in a point cloud",
      "authors": "W Shi, R Rajkumar",
      "year": "2020",
      "cited_by": 596,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3987152815255001944&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Deepgcns: Can gcns go as deep as cnns?",
      "id": "1405916394303361407",
      "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Li_DeepGCNs_Can_GCNs_Go_As_Deep_As_CNNs_ICCV_2019_paper.html",
      "title": "Deepgcns: Can gcns go as deep as cnns?",
      "authors": "G Li, M Muller, A Thabet\u2026",
      "year": "2019",
      "cited_by": 1087,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1405916394303361407&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Deep learning on graphs: A survey",
      "id": "3929066136257329737",
      "url": "https://ieeexplore.ieee.org/abstract/document/9039675/",
      "title": "Deep learning on graphs: A survey",
      "authors": "Z Zhang, P Cui, W Zhu",
      "year": "2020",
      "cited_by": 1191,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3929066136257329737&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Beyond low-frequency information in graph convolutional networks",
      "id": "6969950659727941449",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/16514",
      "title": "Beyond low-frequency information in graph convolutional networks",
      "authors": "D Bo, X Wang, C Shi, H Shen",
      "year": "2021",
      "cited_by": 303,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6969950659727941449&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Knowledge graphs",
      "id": "4712708126956095125",
      "url": "https://dl.acm.org/doi/abs/10.1145/3447772",
      "title": "Knowledge graphs",
      "authors": "A Hogan, E Blomqvist, M Cochez, C d'Amato\u2026",
      "year": "2021",
      "cited_by": 963,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4712708126956095125&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "On the bottleneck of graph neural networks and its practical implications",
      "id": "5884209795367025285",
      "url": "https://arxiv.org/abs/2006.05205",
      "title": "On the bottleneck of graph neural networks and its practical implications",
      "authors": "U Alon, E Yahav",
      "year": "2020",
      "cited_by": 412,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5884209795367025285&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Towards multi-modal causability with graph neural networks enabling information fusion for explainable AI",
      "id": "16286153053570566579",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253521000142",
      "title": "Towards multi-modal causability with graph neural networks enabling information fusion for explainable AI",
      "authors": "A Holzinger, B Malle, A Saranti, B Pfeifer",
      "year": "2021",
      "cited_by": 248,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16286153053570566579&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "An introductory review of deep learning for prediction models with big data",
      "id": "8218634905233683023",
      "url": "https://www.frontiersin.org/articles/10.3389/frai.2020.00004/full",
      "title": "An introductory review of deep learning for prediction models with big data",
      "authors": "F Emmert-Streib, Z Yang, H Feng, S Tripathi\u2026",
      "year": "2020",
      "cited_by": 441,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8218634905233683023&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Self-supervised hypergraph convolutional networks for session-based recommendation",
      "id": "8173578619526272020",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/16578",
      "title": "Self-supervised hypergraph convolutional networks for session-based recommendation",
      "authors": "X Xia, H Yin, J Yu, Q Wang, L Cui\u2026",
      "year": "2021",
      "cited_by": 287,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8173578619526272020&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Am-gcn: Adaptive multi-channel graph convolutional networks",
      "id": "15628822607882875170",
      "url": "https://dl.acm.org/doi/abs/10.1145/3394486.3403177",
      "title": "Am-gcn: Adaptive multi-channel graph convolutional networks",
      "authors": "X Wang, M Zhu, D Bo, P Cui, C Shi, J Pei",
      "year": "2020",
      "cited_by": 326,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15628822607882875170&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph structure learning for robust graph neural networks",
      "id": "13519623104352135728",
      "url": "https://dl.acm.org/doi/abs/10.1145/3394486.3403049",
      "title": "Graph structure learning for robust graph neural networks",
      "authors": "W Jin, Y Ma, X Liu, X Tang, S Wang\u2026",
      "year": "2020",
      "cited_by": 398,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13519623104352135728&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph self-supervised learning: A survey",
      "id": "11740996352054171303",
      "url": "https://ieeexplore.ieee.org/abstract/document/9770382/",
      "title": "Graph self-supervised learning: A survey",
      "authors": "Y Liu, M Jin, S Pan, C Zhou, Y Zheng\u2026",
      "year": "2022",
      "cited_by": 256,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11740996352054171303&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Deep closest point: Learning representations for point cloud registration",
      "id": "13319126561466992426",
      "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Wang_Deep_Closest_Point_Learning_Representations_for_Point_Cloud_Registration_ICCV_2019_paper.html",
      "title": "Deep closest point: Learning representations for point cloud registration",
      "authors": "Y Wang, JM Solomon",
      "year": "2019",
      "cited_by": 702,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13319126561466992426&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph representation learning in biomedicine and healthcare",
      "id": "18175359140763832369",
      "url": "https://www.nature.com/articles/s41551-022-00942-x",
      "title": "Graph representation learning in biomedicine and healthcare",
      "authors": "MM Li, K Huang, M Zitnik",
      "year": "2022",
      "cited_by": 62,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18175359140763832369&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Spectral temporal graph neural network for multivariate time-series forecasting",
      "id": "8609729441168460418",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/cdf6581cb7aca4b7e19ef136c6e601a5-Abstract.html",
      "title": "Spectral temporal graph neural network for multivariate time-series forecasting",
      "authors": "D Cao, Y Wang, J Duan, C Zhang\u2026",
      "year": "2020",
      "cited_by": 262,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8609729441168460418&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Hierarchically structured bioinspired nanocomposites",
      "id": "12338916099901568166",
      "url": "https://www.nature.com/articles/s41563-022-01384-1",
      "title": "Hierarchically structured bioinspired nanocomposites",
      "authors": "D Nepal, S Kang, KM Adstedt, K Kanhaiya\u2026",
      "year": "2023",
      "cited_by": 61,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12338916099901568166&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Traffic flow prediction via spatial temporal graph neural network",
      "id": "10361934383634103378",
      "url": "https://dl.acm.org/doi/abs/10.1145/3366423.3380186",
      "title": "Traffic flow prediction via spatial temporal graph neural network",
      "authors": "X Wang, Y Ma, Y Wang, W Jin, X Wang, J Tang\u2026",
      "year": "2020",
      "cited_by": 337,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10361934383634103378&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Semi-supervised city-wide parking availability prediction via hierarchical recurrent graph neural network",
      "id": "10034248469511743317",
      "url": "https://ieeexplore.ieee.org/abstract/document/9241427/",
      "title": "Semi-supervised city-wide parking availability prediction via hierarchical recurrent graph neural network",
      "authors": "W Zhang, H Liu, Y Liu, J Zhou, T Xu\u2026",
      "year": "2020",
      "cited_by": 249,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10034248469511743317&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Are graph augmentations necessary? simple graph contrastive learning for recommendation",
      "id": "13094368588973025667",
      "url": "https://dl.acm.org/doi/abs/10.1145/3477495.3531937",
      "title": "Are graph augmentations necessary? simple graph contrastive learning for recommendation",
      "authors": "J Yu, H Yin, X Xia, T Chen, L Cui\u2026",
      "year": "2022",
      "cited_by": 174,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13094368588973025667&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Software vulnerability detection using deep neural networks: a survey",
      "id": "14507474565925582559",
      "url": "https://ieeexplore.ieee.org/abstract/document/9108283/",
      "title": "Software vulnerability detection using deep neural networks: a survey",
      "authors": "G Lin, S Wen, QL Han, J Zhang\u2026",
      "year": "2020",
      "cited_by": 285,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14507474565925582559&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Self-supervised multi-channel hypergraph convolutional network for social recommendation",
      "id": "8608635600889702315",
      "url": "https://dl.acm.org/doi/abs/10.1145/3442381.3449844",
      "title": "Self-supervised multi-channel hypergraph convolutional network for social recommendation",
      "authors": "J Yu, H Yin, J Li, Q Wang, NQV Hung\u2026",
      "year": "2021",
      "cited_by": 230,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8608635600889702315&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Combustion machine learning: Principles, progress and prospects",
      "id": "3480504377185349195",
      "url": "https://www.sciencedirect.com/science/article/pii/S0360128522000193",
      "title": "Combustion machine learning: Principles, progress and prospects",
      "authors": "M Ihme, WT Chung, AA Mishra",
      "year": "2022",
      "cited_by": 74,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3480504377185349195&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph learning: A survey",
      "id": "8264388784225550416",
      "url": "https://ieeexplore.ieee.org/abstract/document/9416834/",
      "title": "Graph learning: A survey",
      "authors": "F Xia, K Sun, S Yu, A Aziz, L Wan\u2026",
      "year": "2021",
      "cited_by": 193,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8264388784225550416&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A survey of community detection approaches: From statistical modeling to deep learning",
      "id": "16185498123764366373",
      "url": "https://ieeexplore.ieee.org/abstract/document/9511798/",
      "title": "A survey of community detection approaches: From statistical modeling to deep learning",
      "authors": "D Jin, Z Yu, P Jiao, S Pan, D He, J Wu\u2026",
      "year": "2021",
      "cited_by": 195,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16185498123764366373&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A compact review of molecular property prediction with graph neural networks",
      "id": "3692815723362239451",
      "url": "https://www.sciencedirect.com/science/article/pii/S1740674920300305",
      "title": "A compact review of molecular property prediction with graph neural networks",
      "authors": "O Wieder, S Kohlbacher, M Kuenemann\u2026",
      "year": "2020",
      "cited_by": 223,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3692815723362239451&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "How powerful are spectral graph neural networks",
      "id": "17960766448265380456",
      "url": "https://proceedings.mlr.press/v162/wang22am.html",
      "title": "How powerful are spectral graph neural networks",
      "authors": "X Wang, M Zhang",
      "year": "2022",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17960766448265380456&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Review on deep learning applications in frequency analysis and control of modern power system",
      "id": "3243408560707200262",
      "url": "https://www.sciencedirect.com/science/article/pii/S0142061521009686",
      "title": "Review on deep learning applications in frequency analysis and control of modern power system",
      "authors": "Y Zhang, X Shi, H Zhang, Y Cao, V Terzija",
      "year": "2022",
      "cited_by": 141,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3243408560707200262&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A tutorial on ultrareliable and low-latency communications in 6G: Integrating domain knowledge into deep learning",
      "id": "11612055028743993917",
      "url": "https://ieeexplore.ieee.org/abstract/document/9369424/",
      "title": "A tutorial on ultrareliable and low-latency communications in 6G: Integrating domain knowledge into deep learning",
      "authors": "C She, C Sun, Z Gu, Y Li, C Yang\u2026",
      "year": "2021",
      "cited_by": 225,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11612055028743993917&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Specter: Document-level representation learning using citation-informed transformers",
      "id": "942093327978373135",
      "url": "https://arxiv.org/abs/2004.07180",
      "title": "Specter: Document-level representation learning using citation-informed transformers",
      "authors": "A Cohan, S Feldman, I Beltagy, D Downey\u2026",
      "year": "2020",
      "cited_by": 311,
      "cited_by_url": "https://scholar.google.com/scholar?cites=942093327978373135&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Self-supervised heterogeneous graph neural network with co-contrastive learning",
      "id": "6584430158722490128",
      "url": "https://dl.acm.org/doi/abs/10.1145/3447548.3467415",
      "title": "Self-supervised heterogeneous graph neural network with co-contrastive learning",
      "authors": "X Wang, N Liu, H Han, C Shi",
      "year": "2021",
      "cited_by": 178,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6584430158722490128&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Learning knowledge graph embedding with heterogeneous relation attention networks",
      "id": "204598726516650366",
      "url": "https://ieeexplore.ieee.org/abstract/document/9359364/",
      "title": "Learning knowledge graph embedding with heterogeneous relation attention networks",
      "authors": "Z Li, H Liu, Z Zhang, T Liu\u2026",
      "year": "2021",
      "cited_by": 187,
      "cited_by_url": "https://scholar.google.com/scholar?cites=204598726516650366&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Linking points with labels in 3D: A review of point cloud semantic segmentation",
      "id": "17047112888909822506",
      "url": "https://ieeexplore.ieee.org/abstract/document/9028090/",
      "title": "Linking points with labels in 3D: A review of point cloud semantic segmentation",
      "authors": "Y Xie, J Tian, XX Zhu",
      "year": "2020",
      "cited_by": 325,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17047112888909822506&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Utilizing graph machine learning within drug discovery and development",
      "id": "7072607443445254562",
      "url": "https://academic.oup.com/bib/article-abstract/22/6/bbab159/6278145",
      "title": "Utilizing graph machine learning within drug discovery and development",
      "authors": "T Gaudelet, B Day, AR Jamasb, J Soman\u2026",
      "year": "2021",
      "cited_by": 171,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7072607443445254562&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Enhancing graph neural network-based fraud detectors against camouflaged fraudsters",
      "id": "7755255229432407884",
      "url": "https://dl.acm.org/doi/abs/10.1145/3340531.3411903",
      "title": "Enhancing graph neural network-based fraud detectors against camouflaged fraudsters",
      "authors": "Y Dou, Z Liu, L Sun, Y Deng, H Peng\u2026",
      "year": "2020",
      "cited_by": 237,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7755255229432407884&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "An overview of deep semi-supervised learning",
      "id": "6916383400010189934",
      "url": "https://arxiv.org/abs/2006.05278",
      "title": "An overview of deep semi-supervised learning",
      "authors": "Y Ouali, C Hudelot, M Tami",
      "year": "2020",
      "cited_by": 254,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6916383400010189934&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Multipole graph neural operator for parametric partial differential equations",
      "id": "13318009799245280479",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/4b21cf96d4cf612f239a6c322b10c8fe-Abstract.html",
      "title": "Multipole graph neural operator for parametric partial differential equations",
      "authors": "Z Li, N Kovachki, K Azizzadenesheli\u2026",
      "year": "2020",
      "cited_by": 214,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13318009799245280479&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Deep learning in human activity recognition with wearable sensors: A review on advances",
      "id": "3632941331539070968",
      "url": "https://www.mdpi.com/1424-8220/22/4/1476",
      "title": "Deep learning in human activity recognition with wearable sensors: A review on advances",
      "authors": "S Zhang, Y Li, S Zhang, F Shahabi, S Xia, Y Deng\u2026",
      "year": "2022",
      "cited_by": 137,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3632941331539070968&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "EEG-based emotion recognition using regularized graph neural networks",
      "id": "16803457256664781582",
      "url": "https://ieeexplore.ieee.org/abstract/document/9091308/",
      "title": "EEG-based emotion recognition using regularized graph neural networks",
      "authors": "P Zhong, D Wang, C Miao",
      "year": "2020",
      "cited_by": 304,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16803457256664781582&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Adversarial attacks on graph neural networks: Perturbations and their patterns",
      "id": "18317541865909512163",
      "url": "https://dl.acm.org/doi/abs/10.1145/3394520",
      "title": "Adversarial attacks on graph neural networks: Perturbations and their patterns",
      "authors": "D Z\u00fcgner, O Borchert, A Akbarnejad\u2026",
      "year": "2020",
      "cited_by": 476,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18317541865909512163&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Integration strategies of multi-omics data for machine learning analysis",
      "id": "18185187817423073352",
      "url": "https://www.sciencedirect.com/science/article/pii/S2001037021002683",
      "title": "Integration strategies of multi-omics data for machine learning analysis",
      "authors": "M Picard, MP Scott-Boyer, A Bodein, O P\u00e9rin\u2026",
      "year": "2021",
      "cited_by": 167,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18185187817423073352&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph neural networks in particle physics",
      "id": "4523751644674550881",
      "url": "https://iopscience.iop.org/article/10.1088/2632-2153/abbf9a/meta",
      "title": "Graph neural networks in particle physics",
      "authors": "J Shlomi, P Battaglia, JR Vlimant",
      "year": "2020",
      "cited_by": 223,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4523751644674550881&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Deep learning for spatio-temporal data mining: A survey",
      "id": "16804172820179337006",
      "url": "https://ieeexplore.ieee.org/abstract/document/9204396/",
      "title": "Deep learning for spatio-temporal data mining: A survey",
      "authors": "S Wang, J Cao, SY Philip",
      "year": "2020",
      "cited_by": 424,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16804172820179337006&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Scaling graph neural networks with approximate pagerank",
      "id": "1939691424133781861",
      "url": "https://dl.acm.org/doi/abs/10.1145/3394486.3403296",
      "title": "Scaling graph neural networks with approximate pagerank",
      "authors": "A Bojchevski, J Gasteiger, B Perozzi, A Kapoor\u2026",
      "year": "2020",
      "cited_by": 205,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1939691424133781861&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Hierarchical adversarial attacks against graph-neural-network-based IoT network intrusion detection system",
      "id": "6018075345772831348",
      "url": "https://ieeexplore.ieee.org/abstract/document/9626144/",
      "title": "Hierarchical adversarial attacks against graph-neural-network-based IoT network intrusion detection system",
      "authors": "X Zhou, W Liang, W Li, K Yan, S Shimizu\u2026",
      "year": "2021",
      "cited_by": 141,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6018075345772831348&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Learning dynamics and heterogeneity of spatial-temporal graph data for traffic forecasting",
      "id": "17854740042612276767",
      "url": "https://ieeexplore.ieee.org/abstract/document/9346058/",
      "title": "Learning dynamics and heterogeneity of spatial-temporal graph data for traffic forecasting",
      "authors": "S Guo, Y Lin, H Wan, X Li\u2026",
      "year": "2021",
      "cited_by": 180,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17854740042612276767&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Atomistic line graph neural network for improved materials property predictions",
      "id": "1656421726766747841",
      "url": "https://www.nature.com/articles/s41524-021-00650-1",
      "title": "Atomistic line graph neural network for improved materials property predictions",
      "authors": "K Choudhary, B DeCost",
      "year": "2021",
      "cited_by": 119,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1656421726766747841&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Hygcn: A gcn accelerator with hybrid architecture",
      "id": "9732428124783939302",
      "url": "https://ieeexplore.ieee.org/abstract/document/9065592/",
      "title": "Hygcn: A gcn accelerator with hybrid architecture",
      "authors": "M Yan, L Deng, X Hu, L Liang, Y Feng\u2026",
      "year": "2020",
      "cited_by": 248,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9732428124783939302&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A survey of graph neural networks for recommender systems: Challenges, methods, and directions",
      "id": "7651463217590835983",
      "url": "https://dl.acm.org/doi/abs/10.1145/3568022",
      "title": "A survey of graph neural networks for recommender systems: Challenges, methods, and directions",
      "authors": "C Gao, Y Zheng, N Li, Y Li, Y Qin, J Piao\u2026",
      "year": "2023",
      "cited_by": 102,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7651463217590835983&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "How to find your friendly neighborhood: Graph attention design with self-supervision",
      "id": "7594913044183235646",
      "url": "https://arxiv.org/abs/2204.04879",
      "title": "How to find your friendly neighborhood: Graph attention design with self-supervision",
      "authors": "D Kim, A Oh",
      "year": "2022",
      "cited_by": 189,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7594913044183235646&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Benchmarking graph neural networks for materials chemistry",
      "id": "11598438983746935209",
      "url": "https://www.nature.com/articles/s41524-021-00554-0",
      "title": "Benchmarking graph neural networks for materials chemistry",
      "authors": "V Fung, J Zhang, E Juarez, BG Sumpter",
      "year": "2021",
      "cited_by": 120,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11598438983746935209&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "When does self-supervision help graph convolutional networks?",
      "id": "8359089573172587095",
      "url": "http://proceedings.mlr.press/v119/you20a.html",
      "title": "When does self-supervision help graph convolutional networks?",
      "authors": "Y You, T Chen, Z Wang, Y Shen",
      "year": "2020",
      "cited_by": 183,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8359089573172587095&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Adaptive graph convolutional recurrent network for traffic forecasting",
      "id": "531500407384902218",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2020/file/ce1aad92b939420fc17005e5461e6f48-Paper.pdf",
      "title": "Adaptive graph convolutional recurrent network for traffic forecasting",
      "authors": "L Bai, L Yao, C Li, X Wang\u2026",
      "year": "2020",
      "cited_by": 581,
      "cited_by_url": "https://scholar.google.com/scholar?cites=531500407384902218&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Can graph neural networks count substructures?",
      "id": "15397526244877086732",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/75877cb75154206c4e65e76b88a12712-Abstract.html",
      "title": "Can graph neural networks count substructures?",
      "authors": "Z Chen, L Chen, S Villar\u2026",
      "year": "2020",
      "cited_by": 223,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15397526244877086732&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A gentle introduction to deep learning for graphs",
      "id": "18161333932150601045",
      "url": "https://www.sciencedirect.com/science/article/pii/S0893608020302197",
      "title": "A gentle introduction to deep learning for graphs",
      "authors": "D Bacciu, F Errica, A Micheli, M Podda",
      "year": "2020",
      "cited_by": 225,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18161333932150601045&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A survey of knowledge-enhanced text generation",
      "id": "12908963143152569355",
      "url": "https://dl.acm.org/doi/abs/10.1145/3512467",
      "title": "A survey of knowledge-enhanced text generation",
      "authors": "W Yu, C Zhu, Z Li, Z Hu, Q Wang, H Ji\u2026",
      "year": "2022",
      "cited_by": 155,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12908963143152569355&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Anomaly detection on attributed networks via contrastive self-supervised learning",
      "id": "4499233656145369438",
      "url": "https://ieeexplore.ieee.org/abstract/document/9395172/",
      "title": "Anomaly detection on attributed networks via contrastive self-supervised learning",
      "authors": "Y Liu, Z Li, S Pan, C Gong, C Zhou\u2026",
      "year": "2021",
      "cited_by": 140,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4499233656145369438&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Heterogeneous graph structure learning for graph neural networks",
      "id": "8291535141920945881",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/16600",
      "title": "Heterogeneous graph structure learning for graph neural networks",
      "authors": "J Zhao, X Wang, C Shi, B Hu, G Song\u2026",
      "year": "2021",
      "cited_by": 136,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8291535141920945881&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Computing graph neural networks: A survey from algorithms to accelerators",
      "id": "16222652166929144204",
      "url": "https://dl.acm.org/doi/abs/10.1145/3477141",
      "title": "Computing graph neural networks: A survey from algorithms to accelerators",
      "authors": "S Abadal, A Jain, R Guirado, J L\u00f3pez-Alonso\u2026",
      "year": "2021",
      "cited_by": 149,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16222652166929144204&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Examining covid-19 forecasting using spatio-temporal graph neural networks",
      "id": "11491875380349289404",
      "url": "https://arxiv.org/abs/2007.03113",
      "title": "Examining covid-19 forecasting using spatio-temporal graph neural networks",
      "authors": "A Kapoor, X Ben, L Liu, B Perozzi, M Barnes\u2026",
      "year": "2020",
      "cited_by": 199,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11491875380349289404&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph neural networks for materials science and chemistry",
      "id": "3720958980403020816",
      "url": "https://www.nature.com/articles/s43246-022-00315-6",
      "title": "Graph neural networks for materials science and chemistry",
      "authors": "P Reiser, M Neubert, A Eberhard, L Torresi\u2026",
      "year": "2022",
      "cited_by": 74,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3720958980403020816&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "A survey on trajectory-prediction methods for autonomous driving",
      "id": "9486832350006291839",
      "url": "https://ieeexplore.ieee.org/abstract/document/9756903/",
      "title": "A survey on trajectory-prediction methods for autonomous driving",
      "authors": "Y Huang, J Du, Z Yang, Z Zhou\u2026",
      "year": "2022",
      "cited_by": 99,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9486832350006291839&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Text level graph neural network for text classification",
      "id": "1051374793971189386",
      "url": "https://arxiv.org/abs/1910.02356",
      "title": "Text level graph neural network for text classification",
      "authors": "L Huang, D Ma, S Li, X Zhang, H Wang",
      "year": "2019",
      "cited_by": 248,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1051374793971189386&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Node similarity preserving graph convolutional networks",
      "id": "3658250324739476352",
      "url": "https://dl.acm.org/doi/abs/10.1145/3437963.3441735",
      "title": "Node similarity preserving graph convolutional networks",
      "authors": "W Jin, T Derr, Y Wang, Y Ma, Z Liu, J Tang",
      "year": "2021",
      "cited_by": 158,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3658250324739476352&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "G-mixup: Graph data augmentation for graph classification",
      "id": "16313647976714156830",
      "url": "https://proceedings.mlr.press/v162/han22c.html",
      "title": "G-mixup: Graph data augmentation for graph classification",
      "authors": "X Han, Z Jiang, N Liu, X Hu",
      "year": "2022",
      "cited_by": 74,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16313647976714156830&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Attention, please! A survey of neural attention models in deep learning",
      "id": "2604085176257305633",
      "url": "https://link.springer.com/article/10.1007/s10462-022-10148-x",
      "title": "Attention, please! A survey of neural attention models in deep learning",
      "authors": "A de Santana Correia, EL Colombini",
      "year": "2022",
      "cited_by": 114,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2604085176257305633&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Heterogeneous graph neural network via attribute completion",
      "id": "17770512424346032016",
      "url": "https://dl.acm.org/doi/abs/10.1145/3442381.3449914",
      "title": "Heterogeneous graph neural network via attribute completion",
      "authors": "D Jin, C Huo, C Liang, L Yang",
      "year": "2021",
      "cited_by": 114,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17770512424346032016&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Graph learning based recommender systems: A review",
      "id": "11601132339555571470",
      "url": "https://arxiv.org/abs/2105.06339",
      "title": "Graph learning based recommender systems: A review",
      "authors": "S Wang, L Hu, Y Wang, X He, QZ Sheng\u2026",
      "year": "2021",
      "cited_by": 124,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11601132339555571470&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Multi-range attentive bicomponent graph convolutional network for traffic forecasting",
      "id": "1211835406473191863",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/5758",
      "title": "Multi-range attentive bicomponent graph convolutional network for traffic forecasting",
      "authors": "W Chen, L Chen, Y Xie, W Cao, Y Gao\u2026",
      "year": "2020",
      "cited_by": 224,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1211835406473191863&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "The emerging graph neural networks for intelligent fault diagnostics and prognostics: A guideline and a benchmark study",
      "id": "4347083033764848435",
      "url": "https://www.sciencedirect.com/science/article/pii/S0888327021009791",
      "title": "The emerging graph neural networks for intelligent fault diagnostics and prognostics: A guideline and a benchmark study",
      "authors": "T Li, Z Zhou, S Li, C Sun, R Yan, X Chen",
      "year": "2022",
      "cited_by": 92,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4347083033764848435&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 8
    },
    {
      "label": "Fcos: Fully convolutional one-stage object detection",
      "id": "9538084449875791919",
      "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Tian_FCOS_Fully_Convolutional_One-Stage_Object_Detection_ICCV_2019_paper.html",
      "title": "Fcos: Fully convolutional one-stage object detection",
      "authors": "Z Tian, C Shen, H Chen, T He",
      "year": "2019",
      "cited_by": 4413,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9538084449875791919&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Recent advances in deep learning for object detection",
      "id": "11408603882397693774",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231220301430",
      "title": "Recent advances in deep learning for object detection",
      "authors": "X Wu, D Sahoo, SCH Hoi",
      "year": "2020",
      "cited_by": 688,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11408603882397693774&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Scaling up your kernels to 31x31: Revisiting large kernel design in cnns",
      "id": "12500443856801763727",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Ding_Scaling_Up_Your_Kernels_to_31x31_Revisiting_Large_Kernel_Design_CVPR_2022_paper.html",
      "title": "Scaling up your kernels to 31x31: Revisiting large kernel design in cnns",
      "authors": "X Ding, X Zhang, J Han, G Ding",
      "year": "2022",
      "cited_by": 357,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12500443856801763727&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Efficientdet: Scalable and efficient object detection",
      "id": "16138254679061222132",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Tan_EfficientDet_Scalable_and_Efficient_Object_Detection_CVPR_2020_paper.html",
      "title": "Efficientdet: Scalable and efficient object detection",
      "authors": "M Tan, R Pang, QV Le",
      "year": "2020",
      "cited_by": 4585,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16138254679061222132&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Deep high-resolution representation learning for visual recognition",
      "id": "15505711795824202735",
      "url": "https://ieeexplore.ieee.org/abstract/document/9052469/",
      "title": "Deep high-resolution representation learning for visual recognition",
      "authors": "J Wang, K Sun, T Cheng, B Jiang\u2026",
      "year": "2020",
      "cited_by": 2478,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15505711795824202735&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Bridging the gap between anchor-based and anchor-free detection via adaptive training sample selection",
      "id": "11324600873272743514",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Zhang_Bridging_the_Gap_Between_Anchor-Based_and_Anchor-Free_Detection_via_Adaptive_CVPR_2020_paper.html",
      "title": "Bridging the gap between anchor-based and anchor-free detection via adaptive training sample selection",
      "authors": "S Zhang, C Chi, Y Yao, Z Lei\u2026",
      "year": "2020",
      "cited_by": 1230,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11324600873272743514&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Tracking objects as points",
      "id": "1564404986299438483",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58548-8_28",
      "title": "Tracking objects as points",
      "authors": "X Zhou, V Koltun, P Kr\u00e4henb\u00fchl",
      "year": "2020",
      "cited_by": 837,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1564404986299438483&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "MMDetection: Open mmlab detection toolbox and benchmark",
      "id": "4116193485073279318",
      "url": "https://arxiv.org/abs/1906.07155",
      "title": "MMDetection: Open mmlab detection toolbox and benchmark",
      "authors": "K Chen, J Wang, J Pang, Y Cao, Y Xiong, X Li\u2026",
      "year": "2019",
      "cited_by": 2251,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4116193485073279318&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "End-to-end semi-supervised object detection with soft teacher",
      "id": "14550673639887731046",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Xu_End-to-End_Semi-Supervised_Object_Detection_With_Soft_Teacher_ICCV_2021_paper.html",
      "title": "End-to-end semi-supervised object detection with soft teacher",
      "authors": "M Xu, Z Zhang, H Hu, J Wang, L Wang\u2026",
      "year": "2021",
      "cited_by": 310,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14550673639887731046&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Oriented R-CNN for object detection",
      "id": "5146522853377591327",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Xie_Oriented_R-CNN_for_Object_Detection_ICCV_2021_paper.html",
      "title": "Oriented R-CNN for object detection",
      "authors": "X Xie, G Cheng, J Wang, X Yao\u2026",
      "year": "2021",
      "cited_by": 316,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5146522853377591327&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Bevfusion: Multi-task multi-sensor fusion with unified bird's-eye view representation",
      "id": "18039062144864581963",
      "url": "https://ieeexplore.ieee.org/abstract/document/10160968/",
      "title": "Bevfusion: Multi-task multi-sensor fusion with unified bird's-eye view representation",
      "authors": "Z Liu, H Tang, A Amini, X Yang, H Mao\u2026",
      "year": "2023",
      "cited_by": 222,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18039062144864581963&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "A survey of deep learning-based object detection",
      "id": "5669364687087032958",
      "url": "https://ieeexplore.ieee.org/abstract/document/8825470/",
      "title": "A survey of deep learning-based object detection",
      "authors": "L Jiao, F Zhang, F Liu, S Yang, L Li, Z Feng\u2026",
      "year": "2019",
      "cited_by": 1065,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5669364687087032958&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Siamese box adaptive network for visual tracking",
      "id": "9040151999224305592",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Chen_Siamese_Box_Adaptive_Network_for_Visual_Tracking_CVPR_2020_paper.html",
      "title": "Siamese box adaptive network for visual tracking",
      "authors": "Z Chen, B Zhong, G Li, S Zhang\u2026",
      "year": "2020",
      "cited_by": 642,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9040151999224305592&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "3dssd: Point-based 3d single stage object detector",
      "id": "3720837586692381467",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Yang_3DSSD_Point-Based_3D_Single_Stage_Object_Detector_CVPR_2020_paper.html",
      "title": "3dssd: Point-based 3d single stage object detector",
      "authors": "Z Yang, Y Sun, S Liu, J Jia",
      "year": "2020",
      "cited_by": 692,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3720837586692381467&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Fcos3d: Fully convolutional one-stage monocular 3d object detection",
      "id": "16050906463468676059",
      "url": "https://openaccess.thecvf.com/content/ICCV2021W/3DODI/html/Wang_FCOS3D_Fully_Convolutional_One-Stage_Monocular_3D_Object_Detection_ICCVW_2021_paper.html",
      "title": "Fcos3d: Fully convolutional one-stage monocular 3d object detection",
      "authors": "T Wang, X Zhu, J Pang, D Lin",
      "year": "2021",
      "cited_by": 299,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16050906463468676059&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Varifocalnet: An iou-aware dense object detector",
      "id": "18267268624032061291",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Zhang_VarifocalNet_An_IoU-Aware_Dense_Object_Detector_CVPR_2021_paper.html",
      "title": "Varifocalnet: An iou-aware dense object detector",
      "authors": "H Zhang, Y Wang, F Dayoub\u2026",
      "year": "2021",
      "cited_by": 432,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18267268624032061291&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Solov2: Dynamic and fast instance segmentation",
      "id": "4993232610053036190",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/cd3afef9b8b89558cd56638c3631868a-Abstract.html",
      "title": "Solov2: Dynamic and fast instance segmentation",
      "authors": "X Wang, R Zhang, T Kong, L Li\u2026",
      "year": "2020",
      "cited_by": 596,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4993232610053036190&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Detectors: Detecting objects with recursive feature pyramid and switchable atrous convolution",
      "id": "3466946125865762121",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Qiao_DetectoRS_Detecting_Objects_With_Recursive_Feature_Pyramid_and_Switchable_Atrous_CVPR_2021_paper.html",
      "title": "Detectors: Detecting objects with recursive feature pyramid and switchable atrous convolution",
      "authors": "S Qiao, LC Chen, A Yuille",
      "year": "2021",
      "cited_by": 612,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3466946125865762121&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection",
      "id": "16305632232773240100",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/f0bda020d2470f2e74990a07a607ebd9-Abstract.html",
      "title": "Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection",
      "authors": "X Li, W Wang, L Wu, S Chen, X Hu\u2026",
      "year": "2020",
      "cited_by": 519,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16305632232773240100&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Ocean: Object-aware anchor-free tracking",
      "id": "10517065804384853053",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58589-1_46",
      "title": "Ocean: Object-aware anchor-free tracking",
      "authors": "Z Zhang, H Peng, J Fu, B Li, W Hu",
      "year": "2020",
      "cited_by": 505,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10517065804384853053&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Ota: Optimal transport assignment for object detection",
      "id": "14858856697824684994",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Ge_OTA_Optimal_Transport_Assignment_for_Object_Detection_CVPR_2021_paper.html",
      "title": "Ota: Optimal transport assignment for object detection",
      "authors": "Z Ge, S Liu, Z Li, O Yoshie\u2026",
      "year": "2021",
      "cited_by": 289,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14858856697824684994&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Hinet: Half instance normalization network for image restoration",
      "id": "2731814227384441305",
      "url": "https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Chen_HINet_Half_Instance_Normalization_Network_for_Image_Restoration_CVPRW_2021_paper.html",
      "title": "Hinet: Half instance normalization network for image restoration",
      "authors": "L Chen, X Lu, J Zhang, X Chu\u2026",
      "year": "2021",
      "cited_by": 257,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2731814227384441305&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Regionclip: Region-based language-image pretraining",
      "id": "10020660180667111529",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhong_RegionCLIP_Region-Based_Language-Image_Pretraining_CVPR_2022_paper.html",
      "title": "Regionclip: Region-based language-image pretraining",
      "authors": "Y Zhong, J Yang, P Zhang, C Li\u2026",
      "year": "2022",
      "cited_by": 165,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10020660180667111529&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Solo: Segmenting objects by locations",
      "id": "3426844125187450693",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58523-5_38",
      "title": "Solo: Segmenting objects by locations",
      "authors": "X Wang, T Kong, C Shen, Y Jiang, L Li",
      "year": "2020",
      "cited_by": 580,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3426844125187450693&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Siamfc++: Towards robust and accurate visual tracking with target estimation guidelines",
      "id": "4790520819340140445",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/6944",
      "title": "Siamfc++: Towards robust and accurate visual tracking with target estimation guidelines",
      "authors": "Y Xu, Z Wang, Z Li, Y Yuan, G Yu",
      "year": "2020",
      "cited_by": 610,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4790520819340140445&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "SiamCAR: Siamese fully convolutional classification and regression for visual tracking",
      "id": "12328462444653843486",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Guo_SiamCAR_Siamese_Fully_Convolutional_Classification_and_Regression_for_Visual_Tracking_CVPR_2020_paper.html",
      "title": "SiamCAR: Siamese fully convolutional classification and regression for visual tracking",
      "authors": "D Guo, J Wang, Y Cui, Z Wang\u2026",
      "year": "2020",
      "cited_by": 564,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12328462444653843486&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Conditional convolutions for instance segmentation",
      "id": "12541147144211358106",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58452-8_17",
      "title": "Conditional convolutions for instance segmentation",
      "authors": "Z Tian, C Shen, H Chen",
      "year": "2020",
      "cited_by": 490,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12541147144211358106&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Asymmetric loss for multi-label classification",
      "id": "11565832587997700911",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Ridnik_Asymmetric_Loss_for_Multi-Label_Classification_ICCV_2021_paper.html",
      "title": "Asymmetric loss for multi-label classification",
      "authors": "T Ridnik, E Ben-Baruch, N Zamir\u2026",
      "year": "2021",
      "cited_by": 206,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11565832587997700911&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Propagate yourself: Exploring pixel-level consistency for unsupervised visual representation learning",
      "id": "13904438580236939165",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Xie_Propagate_Yourself_Exploring_Pixel-Level_Consistency_for_Unsupervised_Visual_Representation_Learning_CVPR_2021_paper.html",
      "title": "Propagate yourself: Exploring pixel-level consistency for unsupervised visual representation learning",
      "authors": "Z Xie, Y Lin, Z Zhang, Y Cao\u2026",
      "year": "2021",
      "cited_by": 331,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13904438580236939165&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Polarmask: Single shot instance segmentation with polar representation",
      "id": "15407313785451367942",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Xie_PolarMask_Single_Shot_Instance_Segmentation_With_Polar_Representation_CVPR_2020_paper.html",
      "title": "Polarmask: Single shot instance segmentation with polar representation",
      "authors": "E Xie, P Sun, X Song, W Wang, X Liu\u2026",
      "year": "2020",
      "cited_by": 523,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15407313785451367942&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Tood: Task-aligned one-stage object detection",
      "id": "6294085712262467065",
      "url": "https://www.computer.org/csdl/proceedings-article/iccv/2021/281200d490/1BmEvqSJIEE",
      "title": "Tood: Task-aligned one-stage object detection",
      "authors": "C Feng, Y Zhong, Y Gao, MR Scott\u2026",
      "year": "2021",
      "cited_by": 278,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6294085712262467065&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Is pseudo-lidar needed for monocular 3d object detection?",
      "id": "15376920793982085069",
      "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Park_Is_Pseudo-Lidar_Needed_for_Monocular_3D_Object_Detection_ICCV_2021_paper.html?ref=https://githubhelp.com",
      "title": "Is pseudo-lidar needed for monocular 3d object detection?",
      "authors": "D Park, R Ambrus, V Guizilini, J Li\u2026",
      "year": "2021",
      "cited_by": 190,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15376920793982085069&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Fsce: Few-shot object detection via contrastive proposal encoding",
      "id": "3308996211432317749",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Sun_FSCE_Few-Shot_Object_Detection_via_Contrastive_Proposal_Encoding_CVPR_2021_paper.html",
      "title": "Fsce: Few-shot object detection via contrastive proposal encoding",
      "authors": "B Sun, B Li, S Cai, Y Yuan\u2026",
      "year": "2021",
      "cited_by": 230,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3308996211432317749&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Centermask: Real-time anchor-free instance segmentation",
      "id": "9190599054932808738",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Lee_CenterMask_Real-Time_Anchor-Free_Instance_Segmentation_CVPR_2020_paper.html",
      "title": "Centermask: Real-time anchor-free instance segmentation",
      "authors": "Y Lee, J Park",
      "year": "2020",
      "cited_by": 481,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9190599054932808738&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Blendmask: Top-down meets bottom-up for instance segmentation",
      "id": "6999319186345681083",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Chen_BlendMask_Top-Down_Meets_Bottom-Up_for_Instance_Segmentation_CVPR_2020_paper.html",
      "title": "Blendmask: Top-down meets bottom-up for instance segmentation",
      "authors": "H Chen, K Sun, Z Tian, C Shen\u2026",
      "year": "2020",
      "cited_by": 455,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6999319186345681083&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Foveabox: Beyound anchor-based object detection",
      "id": "4793705234619070656",
      "url": "https://ieeexplore.ieee.org/abstract/document/9123553/",
      "title": "Foveabox: Beyound anchor-based object detection",
      "authors": "T Kong, F Sun, H Liu, Y Jiang, L Li\u2026",
      "year": "2020",
      "cited_by": 792,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4793705234619070656&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Rethinking transformer-based set prediction for object detection",
      "id": "11352324708624125387",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Sun_Rethinking_Transformer-Based_Set_Prediction_for_Object_Detection_ICCV_2021_paper.html",
      "title": "Rethinking transformer-based set prediction for object detection",
      "authors": "Z Sun, S Cao, Y Yang\u2026",
      "year": "2021",
      "cited_by": 252,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11352324708624125387&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "The seventh visual object tracking VOT2019 challenge results",
      "id": "760283713428624225",
      "url": "http://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Kristan_The_Seventh_Visual_Object_Tracking_VOT2019_Challenge_Results_ICCVW_2019_paper.html",
      "title": "The seventh visual object tracking VOT2019 challenge results",
      "authors": "M Kristan, J Matas, A Leonardis\u2026",
      "year": "2019",
      "cited_by": 457,
      "cited_by_url": "https://scholar.google.com/scholar?cites=760283713428624225&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Learning spatial fusion for single-shot object detection",
      "id": "3077479873636042159",
      "url": "https://arxiv.org/abs/1911.09516",
      "title": "Learning spatial fusion for single-shot object detection",
      "authors": "S Liu, D Huang, Y Wang",
      "year": "2019",
      "cited_by": 465,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3077479873636042159&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Align deep features for oriented object detection",
      "id": "15278380461775262117",
      "url": "https://ieeexplore.ieee.org/abstract/document/9377550/",
      "title": "Align deep features for oriented object detection",
      "authors": "J Han, J Ding, J Li, GS Xia",
      "year": "2021",
      "cited_by": 360,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15278380461775262117&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Transforming model prediction for tracking",
      "id": "10187246864084975926",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Mayer_Transforming_Model_Prediction_for_Tracking_CVPR_2022_paper.html",
      "title": "Transforming model prediction for tracking",
      "authors": "C Mayer, M Danelljan, G Bhat, M Paul\u2026",
      "year": "2022",
      "cited_by": 111,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10187246864084975926&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "BERTERS: Multimodal Representation Learning for Expert Recommendation System with Transformer",
      "id": "12308813102675740697",
      "url": "https://www.academia.edu/download/80829631/2007.07229v1.pdf",
      "title": "BERTERS: Multimodal Representation Learning for Expert Recommendation System with Transformer",
      "authors": "N Nikzad\u2013Khasmakhia, M Balafara\u2026",
      "year": "2020",
      "cited_by": 329,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12308813102675740697&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Dynamic R-CNN: Towards high quality object detection via dynamic training",
      "id": "17049037070556303909",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58555-6_16",
      "title": "Dynamic R-CNN: Towards high quality object detection via dynamic training",
      "authors": "H Zhang, H Chang, B Ma, N Wang, X Chen",
      "year": "2020",
      "cited_by": 352,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17049037070556303909&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Fast convergence of detr with spatially modulated co-attention",
      "id": "14304438718574157071",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Gao_Fast_Convergence_of_DETR_With_Spatially_Modulated_Co-Attention_ICCV_2021_paper.html",
      "title": "Fast convergence of detr with spatially modulated co-attention",
      "authors": "P Gao, M Zheng, X Wang, J Dai\u2026",
      "year": "2021",
      "cited_by": 206,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14304438718574157071&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Bevdet: High-performance multi-camera 3d object detection in bird-eye-view",
      "id": "11305281026744071790",
      "url": "https://arxiv.org/abs/2112.11790",
      "title": "Bevdet: High-performance multi-camera 3d object detection in bird-eye-view",
      "authors": "J Huang, G Huang, Z Zhu, Y Ye, D Du",
      "year": "2021",
      "cited_by": 209,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11305281026744071790&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Probabilistic anchor assignment with iou prediction for object detection",
      "id": "2210620764419829906",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58595-2_22",
      "title": "Probabilistic anchor assignment with iou prediction for object detection",
      "authors": "K Kim, HS Lee",
      "year": "2020",
      "cited_by": 307,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2210620764419829906&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Probabilistic and geometric depth: Detecting objects in perspective",
      "id": "1321793621715878501",
      "url": "https://proceedings.mlr.press/v164/wang22i.html",
      "title": "Probabilistic and geometric depth: Detecting objects in perspective",
      "authors": "T Wang, ZHU Xinge, J Pang\u2026",
      "year": "2022",
      "cited_by": 157,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1321793621715878501&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Stmtrack: Template-free visual tracking with space-time memory networks",
      "id": "15248432581458880980",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Fu_STMTrack_Template-Free_Visual_Tracking_With_Space-Time_Memory_Networks_CVPR_2021_paper.html",
      "title": "Stmtrack: Template-free visual tracking with space-time memory networks",
      "authors": "Z Fu, Q Liu, Z Fu, Y Wang",
      "year": "2021",
      "cited_by": 167,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15248432581458880980&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Structured knowledge distillation for semantic segmentation",
      "id": "15847441662530625185",
      "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Structured_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2019_paper.html",
      "title": "Structured knowledge distillation for semantic segmentation",
      "authors": "Y Liu, K Chen, C Liu, Z Qin, Z Luo\u2026",
      "year": "2019",
      "cited_by": 601,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15847441662530625185&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Augfpn: Improving multi-scale feature learning for object detection",
      "id": "890350355816522800",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Guo_AugFPN_Improving_Multi-Scale_Feature_Learning_for_Object_Detection_CVPR_2020_paper.html",
      "title": "Augfpn: Improving multi-scale feature learning for object detection",
      "authors": "C Guo, B Fan, Q Zhang, S Xiang\u2026",
      "year": "2020",
      "cited_by": 339,
      "cited_by_url": "https://scholar.google.com/scholar?cites=890350355816522800&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Revisiting the sibling head in object detector",
      "id": "7794016071296671172",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Song_Revisiting_the_Sibling_Head_in_Object_Detector_CVPR_2020_paper",
      "title": "Revisiting the sibling head in object detector",
      "authors": "G Song, Y Liu, X Wang",
      "year": "2020",
      "cited_by": 326,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7794016071296671172&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Pf-net: Point fractal network for 3d point cloud completion",
      "id": "14672664302977559137",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Huang_PF-Net_Point_Fractal_Network_for_3D_Point_Cloud_Completion_CVPR_2020_paper.html",
      "title": "Pf-net: Point fractal network for 3d point cloud completion",
      "authors": "Z Huang, Y Yu, J Xu, F Ni, X Le",
      "year": "2020",
      "cited_by": 316,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14672664302977559137&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Enforcing geometric constraints of virtual normal for depth prediction",
      "id": "13259842884566962187",
      "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Yin_Enforcing_Geometric_Constraints_of_Virtual_Normal_for_Depth_Prediction_ICCV_2019_paper.html",
      "title": "Enforcing geometric constraints of virtual normal for depth prediction",
      "authors": "W Yin, Y Liu, C Shen, Y Yan",
      "year": "2019",
      "cited_by": 384,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13259842884566962187&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Generalized focal loss v2: Learning reliable localization quality estimation for dense object detection",
      "id": "12458152692195612427",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Li_Generalized_Focal_Loss_V2_Learning_Reliable_Localization_Quality_Estimation_for_CVPR_2021_paper.html",
      "title": "Generalized focal loss v2: Learning reliable localization quality estimation for dense object detection",
      "authors": "X Li, W Wang, X Hu, J Li, J Tang\u2026",
      "year": "2021",
      "cited_by": 190,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12458152692195612427&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "FCOS: A simple and strong anchor-free object detector",
      "id": "18416642050963457459",
      "url": "https://ieeexplore.ieee.org/abstract/document/9229517/",
      "title": "FCOS: A simple and strong anchor-free object detector",
      "authors": "Z Tian, C Shen, H Chen, T He",
      "year": "2020",
      "cited_by": 272,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18416642050963457459&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Relationtrack: Relation-aware multiple object tracking with decoupled representation",
      "id": "3028370674147212605",
      "url": "https://ieeexplore.ieee.org/abstract/document/9709649/",
      "title": "Relationtrack: Relation-aware multiple object tracking with decoupled representation",
      "authors": "E Yu, Z Li, S Han, H Wang",
      "year": "2022",
      "cited_by": 80,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3028370674147212605&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "ISNet: Towards improving separability for remote sensing image change detection",
      "id": "11978445553624214380",
      "url": "https://ieeexplore.ieee.org/abstract/document/9772654/",
      "title": "ISNet: Towards improving separability for remote sensing image change detection",
      "authors": "G Cheng, G Wang, J Han",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11978445553624214380&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Rethinking efficient lane detection via curve modeling",
      "id": "949946091219062353",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Feng_Rethinking_Efficient_Lane_Detection_via_Curve_Modeling_CVPR_2022_paper.html",
      "title": "Rethinking efficient lane detection via curve modeling",
      "authors": "Z Feng, S Guo, X Tan, K Xu\u2026",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=949946091219062353&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Head: Hetero-assists distillation for heterogeneous object detectors",
      "id": "9132276678803270854",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_19",
      "title": "Head: Hetero-assists distillation for heterogeneous object detectors",
      "authors": "L Wang, X Li, Y Liao, Z Jiang, J Wu, F Wang\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9132276678803270854&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "SegContrast: 3D point cloud feature representation learning through self-supervised segment discrimination",
      "id": "6230352926792784452",
      "url": "https://ieeexplore.ieee.org/abstract/document/9681336/",
      "title": "SegContrast: 3D point cloud feature representation learning through self-supervised segment discrimination",
      "authors": "L Nunes, R Marcuzzi, X Chen, J Behley\u2026",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6230352926792784452&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Ship detection in SAR images based on feature enhancement Swin transformer and adjacent feature fusion",
      "id": "12916943626500149813",
      "url": "https://www.mdpi.com/2072-4292/14/13/3186",
      "title": "Ship detection in SAR images based on feature enhancement Swin transformer and adjacent feature fusion",
      "authors": "K Li, M Zhang, M Xu, R Tang, L Wang, H Wang",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12916943626500149813&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Instance-aware distillation for efficient object detection in remote sensing images",
      "id": "282502688385514417",
      "url": "https://ieeexplore.ieee.org/abstract/document/10024393/",
      "title": "Instance-aware distillation for efficient object detection in remote sensing images",
      "authors": "C Li, G Cheng, G Wang, P Zhou\u2026",
      "year": "2023",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=282502688385514417&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "PAG-YOLO: A portable attention-guided YOLO network for small ship detection",
      "id": "13126613410294485366",
      "url": "https://www.mdpi.com/2072-4292/13/16/3059",
      "title": "PAG-YOLO: A portable attention-guided YOLO network for small ship detection",
      "authors": "J Hu, X Zhi, T Shi, W Zhang, Y Cui, S Zhao",
      "year": "2021",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13126613410294485366&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Fovea: Foveated image magnification for autonomous navigation",
      "id": "7011964847765802199",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Thavamani_FOVEA_Foveated_Image_Magnification_for_Autonomous_Navigation_ICCV_2021_paper.html",
      "title": "Fovea: Foveated image magnification for autonomous navigation",
      "authors": "C Thavamani, M Li, N Cebron\u2026",
      "year": "2021",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7011964847765802199&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "PillarNeXt: Rethinking network designs for 3D object detection in LiDAR point clouds",
      "id": "8654903568547047842",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Li_PillarNeXt_Rethinking_Network_Designs_for_3D_Object_Detection_in_LiDAR_CVPR_2023_paper.html",
      "title": "PillarNeXt: Rethinking network designs for 3D object detection in LiDAR point clouds",
      "authors": "J Li, C Luo, X Yang",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8654903568547047842&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Efficient decoder-free object detection with transformers",
      "id": "5278530239378148719",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20080-9_5",
      "title": "Efficient decoder-free object detection with transformers",
      "authors": "P Chen, M Zhang, Y Shen, K Sheng, Y Gao\u2026",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5278530239378148719&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Half-UNet: A simplified U-Net architecture for medical image segmentation",
      "id": "2885916562392086198",
      "url": "https://www.frontiersin.org/articles/10.3389/fninf.2022.911679/full",
      "title": "Half-UNet: A simplified U-Net architecture for medical image segmentation",
      "authors": "H Lu, Y She, J Tie, S Xu",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2885916562392086198&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Pai3d: Painting adaptive instance-prior for 3d object detection",
      "id": "283347957351040289",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-25072-9_32",
      "title": "Pai3d: Painting adaptive instance-prior for 3d object detection",
      "authors": "H Liu, Z Xu, D Wang, B Zhang, G Wang, B Dong\u2026",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=283347957351040289&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "A lightweight network based on one-level feature for ship detection in SAR images",
      "id": "2620378263331322045",
      "url": "https://www.mdpi.com/2072-4292/14/14/3321",
      "title": "A lightweight network based on one-level feature for ship detection in SAR images",
      "authors": "W Yu, Z Wang, J Li, Y Luo, Z Yu",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2620378263331322045&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "A fast and accurate method of power line intelligent inspection based on edge computing",
      "id": "8136487588159115675",
      "url": "https://ieeexplore.ieee.org/abstract/document/9722917/",
      "title": "A fast and accurate method of power line intelligent inspection based on edge computing",
      "authors": "M Liu, Z Li, Y Li, Y Liu",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8136487588159115675&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Detecting wheat heads from UAV low-altitude remote sensing images using Deep Learning based on transformer",
      "id": "3137631071934908410",
      "url": "https://www.mdpi.com/2072-4292/14/20/5141",
      "title": "Detecting wheat heads from UAV low-altitude remote sensing images using Deep Learning based on transformer",
      "authors": "J Zhu, G Yang, X Feng, X Li, H Fang, J Zhang, X Bai\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3137631071934908410&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Domain generalization in deep learning based mass detection in mammography: A large-scale multi-center study",
      "id": "1587380561678705672",
      "url": "https://www.sciencedirect.com/science/article/pii/S0933365722001415",
      "title": "Domain generalization in deep learning based mass detection in mammography: A large-scale multi-center study",
      "authors": "L Garrucho, K Kushibar, S Jouide, O Diaz\u2026",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1587380561678705672&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "MS-IAF: Multi-Scale information augmentation framework for aircraft detection",
      "id": "18269904853006408245",
      "url": "https://www.mdpi.com/2072-4292/14/15/3696",
      "title": "MS-IAF: Multi-Scale information augmentation framework for aircraft detection",
      "authors": "Y Zhao, J Li, W Li, P Shan, X Wang, L Li, Q Fu",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18269904853006408245&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Improving object detection by label assignment distillation",
      "id": "8884306980263647674",
      "url": "https://openaccess.thecvf.com/content/WACV2022/html/Nguyen_Improving_Object_Detection_by_Label_Assignment_Distillation_WACV_2022_paper.html",
      "title": "Improving object detection by label assignment distillation",
      "authors": "CH Nguyen, TC Nguyen, TN Tang\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8884306980263647674&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Rethinking general underwater object detection: Datasets, challenges, and solutions",
      "id": "11272776230560973281",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231222013169",
      "title": "Rethinking general underwater object detection: Datasets, challenges, and solutions",
      "authors": "C Fu, R Liu, X Fan, P Chen, H Fu, W Yuan, M Zhu\u2026",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11272776230560973281&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "A review on anchor assignment and sampling heuristics in deep learning-based object detection",
      "id": "1187656217922278561",
      "url": "https://www.sciencedirect.com/science/article/pii/S092523122200861X",
      "title": "A review on anchor assignment and sampling heuristics in deep learning-based object detection",
      "authors": "XT Vo, KH Jo",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1187656217922278561&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "An efficient and lightweight CNN model with soft quantification for ship detection in SAR images",
      "id": "17222739228813142360",
      "url": "https://ieeexplore.ieee.org/abstract/document/9805750/",
      "title": "An efficient and lightweight CNN model with soft quantification for ship detection in SAR images",
      "authors": "X Yang, J Zhang, C Chen\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17222739228813142360&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Object detection based on fusion of sparse point cloud and image information",
      "id": "9386562677703754376",
      "url": "https://ieeexplore.ieee.org/abstract/document/9507517/",
      "title": "Object detection based on fusion of sparse point cloud and image information",
      "authors": "X Xu, L Zhang, J Yang, C Cao, Z Tan\u2026",
      "year": "2021",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9386562677703754376&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "FEA-swin: Foreground enhancement attention swin transformer network for accurate UAV-based dense object detection",
      "id": "18231280624475386436",
      "url": "https://www.mdpi.com/1424-8220/22/18/6993",
      "title": "FEA-swin: Foreground enhancement attention swin transformer network for accurate UAV-based dense object detection",
      "authors": "W Xu, C Zhang, Q Wang, P Dai",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18231280624475386436&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "AgriPest-YOLO: A rapid light-trap agricultural pest detection method based on deep learning",
      "id": "18294362283448718927",
      "url": "https://www.frontiersin.org/articles/10.3389/fpls.2022.1079384/full",
      "title": "AgriPest-YOLO: A rapid light-trap agricultural pest detection method based on deep learning",
      "authors": "W Zhang, H Huang, Y Sun, X Wu",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18294362283448718927&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Automatic Check-Out via Prototype-Based Classifier Learning from Single-Product Exemplars",
      "id": "9346886979579970159",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19806-9_16",
      "title": "Automatic Check-Out via Prototype-Based Classifier Learning from Single-Product Exemplars",
      "authors": "H Chen, XS Wei, F Zhang, Y Shen, H Xu\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9346886979579970159&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Mask or non-mask? robust face mask detector via triplet-consistency representation learning",
      "id": "1810771332585372148",
      "url": "https://dl.acm.org/doi/abs/10.1145/3472623",
      "title": "Mask or non-mask? robust face mask detector via triplet-consistency representation learning",
      "authors": "CW Yang, TH Phung, HH Shuai\u2026",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1810771332585372148&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Cross attention redistribution with contrastive learning for few shot object detection",
      "id": "1147425233131687163",
      "url": "https://www.sciencedirect.com/science/article/pii/S0141938222000129",
      "title": "Cross attention redistribution with contrastive learning for few shot object detection",
      "authors": "J Quan, B Ge, L Chen",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1147425233131687163&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "A guide to image and video based small object detection using deep learning: Case study of maritime surveillance",
      "id": "4888428022255023575",
      "url": "https://arxiv.org/abs/2207.12926",
      "title": "A guide to image and video based small object detection using deep learning: Case study of maritime surveillance",
      "authors": "AM Rekavandi, L Xu, F Boussaid\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4888428022255023575&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Trident\u2010YOLO: Improving the precision and speed of mobile device object detection",
      "id": "18156777187430112022",
      "url": "https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/ipr2.12340",
      "title": "Trident\u2010YOLO: Improving the precision and speed of mobile device object detection",
      "authors": "G Wang, H Ding, B Li, R Nie, Y Zhao",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18156777187430112022&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "YOLO-SD: Small Ship Detection in SAR Images by Multi-Scale Convolution and Feature Transformer Module",
      "id": "4470676289942389642",
      "url": "https://www.mdpi.com/2072-4292/14/20/5268",
      "title": "YOLO-SD: Small Ship Detection in SAR Images by Multi-Scale Convolution and Feature Transformer Module",
      "authors": "S Wang, S Gao, L Zhou, R Liu, H Zhang, J Liu, Y Jia\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4470676289942389642&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Mae-det: Revisiting maximum entropy principle in zero-shot nas for efficient object detection",
      "id": "6294936790423161188",
      "url": "https://arxiv.org/abs/2111.13336",
      "title": "Mae-det: Revisiting maximum entropy principle in zero-shot nas for efficient object detection",
      "authors": "Z Sun, M Lin, X Sun, Z Tan, H Li, R Jin",
      "year": "2021",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6294936790423161188&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "BoxMask: Revisiting Bounding Box Supervision for Video Object Detection",
      "id": "10175988650775937306",
      "url": "https://openaccess.thecvf.com/content/WACV2023/html/Hashmi_BoxMask_Revisiting_Bounding_Box_Supervision_for_Video_Object_Detection_WACV_2023_paper.html",
      "title": "BoxMask: Revisiting Bounding Box Supervision for Video Object Detection",
      "authors": "KA Hashmi, A Pagani, D Stricker\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10175988650775937306&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "REAP: A Large-Scale Realistic Adversarial Patch Benchmark",
      "id": "12727040761225033710",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Hingun_REAP_A_Large-Scale_Realistic_Adversarial_Patch_Benchmark_ICCV_2023_paper.html",
      "title": "REAP: A Large-Scale Realistic Adversarial Patch Benchmark",
      "authors": "N Hingun, C Sitawarin, J Li\u2026",
      "year": "2023",
      "modularity": 11
    },
    {
      "label": "MFANet: multi-scale feature fusion network with attention mechanism",
      "id": "13204595328459365591",
      "url": "https://link.springer.com/article/10.1007/s00371-022-02503-4",
      "title": "MFANet: multi-scale feature fusion network with attention mechanism",
      "authors": "G Wang, X Gan, Q Cao, Q Zhai",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13204595328459365591&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Design, integration, and evaluation of a robotic peach packaging system based on deep learning",
      "id": "17237009222277721047",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169923004015",
      "title": "Design, integration, and evaluation of a robotic peach packaging system based on deep learning",
      "authors": "Q Wang, D Wu, Z Sun, M Zhou, D Cui, L Xie\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17237009222277721047&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Remote sensing object detection based on receptive field expansion block",
      "id": "17855267959511452037",
      "url": "https://ieeexplore.ieee.org/abstract/document/9537586/",
      "title": "Remote sensing object detection based on receptive field expansion block",
      "authors": "X Dong, R Fu, Y Gao, Y Qin, Y Ye\u2026",
      "year": "2021",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17855267959511452037&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Uncertainty-aware accurate insulator fault detection based on an improved YOLOX model",
      "id": "3563115954885327440",
      "url": "https://www.sciencedirect.com/science/article/pii/S2352484722019205",
      "title": "Uncertainty-aware accurate insulator fault detection based on an improved YOLOX model",
      "authors": "Z Dai",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3563115954885327440&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Reasonable object detection guided by knowledge of global context and category relationship",
      "id": "7854236750952897970",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417422014221",
      "title": "Reasonable object detection guided by knowledge of global context and category relationship",
      "authors": "H Ji, K Ye, Q Wan, L Shen",
      "year": "2022",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7854236750952897970&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "CCST: crowd counting with swin transformer",
      "id": "7711517380639147333",
      "url": "https://link.springer.com/article/10.1007/s00371-022-02485-3",
      "title": "CCST: crowd counting with swin transformer",
      "authors": "B Li, Y Zhang, H Xu, B Yin",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7711517380639147333&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "A Sample Balance-Based Regression Module for Object Detection in Construction Sites",
      "id": "1089623869034577539",
      "url": "https://www.mdpi.com/2076-3417/12/13/6752",
      "title": "A Sample Balance-Based Regression Module for Object Detection in Construction Sites",
      "authors": "X Wang, H Wang, C Zhang, Q He, L Huo",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1089623869034577539&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "M2YOLOF: Based on effective receptive fields and multiple-in-single-out encoder for object detection",
      "id": "8366499969990031131",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417422019467",
      "title": "M2YOLOF: Based on effective receptive fields and multiple-in-single-out encoder for object detection",
      "authors": "Q Wang, Y Qian, Y Hu, C Wang, X Ye\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8366499969990031131&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Manipal-UAV person detection dataset: A step towards benchmarking dataset and algorithms for small object detection",
      "id": "3451836672949095488",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271622003008",
      "title": "Manipal-UAV person detection dataset: A step towards benchmarking dataset and algorithms for small object detection",
      "authors": "KR Akshatha, AK Karunakar, S Shenoy\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3451836672949095488&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "PODA: Prompt-driven Zero-shot Domain Adaptation",
      "id": "Lq8Umk34rDIJ",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Fahes_PODA_Prompt-driven_Zero-shot_Domain_Adaptation_ICCV_2023_paper.html",
      "title": "PODA: Prompt-driven Zero-shot Domain Adaptation",
      "authors": "M Fahes, TH Vu, A Bursuc, P P\u00e9rez\u2026",
      "year": "2023",
      "modularity": 11
    },
    {
      "label": "Joint Attention-Guided feature fusion network for saliency detection of surface defects",
      "id": "17178883444476643109",
      "url": "https://ieeexplore.ieee.org/abstract/document/9933904/",
      "title": "Joint Attention-Guided feature fusion network for saliency detection of surface defects",
      "authors": "X Jiang, F Yan, Y Lu, K Wang, S Guo\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17178883444476643109&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Finding nonrigid tiny person with densely cropped and local attention object detector networks in low-altitude aerial images",
      "id": "15088715437227844190",
      "url": "https://ieeexplore.ieee.org/abstract/document/9779100/",
      "title": "Finding nonrigid tiny person with densely cropped and local attention object detector networks in low-altitude aerial images",
      "authors": "X Zhang, Y Feng, S Zhang, N Wang\u2026",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15088715437227844190&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Optimal correction cost for object detection evaluation",
      "id": "2642922896219719634",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Otani_Optimal_Correction_Cost_for_Object_Detection_Evaluation_CVPR_2022_paper.html",
      "title": "Optimal correction cost for object detection evaluation",
      "authors": "M Otani, R Togashi, Y Nakashima\u2026",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2642922896219719634&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Traffic incident detection based on a global trajectory spatiotemporal map",
      "id": "4505986135620301670",
      "url": "https://link.springer.com/article/10.1007/s40747-021-00602-8",
      "title": "Traffic incident detection based on a global trajectory spatiotemporal map",
      "authors": "H Liang, H Song, X Yun, S Sun, Y Wang\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4505986135620301670&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Sdtp: Semantic-aware decoupled transformer pyramid for dense image prediction",
      "id": "4657133348792854073",
      "url": "https://ieeexplore.ieee.org/abstract/document/9740668/",
      "title": "Sdtp: Semantic-aware decoupled transformer pyramid for dense image prediction",
      "authors": "Z Li, Y Liu, B Li, B Feng, K Wu\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4657133348792854073&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Pavement Surface Defect Detection Using Mask Region-Based Convolutional Neural Networks and Transfer Learning",
      "id": "4748746639276173174",
      "url": "https://www.mdpi.com/2076-3417/12/15/7364",
      "title": "Pavement Surface Defect Detection Using Mask Region-Based Convolutional Neural Networks and Transfer Learning",
      "authors": "Y He, Z Jin, J Zhang, S Teng, G Chen, X Sun, F Cui",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4748746639276173174&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "PVDet: Towards pedestrian and vehicle detection on gigapixel-level images",
      "id": "1365022424711941058",
      "url": "https://www.sciencedirect.com/science/article/pii/S0952197622006959",
      "title": "PVDet: Towards pedestrian and vehicle detection on gigapixel-level images",
      "authors": "W Mo, W Zhang, H Wei, R Cao, Y Ke, Y Luo",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1365022424711941058&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Advances in medical image analysis with vision transformers: A comprehensive review",
      "id": "4381569612155749359",
      "url": "https://arxiv.org/abs/2301.03505",
      "title": "Advances in medical image analysis with vision transformers: A comprehensive review",
      "authors": "R Azad, A Kazerouni, M Heidari, EK Aghdam\u2026",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4381569612155749359&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "TE-YOLOF: Tiny and efficient YOLOF for blood cell detection",
      "id": "9304804814105874282",
      "url": "https://www.sciencedirect.com/science/article/pii/S1746809421010132",
      "title": "TE-YOLOF: Tiny and efficient YOLOF for blood cell detection",
      "authors": "F Xu, X Li, H Yang, Y Wang, W Xiang",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9304804814105874282&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "EYOLOX: An Efficient One-Stage Object Detection Network Based on YOLOX",
      "id": "745746885882128143",
      "url": "https://www.mdpi.com/2076-3417/13/3/1506",
      "title": "EYOLOX: An Efficient One-Stage Object Detection Network Based on YOLOX",
      "authors": "R Tang, H Sun, D Liu, H Xu, M Qi, J Kong",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=745746885882128143&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Deep Learning for Logo Detection: A Survey",
      "id": "3394653354596589290",
      "url": "https://arxiv.org/abs/2210.04399",
      "title": "Deep Learning for Logo Detection: A Survey",
      "authors": "S Hou, J Li, W Min, Q Hou, Y Zhao, Y Zheng\u2026",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3394653354596589290&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "An anchor-free defect detector for complex background based on pixelwise adaptive multiscale feature fusion",
      "id": "2190081206030913404",
      "url": "https://ieeexplore.ieee.org/abstract/document/9992183/",
      "title": "An anchor-free defect detector for complex background based on pixelwise adaptive multiscale feature fusion",
      "authors": "H Lu, M Fang, Y Qiu, W Xu",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2190081206030913404&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "PersonGONE: Image inpainting for automated checkout solution",
      "id": "9343841596799945450",
      "url": "http://openaccess.thecvf.com/content/CVPR2022W/AICity/html/Bartl_PersonGONE_Image_Inpainting_for_Automated_Checkout_Solution_CVPRW_2022_paper.html",
      "title": "PersonGONE: Image inpainting for automated checkout solution",
      "authors": "V Bartl, J \u0160pa\u0148hel, A Herout",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9343841596799945450&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Surround-view Fisheye BEV-Perception for Valet Parking: Dataset, Baseline and Distortion-insensitive Multi-task Framework",
      "id": "8353648664327356722",
      "url": "https://ieeexplore.ieee.org/abstract/document/9941140/",
      "title": "Surround-view Fisheye BEV-Perception for Valet Parking: Dataset, Baseline and Distortion-insensitive Multi-task Framework",
      "authors": "Z Wu, Y Gan, X Li, Y Wu, X Wang\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8353648664327356722&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "GLE-Net: A global and local ensemble network for aerial object detection",
      "id": "4120546132280571779",
      "url": "https://link.springer.com/article/10.1007/s44196-021-00056-3",
      "title": "GLE-Net: A global and local ensemble network for aerial object detection",
      "authors": "J Liao, Y Liu, Y Piao, J Su, G Cai, Y Wu",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4120546132280571779&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "SE-COTR: A novel fruit segmentation model for green apples application in complex orchard",
      "id": "13843016997180263542",
      "url": "https://spj.science.org/doi/abs/10.34133/plantphenomics.0005",
      "title": "SE-COTR: A novel fruit segmentation model for green apples application in complex orchard",
      "authors": "Z Wang, Z Zhang, Y Lu, R Luo, Y Niu, X Yang\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13843016997180263542&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "Aircraft Target Detection in Low Signal-to-Noise Ratio Visible Remote Sensing Images",
      "id": "18113388340145752965",
      "url": "https://www.mdpi.com/2072-4292/15/8/1971",
      "title": "Aircraft Target Detection in Low Signal-to-Noise Ratio Visible Remote Sensing Images",
      "authors": "R Niu, X Zhi, S Jiang, J Gong, W Zhang, L Yu",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18113388340145752965&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "A Dynamic Weights-Based Wavelet Attention Neural Network for Defect Detection",
      "id": "10442483506407696721",
      "url": "https://ieeexplore.ieee.org/abstract/document/10179489/",
      "title": "A Dynamic Weights-Based Wavelet Attention Neural Network for Defect Detection",
      "authors": "J Liu, H Zhao, Z Chen, Q Wang\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10442483506407696721&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 11
    },
    {
      "label": "A review on deep learning in UAV remote sensing",
      "id": "728770006208310182",
      "url": "https://www.sciencedirect.com/science/article/pii/S030324342100163X",
      "title": "A review on deep learning in UAV remote sensing",
      "authors": "LP Osco, JM Junior, APM Ramos\u2026",
      "year": "2021",
      "cited_by": 203,
      "cited_by_url": "https://scholar.google.com/scholar?cites=728770006208310182&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Recent advances on loss functions in deep learning for computer vision",
      "id": "2381336199697874290",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231222005239",
      "title": "Recent advances on loss functions in deep learning for computer vision",
      "authors": "Y Tian, D Su, S Lauria, X Liu",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2381336199697874290&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Learning salient boundary feature for anchor-free temporal action localization",
      "id": "8767327019590446489",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Lin_Learning_Salient_Boundary_Feature_for_Anchor-free_Temporal_Action_Localization_CVPR_2021_paper.html",
      "title": "Learning salient boundary feature for anchor-free temporal action localization",
      "authors": "C Lin, C Xu, D Luo, Y Wang, Y Tai\u2026",
      "year": "2021",
      "cited_by": 154,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8767327019590446489&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "End-to-end object detection with fully convolutional network",
      "id": "5174677530138095658",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_End-to-End_Object_Detection_With_Fully_Convolutional_Network_CVPR_2021_paper.html?ref=https://githubhelp.com",
      "title": "End-to-end object detection with fully convolutional network",
      "authors": "J Wang, L Song, Z Li, H Sun, J Sun\u2026",
      "year": "2021",
      "cited_by": 172,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5174677530138095658&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Dynamic anchor learning for arbitrary-oriented object detection",
      "id": "10604255508526386376",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/16336",
      "title": "Dynamic anchor learning for arbitrary-oriented object detection",
      "authors": "Q Ming, Z Zhou, L Miao, H Zhang, L Li",
      "year": "2021",
      "cited_by": 192,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10604255508526386376&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Generalized few-shot object detection without forgetting",
      "id": "6196888269192586051",
      "url": "https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Generalized_Few-Shot_Object_Detection_Without_Forgetting_CVPR_2021_paper.html?ref=https://githubhelp.com",
      "title": "Generalized few-shot object detection without forgetting",
      "authors": "Z Fan, Y Ma, Z Li, J Sun",
      "year": "2021",
      "cited_by": 117,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6196888269192586051&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Anchor-free oriented proposal generator for object detection",
      "id": "2965311170207987165",
      "url": "https://ieeexplore.ieee.org/abstract/document/9795321/",
      "title": "Anchor-free oriented proposal generator for object detection",
      "authors": "G Cheng, J Wang, K Li, X Xie, C Lang\u2026",
      "year": "2022",
      "cited_by": 109,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2965311170207987165&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Mmrotate: A rotated object detection benchmark using pytorch",
      "id": "11140668418037577536",
      "url": "https://dl.acm.org/doi/abs/10.1145/3503161.3548541",
      "title": "Mmrotate: A rotated object detection benchmark using pytorch",
      "authors": "Y Zhou, X Yang, G Zhang, J Wang, Y Liu\u2026",
      "year": "2022",
      "cited_by": 86,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11140668418037577536&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Dense teacher: Dense pseudo-labels for semi-supervised object detection",
      "id": "17675636447045263550",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_3",
      "title": "Dense teacher: Dense pseudo-labels for semi-supervised object detection",
      "authors": "H Zhou, Z Ge, S Liu, W Mao, Z Li, H Yu\u2026",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17675636447045263550&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Liga-stereo: Learning lidar geometry aware representations for stereo-based 3d detector",
      "id": "1878991916435892092",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Guo_LIGA-Stereo_Learning_LiDAR_Geometry_Aware_Representations_for_Stereo-Based_3D_Detector_ICCV_2021_paper.html",
      "title": "Liga-stereo: Learning lidar geometry aware representations for stereo-based 3d detector",
      "authors": "X Guo, S Shi, X Wang, H Li",
      "year": "2021",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1878991916435892092&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Tresnet: High performance gpu-dedicated architecture",
      "id": "4988547052049874893",
      "url": "http://openaccess.thecvf.com/content/WACV2021/html/Ridnik_TResNet_High_Performance_GPU-Dedicated_Architecture_WACV_2021_paper.html",
      "title": "Tresnet: High performance gpu-dedicated architecture",
      "authors": "T Ridnik, H Lawen, A Noy\u2026",
      "year": "2021",
      "cited_by": 187,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4988547052049874893&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Autoassign: Differentiable label assignment for dense object detection",
      "id": "4350254585552726003",
      "url": "https://arxiv.org/abs/2007.03496",
      "title": "Autoassign: Differentiable label assignment for dense object detection",
      "authors": "B Zhu, J Wang, Z Jiang, F Zong, S Liu, Z Li\u2026",
      "year": "2020",
      "cited_by": 181,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4350254585552726003&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "LS-SSDD-v1. 0: A deep learning dataset dedicated to small ship detection from large-scale Sentinel-1 SAR images",
      "id": "124174586124414315",
      "url": "https://www.mdpi.com/2072-4292/12/18/2997",
      "title": "LS-SSDD-v1. 0: A deep learning dataset dedicated to small ship detection from large-scale Sentinel-1 SAR images",
      "authors": "T Zhang, X Zhang, X Ke, X Zhan, J Shi, S Wei, D Pan\u2026",
      "year": "2020",
      "cited_by": 144,
      "cited_by_url": "https://scholar.google.com/scholar?cites=124174586124414315&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Monocular 3d object detection with depth from motion",
      "id": "6486278392250669413",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20077-9_23",
      "title": "Monocular 3d object detection with depth from motion",
      "authors": "T Wang, J Pang, D Lin",
      "year": "2022",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6486278392250669413&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Beyond bounding-box: Convex-hull feature adaptation for oriented and densely packed object detection",
      "id": "11137887749868459671",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Guo_Beyond_Bounding-Box_Convex-Hull_Feature_Adaptation_for_Oriented_and_Densely_Packed_CVPR_2021_paper.html",
      "title": "Beyond bounding-box: Convex-hull feature adaptation for oriented and densely packed object detection",
      "authors": "Z Guo, C Liu, X Zhang, J Jiao, X Ji\u2026",
      "year": "2021",
      "cited_by": 82,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11137887749868459671&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Object discovery and representation networks",
      "id": "2275159817454841223",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19812-0_8",
      "title": "Object discovery and representation networks",
      "authors": "OJ H\u00e9naff, S Koppula, E Shelhamer, D Zoran\u2026",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2275159817454841223&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Group fisher pruning for practical network compression",
      "id": "7436704720048829343",
      "url": "http://proceedings.mlr.press/v139/liu21ab.html?ref=https://githubhelp.com",
      "title": "Group fisher pruning for practical network compression",
      "authors": "L Liu, S Zhang, Z Kuang, A Zhou\u2026",
      "year": "2021",
      "cited_by": 81,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7436704720048829343&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "QueryDet: Cascaded sparse query for accelerating high-resolution small object detection",
      "id": "10062072141692223467",
      "url": "https://openaccess.thecvf.com/content/CVPR2022/html/Yang_QueryDet_Cascaded_Sparse_Query_for_Accelerating_High-Resolution_Small_Object_Detection_CVPR_2022_paper.html?ref=https://githubhelp.com",
      "title": "QueryDet: Cascaded sparse query for accelerating high-resolution small object detection",
      "authors": "C Yang, Z Huang, N Wang",
      "year": "2022",
      "cited_by": 105,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10062072141692223467&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Imvoxelnet: Image to voxels projection for monocular and multi-view general-purpose 3d object detection",
      "id": "14766840776929327982",
      "url": "http://openaccess.thecvf.com/content/WACV2022/html/Rukhovich_ImVoxelNet_Image_to_Voxels_Projection_for_Monocular_and_Multi-View_General-Purpose_WACV_2022_paper.html",
      "title": "Imvoxelnet: Image to voxels projection for monocular and multi-view general-purpose 3d object detection",
      "authors": "D Rukhovich, A Vorontsova\u2026",
      "year": "2022",
      "cited_by": 95,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14766840776929327982&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "An empirical study of remote sensing pretraining",
      "id": "10951300284096917451",
      "url": "https://ieeexplore.ieee.org/abstract/document/9782149/",
      "title": "An empirical study of remote sensing pretraining",
      "authors": "D Wang, J Zhang, B Du, GS Xia\u2026",
      "year": "2022",
      "cited_by": 65,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10951300284096917451&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Unbiased teacher v2: Semi-supervised object detection for anchor-free and anchor-based detectors",
      "id": "15129909426072124916",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Liu_Unbiased_Teacher_v2_Semi-Supervised_Object_Detection_for_Anchor-Free_and_Anchor-Based_CVPR_2022_paper.html",
      "title": "Unbiased teacher v2: Semi-supervised object detection for anchor-free and anchor-based detectors",
      "authors": "YC Liu, CY Ma, Z Kira",
      "year": "2022",
      "cited_by": 47,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15129909426072124916&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Balance learning for ship detection from synthetic aperture radar remote sensing imagery",
      "id": "12867622177717661888",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271621002781",
      "title": "Balance learning for ship detection from synthetic aperture radar remote sensing imagery",
      "authors": "T Zhang, X Zhang, C Liu, J Shi, S Wei, I Ahmad\u2026",
      "year": "2021",
      "cited_by": 61,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12867622177717661888&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Video self-stitching graph network for temporal action localization",
      "id": "625028681591269424",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Video_Self-Stitching_Graph_Network_for_Temporal_Action_Localization_ICCV_2021_paper.html",
      "title": "Video self-stitching graph network for temporal action localization",
      "authors": "C Zhao, AK Thabet, B Ghanem",
      "year": "2021",
      "cited_by": 90,
      "cited_by_url": "https://scholar.google.com/scholar?cites=625028681591269424&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Shape-adaptive selection and measurement for oriented object detection",
      "id": "9394900835405963044",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/19975",
      "title": "Shape-adaptive selection and measurement for oriented object detection",
      "authors": "L Hou, K Lu, J Xue, Y Li",
      "year": "2022",
      "cited_by": 55,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9394900835405963044&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Unsupervised learning of accurate siamese tracking",
      "id": "4089155253019708361",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Shen_Unsupervised_Learning_of_Accurate_Siamese_Tracking_CVPR_2022_paper.html",
      "title": "Unsupervised learning of accurate siamese tracking",
      "authors": "Q Shen, L Qiao, J Guo, P Li, X Li, B Li\u2026",
      "year": "2022",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4089155253019708361&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Label matching semi-supervised object detection",
      "id": "17297670040926232009",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Chen_Label_Matching_Semi-Supervised_Object_Detection_CVPR_2022_paper.html",
      "title": "Label matching semi-supervised object detection",
      "authors": "B Chen, W Chen, S Yang, Y Xuan\u2026",
      "year": "2022",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17297670040926232009&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Reppoints v2: Verification meets regression for object detection",
      "id": "14843700105251392523",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/3ce3bd7d63a2c9c81983cc8e9bd02ae5-Abstract.html",
      "title": "Reppoints v2: Verification meets regression for object detection",
      "authors": "Y Chen, Z Zhang, Y Cao, L Wang\u2026",
      "year": "2020",
      "cited_by": 101,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14843700105251392523&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Point-set anchors for object detection, instance segmentation and pose estimation",
      "id": "8225197904370189459",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58607-2_31",
      "title": "Point-set anchors for object detection, instance segmentation and pose estimation",
      "authors": "F Wei, X Sun, H Li, J Wang, S Lin",
      "year": "2020",
      "cited_by": 106,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8225197904370189459&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Fcaf3d: Fully convolutional anchor-free 3d object detection",
      "id": "4527666642194648577",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20080-9_28",
      "title": "Fcaf3d: Fully convolutional anchor-free 3d object detection",
      "authors": "D Rukhovich, A Vorontsova, A Konushin",
      "year": "2022",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4527666642194648577&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "FPCB surface defect detection: A decoupled two-stage object detection framework",
      "id": "11128139934147031880",
      "url": "https://ieeexplore.ieee.org/abstract/document/9465824/",
      "title": "FPCB surface defect detection: A decoupled two-stage object detection framework",
      "authors": "J Luo, Z Yang, S Li, Y Wu",
      "year": "2021",
      "cited_by": 63,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11128139934147031880&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "SiamCorners: Siamese corner networks for visual tracking",
      "id": "3406496252840731715",
      "url": "https://ieeexplore.ieee.org/abstract/document/9410380/",
      "title": "SiamCorners: Siamese corner networks for visual tracking",
      "authors": "K Yang, Z He, W Pei, Z Zhou, X Li\u2026",
      "year": "2021",
      "cited_by": 68,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3406496252840731715&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Corner proposal network for anchor-free, two-stage object detection",
      "id": "13568718297544497544",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58580-8_24",
      "title": "Corner proposal network for anchor-free, two-stage object detection",
      "authors": "K Duan, L Xie, H Qi, S Bai, Q Huang, Q Tian",
      "year": "2020",
      "cited_by": 93,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13568718297544497544&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Open-vocabulary one-stage detection with hierarchical visual-language knowledge distillation",
      "id": "12711419494084177503",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Ma_Open-Vocabulary_One-Stage_Detection_With_Hierarchical_Visual-Language_Knowledge_Distillation_CVPR_2022_paper.html",
      "title": "Open-vocabulary one-stage detection with hierarchical visual-language knowledge distillation",
      "authors": "Z Ma, G Luo, J Gao, L Li, Y Chen\u2026",
      "year": "2022",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12711419494084177503&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "A survey of convolutional neural networks: analysis, applications, and prospects",
      "id": "9396440723658947289",
      "url": "https://ieeexplore.ieee.org/abstract/document/9451544/",
      "title": "A survey of convolutional neural networks: analysis, applications, and prospects",
      "authors": "Z Li, F Liu, W Yang, S Peng\u2026",
      "year": "2021",
      "cited_by": 1166,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9396440723658947289&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving",
      "id": "17659240868782185606",
      "url": "https://ieeexplore.ieee.org/abstract/document/9857660/",
      "title": "Federated vehicular transformers and their federations: Privacy-preserving computing and cooperation for autonomous driving",
      "authors": "Y Tian, J Wang, Y Wang, C Zhao\u2026",
      "year": "2022",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17659240868782185606&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Application and progress of chemometrics in voltammetric biosensing",
      "id": "1330128288162812959",
      "url": "https://www.mdpi.com/2079-6374/12/7/494",
      "title": "Application and progress of chemometrics in voltammetric biosensing",
      "authors": "J Liu, Y Xu, S Liu, S Yu, Z Yu, SS Low",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1330128288162812959&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Cyber security in smart cities: a review of deep learning-based applications and case studies",
      "id": "12461780382342897766",
      "url": "https://www.sciencedirect.com/science/article/pii/S2210670720308714",
      "title": "Cyber security in smart cities: a review of deep learning-based applications and case studies",
      "authors": "D Chen, P Wawrzynski, Z Lv",
      "year": "2021",
      "cited_by": 167,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12461780382342897766&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Uni-perceiver: Pre-training unified architecture for generic perception for zero-shot and few-shot tasks",
      "id": "2894457065609999138",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhu_Uni-Perceiver_Pre-Training_Unified_Architecture_for_Generic_Perception_for_Zero-Shot_and_CVPR_2022_paper.html",
      "title": "Uni-perceiver: Pre-training unified architecture for generic perception for zero-shot and few-shot tasks",
      "authors": "X Zhu, J Zhu, H Li, X Wu, H Li\u2026",
      "year": "2022",
      "cited_by": 61,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2894457065609999138&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence",
      "id": "3367852488199289115",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253523001148",
      "title": "Explainable Artificial Intelligence (XAI): What we know and what is left to attain Trustworthy Artificial Intelligence",
      "authors": "S Ali, T Abuhmed, S El-Sappagh, K Muhammad\u2026",
      "year": "2023",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3367852488199289115&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Hardware and software optimizations for accelerating deep neural networks: Survey of current trends, challenges, and the road ahead",
      "id": "10959765252077951834",
      "url": "https://ieeexplore.ieee.org/abstract/document/9269334/",
      "title": "Hardware and software optimizations for accelerating deep neural networks: Survey of current trends, challenges, and the road ahead",
      "authors": "M Capra, B Bussolino, A Marchisio, G Masera\u2026",
      "year": "2020",
      "cited_by": 116,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10959765252077951834&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Chaotic harris hawks optimization with quasi-reflection-based learning: An application to enhance cnn design",
      "id": "6330853643103469907",
      "url": "https://www.mdpi.com/1424-8220/21/19/6654",
      "title": "Chaotic harris hawks optimization with quasi-reflection-based learning: An application to enhance cnn design",
      "authors": "J Basha, N Bacanin, N Vukobrat, M Zivkovic\u2026",
      "year": "2021",
      "cited_by": 55,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6330853643103469907&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A novel deep convolution multi-adversarial domain adaptation model for rolling bearing fault diagnosis",
      "id": "11264330757232304805",
      "url": "https://www.sciencedirect.com/science/article/pii/S0263224122000549",
      "title": "A novel deep convolution multi-adversarial domain adaptation model for rolling bearing fault diagnosis",
      "authors": "L Wan, Y Li, K Chen, K Gong, C Li",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11264330757232304805&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Deep CNN-based damage classification of milled rice grains using a high-magnification image dataset",
      "id": "104652044397290954",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922001284",
      "title": "Deep CNN-based damage classification of milled rice grains using a high-magnification image dataset",
      "authors": "K Moses, A Miglani, PK Kankar",
      "year": "2022",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=104652044397290954&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Uni-perceiver-moe: Learning sparse generalist models with conditional moes",
      "id": "8405812116415915225",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/11fc8c98b46d4cbdfe8157267228f7d7-Abstract-Conference.html",
      "title": "Uni-perceiver-moe: Learning sparse generalist models with conditional moes",
      "authors": "J Zhu, X Zhu, W Wang, X Wang, H Li\u2026",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8405812116415915225&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Multi-level feature fusion for multimodal human activity recognition in Internet of Healthcare Things",
      "id": "11817815354857298574",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253523000246",
      "title": "Multi-level feature fusion for multimodal human activity recognition in Internet of Healthcare Things",
      "authors": "MM Islam, S Nooruddin, F Karray, G Muhammad",
      "year": "2023",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11817815354857298574&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A hybrid DNN\u2013LSTM model for detecting phishing URLs",
      "id": "16381610666186844878",
      "url": "https://link.springer.com/article/10.1007/s00521-021-06401-z",
      "title": "A hybrid DNN\u2013LSTM model for detecting phishing URLs",
      "authors": "A Ozcan, C Catal, E Donmez, B Senturk",
      "year": "2021",
      "cited_by": 47,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16381610666186844878&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A computer-aided diagnostic framework for coronavirus diagnosis using texture-based radiomics images",
      "id": "3245855105634480603",
      "url": "https://journals.sagepub.com/doi/abs/10.1177/20552076221092543",
      "title": "A computer-aided diagnostic framework for coronavirus diagnosis using texture-based radiomics images",
      "authors": "O Attallah",
      "year": "2022",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3245855105634480603&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Deep CNN and deep GAN in computational visual perception-driven image analysis",
      "id": "3529628295378086556",
      "url": "https://www.hindawi.com/journals/complexity/2021/5541134/",
      "title": "Deep CNN and deep GAN in computational visual perception-driven image analysis",
      "authors": "R Nandhini Abirami, PM Durai Raj Vincent\u2026",
      "year": "2021",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3529628295378086556&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Reveal of vision transformers robustness against adversarial attacks",
      "id": "7737148347777017891",
      "url": "https://arxiv.org/abs/2106.03734",
      "title": "Reveal of vision transformers robustness against adversarial attacks",
      "authors": "A Aldahdooh, W Hamidouche, O Deforges",
      "year": "2021",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7737148347777017891&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Challenging the security of logic locking schemes in the era of deep learning: A neuroevolutionary approach",
      "id": "7585820726866106888",
      "url": "https://dl.acm.org/doi/abs/10.1145/3431389",
      "title": "Challenging the security of logic locking schemes in the era of deep learning: A neuroevolutionary approach",
      "authors": "D Sisejkovic, F Merchant, LM Reimann\u2026",
      "year": "2021",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7585820726866106888&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Application of reinforcement learning and deep learning in multiple-input and multiple-output (MIMO) systems",
      "id": "16752346668949596807",
      "url": "https://www.mdpi.com/1424-8220/22/1/309",
      "title": "Application of reinforcement learning and deep learning in multiple-input and multiple-output (MIMO) systems",
      "authors": "M Naeem, G De Pietro, A Coronato",
      "year": "2021",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16752346668949596807&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Survey of deep learning paradigms for speech processing",
      "id": "9766170352567939917",
      "url": "https://link.springer.com/article/10.1007/s11277-022-09640-y",
      "title": "Survey of deep learning paradigms for speech processing",
      "authors": "KB Bhangale, M Kothandaraman",
      "year": "2022",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9766170352567939917&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "EDNC: Ensemble deep neural network for COVID-19 recognition",
      "id": "13409251986329658691",
      "url": "https://www.mdpi.com/2379-139X/8/2/71",
      "title": "EDNC: Ensemble deep neural network for COVID-19 recognition",
      "authors": "L Yang, SH Wang, YD Zhang",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13409251986329658691&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A CSI-based human activity recognition using deep learning",
      "id": "473530282656916811",
      "url": "https://www.mdpi.com/1424-8220/21/21/7225",
      "title": "A CSI-based human activity recognition using deep learning",
      "authors": "PF Moshiri, R Shahbazian, M Nabati, SA Ghorashi",
      "year": "2021",
      "cited_by": 35,
      "cited_by_url": "https://scholar.google.com/scholar?cites=473530282656916811&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Deep learning approaches and interventions for futuristic engineering in agriculture",
      "id": "1190843868981231273",
      "url": "https://link.springer.com/article/10.1007/s00521-022-07744-x",
      "title": "Deep learning approaches and interventions for futuristic engineering in agriculture",
      "authors": "SK Chakraborty, NS Chandel, D Jat, MK Tiwari\u2026",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1190843868981231273&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A novel information processing method based on an ensemble of Auto-Encoders for unsupervised fault detection",
      "id": "11786070565691042647",
      "url": "https://www.sciencedirect.com/science/article/pii/S0166361522001403",
      "title": "A novel information processing method based on an ensemble of Auto-Encoders for unsupervised fault detection",
      "authors": "S Plakias, YS Boutalis",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11786070565691042647&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A novel approach for APT attack detection based on combined deep learning model",
      "id": "9568123547245923264",
      "url": "https://link.springer.com/article/10.1007/s00521-021-05952-5",
      "title": "A novel approach for APT attack detection based on combined deep learning model",
      "authors": "C Do Xuan, MH Dao",
      "year": "2021",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9568123547245923264&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Large\u2010scale structural health monitoring using composite recurrent neural networks and grid environments",
      "id": "9275353594998479018",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12845",
      "title": "Large\u2010scale structural health monitoring using composite recurrent neural networks and grid environments",
      "authors": "KA Eltouny, X Liang",
      "year": "2023",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9275353594998479018&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Promoting smart tourism personalised services via a combination of deep learning techniques",
      "id": "674676834371939814",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417421013154",
      "title": "Promoting smart tourism personalised services via a combination of deep learning techniques",
      "authors": "A Kontogianni, E Alepis, C Patsakis",
      "year": "2022",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=674676834371939814&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "AI meets UAVs: A survey on AI empowered UAV perception systems for precision agriculture",
      "id": "16147182476848743143",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231222013996",
      "title": "AI meets UAVs: A survey on AI empowered UAV perception systems for precision agriculture",
      "authors": "J Su, X Zhu, S Li, WH Chen",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16147182476848743143&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A comprehensive survey of machine learning applied to radar signal processing",
      "id": "6604331675399620890",
      "url": "https://arxiv.org/abs/2009.13702",
      "title": "A comprehensive survey of machine learning applied to radar signal processing",
      "authors": "P Lang, X Fu, M Martorella, J Dong, R Qin\u2026",
      "year": "2020",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6604331675399620890&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Convolutional neural networks: A survey",
      "id": "17835922521314202374",
      "url": "https://www.mdpi.com/2073-431X/12/8/151",
      "title": "Convolutional neural networks: A survey",
      "authors": "M Krichen",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17835922521314202374&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A review of driver fatigue detection and its advances on the use of RGB-D camera and deep learning",
      "id": "8491094163353345221",
      "url": "https://www.sciencedirect.com/science/article/pii/S0952197622003967",
      "title": "A review of driver fatigue detection and its advances on the use of RGB-D camera and deep learning",
      "authors": "F Liu, D Chen, J Zhou, F Xu",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8491094163353345221&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Deep ensemble learning for human activity recognition using wearable sensors via filter activation",
      "id": "2776188056280590893",
      "url": "https://dl.acm.org/doi/abs/10.1145/3551486",
      "title": "Deep ensemble learning for human activity recognition using wearable sensors via filter activation",
      "authors": "W Huang, L Zhang, S Wang, H Wu\u2026",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2776188056280590893&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "DSMNN-Net: A deep siamese morphological neural network model for burned area mapping using multispectral sentinel-2 and hyperspectral PRISMA\u00a0\u2026",
      "id": "12148457517294144158",
      "url": "https://www.mdpi.com/2072-4292/13/24/5138",
      "title": "DSMNN-Net: A deep siamese morphological neural network model for burned area mapping using multispectral sentinel-2 and hyperspectral PRISMA\u00a0\u2026",
      "authors": "ST Seydi, M Hasanlou, J Chanussot",
      "year": "2021",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12148457517294144158&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Encoding contextual information by interlacing transformer and convolution for remote sensing imagery semantic segmentation",
      "id": "162944317775498564",
      "url": "https://www.mdpi.com/2072-4292/14/16/4065",
      "title": "Encoding contextual information by interlacing transformer and convolution for remote sensing imagery semantic segmentation",
      "authors": "X Li, F Xu, R Xia, T Li, Z Chen, X Wang, Z Xu, X Lyu",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=162944317775498564&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Review of machine learning based fault detection for centrifugal pump induction motors",
      "id": "7022412739527890738",
      "url": "https://ieeexplore.ieee.org/abstract/document/9812600/",
      "title": "Review of machine learning based fault detection for centrifugal pump induction motors",
      "authors": "CE Sunal, V Dyo, V Velisavljevic",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7022412739527890738&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "An intelligent environment for preventing medication errors in home treatment",
      "id": "16729230970251043916",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417421017218",
      "title": "An intelligent environment for preventing medication errors in home treatment",
      "authors": "M Ciampi, A Coronato, M Naeem, S Silvestri",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16729230970251043916&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "IEViT: An enhanced vision transformer architecture for chest X-ray image classification",
      "id": "7643365245113467622",
      "url": "https://www.sciencedirect.com/science/article/pii/S0169260722005223",
      "title": "IEViT: An enhanced vision transformer architecture for chest X-ray image classification",
      "authors": "GI Okolo, S Katsigiannis, N Ramzan",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7643365245113467622&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Intrusion detection systems: A state-of-the-art taxonomy and survey",
      "id": "11258068837507688644",
      "url": "https://link.springer.com/article/10.1007/s13369-022-07412-1",
      "title": "Intrusion detection systems: A state-of-the-art taxonomy and survey",
      "authors": "M Alkasassbeh, S Al-Haj Baddar",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11258068837507688644&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Homo\u2013heterogenous transformer learning framework for RS scene classification",
      "id": "17820547851845778893",
      "url": "https://ieeexplore.ieee.org/abstract/document/9726930/",
      "title": "Homo\u2013heterogenous transformer learning framework for RS scene classification",
      "authors": "J Ma, M Li, X Tang, X Zhang, F Liu\u2026",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17820547851845778893&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "QTTNet: Quantized tensor train neural networks for 3D object and video recognition",
      "id": "13749289119625037185",
      "url": "https://www.sciencedirect.com/science/article/pii/S0893608021002306",
      "title": "QTTNet: Quantized tensor train neural networks for 3D object and video recognition",
      "authors": "D Lee, D Wang, Y Yang, L Deng, G Zhao, G Li",
      "year": "2021",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13749289119625037185&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Hybrid-COVID: a novel hybrid 2D/3D CNN based on cross-domain adaptation approach for COVID-19 screening from chest X-ray images",
      "id": "7991192741706114520",
      "url": "https://link.springer.com/article/10.1007/s13246-020-00957-1",
      "title": "Hybrid-COVID: a novel hybrid 2D/3D CNN based on cross-domain adaptation approach for COVID-19 screening from chest X-ray images",
      "authors": "K Bayoudh, F Hamdaoui, A Mtibaa",
      "year": "2020",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7991192741706114520&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Dig information of nanogenerators by machine learning",
      "id": "7647425146852033954",
      "url": "https://www.sciencedirect.com/science/article/pii/S2211285523004937",
      "title": "Dig information of nanogenerators by machine learning",
      "authors": "J Zhang, Y Yu, L Zhang, J Chen, X Wang, X Wang",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7647425146852033954&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "CNN-CNN: Dual Convolutional Neural Network Approach for Feature Selection and Attack Detection on Internet of Things Networks",
      "id": "11663125968410326892",
      "url": "https://www.mdpi.com/1424-8220/23/14/6507",
      "title": "CNN-CNN: Dual Convolutional Neural Network Approach for Feature Selection and Attack Detection on Internet of Things Networks",
      "authors": "BA Alabsi, M Anbar, SDA Rihan",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11663125968410326892&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Combining deep learning and fluorescence imaging to automatically identify fecal contamination on meat carcasses",
      "id": "166903673990182366",
      "url": "https://www.nature.com/articles/s41598-022-06379-1",
      "title": "Combining deep learning and fluorescence imaging to automatically identify fecal contamination on meat carcasses",
      "authors": "HT Gorji, SM Shahabi, A Sharma, LQ Tande\u2026",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=166903673990182366&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "An AI-empowered infrastructure for risk prevention during medical examination",
      "id": "9882802714230086643",
      "url": "https://www.sciencedirect.com/science/article/pii/S095741742300550X",
      "title": "An AI-empowered infrastructure for risk prevention during medical examination",
      "authors": "SIH Shah, M Naeem, G Paragliola, A Coronato\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9882802714230086643&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A novel vibration-based prognostic scheme for gear health management in surface wear progression of the intelligent manufacturing system",
      "id": "15888192171340754642",
      "url": "https://www.sciencedirect.com/science/article/pii/S0043164823000807",
      "title": "A novel vibration-based prognostic scheme for gear health management in surface wear progression of the intelligent manufacturing system",
      "authors": "K Feng, JC Ji, Q Ni, Y Li, W Mao, L Liu",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15888192171340754642&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Semi-supervised vision transformer with adaptive token sampling for breast cancer classification",
      "id": "12874330746450003457",
      "url": "https://www.frontiersin.org/articles/10.3389/fphar.2022.929755/full",
      "title": "Semi-supervised vision transformer with adaptive token sampling for breast cancer classification",
      "authors": "W Wang, R Jiang, N Cui, Q Li, F Yuan\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12874330746450003457&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Computational chromatography: A machine learning strategy for demixing individual chemical components in complex mixtures",
      "id": "11163389046080764508",
      "url": "https://www.pnas.org/doi/abs/10.1073/pnas.2211406119",
      "title": "Computational chromatography: A machine learning strategy for demixing individual chemical components in complex mixtures",
      "authors": "MM Bajomo, Y Ju, J Zhou\u2026",
      "year": "2022",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11163389046080764508&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Relation-attention networks for remote sensing scene classification",
      "id": "11069243657064968619",
      "url": "https://ieeexplore.ieee.org/abstract/document/9652121/",
      "title": "Relation-attention networks for remote sensing scene classification",
      "authors": "X Wang, L Duan, C Ning, H Zhou",
      "year": "2021",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11069243657064968619&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Deep mutual attention network for acoustic scene classification",
      "id": "8285293036267904321",
      "url": "https://www.sciencedirect.com/science/article/pii/S1051200422000677",
      "title": "Deep mutual attention network for acoustic scene classification",
      "authors": "W Xie, Q He, Z Yu, Y Li",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8285293036267904321&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Recommender systems based on graph embedding techniques: A review",
      "id": "10942600018958755822",
      "url": "https://ieeexplore.ieee.org/abstract/document/9772660/",
      "title": "Recommender systems based on graph embedding techniques: A review",
      "authors": "Y Deng",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10942600018958755822&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "An evolutionary explainable deep learning approach for Alzheimer's MRI classification",
      "id": "14522233362639662098",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417423002105",
      "title": "An evolutionary explainable deep learning approach for Alzheimer's MRI classification",
      "authors": "S Shojaei, MS Abadeh, Z Momeni",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14522233362639662098&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Dualformer: Local-global stratified transformer for efficient video recognition",
      "id": "5432221077116828342",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19830-4_33",
      "title": "Dualformer: Local-global stratified transformer for efficient video recognition",
      "authors": "Y Liang, P Zhou, R Zimmermann, S Yan",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5432221077116828342&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A bayesian framework for integrated deep metric learning and tracking of vulnerable road users using automotive radars",
      "id": "12109569770609306860",
      "url": "https://ieeexplore.ieee.org/abstract/document/9423952/",
      "title": "A bayesian framework for integrated deep metric learning and tracking of vulnerable road users using automotive radars",
      "authors": "A Dubey, A Santra, J Fuchs, M L\u00fcbke, R Weigel\u2026",
      "year": "2021",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12109569770609306860&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "LMFFNet: a well-balanced lightweight network for fast and accurate semantic segmentation",
      "id": "9800786600952641254",
      "url": "https://ieeexplore.ieee.org/abstract/document/9783460/",
      "title": "LMFFNet: a well-balanced lightweight network for fast and accurate semantic segmentation",
      "authors": "M Shi, J Shen, Q Yi, J Weng, Z Huang\u2026",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9800786600952641254&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Automatic segmentation of optic disc in retinal fundus images using semi-supervised deep learning",
      "id": "3851853212057137221",
      "url": "https://link.springer.com/article/10.1007/s11042-020-09778-6",
      "title": "Automatic segmentation of optic disc in retinal fundus images using semi-supervised deep learning",
      "authors": "S Bengani",
      "year": "2021",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3851853212057137221&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Enhancing ensemble diversity based on multiscale dilated convolution in image classification",
      "id": "5116550664858304460",
      "url": "https://www.sciencedirect.com/science/article/pii/S0020025522004960",
      "title": "Enhancing ensemble diversity based on multiscale dilated convolution in image classification",
      "authors": "GR You, YR Shiue, CT Su, QL Huang",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5116550664858304460&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Unsupervised deep multitask anomaly detection with robust alarm strategy for online evaluation of bearing early fault occurrence",
      "id": "6524394779160024104",
      "url": "https://ieeexplore.ieee.org/abstract/document/9862997/",
      "title": "Unsupervised deep multitask anomaly detection with robust alarm strategy for online evaluation of bearing early fault occurrence",
      "authors": "W Mao, H Shi, G Wang, X Liang",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6524394779160024104&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A Deep Learning Approach to Organic Pollutants Classification Using Voltammetry",
      "id": "9586487638855151494",
      "url": "https://www.mdpi.com/1424-8220/22/20/8032",
      "title": "A Deep Learning Approach to Organic Pollutants Classification Using Voltammetry",
      "authors": "M Molinara, R Cancelliere, A Di Tinno, L Ferrigno\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9586487638855151494&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Artificial intelligence methodologies for data management",
      "id": "409384955469315628",
      "url": "https://www.mdpi.com/2073-8994/13/11/2040",
      "title": "Artificial intelligence methodologies for data management",
      "authors": "J Serey, L Quezada, M Alfaro, G Fuertes, M Vargas\u2026",
      "year": "2021",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=409384955469315628&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Learning in RKHM: a C*-Algebraic Twist for Kernel Machines",
      "id": "9288583655021028647",
      "url": "https://proceedings.mlr.press/v206/hashimoto23a.html",
      "title": "Learning in RKHM: a C*-Algebraic Twist for Kernel Machines",
      "authors": "Y Hashimoto, M Ikeda, H Kadri",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9288583655021028647&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Continuous estimation of power system inertia using convolutional neural networks",
      "id": "15152142901961614455",
      "url": "https://www.nature.com/articles/s41467-023-40192-2",
      "title": "Continuous estimation of power system inertia using convolutional neural networks",
      "authors": "D Linaro, F Bizzarri, D Del Giudice, C Pisani\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15152142901961614455&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Engineering semantic communication: A survey",
      "id": "17659066342463746102",
      "url": "https://ieeexplore.ieee.org/abstract/document/10038657/",
      "title": "Engineering semantic communication: A survey",
      "authors": "D Wheeler, B Natarajan",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17659066342463746102&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Applying a deep residual network coupling with transfer learning for recyclable waste sorting",
      "id": "3079241190308487697",
      "url": "https://link.springer.com/article/10.1007/s11356-022-22167-w",
      "title": "Applying a deep residual network coupling with transfer learning for recyclable waste sorting",
      "authors": "K Lin, Y Zhao, X Gao, M Zhang, C Zhao, L Peng\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3079241190308487697&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A deep learning-based intelligent receiver for improving the reliability of the MIMO wireless communication system",
      "id": "5544945261975848615",
      "url": "https://ieeexplore.ieee.org/abstract/document/9733027/",
      "title": "A deep learning-based intelligent receiver for improving the reliability of the MIMO wireless communication system",
      "authors": "B Wang, K Xu, S Zheng, H Zhou\u2026",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5544945261975848615&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A deep convolutional neural network-based multi-class image classification for automatic wafer map failure recognition in semiconductor manufacturing",
      "id": "8932281142246040268",
      "url": "https://www.mdpi.com/2076-3417/11/20/9769",
      "title": "A deep convolutional neural network-based multi-class image classification for automatic wafer map failure recognition in semiconductor manufacturing",
      "authors": "H Zheng, SWA Sherazi, SH Son, JY Lee",
      "year": "2021",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8932281142246040268&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "DANTD: A deep abnormal network traffic detection model for security of industrial internet of things using high-order features",
      "id": "4804878180815758179",
      "url": "https://ieeexplore.ieee.org/abstract/document/10061601/",
      "title": "DANTD: A deep abnormal network traffic detection model for security of industrial internet of things using high-order features",
      "authors": "G Shi, X Shen, F Xiao, Y He",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4804878180815758179&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Combination of political optimizer, particle swarm optimizer, and convolutional neural network for brain tumor detection",
      "id": "12494571714440080437",
      "url": "https://www.sciencedirect.com/science/article/pii/S1746809422008886",
      "title": "Combination of political optimizer, particle swarm optimizer, and convolutional neural network for brain tumor detection",
      "authors": "AH Bashkandi, K Sadoughi, F Aflaki\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12494571714440080437&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "PPNNP: A privacy-preserving neural network prediction with separated data providers using multi-client inner-product encryption",
      "id": "12934231027519550777",
      "url": "https://www.sciencedirect.com/science/article/pii/S0920548922000460",
      "title": "PPNNP: A privacy-preserving neural network prediction with separated data providers using multi-client inner-product encryption",
      "authors": "M Zhang, S Huang, G Shen, Y Wang",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12934231027519550777&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Automatic generation of artificial images of leukocytes and leukemic cells using generative adversarial networks (syntheticcellgan)",
      "id": "4286407019373546306",
      "url": "https://www.sciencedirect.com/science/article/pii/S0169260722006952",
      "title": "Automatic generation of artificial images of leukocytes and leukemic cells using generative adversarial networks (syntheticcellgan)",
      "authors": "K Barrera, A Merino, A Molina, J Rodellar",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4286407019373546306&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Convolutional neural networks with transfer learning for recognition of COVID-19: a comparative study of different approaches",
      "id": "12934860564933811755",
      "url": "https://www.mdpi.com/2673-2688/1/4/34",
      "title": "Convolutional neural networks with transfer learning for recognition of COVID-19: a comparative study of different approaches",
      "authors": "T Garg, M Garg, OP Mahela, AR Garg",
      "year": "2020",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12934860564933811755&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Deep learning for visual speech analysis: A survey",
      "id": "6471952400524995967",
      "url": "https://arxiv.org/abs/2205.10839",
      "title": "Deep learning for visual speech analysis: A survey",
      "authors": "C Sheng, G Kuang, L Bai, C Hou, Y Guo, X Xu\u2026",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6471952400524995967&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Graph convolutional networks in language and vision: A survey",
      "id": "2936922659962418453",
      "url": "https://www.sciencedirect.com/science/article/pii/S0950705122006220",
      "title": "Graph convolutional networks in language and vision: A survey",
      "authors": "H Ren, W Lu, Y Xiao, X Chang, X Wang, Z Dong\u2026",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2936922659962418453&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Theoretical understanding of convolutional neural network: concepts, architectures, applications, future directions",
      "id": "5343150201557663140",
      "url": "https://www.mdpi.com/2079-3197/11/3/52",
      "title": "Theoretical understanding of convolutional neural network: concepts, architectures, applications, future directions",
      "authors": "MM Taye",
      "year": "2023",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5343150201557663140&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "BreathMentor: Acoustic-based Diaphragmatic Breathing Monitor System",
      "id": "288293461476145835",
      "url": "https://dl.acm.org/doi/abs/10.1145/3534595",
      "title": "BreathMentor: Acoustic-based Diaphragmatic Breathing Monitor System",
      "authors": "Y Gong, Q Zhang, BHP NG, W Li",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=288293461476145835&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Black-box dataset ownership verification via backdoor watermarking",
      "id": "1946486029826048685",
      "url": "https://ieeexplore.ieee.org/abstract/document/10097580/",
      "title": "Black-box dataset ownership verification via backdoor watermarking",
      "authors": "Y Li, M Zhu, X Yang, Y Jiang, T Wei\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1946486029826048685&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Designing optimal convolutional neural network architecture using differential evolution algorithm",
      "id": "13147547687598130899",
      "url": "https://www.cell.com/patterns/pdf/S2666-3899(22)00178-7.pdf",
      "title": "Designing optimal convolutional neural network architecture using differential evolution algorithm",
      "authors": "A Ghosh, ND Jana, S Mallik, Z Zhao",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13147547687598130899&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Enhanced Arabic Sentiment Analysis Using a Novel Stacking Ensemble of Hybrid and Deep Learning Models",
      "id": "1188818162646880118",
      "url": "https://www.mdpi.com/2076-3417/12/18/8967",
      "title": "Enhanced Arabic Sentiment Analysis Using a Novel Stacking Ensemble of Hybrid and Deep Learning Models",
      "authors": "H Saleh, S Mostafa, LA Gabralla, A O. Aseeri\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1188818162646880118&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Real-time deep anomaly detection framework for multivariate time-series data in industrial iot",
      "id": "8069973205387436662",
      "url": "https://ieeexplore.ieee.org/abstract/document/9915308/",
      "title": "Real-time deep anomaly detection framework for multivariate time-series data in industrial iot",
      "authors": "H Nizam, S Zafar, Z Lv, F Wang, X Hu",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8069973205387436662&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Machine Learning for Millimeter Wave and Terahertz Beam Management: A Survey and Open Challenges",
      "id": "7181641912111691081",
      "url": "https://ieeexplore.ieee.org/abstract/document/10036372/",
      "title": "Machine Learning for Millimeter Wave and Terahertz Beam Management: A Survey and Open Challenges",
      "authors": "MQ Khan, A Gaber, P Schulz, G Fettweis",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7181641912111691081&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A mathematical framework for improved weight initialization of neural networks using Lagrange multipliers",
      "id": "18387253888735733879",
      "url": "https://www.sciencedirect.com/science/article/pii/S0893608023003921",
      "title": "A mathematical framework for improved weight initialization of neural networks using Lagrange multipliers",
      "authors": "I de Pater, M Mitici",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18387253888735733879&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A multimodal hyper-fusion transformer for remote sensing image classification",
      "id": "14318958312133554657",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253523000866",
      "title": "A multimodal hyper-fusion transformer for remote sensing image classification",
      "authors": "M Ma, W Ma, L Jiao, X Liu, L Li, Z Feng, S Yang",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14318958312133554657&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A continuous convolutional trainable filter for modelling unstructured data",
      "id": "6617971465675626792",
      "url": "https://link.springer.com/article/10.1007/s00466-023-02291-1",
      "title": "A continuous convolutional trainable filter for modelling unstructured data",
      "authors": "D Coscia, L Meneghetti, N Demo, G Stabile\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6617971465675626792&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "An intelligent anti-jamming scheme for cognitive radio based on deep reinforcement learning",
      "id": "16908822867886701327",
      "url": "https://ieeexplore.ieee.org/abstract/document/9249051/",
      "title": "An intelligent anti-jamming scheme for cognitive radio based on deep reinforcement learning",
      "authors": "J Xu, H Lou, W Zhang, G Sang",
      "year": "2020",
      "cited_by": 26,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16908822867886701327&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Weedgan: a novel generative adversarial network for cotton weed identification",
      "id": "3307690701392927370",
      "url": "https://link.springer.com/article/10.1007/s00371-022-02742-5",
      "title": "Weedgan: a novel generative adversarial network for cotton weed identification",
      "authors": "V Sharma, AK Tripathi, H Mittal, A Parmar, A Soni\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3307690701392927370&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "CNN-Pred: Prediction of single-stranded and double-stranded DNA-binding protein using convolutional neural networks",
      "id": "11526591086958196796",
      "url": "https://www.sciencedirect.com/science/article/pii/S0378111922008654",
      "title": "CNN-Pred: Prediction of single-stranded and double-stranded DNA-binding protein using convolutional neural networks",
      "authors": "F Manavi, A Sharma, R Sharma, T Tsunoda\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11526591086958196796&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "A BERT encoding with Recurrent Neural Network and Long-Short Term Memory for breast cancer image classification",
      "id": "12934682784061910585",
      "url": "https://www.sciencedirect.com/science/article/pii/S2772662223000176",
      "title": "A BERT encoding with Recurrent Neural Network and Long-Short Term Memory for breast cancer image classification",
      "authors": "S Chaudhury, K Sau",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12934682784061910585&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "The Geometry of Feature Space in Deep Learning Models: A Holistic Perspective and Comprehensive Review",
      "id": "7854799250999961474",
      "url": "https://www.mdpi.com/2227-7390/11/10/2375",
      "title": "The Geometry of Feature Space in Deep Learning Models: A Holistic Perspective and Comprehensive Review",
      "authors": "M Lee",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7854799250999961474&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Polarimetric Imaging via Deep Learning: A Review",
      "id": "5383924793672854664",
      "url": "https://www.mdpi.com/2072-4292/15/6/1540",
      "title": "Polarimetric Imaging via Deep Learning: A Review",
      "authors": "X Li, L Yan, P Qi, L Zhang, F Goudail, T Liu, J Zhai\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5383924793672854664&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Lightweight deep CNN-based models for early detection of COVID-19 patients from chest X-ray images",
      "id": "10139905476651083212",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417423004013",
      "title": "Lightweight deep CNN-based models for early detection of COVID-19 patients from chest X-ray images",
      "authors": "HI Hussein, AO Mohammed, MM Hassan\u2026",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10139905476651083212&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Self-supervised bi-channel transformer networks for computer-aided diagnosis",
      "id": "7149880764356096625",
      "url": "https://ieeexplore.ieee.org/abstract/document/9721019/",
      "title": "Self-supervised bi-channel transformer networks for computer-aided diagnosis",
      "authors": "R Gong, X Han, J Wang, S Ying\u2026",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7149880764356096625&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Machine learning algorithms to detect subclinical keratoconus: systematic review",
      "id": "17663852253493236753",
      "url": "https://medinform.jmir.org/2021/12/e27363",
      "title": "Machine learning algorithms to detect subclinical keratoconus: systematic review",
      "authors": "H Maile, JPO Li, D Gore, M Leucci\u2026",
      "year": "2021",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17663852253493236753&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 6
    },
    {
      "label": "Generalized intersection over union: A metric and a loss for bounding box regression",
      "id": "12644740604491229422",
      "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Rezatofighi_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_CVPR_2019_paper.html",
      "title": "Generalized intersection over union: A metric and a loss for bounding box regression",
      "authors": "H Rezatofighi, N Tsoi, JY Gwak\u2026",
      "year": "2019",
      "cited_by": 3587,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12644740604491229422&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "CSPNet: A new backbone that can enhance learning capability of CNN",
      "id": "13495361512235022596",
      "url": "http://openaccess.thecvf.com/content_CVPRW_2020/html/w28/Wang_CSPNet_A_New_Backbone_That_Can_Enhance_Learning_Capability_of_CVPRW_2020_paper.html",
      "title": "CSPNet: A new backbone that can enhance learning capability of CNN",
      "authors": "CY Wang, HYM Liao, YH Wu\u2026",
      "year": "2020",
      "cited_by": 2882,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13495361512235022596&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Motr: End-to-end multiple-object tracking with transformer",
      "id": "15866259573388647937",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19812-0_38",
      "title": "Motr: End-to-end multiple-object tracking with transformer",
      "authors": "F Zeng, B Dong, Y Zhang, T Wang, X Zhang\u2026",
      "year": "2022",
      "cited_by": 238,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15866259573388647937&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Swintrack: A simple and strong baseline for transformer tracking",
      "id": "5167657309745527366",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/6a5c23219f401f3efd322579002dbb80-Abstract-Conference.html",
      "title": "Swintrack: A simple and strong baseline for transformer tracking",
      "authors": "L Lin, H Fan, Z Zhang, Y Xu\u2026",
      "year": "2022",
      "cited_by": 123,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5167657309745527366&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Multimodal virtual point 3d detection",
      "id": "4582080155258437560",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/895daa408f494ad58006c47a30f51c1f-Abstract.html",
      "title": "Multimodal virtual point 3d detection",
      "authors": "T Yin, X Zhou, P Kr\u00e4henb\u00fchl",
      "year": "2021",
      "cited_by": 110,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4582080155258437560&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Mask dino: Towards a unified transformer-based framework for object detection and segmentation",
      "id": "17229720160752682638",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Li_Mask_DINO_Towards_a_Unified_Transformer-Based_Framework_for_Object_Detection_CVPR_2023_paper.html",
      "title": "Mask dino: Towards a unified transformer-based framework for object detection and segmentation",
      "authors": "F Li, H Zhang, H Xu, S Liu, L Zhang\u2026",
      "year": "2023",
      "cited_by": 102,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17229720160752682638&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Transvg: End-to-end visual grounding with transformers",
      "id": "11676336857650567467",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Deng_TransVG_End-to-End_Visual_Grounding_With_Transformers_ICCV_2021_paper.html",
      "title": "Transvg: End-to-end visual grounding with transformers",
      "authors": "J Deng, Z Yang, T Chen, W Zhou\u2026",
      "year": "2021",
      "cited_by": 167,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11676336857650567467&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Objects are different: Flexible monocular 3d object detection",
      "id": "2733828785339010244",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Objects_Are_Different_Flexible_Monocular_3D_Object_Detection_CVPR_2021_paper.html",
      "title": "Objects are different: Flexible monocular 3d object detection",
      "authors": "Y Zhang, J Lu, J Zhou",
      "year": "2021",
      "cited_by": 152,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2733828785339010244&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Aiatrack: Attention in attention for transformer visual tracking",
      "id": "6724748843400977919",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20047-2_9",
      "title": "Aiatrack: Attention in attention for transformer visual tracking",
      "authors": "S Gao, C Zhou, C Ma, X Wang, J Yuan",
      "year": "2022",
      "cited_by": 70,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6724748843400977919&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "A comprehensive survey of loss functions in machine learning",
      "id": "16852040746567843557",
      "url": "https://link.springer.com/article/10.1007/s40745-020-00253-5",
      "title": "A comprehensive survey of loss functions in machine learning",
      "authors": "Q Wang, Y Ma, K Zhao, Y Tian",
      "year": "2020",
      "cited_by": 305,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16852040746567843557&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Tubetk: Adopting tubes to track multi-object in a one-step training model",
      "id": "9897780157833606863",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Pang_TubeTK_Adopting_Tubes_to_Track_Multi-Object_in_a_One-Step_Training_CVPR_2020_paper.html",
      "title": "Tubetk: Adopting tubes to track multi-object in a one-step training model",
      "authors": "B Pang, Y Li, Y Zhang, M Li\u2026",
      "year": "2020",
      "cited_by": 241,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9897780157833606863&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Joint feature learning and relation modeling for tracking: A one-stream framework",
      "id": "1516895187053369438",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20047-2_20",
      "title": "Joint feature learning and relation modeling for tracking: A one-stream framework",
      "authors": "B Ye, H Chang, B Ma, S Shan, X Chen",
      "year": "2022",
      "cited_by": 101,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1516895187053369438&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "End-to-end human object interaction detection with hoi transformer",
      "id": "5255251082771415776",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Zou_End-to-End_Human_Object_Interaction_Detection_With_HOI_Transformer_CVPR_2021_paper.html",
      "title": "End-to-end human object interaction detection with hoi transformer",
      "authors": "C Zou, B Wang, Y Hu, J Liu, Q Wu\u2026",
      "year": "2021",
      "cited_by": 148,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5255251082771415776&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "An improved YOLOv5 model based on visual attention mechanism: Application to recognition of tomato virus disease",
      "id": "8435222954649090273",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922000977",
      "title": "An improved YOLOv5 model based on visual attention mechanism: Application to recognition of tomato virus disease",
      "authors": "J Qi, X Liu, K Liu, F Xu, H Guo, X Tian, M Li\u2026",
      "year": "2022",
      "cited_by": 105,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8435222954649090273&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Delving into localization errors for monocular 3d object detection",
      "id": "2447420766194254891",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Ma_Delving_Into_Localization_Errors_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html",
      "title": "Delving into localization errors for monocular 3d object detection",
      "authors": "X Ma, Y Zhang, D Xu, D Zhou, S Yi\u2026",
      "year": "2021",
      "cited_by": 126,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2447420766194254891&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Iou loss for 2d/3d object detection",
      "id": "12087685277533101192",
      "url": "https://ieeexplore.ieee.org/abstract/document/8886046/",
      "title": "Iou loss for 2d/3d object detection",
      "authors": "D Zhou, J Fang, X Song, C Guan, J Yin\u2026",
      "year": "2019",
      "cited_by": 311,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12087685277533101192&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "An enhanced CNN-enabled learning method for promoting ship detection in maritime surveillance system",
      "id": "1340805047015841402",
      "url": "https://www.sciencedirect.com/science/article/pii/S0029801821008404",
      "title": "An enhanced CNN-enabled learning method for promoting ship detection in maritime surveillance system",
      "authors": "RW Liu, W Yuan, X Chen, Y Lu",
      "year": "2021",
      "cited_by": 124,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1340805047015841402&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Multi-grained vision language pre-training: Aligning texts with visual concepts",
      "id": "8119995839638175849",
      "url": "https://arxiv.org/abs/2111.08276",
      "title": "Multi-grained vision language pre-training: Aligning texts with visual concepts",
      "authors": "Y Zeng, X Zhang, H Li",
      "year": "2021",
      "cited_by": 127,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8119995839638175849&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Sg-net: Spatial granularity network for one-stage video instance segmentation",
      "id": "15843316366415866499",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Liu_SG-Net_Spatial_Granularity_Network_for_One-Stage_Video_Instance_Segmentation_CVPR_2021_paper.html",
      "title": "Sg-net: Spatial granularity network for one-stage video instance segmentation",
      "authors": "D Liu, Y Cui, W Tan, Y Chen",
      "year": "2021",
      "cited_by": 124,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15843316366415866499&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "End-to-end dense video captioning with parallel decoding",
      "id": "9376665948461610119",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Wang_End-to-End_Dense_Video_Captioning_With_Parallel_Decoding_ICCV_2021_paper.html",
      "title": "End-to-end dense video captioning with parallel decoding",
      "authors": "T Wang, R Zhang, Z Lu, F Zheng\u2026",
      "year": "2021",
      "cited_by": 88,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9376665948461610119&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Toward transformer-based object detection",
      "id": "8315666909540964380",
      "url": "https://arxiv.org/abs/2012.09958",
      "title": "Toward transformer-based object detection",
      "authors": "J Beal, E Kim, E Tzeng, DH Park, A Zhai\u2026",
      "year": "2020",
      "cited_by": 163,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8315666909540964380&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Contournet: Taking a further step toward accurate arbitrary-shaped scene text detection",
      "id": "10407924981028323116",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Wang_ContourNet_Taking_a_Further_Step_Toward_Accurate_Arbitrary-Shaped_Scene_Text_CVPR_2020_paper.html",
      "title": "Contournet: Taking a further step toward accurate arbitrary-shaped scene text detection",
      "authors": "Y Wang, H Xie, ZJ Zha, M Xing\u2026",
      "year": "2020",
      "cited_by": 189,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10407924981028323116&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Face mask recognition system with YOLOV5 based on image recognition",
      "id": "14661055790907170296",
      "url": "https://ieeexplore.ieee.org/abstract/document/9345042/",
      "title": "Face mask recognition system with YOLOV5 based on image recognition",
      "authors": "G Yang, W Feng, J Jin, Q Lei, X Li\u2026",
      "year": "2020",
      "cited_by": 179,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14661055790907170296&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Alpha-refine: Boosting tracking performance by precise bounding box estimation",
      "id": "11874667315223245954",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Yan_Alpha-Refine_Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation_CVPR_2021_paper.html",
      "title": "Alpha-refine: Boosting tracking performance by precise bounding box estimation",
      "authors": "B Yan, X Zhang, D Wang, H Lu\u2026",
      "year": "2021",
      "cited_by": 153,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11874667315223245954&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Piou loss: Towards accurate oriented object detection in complex environments",
      "id": "12353159982052869953",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58558-7_12",
      "title": "Piou loss: Towards accurate oriented object detection in complex environments",
      "authors": "Z Chen, K Chen, W Lin, J See, H Yu, Y Ke\u2026",
      "year": "2020",
      "cited_by": 172,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12353159982052869953&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Qpic: Query-based pairwise human-object interaction detection with image-wide contextual information",
      "id": "2040091967364618062",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Tamura_QPIC_Query-Based_Pairwise_Human-Object_Interaction_Detection_With_Image-Wide_Contextual_Information_CVPR_2021_paper.html",
      "title": "Qpic: Query-based pairwise human-object interaction detection with image-wide contextual information",
      "authors": "M Tamura, H Ohashi\u2026",
      "year": "2021",
      "cited_by": 118,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2040091967364618062&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Tubedetr: Spatio-temporal video grounding with transformers",
      "id": "10434862692373421904",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yang_TubeDETR_Spatio-Temporal_Video_Grounding_With_Transformers_CVPR_2022_paper.html",
      "title": "Tubedetr: Spatio-temporal video grounding with transformers",
      "authors": "A Yang, A Miech, J Sivic, I Laptev\u2026",
      "year": "2022",
      "cited_by": 45,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10434862692373421904&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Dense contrastive learning for self-supervised visual pre-training",
      "id": "8448943115025253905",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Wang_Dense_Contrastive_Learning_for_Self-Supervised_Visual_Pre-Training_CVPR_2021_paper.html",
      "title": "Dense contrastive learning for self-supervised visual pre-training",
      "authors": "X Wang, R Zhang, C Shen\u2026",
      "year": "2021",
      "cited_by": 513,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8448943115025253905&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "ibot: Image bert pre-training with online tokenizer",
      "id": "6668235945473015803",
      "url": "https://arxiv.org/abs/2111.07832",
      "title": "ibot: Image bert pre-training with online tokenizer",
      "authors": "J Zhou, C Wei, H Wang, W Shen, C Xie, A Yuille\u2026",
      "year": "2021",
      "cited_by": 400,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6668235945473015803&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Denseclip: Language-guided dense prediction with context-aware prompting",
      "id": "12719486318898360519",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Rao_DenseCLIP_Language-Guided_Dense_Prediction_With_Context-Aware_Prompting_CVPR_2022_paper.html",
      "title": "Denseclip: Language-guided dense prediction with context-aware prompting",
      "authors": "Y Rao, W Zhao, G Chen, Y Tang\u2026",
      "year": "2022",
      "cited_by": 220,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12719486318898360519&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Exploring cross-image pixel contrast for semantic segmentation",
      "id": "16431656661146854759",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Wang_Exploring_Cross-Image_Pixel_Contrast_for_Semantic_Segmentation_ICCV_2021_paper.html",
      "title": "Exploring cross-image pixel contrast for semantic segmentation",
      "authors": "W Wang, T Zhou, F Yu, J Dai\u2026",
      "year": "2021",
      "cited_by": 339,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16431656661146854759&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Context autoencoder for self-supervised representation learning",
      "id": "3484260075890953852",
      "url": "https://link.springer.com/article/10.1007/s11263-023-01852-4",
      "title": "Context autoencoder for self-supervised representation learning",
      "authors": "X Chen, M Ding, X Wang, Y Xin, S Mo, Y Wang\u2026",
      "year": "2023",
      "cited_by": 175,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3484260075890953852&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Cris: Clip-driven referring image segmentation",
      "id": "12396058489435840533",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wang_CRIS_CLIP-Driven_Referring_Image_Segmentation_CVPR_2022_paper.html",
      "title": "Cris: Clip-driven referring image segmentation",
      "authors": "Z Wang, Y Lu, Q Li, X Tao, Y Guo\u2026",
      "year": "2022",
      "cited_by": 121,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12396058489435840533&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Efficient self-supervised vision transformers for representation learning",
      "id": "15469437604545198809",
      "url": "https://arxiv.org/abs/2106.09785",
      "title": "Efficient self-supervised vision transformers for representation learning",
      "authors": "C Li, J Yang, P Zhang, M Gao, B Xiao, X Dai\u2026",
      "year": "2021",
      "cited_by": 151,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15469437604545198809&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Semi-supervised semantic segmentation with pixel-level contrastive learning from a class-wise memory bank",
      "id": "3898607331439114201",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Alonso_Semi-Supervised_Semantic_Segmentation_With_Pixel-Level_Contrastive_Learning_From_a_Class-Wise_ICCV_2021_paper.html",
      "title": "Semi-supervised semantic segmentation with pixel-level contrastive learning from a class-wise memory bank",
      "authors": "I Alonso, A Sabater, D Ferstl\u2026",
      "year": "2021",
      "cited_by": 151,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3898607331439114201&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Vicregl: Self-supervised learning of local visual features",
      "id": "11133634648290997125",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/39cee562b91611c16ac0b100f0bc1ea1-Abstract-Conference.html",
      "title": "Vicregl: Self-supervised learning of local visual features",
      "authors": "A Bardes, J Ponce, Y LeCun",
      "year": "2022",
      "cited_by": 41,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11133634648290997125&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Deep spectral methods: A surprisingly strong baseline for unsupervised semantic segmentation and localization",
      "id": "4695735279498312558",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Melas-Kyriazi_Deep_Spectral_Methods_A_Surprisingly_Strong_Baseline_for_Unsupervised_Semantic_CVPR_2022_paper.html",
      "title": "Deep spectral methods: A surprisingly strong baseline for unsupervised semantic segmentation and localization",
      "authors": "L Melas-Kyriazi, C Rupprecht\u2026",
      "year": "2022",
      "cited_by": 70,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4695735279498312558&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Ts2vec: Towards universal representation of time series",
      "id": "12107148927806619132",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/20881",
      "title": "Ts2vec: Towards universal representation of time series",
      "authors": "Z Yue, Y Wang, J Duan, T Yang, C Huang\u2026",
      "year": "2022",
      "cited_by": 161,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12107148927806619132&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Pixel contrastive-consistent semi-supervised semantic segmentation",
      "id": "10949691838250411133",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zhong_Pixel_Contrastive-Consistent_Semi-Supervised_Semantic_Segmentation_ICCV_2021_paper.html",
      "title": "Pixel contrastive-consistent semi-supervised semantic segmentation",
      "authors": "Y Zhong, B Yuan, H Wu, Z Yuan\u2026",
      "year": "2021",
      "cited_by": 107,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10949691838250411133&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Contrastive learning rivals masked image modeling in fine-tuning via feature distillation",
      "id": "2183335709889759560",
      "url": "https://arxiv.org/abs/2205.14141",
      "title": "Contrastive learning rivals masked image modeling in fine-tuning via feature distillation",
      "authors": "Y Wei, H Hu, Z Xie, Z Zhang, Y Cao, J Bao\u2026",
      "year": "2022",
      "cited_by": 84,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2183335709889759560&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Regional semantic contrast and aggregation for weakly supervised semantic segmentation",
      "id": "5084328956172259959",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Regional_Semantic_Contrast_and_Aggregation_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2022_paper.html",
      "title": "Regional semantic contrast and aggregation for weakly supervised semantic segmentation",
      "authors": "T Zhou, M Zhang, F Zhao, J Li",
      "year": "2022",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5084328956172259959&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Mst: Masked self-supervised transformer for visual representation",
      "id": "8779019959052555626",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/6dbbe6abe5f14af882ff977fc3f35501-Abstract.html",
      "title": "Mst: Masked self-supervised transformer for visual representation",
      "authors": "Z Li, Z Chen, F Yang, W Li, Y Zhu\u2026",
      "year": "2021",
      "cited_by": 98,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8779019959052555626&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Contrastive learning for label efficient semantic segmentation",
      "id": "12960288265914815983",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Contrastive_Learning_for_Label_Efficient_Semantic_Segmentation_ICCV_2021_paper.html",
      "title": "Contrastive learning for label efficient semantic segmentation",
      "authors": "X Zhao, R Vemulapalli, PA Mansfield\u2026",
      "year": "2021",
      "cited_by": 126,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12960288265914815983&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Revealing the dark secrets of masked image modeling",
      "id": "10341392145675802868",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Xie_Revealing_the_Dark_Secrets_of_Masked_Image_Modeling_CVPR_2023_paper.html",
      "title": "Revealing the dark secrets of masked image modeling",
      "authors": "Z Xie, Z Geng, J Hu, Z Zhang\u2026",
      "year": "2023",
      "cited_by": 47,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10341392145675802868&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Aligning pretraining for detection via object-level contrastive learning",
      "id": "9757750069113028831",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/bf5cd8b2509011b9502a72296edc14a0-Abstract.html",
      "title": "Aligning pretraining for detection via object-level contrastive learning",
      "authors": "F Wei, Y Gao, Z Wu, H Hu, S Lin",
      "year": "2021",
      "cited_by": 90,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9757750069113028831&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Region-aware contrastive learning for semantic segmentation",
      "id": "33927402341244667",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Hu_Region-Aware_Contrastive_Learning_for_Semantic_Segmentation_ICCV_2021_paper.html",
      "title": "Region-aware contrastive learning for semantic segmentation",
      "authors": "H Hu, J Cui, L Wang",
      "year": "2021",
      "cited_by": 79,
      "cited_by_url": "https://scholar.google.com/scholar?cites=33927402341244667&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Sepico: Semantic-guided pixel contrast for domain adaptive semantic segmentation",
      "id": "14524693012131206782",
      "url": "https://ieeexplore.ieee.org/abstract/document/10018569/",
      "title": "Sepico: Semantic-guided pixel contrast for domain adaptive semantic segmentation",
      "authors": "B Xie, S Li, M Li, CH Liu, G Huang\u2026",
      "year": "2023",
      "cited_by": 54,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14524693012131206782&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Cut and learn for unsupervised object detection and instance segmentation",
      "id": "532394135980020430",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Wang_Cut_and_Learn_for_Unsupervised_Object_Detection_and_Instance_Segmentation_CVPR_2023_paper.html",
      "title": "Cut and learn for unsupervised object detection and instance segmentation",
      "authors": "X Wang, R Girdhar, SX Yu\u2026",
      "year": "2023",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=532394135980020430&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Crafting better contrastive views for siamese representation learning",
      "id": "17284983713036766691",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Peng_Crafting_Better_Contrastive_Views_for_Siamese_Representation_Learning_CVPR_2022_paper.html",
      "title": "Crafting better contrastive views for siamese representation learning",
      "authors": "X Peng, K Wang, Z Zhu, M Wang\u2026",
      "year": "2022",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17284983713036766691&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Spot-the-difference self-supervised pre-training for anomaly detection and segmentation",
      "id": "633087071652505085",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20056-4_23",
      "title": "Spot-the-difference self-supervised pre-training for anomaly detection and segmentation",
      "authors": "Y Zou, J Jeong, L Pemula, D Zhang\u2026",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=633087071652505085&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "A survey on label-efficient deep image segmentation: Bridging the gap between weak supervision and dense prediction",
      "id": "14101725080609270309",
      "url": "https://ieeexplore.ieee.org/abstract/document/10048555/",
      "title": "A survey on label-efficient deep image segmentation: Bridging the gap between weak supervision and dense prediction",
      "authors": "W Shen, Z Peng, X Wang, H Wang\u2026",
      "year": "2023",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14101725080609270309&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Region similarity representation learning",
      "id": "17624445298553964188",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Xiao_Region_Similarity_Representation_Learning_ICCV_2021_paper.html",
      "title": "Region similarity representation learning",
      "authors": "T Xiao, CJ Reed, X Wang\u2026",
      "year": "2021",
      "cited_by": 95,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17624445298553964188&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Self-supervised learning of object parts for semantic segmentation",
      "id": "10023428544428348799",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Ziegler_Self-Supervised_Learning_of_Object_Parts_for_Semantic_Segmentation_CVPR_2022_paper.html",
      "title": "Self-supervised learning of object parts for semantic segmentation",
      "authors": "A Ziegler, YM Asano",
      "year": "2022",
      "cited_by": 43,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10023428544428348799&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Freesolo: Learning to segment objects without annotations",
      "id": "3726545131723476858",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wang_FreeSOLO_Learning_To_Segment_Objects_Without_Annotations_CVPR_2022_paper.html",
      "title": "Freesolo: Learning to segment objects without annotations",
      "authors": "X Wang, Z Yu, S De Mello, J Kautz\u2026",
      "year": "2022",
      "cited_by": 47,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3726545131723476858&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Locvtp: Video-text pre-training for temporal localization",
      "id": "12927720534552603420",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19809-0_3",
      "title": "Locvtp: Video-text pre-training for temporal localization",
      "authors": "M Cao, T Yang, J Weng, C Zhang, J Wang\u2026",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12927720534552603420&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Detreg: Unsupervised pretraining with region priors for object detection",
      "id": "10551610679278163665",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Bar_DETReg_Unsupervised_Pretraining_With_Region_Priors_for_Object_Detection_CVPR_2022_paper.html",
      "title": "Detreg: Unsupervised pretraining with region priors for object detection",
      "authors": "A Bar, X Wang, V Kantorov, CJ Reed\u2026",
      "year": "2022",
      "cited_by": 72,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10551610679278163665&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Point-level region contrast for object detection pre-training",
      "id": "8481021928568633762",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Bai_Point-Level_Region_Contrast_for_Object_Detection_Pre-Training_CVPR_2022_paper.html",
      "title": "Point-level region contrast for object detection pre-training",
      "authors": "Y Bai, X Chen, A Kirillov, A Yuille\u2026",
      "year": "2022",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8481021928568633762&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Image-to-lidar self-supervised distillation for autonomous driving data",
      "id": "7983433851687883883",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Sautier_Image-to-Lidar_Self-Supervised_Distillation_for_Autonomous_Driving_Data_CVPR_2022_paper.html",
      "title": "Image-to-lidar self-supervised distillation for autonomous driving data",
      "authors": "C Sautier, G Puy, S Gidaris, A Boulch\u2026",
      "year": "2022",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7983433851687883883&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Denoising pretraining for semantic segmentation",
      "id": "13592875691592926608",
      "url": "https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/html/Brempong_Denoising_Pretraining_for_Semantic_Segmentation_CVPRW_2022_paper.html",
      "title": "Denoising pretraining for semantic segmentation",
      "authors": "EA Brempong, S Kornblith, T Chen\u2026",
      "year": "2022",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13592875691592926608&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Weakly supervised semantic segmentation by pixel-to-prototype contrast",
      "id": "9426593234701255657",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Du_Weakly_Supervised_Semantic_Segmentation_by_Pixel-to-Prototype_Contrast_CVPR_2022_paper.html",
      "title": "Weakly supervised semantic segmentation by pixel-to-prototype contrast",
      "authors": "Y Du, Z Fu, Q Liu, Y Wang",
      "year": "2022",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9426593234701255657&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Self-supervised learning for scene classification in remote sensing: Current state of the art and perspectives",
      "id": "1924986113269211163",
      "url": "https://www.mdpi.com/2072-4292/14/16/3995",
      "title": "Self-supervised learning for scene classification in remote sensing: Current state of the art and perspectives",
      "authors": "P Berg, MT Pham, N Courty",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1924986113269211163&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "C3-semiseg: Contrastive semi-supervised segmentation via cross-set learning and dynamic class-balancing",
      "id": "17074925293404018328",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zhou_C3-SemiSeg_Contrastive_Semi-Supervised_Segmentation_via_Cross-Set_Learning_and_Dynamic_Class-Balancing_ICCV_2021_paper.html",
      "title": "C3-semiseg: Contrastive semi-supervised segmentation via cross-set learning and dynamic class-balancing",
      "authors": "Y Zhou, H Xu, W Zhang, B Gao\u2026",
      "year": "2021",
      "cited_by": 53,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17074925293404018328&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Improving contrastive learning by visualizing feature transformation",
      "id": "5868001138380150922",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zhu_Improving_Contrastive_Learning_by_Visualizing_Feature_Transformation_ICCV_2021_paper.html",
      "title": "Improving contrastive learning by visualizing feature transformation",
      "authors": "R Zhu, B Zhao, J Liu, Z Sun\u2026",
      "year": "2021",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5868001138380150922&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Green hierarchical vision transformer for masked image modeling",
      "id": "5575721172969217810",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/7e487c72fce6e45879a78ee0872d991d-Abstract-Conference.html",
      "title": "Green hierarchical vision transformer for masked image modeling",
      "authors": "L Huang, S You, M Zheng, F Wang\u2026",
      "year": "2022",
      "cited_by": 31,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5575721172969217810&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Unsupervised object-level representation learning from scene images",
      "id": "11947642466448713378",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/f1b6f2857fb6d44dd73c7041e0aa0f19-Abstract.html",
      "title": "Unsupervised object-level representation learning from scene images",
      "authors": "J Xie, X Zhan, Z Liu, YS Ong\u2026",
      "year": "2021",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11947642466448713378&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Hyperbolic contrastive learning for visual representations beyond objects",
      "id": "6750819842213893633",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Ge_Hyperbolic_Contrastive_Learning_for_Visual_Representations_Beyond_Objects_CVPR_2023_paper.html",
      "title": "Hyperbolic contrastive learning for visual representations beyond objects",
      "authors": "S Ge, S Mishra, S Kornblith, CL Li\u2026",
      "year": "2023",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6750819842213893633&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Dual temperature helps contrastive learning without many negative samples: Towards understanding and simplifying moco",
      "id": "11904217105191322390",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Dual_Temperature_Helps_Contrastive_Learning_Without_Many_Negative_Samples_Towards_CVPR_2022_paper.html",
      "title": "Dual temperature helps contrastive learning without many negative samples: Towards understanding and simplifying moco",
      "authors": "C Zhang, K Zhang, TX Pham, A Niu\u2026",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11904217105191322390&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Leveraging real talking faces via self-supervision for robust forgery detection",
      "id": "1775977373440976785",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Haliassos_Leveraging_Real_Talking_Faces_via_Self-Supervision_for_Robust_Forgery_Detection_CVPR_2022_paper.html",
      "title": "Leveraging real talking faces via self-supervision for robust forgery detection",
      "authors": "A Haliassos, R Mira, S Petridis\u2026",
      "year": "2022",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1775977373440976785&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Cross-patch dense contrastive learning for semi-supervised segmentation of cellular nuclei in histopathologic images",
      "id": "1318173233917005478",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wu_Cross-Patch_Dense_Contrastive_Learning_for_Semi-Supervised_Segmentation_of_Cellular_Nuclei_CVPR_2022_paper.html",
      "title": "Cross-patch dense contrastive learning for semi-supervised segmentation of cellular nuclei in histopathologic images",
      "authors": "H Wu, Z Wang, Y Song, L Yang\u2026",
      "year": "2022",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1318173233917005478&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "BigDatasetGAN: Synthesizing ImageNet with pixel-wise annotations",
      "id": "14529545999567875627",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_BigDatasetGAN_Synthesizing_ImageNet_With_Pixel-Wise_Annotations_CVPR_2022_paper.html",
      "title": "BigDatasetGAN: Synthesizing ImageNet with pixel-wise annotations",
      "authors": "D Li, H Ling, SW Kim, K Kreis\u2026",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14529545999567875627&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Self-supervised visual representations learning by contrastive mask prediction",
      "id": "1661264717430846222",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Zhao_Self-Supervised_Visual_Representations_Learning_by_Contrastive_Mask_Prediction_ICCV_2021_paper.html",
      "title": "Self-supervised visual representations learning by contrastive mask prediction",
      "authors": "Y Zhao, G Wang, C Luo, W Zeng\u2026",
      "year": "2021",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1661264717430846222&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Patch-level representation learning for self-supervised vision transformers",
      "id": "15793792687497316784",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yun_Patch-Level_Representation_Learning_for_Self-Supervised_Vision_Transformers_CVPR_2022_paper.html",
      "title": "Patch-level representation learning for self-supervised vision transformers",
      "authors": "S Yun, H Lee, J Kim, J Shin",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15793792687497316784&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Milan: Masked image pretraining on language assisted representation",
      "id": "8981892223562201199",
      "url": "https://arxiv.org/abs/2208.06049",
      "title": "Milan: Masked image pretraining on language assisted representation",
      "authors": "Z Hou, F Sun, YK Chen, Y Xie, SY Kung",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8981892223562201199&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Looking beyond single images for contrastive semantic segmentation learning",
      "id": "10833379900462253180",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/1a68e5f4ade56ed1d4bf273e55510750-Abstract.html",
      "title": "Looking beyond single images for contrastive semantic segmentation learning",
      "authors": "F Zhang, P Torr, R Ranftl\u2026",
      "year": "2021",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10833379900462253180&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Dtg-ssod: Dense teacher guidance for semi-supervised object detection",
      "id": "1047156362824031830",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/3a02b6df276223b68c69ca572cb3c4a8-Abstract-Conference.html",
      "title": "Dtg-ssod: Dense teacher guidance for semi-supervised object detection",
      "authors": "G Li, X Li, Y Wang, W Yichao\u2026",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1047156362824031830&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Revisiting contrastive methods for unsupervised learning of visual representations",
      "id": "735436327696041641",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/8757150decbd89b0f5442ca3db4d0e0e-Abstract.html",
      "title": "Revisiting contrastive methods for unsupervised learning of visual representations",
      "authors": "W Van Gansbeke, S Vandenhende\u2026",
      "year": "2021",
      "cited_by": 43,
      "cited_by_url": "https://scholar.google.com/scholar?cites=735436327696041641&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Multisiam: Self-supervised multi-instance siamese representation learning for autonomous driving",
      "id": "9214065931586807664",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Chen_MultiSiam_Self-Supervised_Multi-Instance_Siamese_Representation_Learning_for_Autonomous_Driving_ICCV_2021_paper.html",
      "title": "Multisiam: Self-supervised multi-instance siamese representation learning for autonomous driving",
      "authors": "K Chen, L Hong, H Xu, Z Li\u2026",
      "year": "2021",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9214065931586807664&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Univip: A unified framework for self-supervised visual pre-training",
      "id": "16212063836582850356",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_UniVIP_A_Unified_Framework_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.html",
      "title": "Univip: A unified framework for self-supervised visual pre-training",
      "authors": "Z Li, Y Zhu, F Yang, W Li, C Zhao\u2026",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16212063836582850356&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Unsupervised pre-training for temporal action localization tasks",
      "id": "14964804060777605755",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Unsupervised_Pre-Training_for_Temporal_Action_Localization_Tasks_CVPR_2022_paper.html",
      "title": "Unsupervised pre-training for temporal action localization tasks",
      "authors": "C Zhang, T Yang, J Weng, M Cao\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14964804060777605755&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "DiRA: Discriminative, restorative, and adversarial learning for self-supervised medical image analysis",
      "id": "10173276721588368719",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Haghighi_DiRA_Discriminative_Restorative_and_Adversarial_Learning_for_Self-Supervised_Medical_Image_CVPR_2022_paper.html",
      "title": "DiRA: Discriminative, restorative, and adversarial learning for self-supervised medical image analysis",
      "authors": "F Haghighi, MRH Taher\u2026",
      "year": "2022",
      "cited_by": 35,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10173276721588368719&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Multi-granularity cross-modal alignment for generalized medical visual representation learning",
      "id": "16722403537302150812",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/d925bda407ada0df3190df323a212661-Abstract-Conference.html",
      "title": "Multi-granularity cross-modal alignment for generalized medical visual representation learning",
      "authors": "F Wang, Y Zhou, S Wang\u2026",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16722403537302150812&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Not just selection, but exploration: Online class-incremental continual learning via dual view consistency",
      "id": "8555368968556268636",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Gu_Not_Just_Selection_but_Exploration_Online_Class-Incremental_Continual_Learning_via_CVPR_2022_paper.html",
      "title": "Not just selection, but exploration: Online class-incremental continual learning via dual view consistency",
      "authors": "Y Gu, X Yang, K Wei, C Deng",
      "year": "2022",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8555368968556268636&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Decoupled adversarial contrastive learning for self-supervised adversarial robustness",
      "id": "33793130511872188",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20056-4_42",
      "title": "Decoupled adversarial contrastive learning for self-supervised adversarial robustness",
      "authors": "C Zhang, K Zhang, C Zhang, A Niu, J Feng\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=33793130511872188&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "A closer look at invariances in self-supervised pre-training for 3d vision",
      "id": "15449354411100450148",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-20056-4_38",
      "title": "A closer look at invariances in self-supervised pre-training for 3d vision",
      "authors": "L Li, M Heizmann",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15449354411100450148&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Joint learning of localized representations from medical images and reports",
      "id": "9049923034415496270",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19809-0_39",
      "title": "Joint learning of localized representations from medical images and reports",
      "authors": "P M\u00fcller, G Kaissis, C Zou, D Rueckert",
      "year": "2022",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9049923034415496270&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Towards discriminative representation: Multi-view trajectory contrastive learning for online multi-object tracking",
      "id": "432444698543425795",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Yu_Towards_Discriminative_Representation_Multi-View_Trajectory_Contrastive_Learning_for_Online_Multi-Object_CVPR_2022_paper.html",
      "title": "Towards discriminative representation: Multi-view trajectory contrastive learning for online multi-object tracking",
      "authors": "E Yu, Z Li, S Han",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=432444698543425795&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "A cookbook of self-supervised learning",
      "id": "9021031822777383648",
      "url": "https://arxiv.org/abs/2304.12210",
      "title": "A cookbook of self-supervised learning",
      "authors": "R Balestriero, M Ibrahim, V Sobal, A Morcos\u2026",
      "year": "2023",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9021031822777383648&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Unsupervised hierarchical semantic segmentation with multiview cosegmentation and clustering transformers",
      "id": "8430936739774837199",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Ke_Unsupervised_Hierarchical_Semantic_Segmentation_With_Multiview_Cosegmentation_and_Clustering_Transformers_CVPR_2022_paper.html",
      "title": "Unsupervised hierarchical semantic segmentation with multiview cosegmentation and clustering transformers",
      "authors": "TW Ke, JJ Hwang, Y Guo, X Wang\u2026",
      "year": "2022",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8430936739774837199&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Exploring set similarity for dense self-supervised representation learning",
      "id": "5638477121687230939",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wang_Exploring_Set_Similarity_for_Dense_Self-Supervised_Representation_Learning_CVPR_2022_paper.html",
      "title": "Exploring set similarity for dense self-supervised representation learning",
      "authors": "Z Wang, Q Li, G Zhang, P Wan\u2026",
      "year": "2022",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5638477121687230939&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Use all the labels: A hierarchical multi-label contrastive learning framework",
      "id": "6099615041197158188",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Use_All_the_Labels_A_Hierarchical_Multi-Label_Contrastive_Learning_Framework_CVPR_2022_paper.html",
      "title": "Use all the labels: A hierarchical multi-label contrastive learning framework",
      "authors": "S Zhang, R Xu, C Xiong\u2026",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6099615041197158188&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Learning self-supervised low-rank network for single-stage weakly and semi-supervised semantic segmentation",
      "id": "8773982247708585699",
      "url": "https://link.springer.com/article/10.1007/s11263-022-01590-z",
      "title": "Learning self-supervised low-rank network for single-stage weakly and semi-supervised semantic segmentation",
      "authors": "J Pan, P Zhu, K Zhang, B Cao, Y Wang\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8773982247708585699&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Learning where to learn in cross-view self-supervised learning",
      "id": "6776914221737060740",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Huang_Learning_Where_To_Learn_in_Cross-View_Self-Supervised_Learning_CVPR_2022_paper.html",
      "title": "Learning where to learn in cross-view self-supervised learning",
      "authors": "L Huang, S You, M Zheng, F Wang\u2026",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6776914221737060740&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Semantic-aware fine-grained correspondence",
      "id": "9515469045960583745",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19821-2_6",
      "title": "Semantic-aware fine-grained correspondence",
      "authors": "Y Hu, R Wang, K Zhang, Y Gao",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9515469045960583745&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Graftnet: Towards domain generalized stereo matching with a broad-spectrum and task-oriented feature",
      "id": "18400465047273061750",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Liu_GraftNet_Towards_Domain_Generalized_Stereo_Matching_With_a_Broad-Spectrum_and_CVPR_2022_paper.html",
      "title": "Graftnet: Towards domain generalized stereo matching with a broad-spectrum and task-oriented feature",
      "authors": "B Liu, H Yu, G Qi",
      "year": "2022",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18400465047273061750&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Vibus: Data-efficient 3d scene parsing with viewpoint bottleneck and uncertainty-spectrum modeling",
      "id": "16150052612237999167",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271622002817",
      "title": "Vibus: Data-efficient 3d scene parsing with viewpoint bottleneck and uncertainty-spectrum modeling",
      "authors": "B Tian, L Luo, H Zhao, G Zhou",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16150052612237999167&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Residual pattern learning for pixel-wise out-of-distribution detection in semantic segmentation",
      "id": "2476318727654891437",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Liu_Residual_Pattern_Learning_for_Pixel-Wise_Out-of-Distribution_Detection_in_Semantic_Segmentation_ICCV_2023_paper.html",
      "title": "Residual pattern learning for pixel-wise out-of-distribution detection in semantic segmentation",
      "authors": "Y Liu, C Ding, Y Tian, G Pang\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2476318727654891437&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Unleashing the power of contrastive self-supervised visual models via contrast-regularized fine-tuning",
      "id": "9361339446003315812",
      "url": "https://proceedings.neurips.cc/paper/2021/hash/fa14d4fe2f19414de3ebd9f63d5c0169-Abstract.html",
      "title": "Unleashing the power of contrastive self-supervised visual models via contrast-regularized fine-tuning",
      "authors": "Y Zhang, B Hooi, D Hu, J Liang\u2026",
      "year": "2021",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9361339446003315812&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Dense semantic contrast for self-supervised visual representation learning",
      "id": "2507058243298497028",
      "url": "https://dl.acm.org/doi/abs/10.1145/3474085.3475551",
      "title": "Dense semantic contrast for self-supervised visual representation learning",
      "authors": "X Li, Y Zhou, Y Zhang, A Zhang, W Wang\u2026",
      "year": "2021",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2507058243298497028&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Move: Unsupervised movable object segmentation and detection",
      "id": "8173455362624893467",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/d7eb232f196124894f2e65b9010a5c57-Abstract-Conference.html",
      "title": "Move: Unsupervised movable object segmentation and detection",
      "authors": "A Bielski, P Favaro",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8173455362624893467&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Revisiting domain generalized stereo matching networks from a feature consistency perspective",
      "id": "5902003836142023006",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Revisiting_Domain_Generalized_Stereo_Matching_Networks_From_a_Feature_Consistency_CVPR_2022_paper.html",
      "title": "Revisiting domain generalized stereo matching networks from a feature consistency perspective",
      "authors": "J Zhang, X Wang, X Bai, C Wang\u2026",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5902003836142023006&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Rethinking the augmentation module in contrastive learning: Learning hierarchical augmentation invariance with expanded views",
      "id": "4005108257678361504",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Rethinking_the_Augmentation_Module_in_Contrastive_Learning_Learning_Hierarchical_Augmentation_CVPR_2022_paper.html",
      "title": "Rethinking the augmentation module in contrastive learning: Learning hierarchical augmentation invariance with expanded views",
      "authors": "J Zhang, K Ma",
      "year": "2022",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4005108257678361504&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Contrastmask: Contrastive learning to segment every thing",
      "id": "7085743912913543637",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wang_ContrastMask_Contrastive_Learning_To_Segment_Every_Thing_CVPR_2022_paper.html",
      "title": "Contrastmask: Contrastive learning to segment every thing",
      "authors": "X Wang, K Zhao, R Zhang, S Ding\u2026",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7085743912913543637&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Large-scale unsupervised semantic segmentation",
      "id": "8011144875870384891",
      "url": "https://ieeexplore.ieee.org/abstract/document/9933726/",
      "title": "Large-scale unsupervised semantic segmentation",
      "authors": "S Gao, ZY Li, MH Yang, MM Cheng\u2026",
      "year": "2022",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8011144875870384891&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation",
      "id": "2931986225761676831",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841523000531",
      "title": "Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation",
      "authors": "K Chaitanya, E Erdil, N Karani, E Konukoglu",
      "year": "2023",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2931986225761676831&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Supervised masked knowledge distillation for few-shot transformers",
      "id": "11156672461051367506",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Lin_Supervised_Masked_Knowledge_Distillation_for_Few-Shot_Transformers_CVPR_2023_paper.html",
      "title": "Supervised masked knowledge distillation for few-shot transformers",
      "authors": "H Lin, G Han, J Ma, S Huang, X Lin\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11156672461051367506&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Investigating the role of negatives in contrastive representation learning",
      "id": "6354529551574600680",
      "url": "https://arxiv.org/abs/2106.09943",
      "title": "Investigating the role of negatives in contrastive representation learning",
      "authors": "JT Ash, S Goel, A Krishnamurthy, D Misra",
      "year": "2021",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6354529551574600680&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "SAM: Self-supervised learning of pixel-wise anatomical embeddings in radiological images",
      "id": "12655218227669740570",
      "url": "https://ieeexplore.ieee.org/abstract/document/9760421/",
      "title": "SAM: Self-supervised learning of pixel-wise anatomical embeddings in radiological images",
      "authors": "K Yan, J Cai, D Jin, S Miao, D Guo\u2026",
      "year": "2022",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12655218227669740570&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "Self-Supervised Learning by Estimating Twin Class Distribution",
      "id": "248902349160897339",
      "url": "https://ieeexplore.ieee.org/abstract/document/10102765/",
      "title": "Self-Supervised Learning by Estimating Twin Class Distribution",
      "authors": "F Wang, T Kong, R Zhang, H Liu\u2026",
      "year": "2023",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=248902349160897339&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 7
    },
    {
      "label": "A unifying review of deep and shallow anomaly detection",
      "id": "535744563039386055",
      "url": "https://ieeexplore.ieee.org/abstract/document/9347460/",
      "title": "A unifying review of deep and shallow anomaly detection",
      "authors": "L Ruff, JR Kauffmann, RA Vandermeulen\u2026",
      "year": "2021",
      "cited_by": 608,
      "cited_by_url": "https://scholar.google.com/scholar?cites=535744563039386055&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Explaining deep neural networks and beyond: A review of methods and applications",
      "id": "12768464336489196273",
      "url": "https://ieeexplore.ieee.org/abstract/document/9369420/",
      "title": "Explaining deep neural networks and beyond: A review of methods and applications",
      "authors": "W Samek, G Montavon, S Lapuschkin\u2026",
      "year": "2021",
      "cited_by": 611,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12768464336489196273&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Cutpaste: Self-supervised learning for anomaly detection and localization",
      "id": "16299082709654826538",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Li_CutPaste_Self-Supervised_Learning_for_Anomaly_Detection_and_Localization_CVPR_2021_paper.html",
      "title": "Cutpaste: Self-supervised learning for anomaly detection and localization",
      "authors": "CL Li, K Sohn, J Yoon, T Pfister",
      "year": "2021",
      "cited_by": 439,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16299082709654826538&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Generalized out-of-distribution detection: A survey",
      "id": "18092310435120949940",
      "url": "https://arxiv.org/abs/2110.11334",
      "title": "Generalized out-of-distribution detection: A survey",
      "authors": "J Yang, K Zhou, Y Li, Z Liu",
      "year": "2021",
      "cited_by": 368,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18092310435120949940&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Combining machine learning and computational chemistry for predictive insights into chemical systems",
      "id": "17544397226639680198",
      "url": "https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.1c00107",
      "title": "Combining machine learning and computational chemistry for predictive insights into chemical systems",
      "authors": "JA Keith, V Vassilev-Galindo, B Cheng\u2026",
      "year": "2021",
      "cited_by": 278,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17544397226639680198&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Machine learning for electrocatalyst and photocatalyst design and discovery",
      "id": "411578991690355580",
      "url": "https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.2c00061",
      "title": "Machine learning for electrocatalyst and photocatalyst design and discovery",
      "authors": "H Mai, TC Le, D Chen, DA Winkler\u2026",
      "year": "2022",
      "cited_by": 78,
      "cited_by_url": "https://scholar.google.com/scholar?cites=411578991690355580&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Adbench: Anomaly detection benchmark",
      "id": "4407607921916219597",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/cf93972b116ca5268827d575f2cc226b-Abstract-Datasets_and_Benchmarks.html",
      "title": "Adbench: Anomaly detection benchmark",
      "authors": "S Han, X Hu, H Huang, M Jiang\u2026",
      "year": "2022",
      "cited_by": 102,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4407607921916219597&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Cflow-ad: Real-time unsupervised anomaly detection with localization via conditional normalizing flows",
      "id": "5644429611266863213",
      "url": "https://openaccess.thecvf.com/content/WACV2022/html/Gudovskiy_CFLOW-AD_Real-Time_Unsupervised_Anomaly_Detection_With_Localization_via_Conditional_Normalizing_WACV_2022_paper.html",
      "title": "Cflow-ad: Real-time unsupervised anomaly detection with localization via conditional normalizing flows",
      "authors": "D Gudovskiy, S Ishizaka\u2026",
      "year": "2022",
      "cited_by": 176,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5644429611266863213&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence",
      "id": "9152627594047007367",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253521002050",
      "title": "Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence",
      "authors": "A Holzinger, M Dehmer, F Emmert-Streib, R Cucchiara\u2026",
      "year": "2022",
      "cited_by": 111,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9152627594047007367&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Learning and evaluating representations for deep one-class classification",
      "id": "6458276904017990971",
      "url": "https://arxiv.org/abs/2011.02578",
      "title": "Learning and evaluating representations for deep one-class classification",
      "authors": "K Sohn, CL Li, J Yoon, M Jin, T Pfister",
      "year": "2020",
      "cited_by": 167,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6458276904017990971&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Pixmix: Dreamlike pictures comprehensively improve safety measures",
      "id": "4245256336048193979",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Hendrycks_PixMix_Dreamlike_Pictures_Comprehensively_Improve_Safety_Measures_CVPR_2022_paper.html",
      "title": "Pixmix: Dreamlike pictures comprehensively improve safety measures",
      "authors": "D Hendrycks, A Zou, M Mazeika\u2026",
      "year": "2022",
      "cited_by": 59,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4245256336048193979&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Explainable deep one-class classification",
      "id": "1382712243609022780",
      "url": "https://arxiv.org/abs/2007.01760",
      "title": "Explainable deep one-class classification",
      "authors": "P Liznerski, L Ruff, RA Vandermeulen\u2026",
      "year": "2020",
      "cited_by": 166,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1382712243609022780&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "A unified survey on anomaly, novelty, open-set, and out-of-distribution detection: Solutions and future challenges",
      "id": "11441760293318611832",
      "url": "https://arxiv.org/abs/2110.14051",
      "title": "A unified survey on anomaly, novelty, open-set, and out-of-distribution detection: Solutions and future challenges",
      "authors": "M Salehi, H Mirzaei, D Hendrycks, Y Li\u2026",
      "year": "2021",
      "cited_by": 100,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11441760293318611832&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Neural transformation learning for deep anomaly detection beyond images",
      "id": "1292087033558963213",
      "url": "https://proceedings.mlr.press/v139/qiu21a.html",
      "title": "Neural transformation learning for deep anomaly detection beyond images",
      "authors": "C Qiu, T Pfrommer, M Kloft, S Mandt\u2026",
      "year": "2021",
      "cited_by": 66,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1292087033558963213&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Graph neural networks for anomaly detection in industrial internet of things",
      "id": "10712076956509058252",
      "url": "https://ieeexplore.ieee.org/abstract/document/9471816/",
      "title": "Graph neural networks for anomaly detection in industrial internet of things",
      "authors": "Y Wu, HN Dai, H Tang",
      "year": "2021",
      "cited_by": 85,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10712076956509058252&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "SHIFT: a synthetic driving dataset for continuous multi-task domain adaptation",
      "id": "16040050996847565363",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Sun_SHIFT_A_Synthetic_Driving_Dataset_for_Continuous_Multi-Task_Domain_Adaptation_CVPR_2022_paper.html",
      "title": "SHIFT: a synthetic driving dataset for continuous multi-task domain adaptation",
      "authors": "T Sun, M Segu, J Postels, Y Wang\u2026",
      "year": "2022",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16040050996847565363&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Unsupervised deep anomaly detection for multi-sensor time-series signals",
      "id": "2307421743935657923",
      "url": "https://ieeexplore.ieee.org/abstract/document/9507359/",
      "title": "Unsupervised deep anomaly detection for multi-sensor time-series signals",
      "authors": "Y Zhang, Y Chen, J Wang, Z Pan",
      "year": "2021",
      "cited_by": 82,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2307421743935657923&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Does your dermatology classifier know what it doesn't know? detecting the long-tail of unseen conditions",
      "id": "678143692114235571",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841521003194",
      "title": "Does your dermatology classifier know what it doesn't know? detecting the long-tail of unseen conditions",
      "authors": "AG Roy, J Ren, S Azizi, A Loh, V Natarajan\u2026",
      "year": "2022",
      "cited_by": 80,
      "cited_by_url": "https://scholar.google.com/scholar?cites=678143692114235571&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Autoencoders for unsupervised anomaly detection in high energy physics",
      "id": "2021435255736482892",
      "url": "https://link.springer.com/article/10.1007/JHEP06(2021)161",
      "title": "Autoencoders for unsupervised anomaly detection in high energy physics",
      "authors": "T Finke, M Kr\u00e4mer, A Morandini, A M\u00fcck\u2026",
      "year": "2021",
      "cited_by": 67,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2021435255736482892&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Demystifying mlops and presenting a recipe for the selection of open-source tools",
      "id": "10864892511232457463",
      "url": "https://www.mdpi.com/2076-3417/11/19/8861",
      "title": "Demystifying mlops and presenting a recipe for the selection of open-source tools",
      "authors": "P Ruf, M Madan, C Reich, D Ould-Abdeslam",
      "year": "2021",
      "cited_by": 59,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10864892511232457463&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Deep learning for unsupervised anomaly localization in industrial images: A survey",
      "id": "9579459676985496387",
      "url": "https://ieeexplore.ieee.org/abstract/document/9849507/",
      "title": "Deep learning for unsupervised anomaly localization in industrial images: A survey",
      "authors": "X Tao, X Gong, X Zhang, S Yan\u2026",
      "year": "2022",
      "cited_by": 45,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9579459676985496387&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Toward explainable artificial intelligence for regression models: A methodological perspective",
      "id": "8190770042431966238",
      "url": "https://ieeexplore.ieee.org/abstract/document/9810062/",
      "title": "Toward explainable artificial intelligence for regression models: A methodological perspective",
      "authors": "S Letzgus, P Wagner, J Lederer\u2026",
      "year": "2022",
      "cited_by": 46,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8190770042431966238&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Anomaly detection-inspired few-shot medical image segmentation through self-supervision with supervoxels",
      "id": "5768724617166869747",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841522000378",
      "title": "Anomaly detection-inspired few-shot medical image segmentation through self-supervision with supervoxels",
      "authors": "S Hansen, S Gautam, R Jenssen\u2026",
      "year": "2022",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5768724617166869747&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Task-relevant failure detection for trajectory predictors in autonomous vehicles",
      "id": "6162716714810201955",
      "url": "https://proceedings.mlr.press/v205/farid23a.html",
      "title": "Task-relevant failure detection for trajectory predictors in autonomous vehicles",
      "authors": "A Farid, S Veer, B Ivanovic, K Leung\u2026",
      "year": "2023",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6162716714810201955&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Out-of-scope intent detection with self-supervision and discriminative training",
      "id": "13078428699608452477",
      "url": "https://arxiv.org/abs/2106.08616",
      "title": "Out-of-scope intent detection with self-supervision and discriminative training",
      "authors": "LM Zhan, H Liang, B Liu, L Fan, XM Wu\u2026",
      "year": "2021",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13078428699608452477&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Truthful AI: Developing and governing AI that does not lie",
      "id": "3308207458495141249",
      "url": "https://arxiv.org/abs/2110.06674",
      "title": "Truthful AI: Developing and governing AI that does not lie",
      "authors": "O Evans, O Cotton-Barratt, L Finnveden\u2026",
      "year": "2021",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3308207458495141249&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Fedaux: Leveraging unlabeled auxiliary data in federated learning",
      "id": "15849255232371913233",
      "url": "https://ieeexplore.ieee.org/abstract/document/9632275/",
      "title": "Fedaux: Leveraging unlabeled auxiliary data in federated learning",
      "authors": "F Sattler, T Korjakow, R Rischke\u2026",
      "year": "2021",
      "cited_by": 60,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15849255232371913233&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Towards robust explanations for deep neural networks",
      "id": "2231389869816478973",
      "url": "https://www.sciencedirect.com/science/article/pii/S0031320321003769",
      "title": "Towards robust explanations for deep neural networks",
      "authors": "AK Dombrowski, CJ Anders, KR M\u00fcller, P Kessel",
      "year": "2022",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2231389869816478973&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Training ood detectors in their natural habitats",
      "id": "8582043463264170613",
      "url": "https://proceedings.mlr.press/v162/katz-samuels22a.html",
      "title": "Training ood detectors in their natural habitats",
      "authors": "J Katz-Samuels, JB Nakhleh\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8582043463264170613&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "A hierarchical transformation-discriminating generative model for few shot anomaly detection",
      "id": "214390233068253722",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Sheynin_A_Hierarchical_Transformation-Discriminating_Generative_Model_for_Few_Shot_Anomaly_Detection_ICCV_2021_paper.html",
      "title": "A hierarchical transformation-discriminating generative model for few shot anomaly detection",
      "authors": "S Sheynin, S Benaim, L Wolf",
      "year": "2021",
      "cited_by": 43,
      "cited_by_url": "https://scholar.google.com/scholar?cites=214390233068253722&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Condition monitoring of wind turbine blades based on self-supervised health representation learning: A conducive technique to effective and reliable utilization of wind\u00a0\u2026",
      "id": "7437266987569487782",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306261922003105",
      "title": "Condition monitoring of wind turbine blades based on self-supervised health representation learning: A conducive technique to effective and reliable utilization of wind\u00a0\u2026",
      "authors": "S Sun, T Wang, H Yang, F Chu",
      "year": "2022",
      "cited_by": 24,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7437266987569487782&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Estimating example difficulty using variance of gradients",
      "id": "11875282308322336079",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Agarwal_Estimating_Example_Difficulty_Using_Variance_of_Gradients_CVPR_2022_paper.html",
      "title": "Estimating example difficulty using variance of gradients",
      "authors": "C Agarwal, D D'souza\u2026",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11875282308322336079&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Latent outlier exposure for anomaly detection with contaminated data",
      "id": "3679566789459312121",
      "url": "https://proceedings.mlr.press/v162/qiu22b.html",
      "title": "Latent outlier exposure for anomaly detection with contaminated data",
      "authors": "C Qiu, A Li, M Kloft, M Rudolph\u2026",
      "year": "2022",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3679566789459312121&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Industrial image anomaly localization based on Gaussian clustering of pretrained feature",
      "id": "14353003944710468963",
      "url": "https://ieeexplore.ieee.org/abstract/document/9479740/",
      "title": "Industrial image anomaly localization based on Gaussian clustering of pretrained feature",
      "authors": "Q Wan, L Gao, X Li, L Wen",
      "year": "2021",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14353003944710468963&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Hyperparameter sensitivity in deep outlier detection: Analysis and a scalable hyper-ensemble solution",
      "id": "14214777377381746715",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/3e9113e2bc2e700baa7d765470f140e1-Abstract-Conference.html",
      "title": "Hyperparameter sensitivity in deep outlier detection: Analysis and a scalable hyper-ensemble solution",
      "authors": "X Ding, L Zhao, L Akoglu",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14214777377381746715&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Software for dataset-wide XAI: from local explanations to global insights with Zennit, CoRelAy, and ViRelAy",
      "id": "15256074903033943732",
      "url": "https://arxiv.org/abs/2106.13200",
      "title": "Software for dataset-wide XAI: from local explanations to global insights with Zennit, CoRelAy, and ViRelAy",
      "authors": "CJ Anders, D Neumann, W Samek, KR M\u00fcller\u2026",
      "year": "2021",
      "cited_by": 42,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15256074903033943732&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "The familiarity hypothesis: Explaining the behavior of deep open set methods",
      "id": "1785343722922140905",
      "url": "https://www.sciencedirect.com/science/article/pii/S0031320322004125",
      "title": "The familiarity hypothesis: Explaining the behavior of deep open set methods",
      "authors": "TG Dietterich, A Guyer",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1785343722922140905&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Natural synthetic anomalies for self-supervised anomaly detection and localization",
      "id": "7248162955817269145",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-19821-2_27",
      "title": "Natural synthetic anomalies for self-supervised anomaly detection and localization",
      "authors": "HM Schl\u00fcter, J Tan, B Hou, B Kainz",
      "year": "2022",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7248162955817269145&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "On the nature and types of anomalies: a review of deviations in data",
      "id": "12121551931273619933",
      "url": "https://link.springer.com/article/10.1007/s41060-021-00265-1",
      "title": "On the nature and types of anomalies: a review of deviations in data",
      "authors": "R Foorthuis",
      "year": "2021",
      "cited_by": 59,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12121551931273619933&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Focus your distribution: Coarse-to-fine non-contrastive learning for anomaly detection and localization",
      "id": "10731212938719398416",
      "url": "https://ieeexplore.ieee.org/abstract/document/9859925/",
      "title": "Focus your distribution: Coarse-to-fine non-contrastive learning for anomaly detection and localization",
      "authors": "Y Zheng, X Wang, R Deng, T Bao\u2026",
      "year": "2022",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10731212938719398416&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "TFAD: A decomposition time series anomaly detection architecture with time-frequency analysis",
      "id": "5272663799261882882",
      "url": "https://dl.acm.org/doi/abs/10.1145/3511808.3557470",
      "title": "TFAD: A decomposition time series anomaly detection architecture with time-frequency analysis",
      "authors": "C Zhang, T Zhou, Q Wen, L Sun",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5272663799261882882&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Deep isolation forest for anomaly detection",
      "id": "14778056948504220863",
      "url": "https://ieeexplore.ieee.org/abstract/document/10108034/",
      "title": "Deep isolation forest for anomaly detection",
      "authors": "H Xu, G Pang, Y Wang, Y Wang",
      "year": "2023",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14778056948504220863&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Gaussian anomaly detection by modeling the distribution of normal data in pretrained deep features",
      "id": "16527862481109793893",
      "url": "https://ieeexplore.ieee.org/abstract/document/9493210/",
      "title": "Gaussian anomaly detection by modeling the distribution of normal data in pretrained deep features",
      "authors": "O Rippel, P Mertens, E K\u00f6nig\u2026",
      "year": "2021",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16527862481109793893&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Transfer-based semantic anomaly detection",
      "id": "11326401675293682123",
      "url": "https://proceedings.mlr.press/v139/deecke21a.html",
      "title": "Transfer-based semantic anomaly detection",
      "authors": "L Deecke, L Ruff\u2026",
      "year": "2021",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11326401675293682123&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Anomaly detection for tabular data with internal contrastive learning",
      "id": "5370677025711722393",
      "url": "https://openreview.net/forum?id=_hszZbt46bT",
      "title": "Anomaly detection for tabular data with internal contrastive learning",
      "authors": "T Shenkar, L Wolf",
      "year": "2021",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5370677025711722393&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Unsupervised image anomaly detection and segmentation based on pretrained feature mapping",
      "id": "4398874471937260991",
      "url": "https://ieeexplore.ieee.org/abstract/document/9795121/",
      "title": "Unsupervised image anomaly detection and segmentation based on pretrained feature mapping",
      "authors": "Q Wan, L Gao, X Li, L Wen",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4398874471937260991&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Perfect density models cannot guarantee anomaly detection",
      "id": "6238566466640748238",
      "url": "https://www.mdpi.com/1099-4300/23/12/1690",
      "title": "Perfect density models cannot guarantee anomaly detection",
      "authors": "C Le Lan, L Dinh",
      "year": "2021",
      "cited_by": 36,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6238566466640748238&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Neural contextual anomaly detection for time series",
      "id": "10024501141005307911",
      "url": "https://arxiv.org/abs/2107.07702",
      "title": "Neural contextual anomaly detection for time series",
      "authors": "CU Carmona, FX Aubet, V Flunkert\u2026",
      "year": "2021",
      "cited_by": 39,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10024501141005307911&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Out-of-distribution detection and selective generation for conditional language models",
      "id": "3567693488984063272",
      "url": "https://arxiv.org/abs/2209.15558",
      "title": "Out-of-distribution detection and selective generation for conditional language models",
      "authors": "J Ren, J Luo, Y Zhao, K Krishna, M Saleh\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3567693488984063272&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "A survey on unsupervised industrial anomaly detection algorithms",
      "id": "15317793119344835263",
      "url": "https://arxiv.org/abs/2204.11161",
      "title": "A survey on unsupervised industrial anomaly detection algorithms",
      "authors": "Y Cui, Z Liu, S Lian",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15317793119344835263&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Low-altitude aerial video surveillance via one-class SVM anomaly detection from textural features in UAV images",
      "id": "17363381983025647699",
      "url": "https://www.mdpi.com/2078-2489/13/1/2",
      "title": "Low-altitude aerial video surveillance via one-class SVM anomaly detection from textural features in UAV images",
      "authors": "D Avola, L Cinque, A Di Mambro, A Diko, A Fagioli\u2026",
      "year": "2021",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17363381983025647699&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Self-supervised anomaly detection: A survey and outlook",
      "id": "9631069152835975454",
      "url": "https://arxiv.org/abs/2205.05173",
      "title": "Self-supervised anomaly detection: A survey and outlook",
      "authors": "H Hojjati, TKK Ho, N Armanfard",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9631069152835975454&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Confidence-based out-of-distribution detection: a comparative study and analysis",
      "id": "8772844806290312927",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-87735-4_12",
      "title": "Confidence-based out-of-distribution detection: a comparative study and analysis",
      "authors": "C Berger, M Paschali, B Glocker\u2026",
      "year": "2021",
      "cited_by": 33,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8772844806290312927&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Task-driven out-of-distribution detection with statistical guarantees for robot learning",
      "id": "16849488672761264795",
      "url": "https://proceedings.mlr.press/v164/farid22a.html",
      "title": "Task-driven out-of-distribution detection with statistical guarantees for robot learning",
      "authors": "A Farid, S Veer, A Majumdar",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16849488672761264795&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Deep convolutional clustering-based time series anomaly detection",
      "id": "13607047470867432902",
      "url": "https://www.mdpi.com/1424-8220/21/16/5488",
      "title": "Deep convolutional clustering-based time series anomaly detection",
      "authors": "GS Chadha, I Islam, A Schwung, SX Ding",
      "year": "2021",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13607047470867432902&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "A call to reflect on evaluation practices for failure detection in image classification",
      "id": "10611118271257578362",
      "url": "https://arxiv.org/abs/2211.15259",
      "title": "A call to reflect on evaluation practices for failure detection in image classification",
      "authors": "PF Jaeger, CT L\u00fcth, L Klein, TJ Bungert",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10611118271257578362&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Admoe: Anomaly detection with mixture-of-experts from noisy labels",
      "id": "17712406442879515542",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25620",
      "title": "Admoe: Anomaly detection with mixture-of-experts from noisy labels",
      "authors": "Y Zhao, G Zheng, S Mukherjee, R McCann\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17712406442879515542&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Generative probabilistic novelty detection with isometric adversarial autoencoders",
      "id": "14403707945550137996",
      "url": "https://openaccess.thecvf.com/content/CVPR2022W/WiCV/html/Almohsen_Generative_Probabilistic_Novelty_Detection_With_Isometric_Adversarial_Autoencoders_CVPRW_2022_paper.html",
      "title": "Generative probabilistic novelty detection with isometric adversarial autoencoders",
      "authors": "R Almohsen, MR Keaton\u2026",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14403707945550137996&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Run-time monitoring of machine learning for robotic perception: A survey of emerging trends",
      "id": "17993515150229039530",
      "url": "https://ieeexplore.ieee.org/abstract/document/9336665/",
      "title": "Run-time monitoring of machine learning for robotic perception: A survey of emerging trends",
      "authors": "QM Rahman, P Corke, F Dayoub",
      "year": "2021",
      "cited_by": 34,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17993515150229039530&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Prototypical residual networks for anomaly detection and localization",
      "id": "15191081335956951903",
      "url": "http://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Prototypical_Residual_Networks_for_Anomaly_Detection_and_Localization_CVPR_2023_paper.html",
      "title": "Prototypical residual networks for anomaly detection and localization",
      "authors": "H Zhang, Z Wu, Z Wang, Z Chen\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15191081335956951903&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Unmanned aerial vehicle flight data anomaly detection and recovery prediction based on spatio-temporal correlation",
      "id": "3634646340176277230",
      "url": "https://ieeexplore.ieee.org/abstract/document/9667119/",
      "title": "Unmanned aerial vehicle flight data anomaly detection and recovery prediction based on spatio-temporal correlation",
      "authors": "J Zhong, Y Zhang, J Wang, C Luo\u2026",
      "year": "2021",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3634646340176277230&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Time series anomaly detection for smart grids: A survey",
      "id": "11311640397140273257",
      "url": "https://ieeexplore.ieee.org/abstract/document/9621752/",
      "title": "Time series anomaly detection for smart grids: A survey",
      "authors": "JE Zhang, D Wu, B Boulet",
      "year": "2021",
      "cited_by": 29,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11311640397140273257&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Zero-shot versus many-shot: Unsupervised texture anomaly detection",
      "id": "2993359408594724286",
      "url": "https://openaccess.thecvf.com/content/WACV2023/html/Aota_Zero-Shot_Versus_Many-Shot_Unsupervised_Texture_Anomaly_Detection_WACV_2023_paper.html",
      "title": "Zero-shot versus many-shot: Unsupervised texture anomaly detection",
      "authors": "T Aota, LTT Tong, T Okatani",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2993359408594724286&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Using binary classifiers for one-class classification",
      "id": "15918548619868169194",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417421012744",
      "title": "Using binary classifiers for one-class classification",
      "authors": "S Kang",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15918548619868169194&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Self-supervised learning for anomaly detection with dynamic local augmentation",
      "id": "490049363149100661",
      "url": "https://ieeexplore.ieee.org/abstract/document/9597511/",
      "title": "Self-supervised learning for anomaly detection with dynamic local augmentation",
      "authors": "S Yoa, S Lee, C Kim, HJ Kim",
      "year": "2021",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=490049363149100661&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Pytorch-ood: A library for out-of-distribution detection based on pytorch",
      "id": "13496204946614385428",
      "url": "https://openaccess.thecvf.com/content/CVPR2022W/HCIS/html/Kirchheim_PyTorch-OOD_A_Library_for_Out-of-Distribution_Detection_Based_on_PyTorch_CVPRW_2022_paper.html",
      "title": "Pytorch-ood: A library for out-of-distribution detection based on pytorch",
      "authors": "K Kirchheim, M Filax, F Ortmeier",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13496204946614385428&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Next-gen intelligent situational awareness systems for maritime surveillance and autonomous navigation",
      "id": "1952208765616162210",
      "url": "https://ieeexplore.ieee.org/abstract/document/9921394/",
      "title": "Next-gen intelligent situational awareness systems for maritime surveillance and autonomous navigation",
      "authors": "N Forti, E d'Afflisio, P Braca, LM Millefiori\u2026",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1952208765616162210&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Full graph autoencoder for one-class group anomaly detection of IIoT system",
      "id": "2240462269536330980",
      "url": "https://ieeexplore.ieee.org/abstract/document/9792242/",
      "title": "Full graph autoencoder for one-class group anomaly detection of IIoT system",
      "authors": "Y Feng, J Chen, Z Liu, H Lv\u2026",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2240462269536330980&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Deep generative model with hierarchical latent factors for time series anomaly detection",
      "id": "10332745316504571260",
      "url": "https://proceedings.mlr.press/v151/challu22a.html",
      "title": "Deep generative model with hierarchical latent factors for time series anomaly detection",
      "authors": "CI Challu, P Jiang, YN Wu\u2026",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10332745316504571260&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Graph anomaly detection with unsupervised GNNs",
      "id": "4974430546160529512",
      "url": "https://arxiv.org/abs/2210.09535",
      "title": "Graph anomaly detection with unsupervised GNNs",
      "authors": "L Zhao, S Sawlani, A Srinivasan, L Akoglu",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4974430546160529512&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Exposing outlier exposure: What can be learned from few, one, and zero outlier images",
      "id": "15589620931717671311",
      "url": "https://arxiv.org/abs/2205.11474",
      "title": "Exposing outlier exposure: What can be learned from few, one, and zero outlier images",
      "authors": "P Liznerski, L Ruff, RA Vandermeulen\u2026",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15589620931717671311&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "A survey on explainable anomaly detection",
      "id": "3454373283041760880",
      "url": "https://dl.acm.org/doi/abs/10.1145/3609333",
      "title": "A survey on explainable anomaly detection",
      "authors": "Z Li, Y Zhu, M Van Leeuwen",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3454373283041760880&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Review on deep learning approaches for anomaly event detection in video surveillance",
      "id": "16811817108630720533",
      "url": "https://www.mdpi.com/2079-9292/12/1/29",
      "title": "Review on deep learning approaches for anomaly event detection in video surveillance",
      "authors": "SA Jebur, KA Hussein, HK Hoomod, L Alzubaidi\u2026",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16811817108630720533&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Semi-Supervised Anomaly Detection via Neural Process",
      "id": "15963090810315431769",
      "url": "https://ieeexplore.ieee.org/abstract/document/10102264/",
      "title": "Semi-Supervised Anomaly Detection via Neural Process",
      "authors": "F Zhou, G Wang, K Zhang, S Liu\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15963090810315431769&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Raising the bar in graph-level anomaly detection",
      "id": "15253833027531638311",
      "url": "https://arxiv.org/abs/2205.13845",
      "title": "Raising the bar in graph-level anomaly detection",
      "authors": "C Qiu, M Kloft, S Mandt, M Rudolph",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15253833027531638311&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Inline nondestructive internal disorder detection in pear fruit using explainable deep anomaly detection on X-ray images",
      "id": "17045973692536155067",
      "url": "https://www.sciencedirect.com/science/article/pii/S0168169922002794",
      "title": "Inline nondestructive internal disorder detection in pear fruit using explainable deep anomaly detection on X-ray images",
      "authors": "T Van De Looverbosch, J He, A Tempelaere\u2026",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17045973692536155067&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 12
    },
    {
      "label": "Object detection with deep learning: A review",
      "id": "13346469121565650680",
      "url": "https://ieeexplore.ieee.org/abstract/document/8627998/",
      "title": "Object detection with deep learning: A review",
      "authors": "ZQ Zhao, P Zheng, S Xu, X Wu",
      "year": "2019",
      "cited_by": 4416,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13346469121565650680&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A survey on deep learning and its applications",
      "id": "8847225001696225074",
      "url": "https://www.sciencedirect.com/science/article/pii/S1574013721000198",
      "title": "A survey on deep learning and its applications",
      "authors": "S Dong, P Wang, K Abbas",
      "year": "2021",
      "cited_by": 529,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8847225001696225074&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A survey of deep learning techniques for autonomous driving",
      "id": "17325452893759607893",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21918",
      "title": "A survey of deep learning techniques for autonomous driving",
      "authors": "S Grigorescu, B Trasnea, T Cocias\u2026",
      "year": "2020",
      "cited_by": 1198,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17325452893759607893&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Study on artificial intelligence: The state of the art and future prospects",
      "id": "9531339919500160456",
      "url": "https://www.sciencedirect.com/science/article/pii/S2452414X21000248",
      "title": "Study on artificial intelligence: The state of the art and future prospects",
      "authors": "C Zhang, Y Lu",
      "year": "2021",
      "cited_by": 395,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9531339919500160456&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A survey on performance metrics for object-detection algorithms",
      "id": "7658252996672799137",
      "url": "https://ieeexplore.ieee.org/abstract/document/9145130/",
      "title": "A survey on performance metrics for object-detection algorithms",
      "authors": "R Padilla, SL Netto, EAB Da Silva",
      "year": "2020",
      "cited_by": 739,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7658252996672799137&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Dive into deep learning",
      "id": "2617964736190327137",
      "url": "https://arxiv.org/abs/2106.11342",
      "title": "Dive into deep learning",
      "authors": "A Zhang, ZC Lipton, M Li, AJ Smola",
      "year": "2021",
      "cited_by": 867,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2617964736190327137&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A Survey of Autonomous Driving: Common Practices and Emerging Technologies",
      "id": "11317456985294514291",
      "url": "https://ieeexplore.ieee.org/abstract/document/9046805/",
      "title": "A Survey of Autonomous Driving: Common Practices and Emerging Technologies",
      "authors": "E Yurtsever, J Lambert, A Carballo, K Takeda",
      "year": "2020",
      "cited_by": 1123,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11317456985294514291&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Unbox the black-box for the medical explainable AI via multi-modal and multi-centre data fusion: A mini-review, two showcases and beyond",
      "id": "1629697025352584075",
      "url": "https://www.sciencedirect.com/science/article/pii/S1566253521001597",
      "title": "Unbox the black-box for the medical explainable AI via multi-modal and multi-centre data fusion: A mini-review, two showcases and beyond",
      "authors": "G Yang, Q Ye, J Xia",
      "year": "2022",
      "cited_by": 285,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1629697025352584075&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Application of deep learning algorithms in geotechnical engineering: a short critical review",
      "id": "3387494033233397434",
      "url": "https://link.springer.com/article/10.1007/s10462-021-09967-1",
      "title": "Application of deep learning algorithms in geotechnical engineering: a short critical review",
      "authors": "W Zhang, H Li, Y Li, H Liu, Y Chen, X Ding",
      "year": "2021",
      "cited_by": 238,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3387494033233397434&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Gliding vertex on the horizontal bounding box for multi-oriented object detection",
      "id": "9453884244192340827",
      "url": "https://ieeexplore.ieee.org/abstract/document/9001201/",
      "title": "Gliding vertex on the horizontal bounding box for multi-oriented object detection",
      "authors": "Y Xu, M Fu, Q Wang, Y Wang, K Chen\u2026",
      "year": "2020",
      "cited_by": 443,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9453884244192340827&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning for chest X-ray analysis: A survey",
      "id": "9105258566287239045",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841521001717",
      "title": "Deep learning for chest X-ray analysis: A survey",
      "authors": "E \u00c7all\u0131, E Sogancioglu, B van Ginneken\u2026",
      "year": "2021",
      "cited_by": 214,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9105258566287239045&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Camouflaged object detection",
      "id": "14930542330832755729",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Fan_Camouflaged_Object_Detection_CVPR_2020_paper.html",
      "title": "Camouflaged object detection",
      "authors": "DP Fan, GP Ji, G Sun, MM Cheng\u2026",
      "year": "2020",
      "cited_by": 339,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14930542330832755729&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Applications of deep learning in stock market prediction: recent progress",
      "id": "14554488295084172370",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417421009441",
      "title": "Applications of deep learning in stock market prediction: recent progress",
      "authors": "W Jiang",
      "year": "2021",
      "cited_by": 327,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14554488295084172370&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "First return, then explore",
      "id": "212018708743960174",
      "url": "https://www.nature.com/articles/s41586-020-03157-9)",
      "title": "First return, then explore",
      "authors": "A Ecoffet, J Huizinga, J Lehman, KO Stanley, J Clune",
      "year": "2021",
      "cited_by": 277,
      "cited_by_url": "https://scholar.google.com/scholar?cites=212018708743960174&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Recent advances in small object detection based on deep learning: A review",
      "id": "17642928594905005472",
      "url": "https://www.sciencedirect.com/science/article/pii/S0262885620300421",
      "title": "Recent advances in small object detection based on deep learning: A review",
      "authors": "K Tong, Y Wu, F Zhou",
      "year": "2020",
      "cited_by": 319,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17642928594905005472&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Concealed object detection",
      "id": "17449731775022216088",
      "url": "https://ieeexplore.ieee.org/abstract/document/9444794/",
      "title": "Concealed object detection",
      "authors": "DP Fan, GP Ji, MM Cheng\u2026",
      "year": "2021",
      "cited_by": 204,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17449731775022216088&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A deep collocation method for the bending analysis of Kirchhoff plate",
      "id": "14081415941935534928",
      "url": "https://arxiv.org/abs/2102.02617",
      "title": "A deep collocation method for the bending analysis of Kirchhoff plate",
      "authors": "H Guo, X Zhuang, T Rabczuk",
      "year": "2021",
      "cited_by": 389,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14081415941935534928&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "YOLO v3-Tiny: Object Detection and Recognition using one stage improved model",
      "id": "12435210238474843309",
      "url": "https://ieeexplore.ieee.org/abstract/document/9074315/",
      "title": "YOLO v3-Tiny: Object Detection and Recognition using one stage improved model",
      "authors": "P Adarsh, P Rathi, M Kumar",
      "year": "2020",
      "cited_by": 339,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12435210238474843309&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Face mask detection using transfer learning of inceptionv3",
      "id": "13748943285480844265",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-66665-1_6",
      "title": "Face mask detection using transfer learning of inceptionv3",
      "authors": "G Jignesh Chowdary, NS Punn, SK Sonbhadra\u2026",
      "year": "2020",
      "cited_by": 267,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13748943285480844265&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Monitoring COVID-19 social distancing with person detection and tracking via fine-tuned YOLO v3 and Deepsort techniques",
      "id": "10547178639330987288",
      "url": "https://arxiv.org/abs/2005.01385",
      "title": "Monitoring COVID-19 social distancing with person detection and tracking via fine-tuned YOLO v3 and Deepsort techniques",
      "authors": "NS Punn, SK Sonbhadra, S Agarwal, G Rai",
      "year": "2020",
      "cited_by": 284,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10547178639330987288&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning for lidar point clouds in autonomous driving: A review",
      "id": "16888371616033308169",
      "url": "https://ieeexplore.ieee.org/abstract/document/9173706/",
      "title": "Deep learning for lidar point clouds in autonomous driving: A review",
      "authors": "Y Li, L Ma, Z Zhong, F Liu\u2026",
      "year": "2020",
      "cited_by": 273,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16888371616033308169&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning for safe autonomous driving: Current challenges and future directions",
      "id": "18079286179474516945",
      "url": "https://ieeexplore.ieee.org/abstract/document/9284628/",
      "title": "Deep learning for safe autonomous driving: Current challenges and future directions",
      "authors": "K Muhammad, A Ullah, J Lloret\u2026",
      "year": "2020",
      "cited_by": 212,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18079286179474516945&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Object detection and image segmentation with deep learning on earth observation data: A review-part i: Evolution and recent trends",
      "id": "16601259166110264431",
      "url": "https://www.mdpi.com/2072-4292/12/10/1667",
      "title": "Object detection and image segmentation with deep learning on earth observation data: A review-part i: Evolution and recent trends",
      "authors": "T Hoeser, C Kuenzer",
      "year": "2020",
      "cited_by": 249,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16601259166110264431&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A review of object detection based on deep learning",
      "id": "7566971192202831904",
      "url": "https://link.springer.com/article/10.1007/s11042-020-08976-6",
      "title": "A review of object detection based on deep learning",
      "authors": "Y Xiao, Z Tian, J Yu, Y Zhang, S Liu, S Du\u2026",
      "year": "2020",
      "cited_by": 261,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7566971192202831904&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Automatic crack classification and segmentation on masonry surfaces using convolutional neural networks and transfer learning",
      "id": "2597379987318853103",
      "url": "https://www.sciencedirect.com/science/article/pii/S0926580521000571",
      "title": "Automatic crack classification and segmentation on masonry surfaces using convolutional neural networks and transfer learning",
      "authors": "D Dais, IE Bal, E Smyrou, V Sarhosis",
      "year": "2021",
      "cited_by": 156,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2597379987318853103&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "RGB-D salient object detection: A survey",
      "id": "15507377305223603161",
      "url": "https://link.springer.com/article/10.1007/s41095-020-0199-z",
      "title": "RGB-D salient object detection: A survey",
      "authors": "T Zhou, DP Fan, MM Cheng, J Shen, L Shao",
      "year": "2021",
      "cited_by": 200,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15507377305223603161&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Prediction of groundwater quality using efficient machine learning technique",
      "id": "11504531406673088307",
      "url": "https://www.sciencedirect.com/science/article/pii/S0045653521007347",
      "title": "Prediction of groundwater quality using efficient machine learning technique",
      "authors": "S Singha, S Pasupuleti, SS Singha, R Singh, S Kumar",
      "year": "2021",
      "cited_by": 129,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11504531406673088307&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Monocular depth estimation based on deep learning: An overview",
      "id": "16324732045488656995",
      "url": "https://link.springer.com/article/10.1007/s11431-020-1582-8",
      "title": "Monocular depth estimation based on deep learning: An overview",
      "authors": "C Zhao, Q Sun, C Zhang, Y Tang, F Qian",
      "year": "2020",
      "cited_by": 244,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16324732045488656995&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep autoencoder based energy method for the bending, vibration, and buckling analysis of Kirchhoff plates with transfer learning",
      "id": "12342618065285300259",
      "url": "https://www.sciencedirect.com/science/article/pii/S099775382100019X",
      "title": "Deep autoencoder based energy method for the bending, vibration, and buckling analysis of Kirchhoff plates with transfer learning",
      "authors": "X Zhuang, H Guo, N Alajlan, H Zhu\u2026",
      "year": "2021",
      "cited_by": 172,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12342618065285300259&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "The impact of pre-and post-image processing techniques on deep learning frameworks: A comprehensive review for digital pathology image analysis",
      "id": "12928939764513613154",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482520304601",
      "title": "The impact of pre-and post-image processing techniques on deep learning frameworks: A comprehensive review for digital pathology image analysis",
      "authors": "M Salvi, UR Acharya, F Molinari\u2026",
      "year": "2021",
      "cited_by": 159,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12928939764513613154&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning for change detection in remote sensing images: Comprehensive review and meta-analysis",
      "id": "5360881814442745026",
      "url": "https://ieeexplore.ieee.org/abstract/document/9136674/",
      "title": "Deep learning for change detection in remote sensing images: Comprehensive review and meta-analysis",
      "authors": "L Khelifi, M Mignotte",
      "year": "2020",
      "cited_by": 205,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5360881814442745026&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A brief review of domain adaptation",
      "id": "4077468826256393449",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-71704-9_65",
      "title": "A brief review of domain adaptation",
      "authors": "A Farahani, S Voghoei, K Rasheed\u2026",
      "year": "2021",
      "cited_by": 218,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4077468826256393449&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning in multi-object detection and tracking: state of the art",
      "id": "3796249632159372698",
      "url": "https://link.springer.com/article/10.1007/s10489-021-02293-7",
      "title": "Deep learning in multi-object detection and tracking: state of the art",
      "authors": "SK Pal, A Pramanik, J Maiti, P Mitra",
      "year": "2021",
      "cited_by": 144,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3796249632159372698&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Automatic detection method of tunnel lining multi\u2010defects via an enhanced You Only Look Once network",
      "id": "6905939594294613143",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12836",
      "title": "Automatic detection method of tunnel lining multi\u2010defects via an enhanced You Only Look Once network",
      "authors": "Z Zhou, J Zhang, C Gong",
      "year": "2022",
      "cited_by": 72,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6905939594294613143&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning in ECG diagnosis: A review",
      "id": "2142612586528747387",
      "url": "https://www.sciencedirect.com/science/article/pii/S0950705121004494",
      "title": "Deep learning in ECG diagnosis: A review",
      "authors": "X Liu, H Wang, Z Li, L Qin",
      "year": "2021",
      "cited_by": 117,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2142612586528747387&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Salient object detection: A survey",
      "id": "9106423587240821276",
      "url": "https://link.springer.com/article/10.1007/s41095-019-0149-9",
      "title": "Salient object detection: A survey",
      "authors": "A Borji, MM Cheng, Q Hou, H Jiang, J Li",
      "year": "2019",
      "cited_by": 868,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9106423587240821276&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Tectonic evolution and paleoposition of the Baoshan and Lincang blocks of West Yunnan during the Paleozoic",
      "id": "2983606601337837743",
      "url": "https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019TC006028",
      "title": "Tectonic evolution and paleoposition of the Baoshan and Lincang blocks of West Yunnan during the Paleozoic",
      "authors": "B Liu, T Peng, W Fan, G Zhao, J Gao, X Dong\u2026",
      "year": "2020",
      "cited_by": 217,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2983606601337837743&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Semi-supervised locality preserving dense graph neural network with ARMA filters and context-aware learning for hyperspectral image classification",
      "id": "16360107983645858167",
      "url": "https://ieeexplore.ieee.org/abstract/document/9506991/",
      "title": "Semi-supervised locality preserving dense graph neural network with ARMA filters and context-aware learning for hyperspectral image classification",
      "authors": "Y Ding, X Zhao, Z Zhang, W Cai\u2026",
      "year": "2021",
      "cited_by": 115,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16360107983645858167&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Visual-based defect detection and classification approaches for industrial applications\u2014A survey",
      "id": "4185948125671434541",
      "url": "https://www.mdpi.com/1424-8220/20/5/1459",
      "title": "Visual-based defect detection and classification approaches for industrial applications\u2014A survey",
      "authors": "T Czimmermann, G Ciuti, M Milazzo, M Chiurazzi\u2026",
      "year": "2020",
      "cited_by": 216,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4185948125671434541&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep neural network concepts for background subtraction: A systematic review and comparative evaluation",
      "id": "15373527129249864261",
      "url": "https://www.sciencedirect.com/science/article/pii/S0893608019301303",
      "title": "Deep neural network concepts for background subtraction: A systematic review and comparative evaluation",
      "authors": "T Bouwmans, S Javed, M Sultana, SK Jung",
      "year": "2019",
      "cited_by": 356,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15373527129249864261&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Multiple object tracking: A literature review",
      "id": "3101580748817568884",
      "url": "https://www.sciencedirect.com/science/article/pii/S0004370220301958",
      "title": "Multiple object tracking: A literature review",
      "authors": "W Luo, J Xing, A Milan, X Zhang, W Liu, TK Kim",
      "year": "2021",
      "cited_by": 813,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3101580748817568884&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Fedvision: An online visual object detection platform powered by federated learning",
      "id": "6067204860221490122",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/7021",
      "title": "Fedvision: An online visual object detection platform powered by federated learning",
      "authors": "Y Liu, A Huang, Y Luo, H Huang, Y Liu\u2026",
      "year": "2020",
      "cited_by": 226,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6067204860221490122&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Deep learning meets SAR: Concepts, models, pitfalls, and perspectives",
      "id": "10469230642894389844",
      "url": "https://ieeexplore.ieee.org/abstract/document/9351574/",
      "title": "Deep learning meets SAR: Concepts, models, pitfalls, and perspectives",
      "authors": "XX Zhu, S Montazeri, M Ali, Y Hua\u2026",
      "year": "2021",
      "cited_by": 180,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10469230642894389844&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Convolutional neural networks for image-based high-throughput plant phenotyping: a review",
      "id": "11773732314594455999",
      "url": "https://spj.science.org/doi/full/10.34133/2020/4152816?adobe_mc=MCMID%3D13000078418609464879081490540568399952%7CMCORGID%3D242B6472541199F70A4C98A6%2540AdobeOrg%7CTS%3D1670976000",
      "title": "Convolutional neural networks for image-based high-throughput plant phenotyping: a review",
      "authors": "Y Jiang, C Li",
      "year": "2020",
      "cited_by": 182,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11773732314594455999&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Anomaly detection in univariate time-series: A survey on the state-of-the-art",
      "id": "4370422915042112938",
      "url": "https://arxiv.org/abs/2004.00433",
      "title": "Anomaly detection in univariate time-series: A survey on the state-of-the-art",
      "authors": "M Braei, S Wagner",
      "year": "2020",
      "cited_by": 189,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4370422915042112938&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Object detection algorithm based on improved YOLOv3",
      "id": "9379156628635523145",
      "url": "https://www.mdpi.com/2079-9292/9/3/537",
      "title": "Object detection algorithm based on improved YOLOv3",
      "authors": "L Zhao, S Li",
      "year": "2020",
      "cited_by": 193,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9379156628635523145&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Recent advances in artificial intelligence and machine learning for nonlinear relationship analysis and process control in drinking water treatment: A review",
      "id": "2488030068881724873",
      "url": "https://www.sciencedirect.com/science/article/pii/S1385894720328011",
      "title": "Recent advances in artificial intelligence and machine learning for nonlinear relationship analysis and process control in drinking water treatment: A review",
      "authors": "L Li, S Rong, R Wang, S Yu",
      "year": "2021",
      "cited_by": 158,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2488030068881724873&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "A review of deep learning with special emphasis on architectures, applications and recent trends",
      "id": "5282584135767767517",
      "url": "https://www.sciencedirect.com/science/article/pii/S095070512030071X",
      "title": "A review of deep learning with special emphasis on architectures, applications and recent trends",
      "authors": "S Sengupta, S Basak, P Saikia, S Paul\u2026",
      "year": "2020",
      "cited_by": 306,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5282584135767767517&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Invisible for both camera and lidar: Security of multi-sensor fusion based perception in autonomous driving under physical-world attacks",
      "id": "10632950128195096357",
      "url": "https://ieeexplore.ieee.org/abstract/document/9519442/",
      "title": "Invisible for both camera and lidar: Security of multi-sensor fusion based perception in autonomous driving under physical-world attacks",
      "authors": "Y Cao, N Wang, C Xiao, D Yang, J Fang\u2026",
      "year": "2021",
      "cited_by": 111,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10632950128195096357&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "DS-CNN: A pre-trained Xception model based on depth-wise separable convolutional neural network for finger vein recognition",
      "id": "708621415733870473",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417421015943",
      "title": "DS-CNN: A pre-trained Xception model based on depth-wise separable convolutional neural network for finger vein recognition",
      "authors": "K Shaheed, A Mao, I Qureshi, M Kumar\u2026",
      "year": "2022",
      "cited_by": 72,
      "cited_by_url": "https://scholar.google.com/scholar?cites=708621415733870473&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "An evaluation of deep learning methods for small object detection",
      "id": "9316980701966772208",
      "url": "https://www.hindawi.com/journals/jece/2020/3189691/",
      "title": "An evaluation of deep learning methods for small object detection",
      "authors": "ND Nguyen, T Do, TD Ngo, DD Le",
      "year": "2020",
      "cited_by": 163,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9316980701966772208&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Mini-YOLOv3: real-time object detector for embedded applications",
      "id": "7644063362073502300",
      "url": "https://ieeexplore.ieee.org/abstract/document/8839032/",
      "title": "Mini-YOLOv3: real-time object detector for embedded applications",
      "authors": "QC Mao, HM Sun, YB Liu, RS Jia",
      "year": "2019",
      "cited_by": 204,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7644063362073502300&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Real-time face mask detection method based on YOLOv3",
      "id": "14163003192753029307",
      "url": "https://www.mdpi.com/2079-9292/10/7/837",
      "title": "Real-time face mask detection method based on YOLOv3",
      "authors": "X Jiang, T Gao, Z Zhu, Y Zhao",
      "year": "2021",
      "cited_by": 112,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14163003192753029307&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "New generation deep learning for video object detection: A survey",
      "id": "18400177295485631651",
      "url": "https://ieeexplore.ieee.org/abstract/document/9345705/",
      "title": "New generation deep learning for video object detection: A survey",
      "authors": "L Jiao, R Zhang, F Liu, S Yang, B Hou\u2026",
      "year": "2021",
      "cited_by": 102,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18400177295485631651&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Ship detection in large-scale SAR images via spatial shuffle-group enhance attention",
      "id": "1644345333320747257",
      "url": "https://ieeexplore.ieee.org/abstract/document/9106758/",
      "title": "Ship detection in large-scale SAR images via spatial shuffle-group enhance attention",
      "authors": "Z Cui, X Wang, N Liu, Z Cao\u2026",
      "year": "2020",
      "cited_by": 147,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1644345333320747257&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Small-object detection in remote sensing images with end-to-end edge-enhanced GAN and object detector network",
      "id": "3224984904288274964",
      "url": "https://www.mdpi.com/2072-4292/12/9/1432",
      "title": "Small-object detection in remote sensing images with end-to-end edge-enhanced GAN and object detector network",
      "authors": "J Rabbi, N Ray, M Schubert, S Chowdhury, D Chao",
      "year": "2020",
      "cited_by": 168,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3224984904288274964&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Scop: Scientific control for reliable neural network pruning",
      "id": "10691651773549756733",
      "url": "https://proceedings.neurips.cc/paper/2020/hash/7bcdf75ad237b8e02e301f4091fb6bc8-Abstract.html",
      "title": "Scop: Scientific control for reliable neural network pruning",
      "authors": "Y Tang, Y Wang, Y Xu, D Tao, C Xu\u2026",
      "year": "2020",
      "cited_by": 116,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10691651773549756733&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 4
    },
    {
      "label": "Opportunities and challenges in explainable artificial intelligence (xai): A survey",
      "id": "16945998805068988708",
      "url": "https://arxiv.org/abs/2006.11371",
      "title": "Opportunities and challenges in explainable artificial intelligence (xai): A survey",
      "authors": "A Das, P Rad",
      "year": "2020",
      "cited_by": 538,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16945998805068988708&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Deep learning for object detection and scene perception in self-driving cars: Survey, challenges, and open issues",
      "id": "2507582518469208253",
      "url": "https://www.sciencedirect.com/science/article/pii/S2590005621000059",
      "title": "Deep learning for object detection and scene perception in self-driving cars: Survey, challenges, and open issues",
      "authors": "A Gupta, A Anpalagan, L Guan, AS Khwaja",
      "year": "2021",
      "cited_by": 239,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2507582518469208253&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Machine learning and deep learning",
      "id": "15761127917409164495",
      "url": "https://link.springer.com/article/10.1007/s12525-021-00475-2",
      "title": "Machine learning and deep learning",
      "authors": "C Janiesch, P Zschech, K Heinrich",
      "year": "2021",
      "cited_by": 937,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15761127917409164495&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Learning to prompt for continual learning",
      "id": "11127330701624169778",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Wang_Learning_To_Prompt_for_Continual_Learning_CVPR_2022_paper.html",
      "title": "Learning to prompt for continual learning",
      "authors": "Z Wang, Z Zhang, CY Lee, H Zhang\u2026",
      "year": "2022",
      "cited_by": 185,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11127330701624169778&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Explainable deep learning: A field guide for the uninitiated",
      "id": "5823096581545580132",
      "url": "https://www.jair.org/index.php/jair/article/view/13200",
      "title": "Explainable deep learning: A field guide for the uninitiated",
      "authors": "G Ras, N Xie, M Van Gerven, D Doran",
      "year": "2022",
      "cited_by": 346,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5823096581545580132&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Intelligent driving intelligence test for autonomous vehicles with naturalistic and adversarial environment",
      "id": "14750169433894795213",
      "url": "https://www.nature.com/articles/s41467-021-21007-8",
      "title": "Intelligent driving intelligence test for autonomous vehicles with naturalistic and adversarial environment",
      "authors": "S Feng, X Yan, H Sun, Y Feng, HX Liu",
      "year": "2021",
      "cited_by": 179,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14750169433894795213&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Explainable artificial intelligence: objectives, stakeholders, and future research opportunities",
      "id": "14799418040721278868",
      "url": "https://www.tandfonline.com/doi/abs/10.1080/10580530.2020.1849465",
      "title": "Explainable artificial intelligence: objectives, stakeholders, and future research opportunities",
      "authors": "C Meske, E Bunde, J Schneider\u2026",
      "year": "2022",
      "cited_by": 231,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14799418040721278868&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Automotive LiDAR technology: A survey",
      "id": "11207367590828257735",
      "url": "https://ieeexplore.ieee.org/abstract/document/9455394/",
      "title": "Automotive LiDAR technology: A survey",
      "authors": "R Roriz, J Cabral, T Gomes",
      "year": "2021",
      "cited_by": 145,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11207367590828257735&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets",
      "id": "16563837428337733383",
      "url": "https://link.springer.com/article/10.1007/s00371-021-02166-7",
      "title": "A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets",
      "authors": "K Bayoudh, R Knani, F Hamdaoui, A Mtibaa",
      "year": "2021",
      "cited_by": 138,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16563837428337733383&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Video summarization using deep neural networks: A survey",
      "id": "3429732511943586845",
      "url": "https://ieeexplore.ieee.org/abstract/document/9594911/",
      "title": "Video summarization using deep neural networks: A survey",
      "authors": "E Apostolidis, E Adamantidou, AI Metsai\u2026",
      "year": "2021",
      "cited_by": 137,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3429732511943586845&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Decision making of autonomous vehicles in lane change scenarios: Deep reinforcement learning approaches with risk awareness",
      "id": "15938347331059363535",
      "url": "https://www.sciencedirect.com/science/article/pii/S0968090X21004411",
      "title": "Decision making of autonomous vehicles in lane change scenarios: Deep reinforcement learning approaches with risk awareness",
      "authors": "G Li, Y Yang, S Li, X Qu, N Lyu, SE Li",
      "year": "2022",
      "cited_by": 85,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15938347331059363535&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Risk assessment based collision avoidance decision-making for autonomous vehicles in multi-scenarios",
      "id": "11324300263159808676",
      "url": "https://www.sciencedirect.com/science/article/pii/S0968090X20307257",
      "title": "Risk assessment based collision avoidance decision-making for autonomous vehicles in multi-scenarios",
      "authors": "G Li, Y Yang, T Zhang, X Qu, D Cao, B Cheng\u2026",
      "year": "2021",
      "cited_by": 121,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11324300263159808676&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Milestones in autonomous driving and intelligent vehicles: Survey of surveys",
      "id": "2878363142274078846",
      "url": "https://ieeexplore.ieee.org/abstract/document/9963987/",
      "title": "Milestones in autonomous driving and intelligent vehicles: Survey of surveys",
      "authors": "L Chen, Y Li, C Huang, B Li, Y Xing\u2026",
      "year": "2022",
      "cited_by": 81,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2878363142274078846&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Quo vadis artificial intelligence?",
      "id": "10459154347245074313",
      "url": "https://link.springer.com/article/10.1007/s44163-022-00022-8",
      "title": "Quo vadis artificial intelligence?",
      "authors": "Y Jiang, X Li, H Luo, S Yin, O Kaynak",
      "year": "2022",
      "cited_by": 81,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10459154347245074313&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Semantics for robotic mapping, perception and interaction: A survey",
      "id": "6067064466586264123",
      "url": "https://www.nowpublishers.com/article/Details/ROB-059",
      "title": "Semantics for robotic mapping, perception and interaction: A survey",
      "authors": "S Garg, N S\u00fcnderhauf, F Dayoub\u2026",
      "year": "2020",
      "cited_by": 102,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6067064466586264123&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "6G for vehicle-to-everything (V2X) communications: Enabling technologies, challenges, and opportunities",
      "id": "8114522470454201714",
      "url": "https://ieeexplore.ieee.org/abstract/document/9779322/",
      "title": "6G for vehicle-to-everything (V2X) communications: Enabling technologies, challenges, and opportunities",
      "authors": "M Noor-A-Rahim, Z Liu, H Lee, MO Khyam\u2026",
      "year": "2022",
      "cited_by": 133,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8114522470454201714&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Theory of overparametrization in quantum neural networks",
      "id": "1131610574501943405",
      "url": "https://www.nature.com/articles/s43588-023-00467-6",
      "title": "Theory of overparametrization in quantum neural networks",
      "authors": "M Larocca, N Ju, D Garc\u00eda-Mart\u00edn, PJ Coles\u2026",
      "year": "2023",
      "cited_by": 77,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1131610574501943405&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "An updated survey of efficient hardware architectures for accelerating deep convolutional neural networks",
      "id": "7068343160162404376",
      "url": "https://www.mdpi.com/1999-5903/12/7/113",
      "title": "An updated survey of efficient hardware architectures for accelerating deep convolutional neural networks",
      "authors": "M Capra, B Bussolino, A Marchisio, M Shafique\u2026",
      "year": "2020",
      "cited_by": 136,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7068343160162404376&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Machine learning technologies for secure vehicular communication in internet of vehicles: recent advances and applications",
      "id": "17384033669757226875",
      "url": "https://www.hindawi.com/journals/scn/2021/8868355/",
      "title": "Machine learning technologies for secure vehicular communication in internet of vehicles: recent advances and applications",
      "authors": "ES Ali, MK Hasan, R Hassan, RA Saeed\u2026",
      "year": "2021",
      "cited_by": 101,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17384033669757226875&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A comprehensive survey of ai-generated content (aigc): A history of generative ai from gan to chatgpt",
      "id": "12604090720681450553",
      "url": "https://arxiv.org/abs/2303.04226",
      "title": "A comprehensive survey of ai-generated content (aigc): A history of generative ai from gan to chatgpt",
      "authors": "Y Cao, S Li, Y Liu, Z Yan, Y Dai, PS Yu\u2026",
      "year": "2023",
      "cited_by": 94,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12604090720681450553&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Learning discriminative features by covering local geometric space for point cloud analysis",
      "id": "8617012105369696231",
      "url": "https://ieeexplore.ieee.org/abstract/document/9762976/",
      "title": "Learning discriminative features by covering local geometric space for point cloud analysis",
      "authors": "C Wang, X Ning, L Sun, L Zhang\u2026",
      "year": "2022",
      "cited_by": 56,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8617012105369696231&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Multifunctional optoelectronic synapse based on ferroelectric van der Waals heterostructure for emulating the entire human visual system",
      "id": "10783855747646875569",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.202108014",
      "title": "Multifunctional optoelectronic synapse based on ferroelectric van der Waals heterostructure for emulating the entire human visual system",
      "authors": "F Guo, M Song, MC Wong, R Ding\u2026",
      "year": "2022",
      "cited_by": 54,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10783855747646875569&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A survey on autonomous vehicle control in the era of mixed-autonomy: From physics-based to AI-guided driving policy learning",
      "id": "15129937235725122381",
      "url": "https://www.sciencedirect.com/science/article/pii/S0968090X21000401",
      "title": "A survey on autonomous vehicle control in the era of mixed-autonomy: From physics-based to AI-guided driving policy learning",
      "authors": "X Di, R Shi",
      "year": "2021",
      "cited_by": 114,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15129937235725122381&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Next-generation deep learning based on simulators and synthetic data",
      "id": "9136495772785862243",
      "url": "https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(21)00293-X",
      "title": "Next-generation deep learning based on simulators and synthetic data",
      "authors": "CM de Melo, A Torralba, L Guibas, J DiCarlo\u2026",
      "year": "2022",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9136495772785862243&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Autonomous driving architectures: insights of machine learning and deep learning algorithms",
      "id": "3820824800719710132",
      "url": "https://www.sciencedirect.com/science/article/pii/S2666827021000827",
      "title": "Autonomous driving architectures: insights of machine learning and deep learning algorithms",
      "authors": "MR Bachute, JM Subhedar",
      "year": "2021",
      "cited_by": 73,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3820824800719710132&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A survey of deep RL and IL for autonomous driving policy learning",
      "id": "543244060835176193",
      "url": "https://ieeexplore.ieee.org/abstract/document/9660769/",
      "title": "A survey of deep RL and IL for autonomous driving policy learning",
      "authors": "Z Zhu, H Zhao",
      "year": "2021",
      "cited_by": 83,
      "cited_by_url": "https://scholar.google.com/scholar?cites=543244060835176193&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Physics-informed attention-based neural network for hyperbolic partial differential equations: application to the Buckley\u2013Leverett problem",
      "id": "1056529344033078034",
      "url": "https://www.nature.com/articles/s41598-022-11058-2",
      "title": "Physics-informed attention-based neural network for hyperbolic partial differential equations: application to the Buckley\u2013Leverett problem",
      "authors": "R Rodriguez-Torrado, P Ruiz, L Cueto-Felgueroso\u2026",
      "year": "2022",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1056529344033078034&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Machine Learning, Deep Learning and Statistical Analysis for forecasting building energy consumption\u2014A systematic review",
      "id": "3290950822311574111",
      "url": "https://www.sciencedirect.com/science/article/pii/S0952197622003372",
      "title": "Machine Learning, Deep Learning and Statistical Analysis for forecasting building energy consumption\u2014A systematic review",
      "authors": "M Khalil, AS McGough, Z Pourmirza\u2026",
      "year": "2022",
      "cited_by": 44,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3290950822311574111&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Robustart: Benchmarking robustness on architecture design and training techniques",
      "id": "8485046656923809530",
      "url": "https://arxiv.org/abs/2109.05211",
      "title": "Robustart: Benchmarking robustness on architecture design and training techniques",
      "authors": "S Tang, R Gong, Y Wang, A Liu, J Wang\u2026",
      "year": "2021",
      "cited_by": 67,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8485046656923809530&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Perturbation-based methods for explaining deep neural networks: A survey",
      "id": "8810290142290002002",
      "url": "https://www.sciencedirect.com/science/article/pii/S0167865521002440",
      "title": "Perturbation-based methods for explaining deep neural networks: A survey",
      "authors": "M Ivanovs, R Kadikis, K Ozols",
      "year": "2021",
      "cited_by": 75,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8810290142290002002&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A survey of collaborative machine learning using 5G vehicular communications",
      "id": "5369236400026867300",
      "url": "https://ieeexplore.ieee.org/abstract/document/9706268/",
      "title": "A survey of collaborative machine learning using 5G vehicular communications",
      "authors": "SV Balkus, H Wang, BD Cornet\u2026",
      "year": "2022",
      "cited_by": 35,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5369236400026867300&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Adabits: Neural network quantization with adaptive bit-widths",
      "id": "2908516376509801521",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Jin_AdaBits_Neural_Network_Quantization_With_Adaptive_Bit-Widths_CVPR_2020_paper.html",
      "title": "Adabits: Neural network quantization with adaptive bit-widths",
      "authors": "Q Jin, L Yang, Z Liao",
      "year": "2020",
      "cited_by": 101,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2908516376509801521&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Design and implementation of deep neural network-based control for automatic parking maneuver process",
      "id": "7820015134418027243",
      "url": "https://ieeexplore.ieee.org/abstract/document/9298482/",
      "title": "Design and implementation of deep neural network-based control for automatic parking maneuver process",
      "authors": "R Chai, A Tsourdos, A Savvaris, S Chai\u2026",
      "year": "2020",
      "cited_by": 78,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7820015134418027243&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Driver anomaly quantification for intelligent vehicles: A contrastive learning approach with representation clustering",
      "id": "10599118327233610110",
      "url": "https://ieeexplore.ieee.org/abstract/document/9745337/",
      "title": "Driver anomaly quantification for intelligent vehicles: A contrastive learning approach with representation clustering",
      "authors": "Z Hu, Y Xing, W Gu, D Cao, C Lv",
      "year": "2022",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10599118327233610110&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "The role of artificial intelligence in the mass adoption of electric vehicles",
      "id": "8382044937846336173",
      "url": "https://www.cell.com/joule/pdf/S2542-4351(21)00350-0.pdf",
      "title": "The role of artificial intelligence in the mass adoption of electric vehicles",
      "authors": "M Ahmed, Y Zheng, A Amine, H Fathiannasab, Z Chen",
      "year": "2021",
      "cited_by": 41,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8382044937846336173&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Optical coherent dot-product chip for sophisticated deep learning regression",
      "id": "15720662195716475484",
      "url": "https://www.nature.com/articles/s41377-021-00666-8",
      "title": "Optical coherent dot-product chip for sophisticated deep learning regression",
      "authors": "S Xu, J Wang, H Shu, Z Zhang, S Yi, B Bai\u2026",
      "year": "2021",
      "cited_by": 47,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15720662195716475484&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Diversity matters: Fully exploiting depth clues for reliable monocular 3d object detection",
      "id": "296015877195835414",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Li_Diversity_Matters_Fully_Exploiting_Depth_Clues_for_Reliable_Monocular_3D_CVPR_2022_paper.html",
      "title": "Diversity matters: Fully exploiting depth clues for reliable monocular 3d object detection",
      "authors": "Z Li, Z Qu, Y Zhou, J Liu, H Wang\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=296015877195835414&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Super-human performance in gran turismo sport using deep reinforcement learning",
      "id": "11140667219432227939",
      "url": "https://ieeexplore.ieee.org/abstract/document/9372847/",
      "title": "Super-human performance in gran turismo sport using deep reinforcement learning",
      "authors": "F Fuchs, Y Song, E Kaufmann\u2026",
      "year": "2021",
      "cited_by": 89,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11140667219432227939&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Free lunch for testing: Fuzzing deep-learning libraries from open source",
      "id": "15889454219146822872",
      "url": "https://dl.acm.org/doi/abs/10.1145/3510003.3510041",
      "title": "Free lunch for testing: Fuzzing deep-learning libraries from open source",
      "authors": "A Wei, Y Deng, C Yang, L Zhang",
      "year": "2022",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15889454219146822872&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Partially observable markov decision processes in robotics: A survey",
      "id": "17919992204175632420",
      "url": "https://ieeexplore.ieee.org/abstract/document/9899480/",
      "title": "Partially observable markov decision processes in robotics: A survey",
      "authors": "M Lauri, D Hsu, J Pajarinen",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17919992204175632420&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Artificial intelligence governance for businesses",
      "id": "9829630380879135158",
      "url": "https://www.tandfonline.com/doi/abs/10.1080/10580530.2022.2085825",
      "title": "Artificial intelligence governance for businesses",
      "authors": "J Schneider, R Abraham, C Meske\u2026",
      "year": "2023",
      "cited_by": 23,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9829630380879135158&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Learning-based methods of perception and navigation for ground vehicles in unstructured environments: A review",
      "id": "4490548502357617762",
      "url": "https://www.mdpi.com/1424-8220/21/1/73",
      "title": "Learning-based methods of perception and navigation for ground vehicles in unstructured environments: A review",
      "authors": "DC Guastella, G Muscato",
      "year": "2020",
      "cited_by": 57,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4490548502357617762&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Explainable artificial intelligence for autonomous driving: A comprehensive overview and field guide for future research directions",
      "id": "16208419679375763607",
      "url": "https://arxiv.org/abs/2112.11561",
      "title": "Explainable artificial intelligence for autonomous driving: A comprehensive overview and field guide for future research directions",
      "authors": "S Atakishiyev, M Salameh, H Yao, R Goebel",
      "year": "2021",
      "cited_by": 49,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16208419679375763607&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A review of high-throughput field phenotyping systems: Focusing on ground robots",
      "id": "2749681245987987360",
      "url": "https://spj.science.org/doi/full/10.34133/2022/9760269",
      "title": "A review of high-throughput field phenotyping systems: Focusing on ground robots",
      "authors": "R Xu, C Li",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2749681245987987360&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Prospects for multi-agent collaboration and gaming: challenge, technology, and application",
      "id": "15770340026262104764",
      "url": "https://link.springer.com/article/10.1631/FITEE.2200055",
      "title": "Prospects for multi-agent collaboration and gaming: challenge, technology, and application",
      "authors": "Y Liu, Z Li, Z Jiang, Y He",
      "year": "2022",
      "cited_by": 32,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15770340026262104764&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Deep learning on monocular object pose detection and tracking: A comprehensive overview",
      "id": "13308776082845550262",
      "url": "https://dl.acm.org/doi/abs/10.1145/3524496",
      "title": "Deep learning on monocular object pose detection and tracking: A comprehensive overview",
      "authors": "Z Fan, Y Zhu, Y He, Q Sun, H Liu, J He",
      "year": "2022",
      "cited_by": 41,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13308776082845550262&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Decentralized federated learning for extended sensing in 6G connected vehicles",
      "id": "17895695761643428844",
      "url": "https://www.sciencedirect.com/science/article/pii/S2214209621000656",
      "title": "Decentralized federated learning for extended sensing in 6G connected vehicles",
      "authors": "L Barbieri, S Savazzi, M Brambilla, M Nicoli",
      "year": "2022",
      "cited_by": 41,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17895695761643428844&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Perspectives on future power system control centers for energy transition",
      "id": "10389594312915615958",
      "url": "https://ieeexplore.ieee.org/abstract/document/9744623/",
      "title": "Perspectives on future power system control centers for energy transition",
      "authors": "A Marot, A Kelly, M Naglic, V Barbesant\u2026",
      "year": "2022",
      "cited_by": 30,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10389594312915615958&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "The many faces of adversarial risk",
      "id": "18005903390163138360",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2021/hash/52c4608c2f126708211b9e0a60eaf050-Abstract.html",
      "title": "The many faces of adversarial risk",
      "authors": "MS Pydi, V Jog",
      "year": "2021",
      "cited_by": 20,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18005903390163138360&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A survey of image labelling for computer vision applications",
      "id": "15641048523483845755",
      "url": "https://www.tandfonline.com/doi/abs/10.1080/2573234X.2021.1908861",
      "title": "A survey of image labelling for computer vision applications",
      "authors": "C Sager, C Janiesch, P Zschech",
      "year": "2021",
      "cited_by": 46,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15641048523483845755&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Challenges of machine learning applied to safety-critical cyber-physical systems",
      "id": "3296916295930333686",
      "url": "https://www.mdpi.com/2504-4990/2/4/31",
      "title": "Challenges of machine learning applied to safety-critical cyber-physical systems",
      "authors": "A Pereira, C Thomas",
      "year": "2020",
      "cited_by": 48,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3296916295930333686&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Deep reinforcement learning techniques for vehicular networks: Recent advances and future trends towards 6G",
      "id": "6053988149774622220",
      "url": "https://www.sciencedirect.com/science/article/pii/S221420962100067X",
      "title": "Deep reinforcement learning techniques for vehicular networks: Recent advances and future trends towards 6G",
      "authors": "A Mekrache, A Bradai, E Moulay, S Dawaliby",
      "year": "2022",
      "cited_by": 37,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6053988149774622220&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Towards improving calibration in object detection under domain shift",
      "id": "11971206372978719797",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/fcd812a51b8f8d05cfea22e3c9c4b369-Abstract-Conference.html",
      "title": "Towards improving calibration in object detection under domain shift",
      "authors": "MA Munir, MH Khan, M Sarfraz\u2026",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11971206372978719797&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A stitch in time saves nine: A train-time regularizing loss for improved neural network calibration",
      "id": "7650029386959535850",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Hebbalaguppe_A_Stitch_in_Time_Saves_Nine_A_Train-Time_Regularizing_Loss_CVPR_2022_paper.html",
      "title": "A stitch in time saves nine: A train-time regularizing loss for improved neural network calibration",
      "authors": "R Hebbalaguppe, J Prakash\u2026",
      "year": "2022",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7650029386959535850&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A survey on hybrid human-artificial intelligence for autonomous driving",
      "id": "18195869548361214224",
      "url": "https://ieeexplore.ieee.org/abstract/document/9423526/",
      "title": "A survey on hybrid human-artificial intelligence for autonomous driving",
      "authors": "H Ning, R Yin, A Ullah, F Shi",
      "year": "2021",
      "cited_by": 32,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18195869548361214224&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Combining reinforcement learning with rule-based controllers for transparent and general decision-making in autonomous driving",
      "id": "17109511764161480588",
      "url": "https://www.sciencedirect.com/science/article/pii/S0921889020304085",
      "title": "Combining reinforcement learning with rule-based controllers for transparent and general decision-making in autonomous driving",
      "authors": "A Likmeta, AM Metelli, A Tirinzoni, R Giol\u2026",
      "year": "2020",
      "cited_by": 51,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17109511764161480588&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "The effect of transparency and trust on intelligent system acceptance: Evidence from a user-based study",
      "id": "4773394058091047733",
      "url": "https://link.springer.com/article/10.1007/s12525-022-00593-5",
      "title": "The effect of transparency and trust on intelligent system acceptance: Evidence from a user-based study",
      "authors": "J Wanner, LV Herm, K Heinrich, C Janiesch",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4773394058091047733&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Offline reinforcement learning as anti-exploration",
      "id": "7472077363474028067",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/20783",
      "title": "Offline reinforcement learning as anti-exploration",
      "authors": "S Rezaeifar, R Dadashi, N Vieillard\u2026",
      "year": "2022",
      "cited_by": 27,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7472077363474028067&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "A comprehensive survey on the application of deep and reinforcement learning approaches in autonomous driving",
      "id": "13254274571229991785",
      "url": "https://www.sciencedirect.com/science/article/pii/S1319157822000970",
      "title": "A comprehensive survey on the application of deep and reinforcement learning approaches in autonomous driving",
      "authors": "BB Elallid, N Benamar, AS Hafid, T Rachidi\u2026",
      "year": "2022",
      "cited_by": 35,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13254274571229991785&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Brain-inspired cognitive model with attention for self-driving cars",
      "id": "9602194952104030116",
      "url": "https://ieeexplore.ieee.org/abstract/document/7954050/",
      "title": "Brain-inspired cognitive model with attention for self-driving cars",
      "authors": "S Chen, S Zhang, J Shang, B Chen\u2026",
      "year": "2017",
      "cited_by": 131,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9602194952104030116&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Lychee surface defect detection based on deep convolutional neural networks with gan-based data augmentation",
      "id": "412550918084992142",
      "url": "https://www.mdpi.com/2073-4395/11/8/1500",
      "title": "Lychee surface defect detection based on deep convolutional neural networks with gan-based data augmentation",
      "authors": "C Wang, Z Xiao",
      "year": "2021",
      "cited_by": 32,
      "cited_by_url": "https://scholar.google.com/scholar?cites=412550918084992142&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Autonomous vehicles and intelligent automation: Applications, challenges, and opportunities",
      "id": "5579084922455744576",
      "url": "https://www.hindawi.com/journals/misy/2022/7632892/",
      "title": "Autonomous vehicles and intelligent automation: Applications, challenges, and opportunities",
      "authors": "G Bathla, K Bhadane, RK Singh, R Kumar\u2026",
      "year": "2022",
      "cited_by": 31,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5579084922455744576&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Training uncertainty-aware classifiers with conformalized deep learning",
      "id": "9463717142610823747",
      "url": "https://proceedings.neurips.cc/paper_files/paper/2022/hash/8c96b559340daa7bb29f56ccfbbc9c2f-Abstract-Conference.html",
      "title": "Training uncertainty-aware classifiers with conformalized deep learning",
      "authors": "BS Einbinder, Y Romano, M Sesia\u2026",
      "year": "2022",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9463717142610823747&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Coverage-guided tensor compiler fuzzing with joint ir-pass mutation",
      "id": "521481329840897304",
      "url": "https://dl.acm.org/doi/abs/10.1145/3527317",
      "title": "Coverage-guided tensor compiler fuzzing with joint ir-pass mutation",
      "authors": "J Liu, Y Wei, S Yang, Y Deng, L Zhang",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=521481329840897304&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "TLT: Recurrent fine-tuning transfer learning for water quality long-term prediction",
      "id": "12532017250168790887",
      "url": "https://www.sciencedirect.com/science/article/pii/S0043135422011162",
      "title": "TLT: Recurrent fine-tuning transfer learning for water quality long-term prediction",
      "authors": "L Peng, H Wu, M Gao, H Yi, Q Xiong, L Yang, S Cheng",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12532017250168790887&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Metamaterials: from fundamental physics to intelligent design",
      "id": "13081138058927339532",
      "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/idm2.12049",
      "title": "Metamaterials: from fundamental physics to intelligent design",
      "authors": "J Chen, S Hu, S Zhu, T Li",
      "year": "2023",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13081138058927339532&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Uncovering and correcting shortcut learning in machine learning models for skin cancer diagnosis",
      "id": "18151073209899826471",
      "url": "https://www.mdpi.com/2075-4418/12/1/40",
      "title": "Uncovering and correcting shortcut learning in machine learning models for skin cancer diagnosis",
      "authors": "M Nauta, R Walsh, A Dubowski, C Seifert",
      "year": "2021",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18151073209899826471&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Explaining deep neural networks: A survey on the global interpretation methods",
      "id": "621059241978449016",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925231222012218",
      "title": "Explaining deep neural networks: A survey on the global interpretation methods",
      "authors": "R Saleem, B Yuan, F Kurugollu, A Anjum, L Liu",
      "year": "2022",
      "cited_by": 25,
      "cited_by_url": "https://scholar.google.com/scholar?cites=621059241978449016&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "AI applications in renal pathology",
      "id": "1897738753201623147",
      "url": "https://www.sciencedirect.com/science/article/pii/S0085253821001812",
      "title": "AI applications in renal pathology",
      "authors": "Y Huo, R Deng, Q Liu, AB Fogo, H Yang",
      "year": "2021",
      "cited_by": 54,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1897738753201623147&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Survey on cooperative perception in an automotive context",
      "id": "7436181184954982806",
      "url": "https://ieeexplore.ieee.org/abstract/document/9732063/",
      "title": "Survey on cooperative perception in an automotive context",
      "authors": "A Caillot, S Ouerghi, P Vasseur\u2026",
      "year": "2022",
      "cited_by": 22,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7436181184954982806&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Moving deep learning to the edge",
      "id": "13539442582208875227",
      "url": "https://www.mdpi.com/1999-4893/13/5/125",
      "title": "Moving deep learning to the edge",
      "authors": "MP V\u00e9stias, RP Duarte, JT de Sousa, HC Neto",
      "year": "2020",
      "cited_by": 52,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13539442582208875227&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Scale-up: An efficient black-box input-level backdoor detection via analyzing scaled prediction consistency",
      "id": "11794736720683628583",
      "url": "https://arxiv.org/abs/2302.03251",
      "title": "Scale-up: An efficient black-box input-level backdoor detection via analyzing scaled prediction consistency",
      "authors": "J Guo, Y Li, X Chen, H Guo, L Sun, C Liu",
      "year": "2023",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11794736720683628583&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Robust learning for data poisoning attacks",
      "id": "15738759785276050535",
      "url": "https://proceedings.mlr.press/v139/wang21r.html",
      "title": "Robust learning for data poisoning attacks",
      "authors": "Y Wang, P Mianjy, R Arora",
      "year": "2021",
      "cited_by": 21,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15738759785276050535&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Imagenet-x: Understanding model mistakes with factor of variation annotations",
      "id": "7649876297714062863",
      "url": "https://arxiv.org/abs/2211.01866",
      "title": "Imagenet-x: Understanding model mistakes with factor of variation annotations",
      "authors": "BY Idrissi, D Bouchacourt, R Balestriero\u2026",
      "year": "2022",
      "cited_by": 17,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7649876297714062863&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Learning collision-free space detection from stereo images: Homography matrix brings better data augmentation",
      "id": "14732420770874304307",
      "url": "https://ieeexplore.ieee.org/abstract/document/9360504/",
      "title": "Learning collision-free space detection from stereo images: Homography matrix brings better data augmentation",
      "authors": "R Fan, H Wang, P Cai, J Wu, MJ Bocus\u2026",
      "year": "2021",
      "cited_by": 38,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14732420770874304307&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 14
    },
    {
      "label": "Mammogram breast cancer CAD systems for mass detection and classification: a review",
      "id": "15295068953900215294",
      "url": "https://link.springer.com/article/10.1007/s11042-022-12332-1",
      "title": "Mammogram breast cancer CAD systems for mass detection and classification: a review",
      "authors": "NM Hassan, S Hamad, K Mahar",
      "year": "2022",
      "cited_by": 35,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15295068953900215294&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Precise single-stage detector",
      "id": "15549291371117213871",
      "url": "https://arxiv.org/abs/2210.04252",
      "title": "Precise single-stage detector",
      "authors": "A Chandio, G Gui, T Kumar, I Ullah\u2026",
      "year": "2022",
      "cited_by": 41,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15549291371117213871&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "CE-FPN: Enhancing channel information for object detection",
      "id": "9884544045603971658",
      "url": "https://link.springer.com/article/10.1007/s11042-022-11940-1",
      "title": "CE-FPN: Enhancing channel information for object detection",
      "authors": "Y Luo, X Cao, J Zhang, J Guo, H Shen, T Wang\u2026",
      "year": "2022",
      "cited_by": 71,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9884544045603971658&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Feature split\u2013merge\u2013enhancement network for remote sensing object detection",
      "id": "10628215061802232868",
      "url": "https://ieeexplore.ieee.org/abstract/document/9673713/",
      "title": "Feature split\u2013merge\u2013enhancement network for remote sensing object detection",
      "authors": "W Ma, N Li, H Zhu, L Jiao, X Tang\u2026",
      "year": "2022",
      "cited_by": 45,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10628215061802232868&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Guiding pretraining in reinforcement learning with large language models",
      "id": "9532821550175512200",
      "url": "https://arxiv.org/abs/2302.06692",
      "title": "Guiding pretraining in reinforcement learning with large language models",
      "authors": "Y Du, O Watkins, Z Wang, C Colas, T Darrell\u2026",
      "year": "2023",
      "cited_by": 19,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9532821550175512200&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Integrating deep learning-based iot and fog computing with software-defined networking for detecting weapons in video surveillance systems",
      "id": "12985976504909847163",
      "url": "https://www.mdpi.com/1424-8220/22/14/5075",
      "title": "Integrating deep learning-based iot and fog computing with software-defined networking for detecting weapons in video surveillance systems",
      "authors": "C Fathy, SN Saleh",
      "year": "2022",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12985976504909847163&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Backbones-review: Feature extraction networks for deep learning and deep reinforcement learning approaches",
      "id": "2812153438552156646",
      "url": "https://arxiv.org/abs/2206.08016",
      "title": "Backbones-review: Feature extraction networks for deep learning and deep reinforcement learning approaches",
      "authors": "O Elharrouss, Y Akbari, N Almaadeed\u2026",
      "year": "2022",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2812153438552156646&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Small-object detection based on YOLOv5 in autonomous driving systems",
      "id": "14349697475909471320",
      "url": "https://www.sciencedirect.com/science/article/pii/S0167865523000727",
      "title": "Small-object detection based on YOLOv5 in autonomous driving systems",
      "authors": "B Mahaur, KK Mishra",
      "year": "2023",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14349697475909471320&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Single-stage uav detection and classification with yolov5: Mosaic data augmentation and panet",
      "id": "18351357225093508985",
      "url": "https://ieeexplore.ieee.org/abstract/document/9663841/",
      "title": "Single-stage uav detection and classification with yolov5: Mosaic data augmentation and panet",
      "authors": "F Dadboud, V Patel, V Mehta, M Bolic\u2026",
      "year": "2021",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18351357225093508985&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "FPGA-based accelerator for object detection: A comprehensive survey",
      "id": "11021564807628327569",
      "url": "https://link.springer.com/article/10.1007/s11227-022-04415-5",
      "title": "FPGA-based accelerator for object detection: A comprehensive survey",
      "authors": "K Zeng, Q Ma, JW Wu, Z Chen, T Shen\u2026",
      "year": "2022",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11021564807628327569&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Rail wheel tread defect detection using improved YOLOv3",
      "id": "4655434626952320958",
      "url": "https://www.sciencedirect.com/science/article/pii/S0263224122011551",
      "title": "Rail wheel tread defect detection using improved YOLOv3",
      "authors": "Z Xing, Z Zhang, X Yao, Y Qin, L Jia",
      "year": "2022",
      "cited_by": 12,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4655434626952320958&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Development of a Low-Power IoMT Portable Pillbox for Medication Adherence Improvement and Remote Treatment Adjustment",
      "id": "16079747206913991174",
      "url": "https://www.mdpi.com/1424-8220/22/15/5818",
      "title": "Development of a Low-Power IoMT Portable Pillbox for Medication Adherence Improvement and Remote Treatment Adjustment",
      "authors": "D Karagiannis, K Mitsis, KS Nikita",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16079747206913991174&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A comprehensive review of object detection with deep learning",
      "id": "16432688928939217038",
      "url": "https://www.sciencedirect.com/science/article/pii/S1051200422004298",
      "title": "A comprehensive review of object detection with deep learning",
      "authors": "R Kaur, S Singh",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16432688928939217038&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A survey on deep learning tools dealing with data scarcity: definitions, challenges, solutions, tips, and applications",
      "id": "6456248456066525600",
      "url": "https://link.springer.com/article/10.1186/s40537-023-00727-2",
      "title": "A survey on deep learning tools dealing with data scarcity: definitions, challenges, solutions, tips, and applications",
      "authors": "L Alzubaidi, J Bai, A Al-Sabaawi, J Santamar\u00eda\u2026",
      "year": "2023",
      "cited_by": 28,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6456248456066525600&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Video surveillance using deep transfer learning and deep domain adaptation: Towards better generalization",
      "id": "8123745338600640152",
      "url": "https://www.sciencedirect.com/science/article/pii/S0952197622006881",
      "title": "Video surveillance using deep transfer learning and deep domain adaptation: Towards better generalization",
      "authors": "Y Himeur, S Al-Maadeed, H Kheddar\u2026",
      "year": "2023",
      "cited_by": 18,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8123745338600640152&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Review of recent automated pothole-detection methods",
      "id": "10334732198267289555",
      "url": "https://www.mdpi.com/2076-3417/12/11/5320",
      "title": "Review of recent automated pothole-detection methods",
      "authors": "YM Kim, YG Kim, SY Son, SY Lim, BY Choi, DH Choi",
      "year": "2022",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10334732198267289555&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Towards domain generalization in object detection",
      "id": "5740479134802475221",
      "url": "https://arxiv.org/abs/2203.14387",
      "title": "Towards domain generalization in object detection",
      "authors": "X Zhang, Z Xu, R Xu, J Liu, P Cui, W Wan\u2026",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5740479134802475221&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Allergen30: detecting food items with possible allergens using deep learning-based computer vision",
      "id": "6447041552955227244",
      "url": "https://link.springer.com/article/10.1007/s12161-022-02353-9",
      "title": "Allergen30: detecting food items with possible allergens using deep learning-based computer vision",
      "authors": "M Mishra, T Sarkar, T Choudhury, N Bansal\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6447041552955227244&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A systematic study on reinforcement learning based applications",
      "id": "11016115370073884103",
      "url": "https://www.mdpi.com/1996-1073/16/3/1512",
      "title": "A systematic study on reinforcement learning based applications",
      "authors": "K Sivamayil, E Rajasekar, B Aljafari, S Nikolovski\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11016115370073884103&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Weakly supervised object detection for remote sensing images: A survey",
      "id": "5588318297466755355",
      "url": "https://www.mdpi.com/2072-4292/14/21/5362",
      "title": "Weakly supervised object detection for remote sensing images: A survey",
      "authors": "C Fasana, S Pasini, F Milani, P Fraternali",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5588318297466755355&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Dynamic identification of crane load fall zone: A computer vision approach",
      "id": "7060227414328690906",
      "url": "https://www.sciencedirect.com/science/article/pii/S0925753522002430",
      "title": "Dynamic identification of crane load fall zone: A computer vision approach",
      "authors": "EYT Chian, YM Goh, J Tian, BHW Guo",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7060227414328690906&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Cf-detr: Coarse-to-fine transformers for end-to-end object detection",
      "id": "13890326168676881936",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/19893",
      "title": "Cf-detr: Coarse-to-fine transformers for end-to-end object detection",
      "authors": "X Cao, P Yuan, B Feng, K Niu",
      "year": "2022",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13890326168676881936&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "D-MFPN: A Doppler Feature Matrix Fused with a Multilayer Feature Pyramid Network for SAR Ship Detection",
      "id": "585375656869561806",
      "url": "https://www.mdpi.com/2072-4292/15/3/626",
      "title": "D-MFPN: A Doppler Feature Matrix Fused with a Multilayer Feature Pyramid Network for SAR Ship Detection",
      "authors": "Y Zhou, K Fu, B Han, J Yang, Z Pan, Y Hu, D Yin",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=585375656869561806&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Performance evaluation of deep learning object detectors for weed detection for cotton",
      "id": "10256791187069118291",
      "url": "https://www.sciencedirect.com/science/article/pii/S2772375522000910",
      "title": "Performance evaluation of deep learning object detectors for weed detection for cotton",
      "authors": "A Rahman, Y Lu, H Wang",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10256791187069118291&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "RF-Next: Efficient receptive field search for convolutional neural networks",
      "id": "6955302216815830645",
      "url": "https://ieeexplore.ieee.org/abstract/document/9799540/",
      "title": "RF-Next: Efficient receptive field search for convolutional neural networks",
      "authors": "S Gao, ZY Li, Q Han, MM Cheng\u2026",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6955302216815830645&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Towards optimal foreign object debris detection in an airport environment",
      "id": "9835514645329759223",
      "url": "https://www.sciencedirect.com/science/article/pii/S0957417422018474",
      "title": "Towards optimal foreign object debris detection in an airport environment",
      "authors": "M Noroozi, A Shah",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9835514645329759223&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Machine learning for renal pathologies: an updated survey",
      "id": "12985566362823859744",
      "url": "https://www.mdpi.com/1424-8220/22/13/4989",
      "title": "Machine learning for renal pathologies: an updated survey",
      "authors": "R Magherini, E Mussi, Y Volpe, R Furferi, F Buonamici\u2026",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12985566362823859744&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Using artificial intelligence to support marine macrolitter research: A content analysis and an online database",
      "id": "7984800842432280263",
      "url": "https://www.sciencedirect.com/science/article/pii/S0964569122004422",
      "title": "Using artificial intelligence to support marine macrolitter research: A content analysis and an online database",
      "authors": "DV Politikos, A Adamopoulou, G Petasis\u2026",
      "year": "2023",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7984800842432280263&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Anatomy of Deep Learning Image Classification and Object Detection on Commercial Edge Devices: A Case Study on Face Mask Detection",
      "id": "17521920740408245266",
      "url": "https://ieeexplore.ieee.org/abstract/document/9918067/",
      "title": "Anatomy of Deep Learning Image Classification and Object Detection on Commercial Edge Devices: A Case Study on Face Mask Detection",
      "authors": "D Kolosov, V Kelefouras, P Kourtessis, I Mporas",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17521920740408245266&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Real-Time Embedded Implementation of Improved Object Detector for Resource-Constrained Devices",
      "id": "16420701532688217268",
      "url": "https://www.mdpi.com/2079-9268/12/2/21",
      "title": "Real-Time Embedded Implementation of Improved Object Detector for Resource-Constrained Devices",
      "authors": "N Ravi, M El-Sharkawy",
      "year": "2022",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16420701532688217268&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Multimodal data augmentation for visual-infrared person ReID with corrupted data",
      "id": "8989581343974102697",
      "url": "https://openaccess.thecvf.com/content/WACV2023W/RWS/html/Josi_Multimodal_Data_Augmentation_for_Visual-Infrared_Person_ReID_With_Corrupted_Data_WACVW_2023_paper.html",
      "title": "Multimodal data augmentation for visual-infrared person ReID with corrupted data",
      "authors": "A Josi, M Alehdaghi, RMO Cruz\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8989581343974102697&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Lightweight multi-scale network for small object detection",
      "id": "2488190159038118357",
      "url": "https://peerj.com/articles/cs-1145/",
      "title": "Lightweight multi-scale network for small object detection",
      "authors": "L Li, B Li, H Zhou",
      "year": "2022",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2488190159038118357&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Towards lightweight neural networks for garbage object detection",
      "id": "818429456345308176",
      "url": "https://www.mdpi.com/1424-8220/22/19/7455",
      "title": "Towards lightweight neural networks for garbage object detection",
      "authors": "X Cai, F Shuang, X Sun, Y Duan, G Cheng",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=818429456345308176&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions",
      "id": "18347537605283752941",
      "url": "https://arxiv.org/abs/2307.00014",
      "title": "Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions",
      "authors": "N Cohen, I Klein",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18347537605283752941&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Influence of AVC and HEVC compression on detection of vehicles through Faster R-CNN",
      "id": "7447750230007511033",
      "url": "https://ieeexplore.ieee.org/abstract/document/10247026/",
      "title": "Influence of AVC and HEVC compression on detection of vehicles through Faster R-CNN",
      "authors": "PH Chan, A Huggett, G Souvalioti\u2026",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7447750230007511033&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Recent advances in video analytics for rail network surveillance for security, trespass and suicide prevention\u2014A survey",
      "id": "17445702357043232709",
      "url": "https://www.mdpi.com/1424-8220/22/12/4324",
      "title": "Recent advances in video analytics for rail network surveillance for security, trespass and suicide prevention\u2014A survey",
      "authors": "T Zhang, W Aftab, L Mihaylova, C Langran-Wheeler\u2026",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17445702357043232709&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A comparative review of recent few-shot object detection algorithms",
      "id": "10376554157268421149",
      "url": "https://arxiv.org/abs/2111.00201",
      "title": "A comparative review of recent few-shot object detection algorithms",
      "authors": "L Jiaxu, C Taiyue, G Xinbo, Y Yongtao, W Ye\u2026",
      "year": "2021",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10376554157268421149&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Protein Subcellular Localization Prediction by Concatenation of Convolutional Blocks for Deep Features Extraction from Microscopic Images",
      "id": "9972278693063933261",
      "url": "https://ieeexplore.ieee.org/abstract/document/9999691/",
      "title": "Protein Subcellular Localization Prediction by Concatenation of Convolutional Blocks for Deep Features Extraction from Microscopic Images",
      "authors": "S Aggarwal, S Juneja, J Rashid, D Gupta\u2026",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9972278693063933261&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Intelligent weed management based on object detection neural networks in tomato crops",
      "id": "5102122811255396025",
      "url": "https://www.mdpi.com/2073-4395/12/12/2953",
      "title": "Intelligent weed management based on object detection neural networks in tomato crops",
      "authors": "JM L\u00f3pez-Correa, H Moreno, A Ribeiro, D And\u00fajar",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5102122811255396025&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Detection and classification of COVID-19 by using faster R-CNN and mask R-CNN on CT images",
      "id": "2840095996932934652",
      "url": "https://link.springer.com/article/10.1007/s00521-023-08450-y",
      "title": "Detection and classification of COVID-19 by using faster R-CNN and mask R-CNN on CT images",
      "authors": "ME Sahin, H Ulutas, E Yuce, MF Erkoc",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2840095996932934652&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A DCNN-based arbitrarily-oriented object detector with application to quality control and inspection",
      "id": "1768748882307170392",
      "url": "https://www.sciencedirect.com/science/article/pii/S0166361522001348",
      "title": "A DCNN-based arbitrarily-oriented object detector with application to quality control and inspection",
      "authors": "K Yao, A Ortiz, F Bonnin-Pascual",
      "year": "2022",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1768748882307170392&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Hybrid features by combining visual and text information to improve spam filtering performance",
      "id": "17587187390595037360",
      "url": "https://www.mdpi.com/2079-9292/11/13/2053",
      "title": "Hybrid features by combining visual and text information to improve spam filtering performance",
      "authors": "SG Nam, Y Jang, DG Lee, YS Seo",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17587187390595037360&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "X-ray weld defect detection based on AF-RCNN",
      "id": "188799720050288373",
      "url": "https://link.springer.com/article/10.1007/s40194-022-01281-w",
      "title": "X-ray weld defect detection based on AF-RCNN",
      "authors": "W Liu, S Shan, H Chen, R Wang, J Sun, Z Zhou",
      "year": "2022",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=188799720050288373&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "The study of coal gangue segmentation for location and shape predicts based on multispectral and improved Mask R-CNN",
      "id": "12641103106759054130",
      "url": "https://www.sciencedirect.com/science/article/pii/S0032591022005496",
      "title": "The study of coal gangue segmentation for location and shape predicts based on multispectral and improved Mask R-CNN",
      "authors": "W Lai, F Hu, X Kong, P Yan, K Bian, X Dai",
      "year": "2022",
      "cited_by": 7,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12641103106759054130&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Crop Node Detection and Internode Length Estimation Using an Improved YOLOv5 Model",
      "id": "10335635097204372178",
      "url": "https://www.mdpi.com/2077-0472/13/2/473",
      "title": "Crop Node Detection and Internode Length Estimation Using an Improved YOLOv5 Model",
      "authors": "J Hu, G Li, H Mo, Y Lv, T Qian, M Chen, S Lu",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10335635097204372178&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Reconciling Object-Level and Global-Level Objectives for Long-Tail Detection",
      "id": "TwB7dLsYY-MJ",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Reconciling_Object-Level_and_Global-Level_Objectives_for_Long-Tail_Detection_ICCV_2023_paper.html",
      "title": "Reconciling Object-Level and Global-Level Objectives for Long-Tail Detection",
      "authors": "S Zhang, C Chen, S Peng",
      "year": "2023",
      "modularity": 13
    },
    {
      "label": "G-YOLOX: A Lightweight Network for Detecting Vehicle Types",
      "id": "8653517720287563782",
      "url": "https://www.hindawi.com/journals/js/2022/4488400/",
      "title": "G-YOLOX: A Lightweight Network for Detecting Vehicle Types",
      "authors": "Q Luo, J Wang, M Gao, H Lin, H Zhou, Q Miao",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8653517720287563782&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Bush Detection for Vision-Based UGV Guidance in Blueberry Orchards: Data Set and Methods",
      "id": "5136921629305657035",
      "url": "https://openaccess.thecvf.com/content/CVPR2023W/Precognition/html/Filipovic_Bush_Detection_for_Vision-Based_UGV_Guidance_in_Blueberry_Orchards_Data_CVPRW_2023_paper.html",
      "title": "Bush Detection for Vision-Based UGV Guidance in Blueberry Orchards: Data Set and Methods",
      "authors": "V Filipovi\u0107, D Stefanovi\u0107, N Pajevi\u0107\u2026",
      "year": "2023",
      "modularity": 13
    },
    {
      "label": "KBHN: A knowledge-aware bi-hypergraph network based on visual-knowledge features fusion for teaching image annotation",
      "id": "11099153551339147297",
      "url": "https://www.sciencedirect.com/science/article/pii/S0306457322002072",
      "title": "KBHN: A knowledge-aware bi-hypergraph network based on visual-knowledge features fusion for teaching image annotation",
      "authors": "H Li, J Wang, X Du, Z Hu, S Yang",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11099153551339147297&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Simplification of Deep Neural Network-Based Object Detector for Real-Time Edge Computing",
      "id": "5228079008431707389",
      "url": "https://www.mdpi.com/1424-8220/23/7/3777",
      "title": "Simplification of Deep Neural Network-Based Object Detector for Real-Time Edge Computing",
      "authors": "K Choi, SM Wi, HG Jung, JK Suhr",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5228079008431707389&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Large Selective Kernel Network for Remote Sensing Object Detection",
      "id": "13762120871365653169",
      "url": "https://arxiv.org/abs/2303.09030",
      "title": "Large Selective Kernel Network for Remote Sensing Object Detection",
      "authors": "Y Li, Q Hou, Z Zheng, MM Cheng, J Yang\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13762120871365653169&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Multi-modal 3D Object Detection in Autonomous Driving: A Survey and Taxonomy",
      "id": "11403420526814911334",
      "url": "https://ieeexplore.ieee.org/abstract/document/10093116/",
      "title": "Multi-modal 3D Object Detection in Autonomous Driving: A Survey and Taxonomy",
      "authors": "L Wang, X Zhang, Z Song, J Bi, G Zhang\u2026",
      "year": "2023",
      "cited_by": 11,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11403420526814911334&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "One-shot doc snippet detection: Powering search in document beyond text",
      "id": "3928869340439710212",
      "url": "https://openaccess.thecvf.com/content/WACV2023/html/Java_One-Shot_Doc_Snippet_Detection_Powering_Search_in_Document_Beyond_Text_WACV_2023_paper.html",
      "title": "One-shot doc snippet detection: Powering search in document beyond text",
      "authors": "A Java, S Deshmukh, M Aggarwal\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3928869340439710212&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Individual Tree Detection in Coal Mine Afforestation Area Based on Improved Faster RCNN in UAV RGB Images",
      "id": "6432339791137664150",
      "url": "https://www.mdpi.com/2072-4292/14/21/5545",
      "title": "Individual Tree Detection in Coal Mine Afforestation Area Based on Improved Faster RCNN in UAV RGB Images",
      "authors": "M Luo, Y Tian, S Zhang, L Huang, H Wang, Z Liu\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6432339791137664150&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A survey on deep learning-based monocular spacecraft pose estimation: Current state, limitations and prospects",
      "id": "17407217274075551544",
      "url": "https://www.sciencedirect.com/science/article/pii/S0094576523003995",
      "title": "A survey on deep learning-based monocular spacecraft pose estimation: Current state, limitations and prospects",
      "authors": "L Pauly, W Rharbaoui, C Shneider, A Rathinam\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17407217274075551544&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Segmentation of dental restorations on panoramic radiographs using deep learning",
      "id": "5708297216613512002",
      "url": "https://www.mdpi.com/2075-4418/12/6/1316",
      "title": "Segmentation of dental restorations on panoramic radiographs using deep learning",
      "authors": "C Rohrer, J Krois, J Patel, H Meyer-Lueckel\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5708297216613512002&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Fracture R\u2010CNN: An anchor\u2010efficient anti\u2010interference framework for skull fracture detection in CT images",
      "id": "1676138104604729822",
      "url": "https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.15809",
      "title": "Fracture R\u2010CNN: An anchor\u2010efficient anti\u2010interference framework for skull fracture detection in CT images",
      "authors": "X Lin, Z Yan, Z Kuang, H Zhang, X Deng\u2026",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1676138104604729822&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Research on Fault Diagnosis of Steel Surface Based on Improved YOLOV5",
      "id": "10296222572490103697",
      "url": "https://www.mdpi.com/2227-9717/10/11/2274",
      "title": "Research on Fault Diagnosis of Steel Surface Based on Improved YOLOV5",
      "authors": "W Liu, Y Xiao, A Zheng, Z Zheng, X Liu, Z Zhang, C Li",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10296222572490103697&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Benchmarking 2D multi-object detection and tracking algorithms in autonomous vehicle driving scenarios",
      "id": "12621755854148347362",
      "url": "https://www.mdpi.com/1424-8220/23/8/4024",
      "title": "Benchmarking 2D multi-object detection and tracking algorithms in autonomous vehicle driving scenarios",
      "authors": "D Gragnaniello, A Greco, A Saggese, M Vento\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12621755854148347362&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Detecting common coccinellids found in sorghum using deep learning models",
      "id": "11159799407205847879",
      "url": "https://www.nature.com/articles/s41598-023-36738-5",
      "title": "Detecting common coccinellids found in sorghum using deep learning models",
      "authors": "C Wang, I Grijalva, D Caragea, B McCornack",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11159799407205847879&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Interactive video retrieval in the age of effective joint embedding deep models: lessons from the 11th VBS",
      "id": "3650044505606796741",
      "url": "https://link.springer.com/article/10.1007/s00530-023-01143-5",
      "title": "Interactive video retrieval in the age of effective joint embedding deep models: lessons from the 11th VBS",
      "authors": "J Loko\u010d, S Andreadis, W Bailer, A Duane, C Gurrin\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3650044505606796741&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "YOLOv5-R: lightweight real-time detection based on improved YOLOv5",
      "id": "18214772028547313138",
      "url": "https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-31/issue-3/033033/YOLOv5-R--lightweight-real-time-detection-based-on-improved/10.1117/1.JEI.31.3.033033.short",
      "title": "YOLOv5-R: lightweight real-time detection based on improved YOLOv5",
      "authors": "J Ren, Z Wang, Y Zhang, L Liao",
      "year": "2022",
      "cited_by": 10,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18214772028547313138&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Deep learning based whale detection from satellite imagery",
      "id": "12157739162413628567",
      "url": "https://www.sciencedirect.com/science/article/pii/S2210537923000136",
      "title": "Deep learning based whale detection from satellite imagery",
      "authors": "S Kapoor, M Kumar, M Kaushal",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12157739162413628567&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Research on Intelligent Crack Detection in a Deep-Cut Canal Slope in the Chinese South\u2013North Water Transfer Project",
      "id": "8535109044975227347",
      "url": "https://www.mdpi.com/2072-4292/14/21/5384",
      "title": "Research on Intelligent Crack Detection in a Deep-Cut Canal Slope in the Chinese South\u2013North Water Transfer Project",
      "authors": "Q Hu, P Wang, S Li, W Liu, Y Li, W Lu, Y Kou, F Wei\u2026",
      "year": "2022",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8535109044975227347&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Wasserstein gan based chest x-ray dataset augmentation for deep learning models: Covid-19 detection use-case",
      "id": "11497367426208390181",
      "url": "https://ieeexplore.ieee.org/abstract/document/9871519/",
      "title": "Wasserstein gan based chest x-ray dataset augmentation for deep learning models: Covid-19 detection use-case",
      "authors": "BZ Hussain, I Andleeb, MS Ansari\u2026",
      "year": "2022",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11497367426208390181&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Swin Transformer Combined with Convolution Neural Network for Surface Defect Detection",
      "id": "4643207554767984878",
      "url": "https://www.mdpi.com/2075-1702/10/11/1083",
      "title": "Swin Transformer Combined with Convolution Neural Network for Surface Defect Detection",
      "authors": "Y Li, Y Xiang, H Guo, P Liu, C Liu",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4643207554767984878&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A cell phone app for facial acne severity assessment",
      "id": "18334436816345410388",
      "url": "https://link.springer.com/article/10.1007/s10489-022-03774-z",
      "title": "A cell phone app for facial acne severity assessment",
      "authors": "J Wang, Y Luo, Z Wang, AH Hounye, C Cao, M Hou\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18334436816345410388&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Comparison of Object Detection Algorithms for Street-level Objects",
      "id": "4144441762167508574",
      "url": "https://arxiv.org/abs/2208.11315",
      "title": "Comparison of Object Detection Algorithms for Street-level Objects",
      "authors": "MG Naftali, JS Sulistyawan, K Julian",
      "year": "2022",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4144441762167508574&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Educational Innovation Faced with COVID-19: Deep Learning for Online Exam Cheating Detection",
      "id": "13381915677677103405",
      "url": "https://www.mdpi.com/2227-7102/13/2/194",
      "title": "Educational Innovation Faced with COVID-19: Deep Learning for Online Exam Cheating Detection",
      "authors": "IN Yulita, FA Hariz, I Suryana, AS Prabuwono",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13381915677677103405&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Transformer based tooth classification from cone-beam computed tomography for dental charting",
      "id": "6827564526345704344",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482522006205",
      "title": "Transformer based tooth classification from cone-beam computed tomography for dental charting",
      "authors": "S Gao, X Li, X Li, Z Li, Y Deng",
      "year": "2022",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6827564526345704344&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Improved YOLOv3 Model for Workpiece Stud Leakage Detection",
      "id": "4896734917901521680",
      "url": "https://www.mdpi.com/2079-9292/11/21/3430",
      "title": "Improved YOLOv3 Model for Workpiece Stud Leakage Detection",
      "authors": "P Cong, K Lv, H Feng, J Zhou",
      "year": "2022",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4896734917901521680&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection",
      "id": "16683345231471569427",
      "url": "https://arxiv.org/abs/2303.09026",
      "title": "Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection",
      "authors": "P Zhang, B Liu",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16683345231471569427&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Research on tire crack detection using image deep learning method",
      "id": "18036771643867343218",
      "url": "https://www.nature.com/articles/s41598-023-35227-z",
      "title": "Research on tire crack detection using image deep learning method",
      "authors": "SL Lin",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18036771643867343218&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "An application of stereo matching algorithm based on transfer learning on robots in multiple scenes",
      "id": "7625820698997778911",
      "url": "https://www.nature.com/articles/s41598-023-39964-z",
      "title": "An application of stereo matching algorithm based on transfer learning on robots in multiple scenes",
      "authors": "Y Bi, C Li, X Tong, G Wang, H Sun",
      "year": "2023",
      "modularity": 13
    },
    {
      "label": "ESDDNet: efficient small defect detection network of workpiece surface",
      "id": "2858579394623725590",
      "url": "https://iopscience.iop.org/article/10.1088/1361-6501/ac793d/meta",
      "title": "ESDDNet: efficient small defect detection network of workpiece surface",
      "authors": "G Chen, F Xu, G Liu, CM Chen, M Liu\u2026",
      "year": "2022",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2858579394623725590&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "A Novel Driver Abnormal Behavior Recognition and Analysis Strategy and Its Application in a Practical Vehicle",
      "id": "366512561177278070",
      "url": "https://www.mdpi.com/2073-8994/14/10/1956",
      "title": "A Novel Driver Abnormal Behavior Recognition and Analysis Strategy and Its Application in a Practical Vehicle",
      "authors": "S Liu, X Wang, H Ji, L Wang, Z Hou",
      "year": "2022",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=366512561177278070&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 13
    },
    {
      "label": "Cornernet: Detecting objects as paired keypoints",
      "id": "5999650257677576183",
      "url": "http://openaccess.thecvf.com/content_ECCV_2018/html/Hei_Law_CornerNet_Detecting_Objects_ECCV_2018_paper.html",
      "title": "Cornernet: Detecting objects as paired keypoints",
      "authors": "H Law, J Deng",
      "year": "2018",
      "cited_by": 3665,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5999650257677576183&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Object detection in optical remote sensing images: A survey and a new benchmark",
      "id": "1026291601187748397",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271619302825",
      "title": "Object detection in optical remote sensing images: A survey and a new benchmark",
      "authors": "K Li, G Wan, G Cheng, L Meng, J Han",
      "year": "2020",
      "cited_by": 895,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1026291601187748397&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Vision transformers for dense prediction",
      "id": "16683125965624867998",
      "url": "http://openaccess.thecvf.com/content/ICCV2021/html/Ranftl_Vision_Transformers_for_Dense_Prediction_ICCV_2021_paper.html",
      "title": "Vision transformers for dense prediction",
      "authors": "R Ranftl, A Bochkovskiy\u2026",
      "year": "2021",
      "cited_by": 883,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16683125965624867998&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Center-based 3d object detection and tracking",
      "id": "14703570951981014637",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Yin_Center-Based_3D_Object_Detection_and_Tracking_CVPR_2021_paper.html",
      "title": "Center-based 3d object detection and tracking",
      "authors": "T Yin, X Zhou, P Krahenbuhl",
      "year": "2021",
      "cited_by": 945,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14703570951981014637&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Centernet: Keypoint triplets for object detection",
      "id": "3594606171683130501",
      "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Duan_CenterNet_Keypoint_Triplets_for_Object_Detection_ICCV_2019_paper.html",
      "title": "Centernet: Keypoint triplets for object detection",
      "authors": "K Duan, S Bai, L Xie, H Qi\u2026",
      "year": "2019",
      "cited_by": 2357,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3594606171683130501&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Objects as points",
      "id": "4497917248250067674",
      "url": "https://arxiv.org/abs/1904.07850",
      "title": "Objects as points",
      "authors": "X Zhou, D Wang, P Kr\u00e4henb\u00fchl",
      "year": "2019",
      "cited_by": 3259,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4497917248250067674&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Towards real-time multi-object tracking",
      "id": "7515568945301804297",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58621-8_7",
      "title": "Towards real-time multi-object tracking",
      "authors": "Z Wang, L Zheng, Y Liu, Y Li, S Wang",
      "year": "2020",
      "cited_by": 755,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7515568945301804297&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Nas-fpn: Learning scalable feature pyramid architecture for object detection",
      "id": "17367410418412289203",
      "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Ghiasi_NAS-FPN_Learning_Scalable_Feature_Pyramid_Architecture_for_Object_Detection_CVPR_2019_paper.html",
      "title": "Nas-fpn: Learning scalable feature pyramid architecture for object detection",
      "authors": "G Ghiasi, TY Lin, QV Le",
      "year": "2019",
      "cited_by": 1401,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17367410418412289203&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Libra r-cnn: Towards balanced learning for object detection",
      "id": "13559955005752027345",
      "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Libra_R-CNN_Towards_Balanced_Learning_for_Object_Detection_CVPR_2019_paper.html",
      "title": "Libra r-cnn: Towards balanced learning for object detection",
      "authors": "J Pang, K Chen, J Shi, H Feng\u2026",
      "year": "2019",
      "cited_by": 1321,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13559955005752027345&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "From points to parts: 3d object detection from point cloud with part-aware and part-aggregation network",
      "id": "1086168042066320095",
      "url": "https://ieeexplore.ieee.org/abstract/document/9018080/",
      "title": "From points to parts: 3d object detection from point cloud with part-aware and part-aggregation network",
      "authors": "S Shi, Z Wang, J Shi, X Wang\u2026",
      "year": "2020",
      "cited_by": 625,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1086168042066320095&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Higherhrnet: Scale-aware representation learning for bottom-up human pose estimation",
      "id": "15368170985283079245",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Cheng_HigherHRNet_Scale-Aware_Representation_Learning_for_Bottom-Up_Human_Pose_Estimation_CVPR_2020_paper.html",
      "title": "Higherhrnet: Scale-aware representation learning for bottom-up human pose estimation",
      "authors": "B Cheng, B Xiao, J Wang, H Shi\u2026",
      "year": "2020",
      "cited_by": 584,
      "cited_by_url": "https://scholar.google.com/scholar?cites=15368170985283079245&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Empowering things with intelligence: a survey of the progress, challenges, and opportunities in artificial intelligence of things",
      "id": "989963634595144692",
      "url": "https://ieeexplore.ieee.org/abstract/document/9264235/",
      "title": "Empowering things with intelligence: a survey of the progress, challenges, and opportunities in artificial intelligence of things",
      "authors": "J Zhang, D Tao",
      "year": "2020",
      "cited_by": 341,
      "cited_by_url": "https://scholar.google.com/scholar?cites=989963634595144692&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Probabilistic regression for visual tracking",
      "id": "6281152651769068818",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Danelljan_Probabilistic_Regression_for_Visual_Tracking_CVPR_2020_paper.html",
      "title": "Probabilistic regression for visual tracking",
      "authors": "M Danelljan, LV Gool, R Timofte",
      "year": "2020",
      "cited_by": 462,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6281152651769068818&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Rethinking imagenet pre-training",
      "id": "8945175718646989267",
      "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/He_Rethinking_ImageNet_Pre-Training_ICCV_2019_paper.html",
      "title": "Rethinking imagenet pre-training",
      "authors": "K He, R Girshick, P Doll\u00e1r",
      "year": "2019",
      "cited_by": 1126,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8945175718646989267&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Panoptic-deeplab: A simple, strong, and fast baseline for bottom-up panoptic segmentation",
      "id": "18246305387780116611",
      "url": "http://openaccess.thecvf.com/content_CVPR_2020/html/Cheng_Panoptic-DeepLab_A_Simple_Strong_and_Fast_Baseline_for_Bottom-Up_Panoptic_CVPR_2020_paper.html",
      "title": "Panoptic-deeplab: A simple, strong, and fast baseline for bottom-up panoptic segmentation",
      "authors": "B Cheng, MD Collins, Y Zhu, T Liu\u2026",
      "year": "2020",
      "cited_by": 505,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18246305387780116611&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Bottom-up object detection by grouping extreme and center points",
      "id": "18336064849612757553",
      "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Bottom-Up_Object_Detection_by_Grouping_Extreme_and_Center_Points_CVPR_2019_paper.html",
      "title": "Bottom-up object detection by grouping extreme and center points",
      "authors": "X Zhou, J Zhuo, P Krahenbuhl",
      "year": "2019",
      "cited_by": 975,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18336064849612757553&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Feature selective anchor-free module for single-shot object detection",
      "id": "17369531722515506311",
      "url": "http://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Feature_Selective_Anchor-Free_Module_for_Single-Shot_Object_Detection_CVPR_2019_paper.html",
      "title": "Feature selective anchor-free module for single-shot object detection",
      "authors": "C Zhu, Y He, M Savvides",
      "year": "2019",
      "cited_by": 840,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17369531722515506311&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Reppoints: Point set representation for object detection",
      "id": "6731983785945015219",
      "url": "http://openaccess.thecvf.com/content_ICCV_2019/html/Yang_RepPoints_Point_Set_Representation_for_Object_Detection_ICCV_2019_paper.html",
      "title": "Reppoints: Point set representation for object detection",
      "authors": "Z Yang, S Liu, H Hu, L Wang\u2026",
      "year": "2019",
      "cited_by": 783,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6731983785945015219&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "M2det: A single-shot object detector based on multi-level feature pyramid network",
      "id": "13359963855282714219",
      "url": "https://ojs.aaai.org/index.php/AAAI/article/view/4962",
      "title": "M2det: A single-shot object detector based on multi-level feature pyramid network",
      "authors": "Q Zhao, T Sheng, Y Wang, Z Tang, Y Chen\u2026",
      "year": "2019",
      "cited_by": 785,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13359963855282714219&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "High-resolution representations for labeling pixels and regions",
      "id": "1545024244511440922",
      "url": "https://arxiv.org/abs/1904.04514",
      "title": "High-resolution representations for labeling pixels and regions",
      "authors": "K Sun, Y Zhao, B Jiang, T Cheng, B Xiao, D Liu\u2026",
      "year": "2019",
      "cited_by": 725,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1545024244511440922&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Embracing single stride 3d object detector with sparse transformer",
      "id": "5426394606047885053",
      "url": "http://openaccess.thecvf.com/content/CVPR2022/html/Fan_Embracing_Single_Stride_3D_Object_Detector_With_Sparse_Transformer_CVPR_2022_paper.html",
      "title": "Embracing single stride 3d object detector with sparse transformer",
      "authors": "L Fan, Z Pang, T Zhang, YX Wang\u2026",
      "year": "2022",
      "cited_by": 114,
      "cited_by_url": "https://scholar.google.com/scholar?cites=5426394606047885053&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Improving 3d object detection with channel-wise transformer",
      "id": "10747326374097383015",
      "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Sheng_Improving_3D_Object_Detection_With_Channel-Wise_Transformer_ICCV_2021_paper.html?ref=https://githubhelp.com",
      "title": "Improving 3d object detection with channel-wise transformer",
      "authors": "H Sheng, S Cai, Y Liu, B Deng\u2026",
      "year": "2021",
      "cited_by": 159,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10747326374097383015&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "A simple semi-supervised learning framework for object detection",
      "id": "6145323722830593859",
      "url": "https://arxiv.org/abs/2005.04757",
      "title": "A simple semi-supervised learning framework for object detection",
      "authors": "K Sohn, Z Zhang, CL Li, H Zhang, CY Lee\u2026",
      "year": "2020",
      "cited_by": 357,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6145323722830593859&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Arbitrary-oriented object detection with circular smooth label",
      "id": "14479605661908902222",
      "url": "https://link.springer.com/chapter/10.1007/978-3-030-58598-3_40",
      "title": "Arbitrary-oriented object detection with circular smooth label",
      "authors": "X Yang, J Yan",
      "year": "2020",
      "cited_by": 327,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14479605661908902222&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Bottom-up human pose estimation via disentangled keypoint regression",
      "id": "11348760748613165934",
      "url": "http://openaccess.thecvf.com/content/CVPR2021/html/Geng_Bottom-Up_Human_Pose_Estimation_via_Disentangled_Keypoint_Regression_CVPR_2021_paper.html",
      "title": "Bottom-up human pose estimation via disentangled keypoint regression",
      "authors": "Z Geng, K Sun, B Xiao, Z Zhang\u2026",
      "year": "2021",
      "cited_by": 162,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11348760748613165934&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "FAIR1M: A benchmark dataset for fine-grained object recognition in high-resolution remote sensing imagery",
      "id": "12180218794931662709",
      "url": "https://www.sciencedirect.com/science/article/pii/S0924271621003269",
      "title": "FAIR1M: A benchmark dataset for fine-grained object recognition in high-resolution remote sensing imagery",
      "authors": "X Sun, P Wang, Z Yan, F Xu, R Wang, W Diao\u2026",
      "year": "2022",
      "cited_by": 161,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12180218794931662709&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "Computer vision for autonomous vehicles: Problems, datasets and state of the art",
      "id": "2597834166337025404",
      "url": "https://www.nowpublishers.com/article/Details/CGV-079",
      "title": "Computer vision for autonomous vehicles: Problems, datasets and state of the art",
      "authors": "J Janai, F G\u00fcney, A Behl, A Geiger",
      "year": "2020",
      "cited_by": 850,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2597834166337025404&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 0
    },
    {
      "label": "A survey on generative diffusion model",
      "id": "16128994104714577384",
      "url": "https://arxiv.org/abs/2209.02646",
      "title": "A survey on generative diffusion model",
      "authors": "H Cao, C Tan, Z Gao, Y Xu, G Chen, PA Heng\u2026",
      "year": "2022",
      "cited_by": 73,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16128994104714577384&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Diffusion action segmentation",
      "id": "7941234669662371746",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Diffusion_Action_Segmentation_ICCV_2023_paper.html",
      "title": "Diffusion action segmentation",
      "authors": "D Liu, Q Li, AD Dinh, T Jiang\u2026",
      "year": "2023",
      "cited_by": 4,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7941234669662371746&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Periodically exchange teacher-student for source-free object detection",
      "id": "13076252047124330234",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Liu_Periodically_Exchange_Teacher-Student_for_Source-Free_Object_Detection_ICCV_2023_paper.html",
      "title": "Periodically exchange teacher-student for source-free object detection",
      "authors": "Q Liu, L Lin, Z Shen, Z Yang",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13076252047124330234&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Generative prompt model for weakly supervised object localization",
      "id": "12525771403000822454",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Generative_Prompt_Model_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.html",
      "title": "Generative prompt model for weakly supervised object localization",
      "authors": "Y Zhao, Q Ye, W Wu, C Shen\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12525771403000822454&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation",
      "id": "10942366611650661886",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.html",
      "title": "Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation",
      "authors": "D Peng, P Hu, Q Ke, J Liu",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10942366611650661886&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Belfusion: Latent diffusion for behavior-driven human motion prediction",
      "id": "12060121231554906872",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Barquero_BeLFusion_Latent_Diffusion_for_Behavior-Driven_Human_Motion_Prediction_ICCV_2023_paper.html",
      "title": "Belfusion: Latent diffusion for behavior-driven human motion prediction",
      "authors": "G Barquero, S Escalera\u2026",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=12060121231554906872&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Ddp: Diffusion model for dense visual prediction",
      "id": "13417650621921820369",
      "url": "https://arxiv.org/abs/2303.17559",
      "title": "Ddp: Diffusion model for dense visual prediction",
      "authors": "Y Ji, Z Chen, E Xie, L Hong, X Liu, Z Liu, T Lu\u2026",
      "year": "2023",
      "cited_by": 13,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13417650621921820369&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "DiffPose: SpatioTemporal diffusion model for video-based human pose estimation",
      "id": "6326589465262223216",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Feng_DiffPose_SpatioTemporal_Diffusion_Model_for_Video-Based_Human_Pose_Estimation_ICCV_2023_paper.html",
      "title": "DiffPose: SpatioTemporal diffusion model for video-based human pose estimation",
      "authors": "R Feng, Y Gao, THE Tse, X Ma\u2026",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6326589465262223216&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Unleashing text-to-image diffusion models for visual perception",
      "id": "1678541804692472087",
      "url": "https://arxiv.org/abs/2303.02153",
      "title": "Unleashing text-to-image diffusion models for visual perception",
      "authors": "W Zhao, Y Rao, Z Liu, B Liu, J Zhou, J Lu",
      "year": "2023",
      "cited_by": 15,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1678541804692472087&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Learning to schedule in diffusion probabilistic models",
      "id": "11360965149573855814",
      "url": "https://dl.acm.org/doi/abs/10.1145/3580305.3599412",
      "title": "Learning to schedule in diffusion probabilistic models",
      "authors": "Y Wang, X Wang, AD Dinh, B Du, C Xu",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11360965149573855814&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Diffusion models in medical imaging: A comprehensive survey",
      "id": "10564325131634348410",
      "url": "https://www.sciencedirect.com/science/article/pii/S1361841523001068",
      "title": "Diffusion models in medical imaging: A comprehensive survey",
      "authors": "A Kazerouni, EK Aghdam, M Heidari, R Azad\u2026",
      "year": "2023",
      "cited_by": 14,
      "cited_by_url": "https://scholar.google.com/scholar?cites=10564325131634348410&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Exploring diffusion models for unsupervised video anomaly detection",
      "id": "9095926209623917067",
      "url": "https://ieeexplore.ieee.org/abstract/document/10222594/",
      "title": "Exploring diffusion models for unsupervised video anomaly detection",
      "authors": "AO Tur, N Dall'Asen, C Beyan\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9095926209623917067&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Diffusioninst: Diffusion model for instance segmentation",
      "id": "17382263080131354066",
      "url": "https://arxiv.org/abs/2212.02773",
      "title": "Diffusioninst: Diffusion model for instance segmentation",
      "authors": "Z Gu, H Chen, Z Xu, J Lan, C Meng, W Wang",
      "year": "2022",
      "cited_by": 16,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17382263080131354066&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Dif-fusion: Towards high color fidelity in infrared and visible image fusion with diffusion models",
      "id": "8819593779078451823",
      "url": "https://arxiv.org/abs/2301.08072",
      "title": "Dif-fusion: Towards high color fidelity in infrared and visible image fusion with diffusion models",
      "authors": "J Yue, L Fang, S Xia, Y Deng, J Ma",
      "year": "2023",
      "cited_by": 6,
      "cited_by_url": "https://scholar.google.com/scholar?cites=8819593779078451823&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "LoTE-Animal: A Long Time-span Dataset for Endangered Animal Behavior Understanding",
      "id": "F4Zoh0oPXE0J",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Liu_LoTE-Animal_A_Long_Time-span_Dataset_for_Endangered_Animal_Behavior_Understanding_ICCV_2023_paper.html",
      "title": "LoTE-Animal: A Long Time-span Dataset for Endangered Animal Behavior Understanding",
      "authors": "D Liu, J Hou, S Huang, J Liu, Y He\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Feature Prediction Diffusion Model for Video Anomaly Detection",
      "id": "zMD8xoVPVA0J",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Yan_Feature_Prediction_Diffusion_Model_for_Video_Anomaly_Detection_ICCV_2023_paper.html",
      "title": "Feature Prediction Diffusion Model for Video Anomaly Detection",
      "authors": "C Yan, S Zhang, Y Liu, G Pang\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Diffusionret: Generative text-video retrieval with diffusion model",
      "id": "13193353915930591338",
      "url": "https://arxiv.org/abs/2303.09867",
      "title": "Diffusionret: Generative text-video retrieval with diffusion model",
      "authors": "P Jin, H Li, Z Cheng, K Li, X Ji, C Liu, L Yuan\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=13193353915930591338&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Boundary-denoising for video activity localization",
      "id": "11287002185478389153",
      "url": "https://arxiv.org/abs/2304.02934",
      "title": "Boundary-denoising for video activity localization",
      "authors": "M Xu, M Soldan, J Gao, S Liu, JM P\u00e9rez-R\u00faa\u2026",
      "year": "2023",
      "cited_by": 5,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11287002185478389153&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Random Boxes Are Open-world Object Detectors",
      "id": "1777455714178307276",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Random_Boxes_Are_Open-world_Object_Detectors_ICCV_2023_paper.html",
      "title": "Random Boxes Are Open-world Object Detectors",
      "authors": "Y Wang, Z Yue, XS Hua\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Diffmic: Dual-guidance diffusion network for medical image classification",
      "id": "3143529597089035400",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-43987-2_10",
      "title": "Diffmic: Dual-guidance diffusion network for medical image classification",
      "authors": "Y Yang, H Fu, AI Aviles-Rivero, CB Sch\u00f6nlieb\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3143529597089035400&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Deep Equilibrium Object Detection",
      "id": "9132989520533932624",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Deep_Equilibrium_Object_Detection_ICCV_2023_paper.html",
      "title": "Deep Equilibrium Object Detection",
      "authors": "S Wang, Y Teng, L Wang",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model",
      "id": "sLUFVBct83MJ",
      "url": "http://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Unsupervised_Surface_Anomaly_Detection_with_Diffusion_Probabilistic_Model_ICCV_2023_paper.html",
      "title": "Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model",
      "authors": "X Zhang, N Li, J Li, T Dai, Y Jiang\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "RecursiveDet: End-to-End Region-based Recursive Object Detection",
      "id": "5862922647569477938",
      "url": "https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_RecursiveDet_End-to-End_Region-Based_Recursive_Object_Detection_ICCV_2023_paper.html",
      "title": "RecursiveDet: End-to-End Region-based Recursive Object Detection",
      "authors": "J Zhao, L Sun, Q Li",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DiffusionNER: Boundary Diffusion for Named Entity Recognition",
      "id": "6644117076261818901",
      "url": "https://arxiv.org/abs/2305.13298",
      "title": "DiffusionNER: Boundary Diffusion for Named Entity Recognition",
      "authors": "Y Shen, K Song, X Tan, D Li, W Lu\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6644117076261818901&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Towards Generic and Controllable Attacks Against Object Detection",
      "id": "1224216148116518096",
      "url": "https://arxiv.org/abs/2307.12342",
      "title": "Towards Generic and Controllable Attacks Against Object Detection",
      "authors": "G Li, Y Xu, J Ding, GS Xia",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=1224216148116518096&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Revisiting Table Detection Datasets for Visually Rich Documents",
      "id": "18029852880512974017",
      "url": "https://arxiv.org/abs/2305.04833",
      "title": "Revisiting Table Detection Datasets for Visually Rich Documents",
      "authors": "B Xiao, M Simsek, B Kantarci, AA Alkheir",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=18029852880512974017&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence",
      "id": "4088751988372467068",
      "url": "https://arxiv.org/abs/2305.15347",
      "title": "A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence",
      "authors": "J Zhang, C Herrmann, J Hur, LP Cabrera\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=4088751988372467068&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Structural Pruning for Diffusion Models",
      "id": "16273778234448951456",
      "url": "https://arxiv.org/abs/2305.10924",
      "title": "Structural Pruning for Diffusion Models",
      "authors": "G Fang, X Ma, X Wang",
      "year": "2023",
      "cited_by": 9,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16273778234448951456&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation",
      "id": "17592923797249586375",
      "url": "https://arxiv.org/abs/2303.11579",
      "title": "Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation",
      "authors": "W Shan, Z Liu, X Zhang, Z Wang, K Han\u2026",
      "year": "2023",
      "cited_by": 8,
      "cited_by_url": "https://scholar.google.com/scholar?cites=17592923797249586375&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "DLT: Conditioned layout generation with Joint Discrete-Continuous Diffusion Layout Transformer",
      "id": "6142589876195895306",
      "url": "https://arxiv.org/abs/2303.03755",
      "title": "DLT: Conditioned layout generation with Joint Discrete-Continuous Diffusion Layout Transformer",
      "authors": "E Levi, E Brosh, M Mykhailych, M Perez",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6142589876195895306&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Controllable Mind Visual Diffusion Model",
      "id": "3960507448835907852",
      "url": "https://arxiv.org/abs/2305.10135",
      "title": "Controllable Mind Visual Diffusion Model",
      "authors": "B Zeng, S Li, X Liu, S Gao, X Jiang, X Tang\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3960507448835907852&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "SpectralDiff: A Generative Framework for Hyperspectral Image Classification with Diffusion Models",
      "id": "G95UAM_jS08J",
      "url": "https://ieeexplore.ieee.org/abstract/document/10234379/",
      "title": "SpectralDiff: A Generative Framework for Hyperspectral Image Classification with Diffusion Models",
      "authors": "N Chen, J Yue, L Fang, S Xia",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Denoising Diffusion Semantic Segmentation with Mask Prior Modeling",
      "id": "16273230188622356845",
      "url": "https://arxiv.org/abs/2306.01721",
      "title": "Denoising Diffusion Semantic Segmentation with Mask Prior Modeling",
      "authors": "Z Lai, Y Duan, J Dai, Z Li, Y Fu, H Li, Y Qiao\u2026",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16273230188622356845&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Diffusionstr: Diffusion model for scene text recognition",
      "id": "7240823796445100518",
      "url": "https://ieeexplore.ieee.org/abstract/document/10222793/",
      "title": "Diffusionstr: Diffusion model for scene text recognition",
      "authors": "M Fujitake",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=7240823796445100518&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World",
      "id": "3157779878157184062",
      "url": "https://arxiv.org/abs/2308.01907",
      "title": "The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World",
      "authors": "W Wang, M Shi, Q Li, W Wang, Z Huang, L Xing\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Conformal prediction for trustworthy detection of railway signals",
      "id": "11623041935010349796",
      "url": "https://arxiv.org/abs/2301.11136",
      "title": "Conformal prediction for trustworthy detection of railway signals",
      "authors": "L And\u00e9ol, T Fel, F De Grancey, L Mossina",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11623041935010349796&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Enhancing gland segmentation in colon histology images using an instance-aware diffusion model",
      "id": "14202645124111525490",
      "url": "https://www.sciencedirect.com/science/article/pii/S0010482523009927",
      "title": "Enhancing gland segmentation in colon histology images using an instance-aware diffusion model",
      "authors": "M Sun, J Wang, Q Gong, W Huang",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Dream the Impossible: Outlier Imagination with Diffusion Models",
      "id": "a96v83mzAUoJ",
      "url": "https://arxiv.org/abs/2309.13415",
      "title": "Dream the Impossible: Outlier Imagination with Diffusion Models",
      "authors": "X Du, Y Sun, X Zhu, Y Li",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DAVIS: High-Quality Audio-Visual Separation with Generative Diffusion Models",
      "id": "7355981587734255595",
      "url": "https://arxiv.org/abs/2308.00122",
      "title": "DAVIS: High-Quality Audio-Visual Separation with Generative Diffusion Models",
      "authors": "C Huang, S Liang, Y Tian, A Kumar, C Xu",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Learning proximal operators to discover multiple optima",
      "id": "2741005343281217553",
      "url": "https://arxiv.org/abs/2201.11945",
      "title": "Learning proximal operators to discover multiple optima",
      "authors": "L Li, N Aigerman, VG Kim, J Li, K Greenewald\u2026",
      "year": "2022",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=2741005343281217553&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt",
      "id": "6909744142839740328",
      "url": "https://arxiv.org/abs/2306.04607",
      "title": "Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt",
      "authors": "K Chen, E Xie, Z Chen, L Hong, Z Li\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DFormer: Diffusion-guided Transformer for Universal Image Segmentation",
      "id": "11759926192076555716",
      "url": "https://arxiv.org/abs/2306.03437",
      "title": "DFormer: Diffusion-guided Transformer for Universal Image Segmentation",
      "authors": "H Wang, J Cao, RM Anwer, J Xie, FS Khan\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=11759926192076555716&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Diffusion-based 3D Object Detection with Random Boxes",
      "id": "OaSros3oKKAJ",
      "url": "https://arxiv.org/abs/2309.02049",
      "title": "Diffusion-based 3D Object Detection with Random Boxes",
      "authors": "X Zhou, J Hou, T Yao, D Liang, Z Liu, Z Zou\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Learning A Coarse-to-Fine Diffusion Transformer for Image Restoration",
      "id": "811326051739083462",
      "url": "https://arxiv.org/abs/2308.08730",
      "title": "Learning A Coarse-to-Fine Diffusion Transformer for Image Restoration",
      "authors": "L Wang, Q Yang, C Wang, W Wang, J Pan\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Realistic Noise Synthesis with Diffusion Models",
      "id": "14242124119478297788",
      "url": "https://arxiv.org/abs/2305.14022",
      "title": "Realistic Noise Synthesis with Diffusion Models",
      "authors": "Q Wu, M Han, T Jiang, H Fan, B Zeng, S Liu",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=14242124119478297788&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Zero-Shot Image Harmonization with Generative Model Prior",
      "id": "4554030306715313521",
      "url": "https://arxiv.org/abs/2307.08182",
      "title": "Zero-Shot Image Harmonization with Generative Model Prior",
      "authors": "J Chen, Z Zou, Y Zhang, K Chen, Z Shi",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Table Detection for Visually Rich Document Images",
      "id": "4168455509224505377",
      "url": "https://arxiv.org/abs/2305.19181",
      "title": "Table Detection for Visually Rich Document Images",
      "authors": "B Xiao, M Simsek, B Kantarci, AA Alkheir",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models",
      "id": "13803166602830577984",
      "url": "https://arxiv.org/abs/2308.16777",
      "title": "Ref-Diff: Zero-shot Referring Image Segmentation with Generative Models",
      "authors": "M Ni, Y Zhang, K Feng, X Li, Y Guo, W Zuo",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DiffBEV: Conditional Diffusion Model for Bird's Eye View Perception",
      "id": "764295440409526857",
      "url": "https://arxiv.org/abs/2303.08333",
      "title": "DiffBEV: Conditional Diffusion Model for Bird's Eye View Perception",
      "authors": "J Zou, Z Zhu, Y Ye, X Wang",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=764295440409526857&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Semi-Supervised Cross Domain Teacher-Student Mutual Training for Damaged Building Detection",
      "id": "I3r9FbwuMeoJ",
      "url": "https://ieeexplore.ieee.org/abstract/document/10175376/",
      "title": "Semi-Supervised Cross Domain Teacher-Student Mutual Training for Damaged Building Detection",
      "authors": "J Pan, P Yin, X Sun, J Tan, W Li",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Learning Structure-Guided Diffusion Model for 2D Human Pose Estimation",
      "id": "3555227715383495415",
      "url": "https://arxiv.org/abs/2306.17074",
      "title": "Learning Structure-Guided Diffusion Model for 2D Human Pose Estimation",
      "authors": "Z Qiu, Q Yang, J Wang, X Wang, C Xu, D Fu\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion",
      "id": "3070099986647090116",
      "url": "https://arxiv.org/abs/2303.14863",
      "title": "DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion",
      "authors": "S Nag, X Zhu, J Deng, YZ Song, T Xiang",
      "year": "2023",
      "cited_by": 3,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3070099986647090116&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "SpectralDiff: Hyperspectral Image Classification with Spectral-Spatial Diffusion Models",
      "id": "3366278070706666359",
      "url": "https://arxiv.org/abs/2304.05961",
      "title": "SpectralDiff: Hyperspectral Image Classification with Spectral-Spatial Diffusion Models",
      "authors": "N Chen, J Yue, L Fang, S Xia",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=3366278070706666359&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Diffusion Models Beat GANs on Image Classification",
      "id": "7399476248812336314",
      "url": "https://arxiv.org/abs/2307.08702",
      "title": "Diffusion Models Beat GANs on Image Classification",
      "authors": "S Mukhopadhyay, M Gwilliam, V Agarwal\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Diffusion Probabilistic Models for Graph-Structured Prediction",
      "id": "6622643112892915762",
      "url": "https://arxiv.org/abs/2302.10506",
      "title": "Diffusion Probabilistic Models for Graph-Structured Prediction",
      "authors": "H Jang, S Mo, S Ahn",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6622643112892915762&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "CLE Diffusion: Controllable Light Enhancement Diffusion Model",
      "id": "261887705248316913",
      "url": "https://arxiv.org/abs/2308.06725",
      "title": "CLE Diffusion: Controllable Light Enhancement Diffusion Model",
      "authors": "Y Yin, D Xu, C Tan, P Liu, Y Zhao, Y Wei",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "A Survey on Deep Learning-based Spatio-temporal Action Detection",
      "id": "8435158920283992591",
      "url": "https://arxiv.org/abs/2308.01618",
      "title": "A Survey on Deep Learning-based Spatio-temporal Action Detection",
      "authors": "P Wang, F Zeng, Y Qian",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Reference-based Painterly Inpainting via Diffusion: Crossing the Wild Reference Domain Gap",
      "id": "7539048894844258473",
      "url": "https://arxiv.org/abs/2307.10584",
      "title": "Reference-based Painterly Inpainting via Diffusion: Crossing the Wild Reference Domain Gap",
      "authors": "D Xu, X Xu, W Cong, H Shi, Z Wang",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DiffusionVMR: Diffusion Model for Video Moment Retrieval",
      "id": "17520432466589520461",
      "url": "https://arxiv.org/abs/2308.15109",
      "title": "DiffusionVMR: Diffusion Model for Video Moment Retrieval",
      "authors": "H Zhao, KQ Lin, R Yan, Z Li",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DiffSED: Sound Event Detection with Denoising Diffusion",
      "id": "2202905144227684777",
      "url": "https://arxiv.org/abs/2308.07293",
      "title": "DiffSED: Sound Event Detection with Denoising Diffusion",
      "authors": "S Bhosale, S Nag, D Kanojia, J Deng, X Zhu",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DiffusionTrack: Diffusion Model For Multi-Object Tracking",
      "id": "3941086606225563243",
      "url": "https://arxiv.org/abs/2308.09905",
      "title": "DiffusionTrack: Diffusion Model For Multi-Object Tracking",
      "authors": "R Luo, Z Song, L Ma, J Wei, W Yang\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "PSDiff: Diffusion Model for Person Search with Iterative and Collaborative Refinement",
      "id": "SOWfTYHvJj8J",
      "url": "https://arxiv.org/abs/2309.11125",
      "title": "PSDiff: Diffusion Model for Person Search with Iterative and Collaborative Refinement",
      "authors": "C Jia, M Luo, Z Dang, G Dai, X Chang, J Wang\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion Modeling",
      "id": "7227275169875605471",
      "url": "https://arxiv.org/abs/2308.10705",
      "title": "Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion Modeling",
      "authors": "H Ji, H Deng, Y Dai, H Li",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "DENTEX: An Abnormal Tooth Detection with Dental Enumeration and Diagnosis Benchmark for Panoramic X-rays",
      "id": "6835716193545665416",
      "url": "https://arxiv.org/abs/2305.19112",
      "title": "DENTEX: An Abnormal Tooth Detection with Dental Enumeration and Diagnosis Benchmark for Panoramic X-rays",
      "authors": "IE Hamamci, S Er, E Simsar, AE Yuksel\u2026",
      "year": "2023",
      "cited_by": 2,
      "cited_by_url": "https://scholar.google.com/scholar?cites=6835716193545665416&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling",
      "id": "17019817652517638697",
      "url": "https://arxiv.org/abs/2304.06052",
      "title": "Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling",
      "authors": "L And\u00e9ol, T Fel, F De Grancey, L Mossina",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models",
      "id": "16289864856633093116",
      "url": "https://arxiv.org/abs/2306.06874",
      "title": "VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion Models",
      "authors": "SY Chou, PY Chen, TY Ho",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=16289864856633093116&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "DiffMatch: Diffusion Model for Dense Matching",
      "id": "4733234527636485458",
      "url": "https://arxiv.org/abs/2305.19094",
      "title": "DiffMatch: Diffusion Model for Dense Matching",
      "authors": "J Nam, G Lee, S Kim, H Kim, H Cho, S Kim\u2026",
      "year": "2023",
      "modularity": 18
    },
    {
      "label": "Real-World Denoising via Diffusion Model",
      "id": "9801496609815990936",
      "url": "https://arxiv.org/abs/2305.04457",
      "title": "Real-World Denoising via Diffusion Model",
      "authors": "C Yang, L Liang, Z Su",
      "year": "2023",
      "cited_by": 1,
      "cited_by_url": "https://scholar.google.com/scholar?cites=9801496609815990936&as_sdt=20000005&sciodt=0,21&hl=en",
      "modularity": 18
    },
    {
      "label": "Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images",
      "id": "n4rt-tP6doUJ",
      "url": "https://link.springer.com/chapter/10.1007/978-3-031-43987-2_64",
      "title": "Instance-Aware Diffusion Model for Gland Segmentation in Colon Histology Images",
      "authors": "M Sun, W Huang, Y Zheng",
      "year": "2023",
      "modularity": 18
    }
  ],
  "links": [
    {
      "source": 0,
      "target": 1
    },
    {
      "source": 0,
      "target": 487
    },
    {
      "source": 2,
      "target": 0
    },
    {
      "source": 2,
      "target": 487
    },
    {
      "source": 3,
      "target": 0
    },
    {
      "source": 3,
      "target": 487
    },
    {
      "source": 3,
      "target": 1060
    },
    {
      "source": 4,
      "target": 0
    },
    {
      "source": 4,
      "target": 487
    },
    {
      "source": 5,
      "target": 0
    },
    {
      "source": 6,
      "target": 0
    },
    {
      "source": 7,
      "target": 0
    },
    {
      "source": 7,
      "target": 487
    },
    {
      "source": 8,
      "target": 0
    },
    {
      "source": 9,
      "target": 0
    },
    {
      "source": 9,
      "target": 487
    },
    {
      "source": 9,
      "target": 570
    },
    {
      "source": 9,
      "target": 304
    },
    {
      "source": 9,
      "target": 731
    },
    {
      "source": 9,
      "target": 880
    },
    {
      "source": 9,
      "target": 1570
    },
    {
      "source": 9,
      "target": 1
    },
    {
      "source": 10,
      "target": 0
    },
    {
      "source": 10,
      "target": 487
    },
    {
      "source": 11,
      "target": 0
    },
    {
      "source": 11,
      "target": 487
    },
    {
      "source": 12,
      "target": 0
    },
    {
      "source": 13,
      "target": 0
    },
    {
      "source": 13,
      "target": 487
    },
    {
      "source": 13,
      "target": 522
    },
    {
      "source": 13,
      "target": 1150
    },
    {
      "source": 14,
      "target": 0
    },
    {
      "source": 14,
      "target": 1572
    },
    {
      "source": 15,
      "target": 0
    },
    {
      "source": 16,
      "target": 0
    },
    {
      "source": 17,
      "target": 0
    },
    {
      "source": 17,
      "target": 102
    },
    {
      "source": 17,
      "target": 1060
    },
    {
      "source": 18,
      "target": 0
    },
    {
      "source": 19,
      "target": 0
    },
    {
      "source": 20,
      "target": 0
    },
    {
      "source": 20,
      "target": 1494
    },
    {
      "source": 21,
      "target": 0
    },
    {
      "source": 22,
      "target": 0
    },
    {
      "source": 23,
      "target": 0
    },
    {
      "source": 24,
      "target": 0
    },
    {
      "source": 25,
      "target": 0
    },
    {
      "source": 26,
      "target": 0
    },
    {
      "source": 27,
      "target": 0
    },
    {
      "source": 28,
      "target": 0
    },
    {
      "source": 29,
      "target": 0
    },
    {
      "source": 29,
      "target": 527
    },
    {
      "source": 30,
      "target": 0
    },
    {
      "source": 31,
      "target": 0
    },
    {
      "source": 32,
      "target": 0
    },
    {
      "source": 32,
      "target": 522
    },
    {
      "source": 32,
      "target": 527
    },
    {
      "source": 32,
      "target": 1150
    },
    {
      "source": 33,
      "target": 0
    },
    {
      "source": 34,
      "target": 0
    },
    {
      "source": 35,
      "target": 0
    },
    {
      "source": 35,
      "target": 522
    },
    {
      "source": 35,
      "target": 1570
    },
    {
      "source": 36,
      "target": 0
    },
    {
      "source": 37,
      "target": 0
    },
    {
      "source": 38,
      "target": 0
    },
    {
      "source": 38,
      "target": 394
    },
    {
      "source": 39,
      "target": 0
    },
    {
      "source": 40,
      "target": 0
    },
    {
      "source": 40,
      "target": 1572
    },
    {
      "source": 41,
      "target": 0
    },
    {
      "source": 42,
      "target": 0
    },
    {
      "source": 42,
      "target": 1494
    },
    {
      "source": 43,
      "target": 0
    },
    {
      "source": 44,
      "target": 0
    },
    {
      "source": 45,
      "target": 0
    },
    {
      "source": 46,
      "target": 0
    },
    {
      "source": 47,
      "target": 0
    },
    {
      "source": 48,
      "target": 0
    },
    {
      "source": 49,
      "target": 0
    },
    {
      "source": 50,
      "target": 0
    },
    {
      "source": 51,
      "target": 0
    },
    {
      "source": 52,
      "target": 0
    },
    {
      "source": 53,
      "target": 0
    },
    {
      "source": 54,
      "target": 0
    },
    {
      "source": 55,
      "target": 0
    },
    {
      "source": 55,
      "target": 1004
    },
    {
      "source": 56,
      "target": 0
    },
    {
      "source": 57,
      "target": 0
    },
    {
      "source": 58,
      "target": 0
    },
    {
      "source": 59,
      "target": 0
    },
    {
      "source": 60,
      "target": 0
    },
    {
      "source": 61,
      "target": 0
    },
    {
      "source": 62,
      "target": 0
    },
    {
      "source": 63,
      "target": 0
    },
    {
      "source": 64,
      "target": 0
    },
    {
      "source": 65,
      "target": 0
    },
    {
      "source": 66,
      "target": 0
    },
    {
      "source": 67,
      "target": 0
    },
    {
      "source": 68,
      "target": 0
    },
    {
      "source": 68,
      "target": 880
    },
    {
      "source": 69,
      "target": 0
    },
    {
      "source": 70,
      "target": 0
    },
    {
      "source": 71,
      "target": 0
    },
    {
      "source": 72,
      "target": 0
    },
    {
      "source": 73,
      "target": 0
    },
    {
      "source": 74,
      "target": 0
    },
    {
      "source": 75,
      "target": 0
    },
    {
      "source": 76,
      "target": 0
    },
    {
      "source": 77,
      "target": 0
    },
    {
      "source": 78,
      "target": 0
    },
    {
      "source": 78,
      "target": 1004
    },
    {
      "source": 79,
      "target": 0
    },
    {
      "source": 79,
      "target": 522
    },
    {
      "source": 80,
      "target": 0
    },
    {
      "source": 81,
      "target": 0
    },
    {
      "source": 82,
      "target": 0
    },
    {
      "source": 83,
      "target": 0
    },
    {
      "source": 84,
      "target": 0
    },
    {
      "source": 85,
      "target": 0
    },
    {
      "source": 86,
      "target": 0
    },
    {
      "source": 87,
      "target": 0
    },
    {
      "source": 88,
      "target": 0
    },
    {
      "source": 88,
      "target": 1004
    },
    {
      "source": 89,
      "target": 0
    },
    {
      "source": 89,
      "target": 394
    },
    {
      "source": 90,
      "target": 0
    },
    {
      "source": 91,
      "target": 0
    },
    {
      "source": 91,
      "target": 1004
    },
    {
      "source": 92,
      "target": 0
    },
    {
      "source": 92,
      "target": 1413
    },
    {
      "source": 92,
      "target": 9
    },
    {
      "source": 93,
      "target": 0
    },
    {
      "source": 93,
      "target": 304
    },
    {
      "source": 94,
      "target": 0
    },
    {
      "source": 95,
      "target": 0
    },
    {
      "source": 96,
      "target": 0
    },
    {
      "source": 97,
      "target": 0
    },
    {
      "source": 98,
      "target": 0
    },
    {
      "source": 99,
      "target": 0
    },
    {
      "source": 99,
      "target": 394
    },
    {
      "source": 100,
      "target": 0
    },
    {
      "source": 101,
      "target": 0
    },
    {
      "source": 101,
      "target": 1004
    },
    {
      "source": 102,
      "target": 1
    },
    {
      "source": 103,
      "target": 102
    },
    {
      "source": 103,
      "target": 1570
    },
    {
      "source": 104,
      "target": 102
    },
    {
      "source": 105,
      "target": 102
    },
    {
      "source": 106,
      "target": 102
    },
    {
      "source": 106,
      "target": 487
    },
    {
      "source": 106,
      "target": 522
    },
    {
      "source": 106,
      "target": 1145
    },
    {
      "source": 107,
      "target": 102
    },
    {
      "source": 108,
      "target": 102
    },
    {
      "source": 109,
      "target": 102
    },
    {
      "source": 110,
      "target": 102
    },
    {
      "source": 111,
      "target": 102
    },
    {
      "source": 111,
      "target": 570
    },
    {
      "source": 111,
      "target": 731
    },
    {
      "source": 112,
      "target": 102
    },
    {
      "source": 113,
      "target": 102
    },
    {
      "source": 114,
      "target": 102
    },
    {
      "source": 115,
      "target": 102
    },
    {
      "source": 116,
      "target": 102
    },
    {
      "source": 117,
      "target": 102
    },
    {
      "source": 118,
      "target": 102
    },
    {
      "source": 119,
      "target": 102
    },
    {
      "source": 120,
      "target": 102
    },
    {
      "source": 121,
      "target": 102
    },
    {
      "source": 122,
      "target": 102
    },
    {
      "source": 122,
      "target": 1386
    },
    {
      "source": 123,
      "target": 102
    },
    {
      "source": 123,
      "target": 1570
    },
    {
      "source": 124,
      "target": 102
    },
    {
      "source": 125,
      "target": 102
    },
    {
      "source": 126,
      "target": 102
    },
    {
      "source": 127,
      "target": 102
    },
    {
      "source": 128,
      "target": 102
    },
    {
      "source": 129,
      "target": 102
    },
    {
      "source": 130,
      "target": 102
    },
    {
      "source": 131,
      "target": 102
    },
    {
      "source": 132,
      "target": 102
    },
    {
      "source": 133,
      "target": 102
    },
    {
      "source": 134,
      "target": 102
    },
    {
      "source": 135,
      "target": 102
    },
    {
      "source": 135,
      "target": 1494
    },
    {
      "source": 136,
      "target": 102
    },
    {
      "source": 137,
      "target": 102
    },
    {
      "source": 138,
      "target": 102
    },
    {
      "source": 139,
      "target": 102
    },
    {
      "source": 140,
      "target": 102
    },
    {
      "source": 140,
      "target": 1570
    },
    {
      "source": 141,
      "target": 102
    },
    {
      "source": 141,
      "target": 1060
    },
    {
      "source": 142,
      "target": 102
    },
    {
      "source": 143,
      "target": 102
    },
    {
      "source": 144,
      "target": 102
    },
    {
      "source": 145,
      "target": 102
    },
    {
      "source": 146,
      "target": 102
    },
    {
      "source": 147,
      "target": 102
    },
    {
      "source": 148,
      "target": 102
    },
    {
      "source": 149,
      "target": 102
    },
    {
      "source": 150,
      "target": 102
    },
    {
      "source": 150,
      "target": 1060
    },
    {
      "source": 151,
      "target": 102
    },
    {
      "source": 152,
      "target": 102
    },
    {
      "source": 153,
      "target": 102
    },
    {
      "source": 153,
      "target": 1060
    },
    {
      "source": 154,
      "target": 102
    },
    {
      "source": 155,
      "target": 102
    },
    {
      "source": 156,
      "target": 102
    },
    {
      "source": 157,
      "target": 102
    },
    {
      "source": 158,
      "target": 102
    },
    {
      "source": 159,
      "target": 102
    },
    {
      "source": 160,
      "target": 102
    },
    {
      "source": 161,
      "target": 102
    },
    {
      "source": 162,
      "target": 102
    },
    {
      "source": 163,
      "target": 102
    },
    {
      "source": 164,
      "target": 102
    },
    {
      "source": 165,
      "target": 102
    },
    {
      "source": 166,
      "target": 102
    },
    {
      "source": 167,
      "target": 102
    },
    {
      "source": 168,
      "target": 102
    },
    {
      "source": 169,
      "target": 102
    },
    {
      "source": 170,
      "target": 102
    },
    {
      "source": 171,
      "target": 102
    },
    {
      "source": 172,
      "target": 102
    },
    {
      "source": 173,
      "target": 102
    },
    {
      "source": 174,
      "target": 102
    },
    {
      "source": 175,
      "target": 102
    },
    {
      "source": 175,
      "target": 570
    },
    {
      "source": 175,
      "target": 731
    },
    {
      "source": 176,
      "target": 102
    },
    {
      "source": 177,
      "target": 102
    },
    {
      "source": 178,
      "target": 102
    },
    {
      "source": 179,
      "target": 102
    },
    {
      "source": 179,
      "target": 731
    },
    {
      "source": 180,
      "target": 102
    },
    {
      "source": 181,
      "target": 102
    },
    {
      "source": 182,
      "target": 102
    },
    {
      "source": 183,
      "target": 102
    },
    {
      "source": 184,
      "target": 102
    },
    {
      "source": 185,
      "target": 102
    },
    {
      "source": 186,
      "target": 102
    },
    {
      "source": 187,
      "target": 102
    },
    {
      "source": 188,
      "target": 102
    },
    {
      "source": 189,
      "target": 102
    },
    {
      "source": 190,
      "target": 102
    },
    {
      "source": 191,
      "target": 102
    },
    {
      "source": 192,
      "target": 102
    },
    {
      "source": 193,
      "target": 102
    },
    {
      "source": 194,
      "target": 102
    },
    {
      "source": 195,
      "target": 102
    },
    {
      "source": 196,
      "target": 102
    },
    {
      "source": 197,
      "target": 102
    },
    {
      "source": 198,
      "target": 102
    },
    {
      "source": 199,
      "target": 102
    },
    {
      "source": 200,
      "target": 102
    },
    {
      "source": 200,
      "target": 570
    },
    {
      "source": 200,
      "target": 731
    },
    {
      "source": 200,
      "target": 880
    },
    {
      "source": 201,
      "target": 102
    },
    {
      "source": 202,
      "target": 1
    },
    {
      "source": 202,
      "target": 303
    },
    {
      "source": 202,
      "target": 394
    },
    {
      "source": 202,
      "target": 487
    },
    {
      "source": 202,
      "target": 570
    },
    {
      "source": 202,
      "target": 731
    },
    {
      "source": 202,
      "target": 522
    },
    {
      "source": 202,
      "target": 880
    },
    {
      "source": 202,
      "target": 1145
    },
    {
      "source": 202,
      "target": 1150
    },
    {
      "source": 202,
      "target": 1386
    },
    {
      "source": 203,
      "target": 202
    },
    {
      "source": 203,
      "target": 487
    },
    {
      "source": 203,
      "target": 731
    },
    {
      "source": 203,
      "target": 880
    },
    {
      "source": 203,
      "target": 1145
    },
    {
      "source": 203,
      "target": 1386
    },
    {
      "source": 203,
      "target": 1570
    },
    {
      "source": 203,
      "target": 1778
    },
    {
      "source": 204,
      "target": 202
    },
    {
      "source": 204,
      "target": 303
    },
    {
      "source": 204,
      "target": 487
    },
    {
      "source": 204,
      "target": 731
    },
    {
      "source": 204,
      "target": 522
    },
    {
      "source": 205,
      "target": 202
    },
    {
      "source": 205,
      "target": 303
    },
    {
      "source": 205,
      "target": 731
    },
    {
      "source": 205,
      "target": 880
    },
    {
      "source": 205,
      "target": 1145
    },
    {
      "source": 205,
      "target": 1150
    },
    {
      "source": 205,
      "target": 1386
    },
    {
      "source": 205,
      "target": 1778
    },
    {
      "source": 206,
      "target": 202
    },
    {
      "source": 206,
      "target": 570
    },
    {
      "source": 207,
      "target": 202
    },
    {
      "source": 207,
      "target": 303
    },
    {
      "source": 207,
      "target": 570
    },
    {
      "source": 207,
      "target": 880
    },
    {
      "source": 207,
      "target": 531
    },
    {
      "source": 208,
      "target": 202
    },
    {
      "source": 209,
      "target": 202
    },
    {
      "source": 210,
      "target": 202
    },
    {
      "source": 210,
      "target": 304
    },
    {
      "source": 211,
      "target": 202
    },
    {
      "source": 212,
      "target": 202
    },
    {
      "source": 213,
      "target": 202
    },
    {
      "source": 213,
      "target": 1572
    },
    {
      "source": 214,
      "target": 202
    },
    {
      "source": 214,
      "target": 303
    },
    {
      "source": 215,
      "target": 202
    },
    {
      "source": 215,
      "target": 303
    },
    {
      "source": 216,
      "target": 202
    },
    {
      "source": 216,
      "target": 304
    },
    {
      "source": 217,
      "target": 202
    },
    {
      "source": 218,
      "target": 202
    },
    {
      "source": 219,
      "target": 202
    },
    {
      "source": 220,
      "target": 202
    },
    {
      "source": 221,
      "target": 202
    },
    {
      "source": 221,
      "target": 303
    },
    {
      "source": 222,
      "target": 202
    },
    {
      "source": 222,
      "target": 531
    },
    {
      "source": 223,
      "target": 202
    },
    {
      "source": 224,
      "target": 202
    },
    {
      "source": 225,
      "target": 202
    },
    {
      "source": 226,
      "target": 202
    },
    {
      "source": 227,
      "target": 202
    },
    {
      "source": 228,
      "target": 202
    },
    {
      "source": 228,
      "target": 303
    },
    {
      "source": 228,
      "target": 570
    },
    {
      "source": 229,
      "target": 202
    },
    {
      "source": 230,
      "target": 202
    },
    {
      "source": 230,
      "target": 303
    },
    {
      "source": 231,
      "target": 202
    },
    {
      "source": 232,
      "target": 202
    },
    {
      "source": 232,
      "target": 304
    },
    {
      "source": 233,
      "target": 202
    },
    {
      "source": 233,
      "target": 304
    },
    {
      "source": 234,
      "target": 202
    },
    {
      "source": 235,
      "target": 202
    },
    {
      "source": 235,
      "target": 303
    },
    {
      "source": 235,
      "target": 570
    },
    {
      "source": 236,
      "target": 202
    },
    {
      "source": 237,
      "target": 202
    },
    {
      "source": 238,
      "target": 202
    },
    {
      "source": 239,
      "target": 202
    },
    {
      "source": 239,
      "target": 531
    },
    {
      "source": 240,
      "target": 202
    },
    {
      "source": 241,
      "target": 202
    },
    {
      "source": 242,
      "target": 202
    },
    {
      "source": 242,
      "target": 304
    },
    {
      "source": 242,
      "target": 531
    },
    {
      "source": 243,
      "target": 202
    },
    {
      "source": 244,
      "target": 202
    },
    {
      "source": 244,
      "target": 531
    },
    {
      "source": 245,
      "target": 202
    },
    {
      "source": 246,
      "target": 202
    },
    {
      "source": 247,
      "target": 202
    },
    {
      "source": 248,
      "target": 202
    },
    {
      "source": 249,
      "target": 202
    },
    {
      "source": 250,
      "target": 202
    },
    {
      "source": 251,
      "target": 202
    },
    {
      "source": 252,
      "target": 202
    },
    {
      "source": 253,
      "target": 202
    },
    {
      "source": 254,
      "target": 202
    },
    {
      "source": 255,
      "target": 202
    },
    {
      "source": 256,
      "target": 202
    },
    {
      "source": 257,
      "target": 202
    },
    {
      "source": 257,
      "target": 527
    },
    {
      "source": 258,
      "target": 202
    },
    {
      "source": 259,
      "target": 202
    },
    {
      "source": 260,
      "target": 202
    },
    {
      "source": 261,
      "target": 202
    },
    {
      "source": 262,
      "target": 202
    },
    {
      "source": 263,
      "target": 202
    },
    {
      "source": 264,
      "target": 202
    },
    {
      "source": 264,
      "target": 304
    },
    {
      "source": 265,
      "target": 202
    },
    {
      "source": 266,
      "target": 202
    },
    {
      "source": 267,
      "target": 202
    },
    {
      "source": 268,
      "target": 202
    },
    {
      "source": 269,
      "target": 202
    },
    {
      "source": 270,
      "target": 202
    },
    {
      "source": 271,
      "target": 202
    },
    {
      "source": 271,
      "target": 304
    },
    {
      "source": 272,
      "target": 202
    },
    {
      "source": 273,
      "target": 202
    },
    {
      "source": 274,
      "target": 202
    },
    {
      "source": 274,
      "target": 304
    },
    {
      "source": 275,
      "target": 202
    },
    {
      "source": 276,
      "target": 202
    },
    {
      "source": 277,
      "target": 202
    },
    {
      "source": 278,
      "target": 202
    },
    {
      "source": 279,
      "target": 202
    },
    {
      "source": 280,
      "target": 202
    },
    {
      "source": 281,
      "target": 202
    },
    {
      "source": 282,
      "target": 202
    },
    {
      "source": 283,
      "target": 202
    },
    {
      "source": 284,
      "target": 202
    },
    {
      "source": 284,
      "target": 531
    },
    {
      "source": 285,
      "target": 202
    },
    {
      "source": 286,
      "target": 202
    },
    {
      "source": 286,
      "target": 9
    },
    {
      "source": 287,
      "target": 202
    },
    {
      "source": 288,
      "target": 202
    },
    {
      "source": 289,
      "target": 202
    },
    {
      "source": 290,
      "target": 202
    },
    {
      "source": 290,
      "target": 304
    },
    {
      "source": 291,
      "target": 202
    },
    {
      "source": 291,
      "target": 304
    },
    {
      "source": 292,
      "target": 202
    },
    {
      "source": 293,
      "target": 202
    },
    {
      "source": 294,
      "target": 202
    },
    {
      "source": 295,
      "target": 202
    },
    {
      "source": 296,
      "target": 202
    },
    {
      "source": 297,
      "target": 202
    },
    {
      "source": 298,
      "target": 202
    },
    {
      "source": 299,
      "target": 202
    },
    {
      "source": 299,
      "target": 304
    },
    {
      "source": 300,
      "target": 202
    },
    {
      "source": 301,
      "target": 202
    },
    {
      "source": 302,
      "target": 202
    },
    {
      "source": 303,
      "target": 1
    },
    {
      "source": 303,
      "target": 487
    },
    {
      "source": 303,
      "target": 570
    },
    {
      "source": 303,
      "target": 731
    },
    {
      "source": 303,
      "target": 1145
    },
    {
      "source": 303,
      "target": 531
    },
    {
      "source": 303,
      "target": 1150
    },
    {
      "source": 303,
      "target": 1778
    },
    {
      "source": 304,
      "target": 303
    },
    {
      "source": 304,
      "target": 570
    },
    {
      "source": 304,
      "target": 1
    },
    {
      "source": 304,
      "target": 731
    },
    {
      "source": 304,
      "target": 1145
    },
    {
      "source": 304,
      "target": 1778
    },
    {
      "source": 305,
      "target": 303
    },
    {
      "source": 305,
      "target": 487
    },
    {
      "source": 305,
      "target": 522
    },
    {
      "source": 305,
      "target": 1145
    },
    {
      "source": 305,
      "target": 1386
    },
    {
      "source": 305,
      "target": 1
    },
    {
      "source": 306,
      "target": 303
    },
    {
      "source": 306,
      "target": 487
    },
    {
      "source": 306,
      "target": 731
    },
    {
      "source": 306,
      "target": 527
    },
    {
      "source": 306,
      "target": 1145
    },
    {
      "source": 306,
      "target": 1386
    },
    {
      "source": 307,
      "target": 303
    },
    {
      "source": 307,
      "target": 731
    },
    {
      "source": 307,
      "target": 880
    },
    {
      "source": 308,
      "target": 303
    },
    {
      "source": 309,
      "target": 303
    },
    {
      "source": 309,
      "target": 880
    },
    {
      "source": 309,
      "target": 1386
    },
    {
      "source": 310,
      "target": 303
    },
    {
      "source": 310,
      "target": 570
    },
    {
      "source": 310,
      "target": 531
    },
    {
      "source": 310,
      "target": 9
    },
    {
      "source": 311,
      "target": 303
    },
    {
      "source": 311,
      "target": 731
    },
    {
      "source": 311,
      "target": 522
    },
    {
      "source": 311,
      "target": 1145
    },
    {
      "source": 311,
      "target": 1386
    },
    {
      "source": 312,
      "target": 303
    },
    {
      "source": 313,
      "target": 303
    },
    {
      "source": 313,
      "target": 1386
    },
    {
      "source": 314,
      "target": 303
    },
    {
      "source": 314,
      "target": 522
    },
    {
      "source": 315,
      "target": 303
    },
    {
      "source": 315,
      "target": 731
    },
    {
      "source": 315,
      "target": 522
    },
    {
      "source": 315,
      "target": 527
    },
    {
      "source": 315,
      "target": 531
    },
    {
      "source": 315,
      "target": 1150
    },
    {
      "source": 315,
      "target": 1386
    },
    {
      "source": 316,
      "target": 303
    },
    {
      "source": 317,
      "target": 303
    },
    {
      "source": 318,
      "target": 303
    },
    {
      "source": 318,
      "target": 1386
    },
    {
      "source": 319,
      "target": 303
    },
    {
      "source": 320,
      "target": 303
    },
    {
      "source": 320,
      "target": 304
    },
    {
      "source": 320,
      "target": 731
    },
    {
      "source": 320,
      "target": 880
    },
    {
      "source": 320,
      "target": 531
    },
    {
      "source": 320,
      "target": 1150
    },
    {
      "source": 321,
      "target": 303
    },
    {
      "source": 321,
      "target": 570
    },
    {
      "source": 321,
      "target": 1150
    },
    {
      "source": 321,
      "target": 1386
    },
    {
      "source": 322,
      "target": 303
    },
    {
      "source": 322,
      "target": 1150
    },
    {
      "source": 323,
      "target": 303
    },
    {
      "source": 323,
      "target": 570
    },
    {
      "source": 323,
      "target": 731
    },
    {
      "source": 324,
      "target": 303
    },
    {
      "source": 324,
      "target": 731
    },
    {
      "source": 325,
      "target": 303
    },
    {
      "source": 325,
      "target": 522
    },
    {
      "source": 326,
      "target": 303
    },
    {
      "source": 326,
      "target": 1150
    },
    {
      "source": 327,
      "target": 303
    },
    {
      "source": 327,
      "target": 522
    },
    {
      "source": 328,
      "target": 303
    },
    {
      "source": 329,
      "target": 303
    },
    {
      "source": 330,
      "target": 303
    },
    {
      "source": 331,
      "target": 303
    },
    {
      "source": 332,
      "target": 303
    },
    {
      "source": 333,
      "target": 303
    },
    {
      "source": 333,
      "target": 880
    },
    {
      "source": 334,
      "target": 303
    },
    {
      "source": 334,
      "target": 880
    },
    {
      "source": 335,
      "target": 303
    },
    {
      "source": 335,
      "target": 394
    },
    {
      "source": 335,
      "target": 522
    },
    {
      "source": 335,
      "target": 527
    },
    {
      "source": 336,
      "target": 303
    },
    {
      "source": 336,
      "target": 570
    },
    {
      "source": 337,
      "target": 303
    },
    {
      "source": 338,
      "target": 303
    },
    {
      "source": 339,
      "target": 303
    },
    {
      "source": 339,
      "target": 880
    },
    {
      "source": 340,
      "target": 303
    },
    {
      "source": 341,
      "target": 303
    },
    {
      "source": 342,
      "target": 303
    },
    {
      "source": 342,
      "target": 394
    },
    {
      "source": 342,
      "target": 1413
    },
    {
      "source": 343,
      "target": 303
    },
    {
      "source": 344,
      "target": 303
    },
    {
      "source": 345,
      "target": 303
    },
    {
      "source": 345,
      "target": 394
    },
    {
      "source": 345,
      "target": 1004
    },
    {
      "source": 346,
      "target": 303
    },
    {
      "source": 347,
      "target": 303
    },
    {
      "source": 348,
      "target": 303
    },
    {
      "source": 349,
      "target": 303
    },
    {
      "source": 350,
      "target": 303
    },
    {
      "source": 350,
      "target": 570
    },
    {
      "source": 351,
      "target": 303
    },
    {
      "source": 352,
      "target": 303
    },
    {
      "source": 353,
      "target": 303
    },
    {
      "source": 354,
      "target": 303
    },
    {
      "source": 355,
      "target": 303
    },
    {
      "source": 356,
      "target": 303
    },
    {
      "source": 357,
      "target": 303
    },
    {
      "source": 358,
      "target": 303
    },
    {
      "source": 359,
      "target": 303
    },
    {
      "source": 360,
      "target": 303
    },
    {
      "source": 361,
      "target": 303
    },
    {
      "source": 362,
      "target": 303
    },
    {
      "source": 363,
      "target": 303
    },
    {
      "source": 364,
      "target": 303
    },
    {
      "source": 365,
      "target": 303
    },
    {
      "source": 365,
      "target": 570
    },
    {
      "source": 365,
      "target": 1004
    },
    {
      "source": 365,
      "target": 531
    },
    {
      "source": 366,
      "target": 303
    },
    {
      "source": 366,
      "target": 531
    },
    {
      "source": 367,
      "target": 303
    },
    {
      "source": 368,
      "target": 303
    },
    {
      "source": 369,
      "target": 303
    },
    {
      "source": 370,
      "target": 303
    },
    {
      "source": 371,
      "target": 303
    },
    {
      "source": 372,
      "target": 303
    },
    {
      "source": 373,
      "target": 303
    },
    {
      "source": 374,
      "target": 303
    },
    {
      "source": 375,
      "target": 303
    },
    {
      "source": 376,
      "target": 303
    },
    {
      "source": 376,
      "target": 304
    },
    {
      "source": 377,
      "target": 303
    },
    {
      "source": 378,
      "target": 303
    },
    {
      "source": 378,
      "target": 570
    },
    {
      "source": 379,
      "target": 303
    },
    {
      "source": 379,
      "target": 304
    },
    {
      "source": 380,
      "target": 303
    },
    {
      "source": 380,
      "target": 304
    },
    {
      "source": 381,
      "target": 303
    },
    {
      "source": 381,
      "target": 531
    },
    {
      "source": 382,
      "target": 303
    },
    {
      "source": 383,
      "target": 303
    },
    {
      "source": 384,
      "target": 303
    },
    {
      "source": 385,
      "target": 303
    },
    {
      "source": 385,
      "target": 394
    },
    {
      "source": 386,
      "target": 303
    },
    {
      "source": 387,
      "target": 303
    },
    {
      "source": 388,
      "target": 303
    },
    {
      "source": 389,
      "target": 303
    },
    {
      "source": 389,
      "target": 304
    },
    {
      "source": 390,
      "target": 303
    },
    {
      "source": 391,
      "target": 303
    },
    {
      "source": 392,
      "target": 303
    },
    {
      "source": 393,
      "target": 303
    },
    {
      "source": 394,
      "target": 1
    },
    {
      "source": 394,
      "target": 487
    },
    {
      "source": 394,
      "target": 1004
    },
    {
      "source": 394,
      "target": 1145
    },
    {
      "source": 394,
      "target": 531
    },
    {
      "source": 394,
      "target": 1778
    },
    {
      "source": 395,
      "target": 394
    },
    {
      "source": 396,
      "target": 394
    },
    {
      "source": 397,
      "target": 394
    },
    {
      "source": 397,
      "target": 487
    },
    {
      "source": 398,
      "target": 394
    },
    {
      "source": 398,
      "target": 527
    },
    {
      "source": 398,
      "target": 1004
    },
    {
      "source": 399,
      "target": 394
    },
    {
      "source": 400,
      "target": 394
    },
    {
      "source": 400,
      "target": 880
    },
    {
      "source": 400,
      "target": 1386
    },
    {
      "source": 401,
      "target": 394
    },
    {
      "source": 401,
      "target": 1004
    },
    {
      "source": 402,
      "target": 394
    },
    {
      "source": 402,
      "target": 1004
    },
    {
      "source": 403,
      "target": 394
    },
    {
      "source": 403,
      "target": 522
    },
    {
      "source": 403,
      "target": 1004
    },
    {
      "source": 403,
      "target": 1150
    },
    {
      "source": 404,
      "target": 394
    },
    {
      "source": 404,
      "target": 1004
    },
    {
      "source": 404,
      "target": 1150
    },
    {
      "source": 405,
      "target": 394
    },
    {
      "source": 405,
      "target": 1004
    },
    {
      "source": 406,
      "target": 394
    },
    {
      "source": 407,
      "target": 394
    },
    {
      "source": 408,
      "target": 394
    },
    {
      "source": 408,
      "target": 1413
    },
    {
      "source": 409,
      "target": 394
    },
    {
      "source": 409,
      "target": 1150
    },
    {
      "source": 410,
      "target": 394
    },
    {
      "source": 410,
      "target": 1004
    },
    {
      "source": 411,
      "target": 394
    },
    {
      "source": 412,
      "target": 394
    },
    {
      "source": 413,
      "target": 394
    },
    {
      "source": 413,
      "target": 1413
    },
    {
      "source": 414,
      "target": 394
    },
    {
      "source": 415,
      "target": 394
    },
    {
      "source": 416,
      "target": 394
    },
    {
      "source": 416,
      "target": 1004
    },
    {
      "source": 417,
      "target": 394
    },
    {
      "source": 417,
      "target": 1004
    },
    {
      "source": 418,
      "target": 394
    },
    {
      "source": 419,
      "target": 394
    },
    {
      "source": 420,
      "target": 394
    },
    {
      "source": 420,
      "target": 527
    },
    {
      "source": 421,
      "target": 394
    },
    {
      "source": 422,
      "target": 394
    },
    {
      "source": 423,
      "target": 394
    },
    {
      "source": 424,
      "target": 394
    },
    {
      "source": 425,
      "target": 394
    },
    {
      "source": 426,
      "target": 394
    },
    {
      "source": 427,
      "target": 394
    },
    {
      "source": 428,
      "target": 394
    },
    {
      "source": 429,
      "target": 394
    },
    {
      "source": 430,
      "target": 394
    },
    {
      "source": 430,
      "target": 527
    },
    {
      "source": 430,
      "target": 1004
    },
    {
      "source": 431,
      "target": 394
    },
    {
      "source": 431,
      "target": 1413
    },
    {
      "source": 432,
      "target": 394
    },
    {
      "source": 432,
      "target": 527
    },
    {
      "source": 433,
      "target": 394
    },
    {
      "source": 434,
      "target": 394
    },
    {
      "source": 434,
      "target": 1004
    },
    {
      "source": 435,
      "target": 394
    },
    {
      "source": 436,
      "target": 394
    },
    {
      "source": 436,
      "target": 527
    },
    {
      "source": 437,
      "target": 394
    },
    {
      "source": 438,
      "target": 394
    },
    {
      "source": 439,
      "target": 394
    },
    {
      "source": 440,
      "target": 394
    },
    {
      "source": 441,
      "target": 394
    },
    {
      "source": 442,
      "target": 394
    },
    {
      "source": 442,
      "target": 1004
    },
    {
      "source": 443,
      "target": 394
    },
    {
      "source": 444,
      "target": 394
    },
    {
      "source": 445,
      "target": 394
    },
    {
      "source": 445,
      "target": 1004
    },
    {
      "source": 446,
      "target": 394
    },
    {
      "source": 447,
      "target": 394
    },
    {
      "source": 448,
      "target": 394
    },
    {
      "source": 448,
      "target": 527
    },
    {
      "source": 449,
      "target": 394
    },
    {
      "source": 450,
      "target": 394
    },
    {
      "source": 450,
      "target": 570
    },
    {
      "source": 451,
      "target": 394
    },
    {
      "source": 452,
      "target": 394
    },
    {
      "source": 453,
      "target": 394
    },
    {
      "source": 454,
      "target": 394
    },
    {
      "source": 455,
      "target": 394
    },
    {
      "source": 456,
      "target": 394
    },
    {
      "source": 457,
      "target": 394
    },
    {
      "source": 457,
      "target": 1004
    },
    {
      "source": 458,
      "target": 394
    },
    {
      "source": 458,
      "target": 1004
    },
    {
      "source": 459,
      "target": 394
    },
    {
      "source": 460,
      "target": 394
    },
    {
      "source": 460,
      "target": 527
    },
    {
      "source": 460,
      "target": 1004
    },
    {
      "source": 461,
      "target": 394
    },
    {
      "source": 461,
      "target": 1004
    },
    {
      "source": 462,
      "target": 394
    },
    {
      "source": 463,
      "target": 394
    },
    {
      "source": 463,
      "target": 1004
    },
    {
      "source": 464,
      "target": 394
    },
    {
      "source": 465,
      "target": 394
    },
    {
      "source": 466,
      "target": 394
    },
    {
      "source": 466,
      "target": 1004
    },
    {
      "source": 467,
      "target": 394
    },
    {
      "source": 467,
      "target": 1004
    },
    {
      "source": 468,
      "target": 394
    },
    {
      "source": 469,
      "target": 394
    },
    {
      "source": 470,
      "target": 394
    },
    {
      "source": 471,
      "target": 394
    },
    {
      "source": 471,
      "target": 1004
    },
    {
      "source": 472,
      "target": 394
    },
    {
      "source": 472,
      "target": 1004
    },
    {
      "source": 473,
      "target": 394
    },
    {
      "source": 474,
      "target": 394
    },
    {
      "source": 474,
      "target": 1004
    },
    {
      "source": 475,
      "target": 394
    },
    {
      "source": 476,
      "target": 394
    },
    {
      "source": 477,
      "target": 394
    },
    {
      "source": 478,
      "target": 394
    },
    {
      "source": 479,
      "target": 394
    },
    {
      "source": 480,
      "target": 394
    },
    {
      "source": 481,
      "target": 394
    },
    {
      "source": 482,
      "target": 394
    },
    {
      "source": 483,
      "target": 394
    },
    {
      "source": 484,
      "target": 394
    },
    {
      "source": 485,
      "target": 394
    },
    {
      "source": 486,
      "target": 394
    },
    {
      "source": 487,
      "target": 1
    },
    {
      "source": 487,
      "target": 1145
    },
    {
      "source": 487,
      "target": 1150
    },
    {
      "source": 487,
      "target": 1386
    },
    {
      "source": 488,
      "target": 487
    },
    {
      "source": 489,
      "target": 487
    },
    {
      "source": 490,
      "target": 487
    },
    {
      "source": 491,
      "target": 487
    },
    {
      "source": 491,
      "target": 731
    },
    {
      "source": 491,
      "target": 522
    },
    {
      "source": 491,
      "target": 1150
    },
    {
      "source": 492,
      "target": 487
    },
    {
      "source": 493,
      "target": 487
    },
    {
      "source": 494,
      "target": 487
    },
    {
      "source": 495,
      "target": 487
    },
    {
      "source": 496,
      "target": 487
    },
    {
      "source": 497,
      "target": 487
    },
    {
      "source": 498,
      "target": 487
    },
    {
      "source": 499,
      "target": 487
    },
    {
      "source": 500,
      "target": 487
    },
    {
      "source": 501,
      "target": 487
    },
    {
      "source": 501,
      "target": 1145
    },
    {
      "source": 501,
      "target": 1150
    },
    {
      "source": 502,
      "target": 487
    },
    {
      "source": 503,
      "target": 487
    },
    {
      "source": 504,
      "target": 487
    },
    {
      "source": 505,
      "target": 487
    },
    {
      "source": 506,
      "target": 487
    },
    {
      "source": 507,
      "target": 487
    },
    {
      "source": 508,
      "target": 487
    },
    {
      "source": 509,
      "target": 487
    },
    {
      "source": 510,
      "target": 487
    },
    {
      "source": 511,
      "target": 487
    },
    {
      "source": 512,
      "target": 487
    },
    {
      "source": 513,
      "target": 487
    },
    {
      "source": 514,
      "target": 487
    },
    {
      "source": 514,
      "target": 1386
    },
    {
      "source": 515,
      "target": 487
    },
    {
      "source": 516,
      "target": 487
    },
    {
      "source": 517,
      "target": 487
    },
    {
      "source": 517,
      "target": 1145
    },
    {
      "source": 518,
      "target": 487
    },
    {
      "source": 519,
      "target": 487
    },
    {
      "source": 520,
      "target": 487
    },
    {
      "source": 521,
      "target": 487
    },
    {
      "source": 522,
      "target": 487
    },
    {
      "source": 522,
      "target": 570
    },
    {
      "source": 522,
      "target": 1
    },
    {
      "source": 522,
      "target": 1145
    },
    {
      "source": 522,
      "target": 1150
    },
    {
      "source": 522,
      "target": 1386
    },
    {
      "source": 522,
      "target": 1778
    },
    {
      "source": 523,
      "target": 487
    },
    {
      "source": 524,
      "target": 487
    },
    {
      "source": 524,
      "target": 1145
    },
    {
      "source": 525,
      "target": 487
    },
    {
      "source": 526,
      "target": 487
    },
    {
      "source": 526,
      "target": 1386
    },
    {
      "source": 527,
      "target": 487
    },
    {
      "source": 527,
      "target": 1
    },
    {
      "source": 527,
      "target": 1145
    },
    {
      "source": 528,
      "target": 487
    },
    {
      "source": 529,
      "target": 487
    },
    {
      "source": 530,
      "target": 487
    },
    {
      "source": 530,
      "target": 1386
    },
    {
      "source": 531,
      "target": 487
    },
    {
      "source": 531,
      "target": 731
    },
    {
      "source": 531,
      "target": 1145
    },
    {
      "source": 531,
      "target": 1
    },
    {
      "source": 531,
      "target": 1150
    },
    {
      "source": 531,
      "target": 1386
    },
    {
      "source": 531,
      "target": 1778
    },
    {
      "source": 532,
      "target": 487
    },
    {
      "source": 532,
      "target": 1386
    },
    {
      "source": 533,
      "target": 487
    },
    {
      "source": 534,
      "target": 487
    },
    {
      "source": 535,
      "target": 487
    },
    {
      "source": 536,
      "target": 487
    },
    {
      "source": 536,
      "target": 1386
    },
    {
      "source": 537,
      "target": 487
    },
    {
      "source": 538,
      "target": 487
    },
    {
      "source": 538,
      "target": 1386
    },
    {
      "source": 539,
      "target": 487
    },
    {
      "source": 540,
      "target": 487
    },
    {
      "source": 541,
      "target": 487
    },
    {
      "source": 542,
      "target": 487
    },
    {
      "source": 543,
      "target": 487
    },
    {
      "source": 543,
      "target": 731
    },
    {
      "source": 543,
      "target": 1145
    },
    {
      "source": 543,
      "target": 1150
    },
    {
      "source": 543,
      "target": 1386
    },
    {
      "source": 543,
      "target": 1778
    },
    {
      "source": 544,
      "target": 487
    },
    {
      "source": 545,
      "target": 487
    },
    {
      "source": 545,
      "target": 522
    },
    {
      "source": 545,
      "target": 1150
    },
    {
      "source": 546,
      "target": 487
    },
    {
      "source": 546,
      "target": 1004
    },
    {
      "source": 546,
      "target": 1145
    },
    {
      "source": 547,
      "target": 487
    },
    {
      "source": 548,
      "target": 487
    },
    {
      "source": 548,
      "target": 522
    },
    {
      "source": 549,
      "target": 487
    },
    {
      "source": 550,
      "target": 487
    },
    {
      "source": 551,
      "target": 487
    },
    {
      "source": 552,
      "target": 487
    },
    {
      "source": 553,
      "target": 487
    },
    {
      "source": 554,
      "target": 487
    },
    {
      "source": 555,
      "target": 487
    },
    {
      "source": 555,
      "target": 1150
    },
    {
      "source": 556,
      "target": 487
    },
    {
      "source": 557,
      "target": 487
    },
    {
      "source": 558,
      "target": 487
    },
    {
      "source": 558,
      "target": 1145
    },
    {
      "source": 558,
      "target": 1150
    },
    {
      "source": 558,
      "target": 1778
    },
    {
      "source": 559,
      "target": 487
    },
    {
      "source": 559,
      "target": 522
    },
    {
      "source": 559,
      "target": 1145
    },
    {
      "source": 560,
      "target": 487
    },
    {
      "source": 560,
      "target": 522
    },
    {
      "source": 560,
      "target": 1145
    },
    {
      "source": 560,
      "target": 1150
    },
    {
      "source": 561,
      "target": 487
    },
    {
      "source": 562,
      "target": 487
    },
    {
      "source": 563,
      "target": 487
    },
    {
      "source": 563,
      "target": 570
    },
    {
      "source": 564,
      "target": 487
    },
    {
      "source": 565,
      "target": 487
    },
    {
      "source": 566,
      "target": 487
    },
    {
      "source": 567,
      "target": 487
    },
    {
      "source": 568,
      "target": 487
    },
    {
      "source": 569,
      "target": 487
    },
    {
      "source": 570,
      "target": 1
    },
    {
      "source": 570,
      "target": 731
    },
    {
      "source": 570,
      "target": 1145
    },
    {
      "source": 570,
      "target": 1150
    },
    {
      "source": 570,
      "target": 1778
    },
    {
      "source": 571,
      "target": 570
    },
    {
      "source": 572,
      "target": 570
    },
    {
      "source": 573,
      "target": 570
    },
    {
      "source": 573,
      "target": 731
    },
    {
      "source": 573,
      "target": 1150
    },
    {
      "source": 573,
      "target": 1386
    },
    {
      "source": 574,
      "target": 570
    },
    {
      "source": 574,
      "target": 731
    },
    {
      "source": 574,
      "target": 1150
    },
    {
      "source": 575,
      "target": 570
    },
    {
      "source": 575,
      "target": 1004
    },
    {
      "source": 576,
      "target": 570
    },
    {
      "source": 577,
      "target": 570
    },
    {
      "source": 577,
      "target": 731
    },
    {
      "source": 578,
      "target": 570
    },
    {
      "source": 578,
      "target": 731
    },
    {
      "source": 578,
      "target": 880
    },
    {
      "source": 579,
      "target": 570
    },
    {
      "source": 579,
      "target": 880
    },
    {
      "source": 580,
      "target": 570
    },
    {
      "source": 581,
      "target": 570
    },
    {
      "source": 582,
      "target": 570
    },
    {
      "source": 582,
      "target": 880
    },
    {
      "source": 583,
      "target": 570
    },
    {
      "source": 584,
      "target": 570
    },
    {
      "source": 585,
      "target": 570
    },
    {
      "source": 585,
      "target": 304
    },
    {
      "source": 585,
      "target": 880
    },
    {
      "source": 586,
      "target": 570
    },
    {
      "source": 586,
      "target": 880
    },
    {
      "source": 587,
      "target": 570
    },
    {
      "source": 588,
      "target": 570
    },
    {
      "source": 589,
      "target": 570
    },
    {
      "source": 589,
      "target": 880
    },
    {
      "source": 590,
      "target": 570
    },
    {
      "source": 590,
      "target": 880
    },
    {
      "source": 591,
      "target": 570
    },
    {
      "source": 591,
      "target": 880
    },
    {
      "source": 592,
      "target": 570
    },
    {
      "source": 593,
      "target": 570
    },
    {
      "source": 594,
      "target": 570
    },
    {
      "source": 595,
      "target": 570
    },
    {
      "source": 595,
      "target": 522
    },
    {
      "source": 596,
      "target": 570
    },
    {
      "source": 597,
      "target": 570
    },
    {
      "source": 598,
      "target": 570
    },
    {
      "source": 598,
      "target": 880
    },
    {
      "source": 599,
      "target": 570
    },
    {
      "source": 600,
      "target": 570
    },
    {
      "source": 601,
      "target": 570
    },
    {
      "source": 602,
      "target": 570
    },
    {
      "source": 603,
      "target": 570
    },
    {
      "source": 603,
      "target": 522
    },
    {
      "source": 604,
      "target": 570
    },
    {
      "source": 605,
      "target": 570
    },
    {
      "source": 606,
      "target": 570
    },
    {
      "source": 607,
      "target": 570
    },
    {
      "source": 608,
      "target": 570
    },
    {
      "source": 609,
      "target": 570
    },
    {
      "source": 609,
      "target": 522
    },
    {
      "source": 610,
      "target": 570
    },
    {
      "source": 611,
      "target": 570
    },
    {
      "source": 612,
      "target": 570
    },
    {
      "source": 613,
      "target": 570
    },
    {
      "source": 614,
      "target": 570
    },
    {
      "source": 615,
      "target": 570
    },
    {
      "source": 616,
      "target": 570
    },
    {
      "source": 617,
      "target": 570
    },
    {
      "source": 618,
      "target": 570
    },
    {
      "source": 619,
      "target": 570
    },
    {
      "source": 620,
      "target": 570
    },
    {
      "source": 621,
      "target": 570
    },
    {
      "source": 622,
      "target": 570
    },
    {
      "source": 623,
      "target": 570
    },
    {
      "source": 624,
      "target": 570
    },
    {
      "source": 625,
      "target": 570
    },
    {
      "source": 626,
      "target": 570
    },
    {
      "source": 627,
      "target": 570
    },
    {
      "source": 628,
      "target": 570
    },
    {
      "source": 629,
      "target": 570
    },
    {
      "source": 630,
      "target": 570
    },
    {
      "source": 631,
      "target": 570
    },
    {
      "source": 632,
      "target": 570
    },
    {
      "source": 633,
      "target": 570
    },
    {
      "source": 634,
      "target": 570
    },
    {
      "source": 635,
      "target": 570
    },
    {
      "source": 636,
      "target": 570
    },
    {
      "source": 637,
      "target": 570
    },
    {
      "source": 638,
      "target": 570
    },
    {
      "source": 638,
      "target": 531
    },
    {
      "source": 639,
      "target": 570
    },
    {
      "source": 640,
      "target": 570
    },
    {
      "source": 641,
      "target": 570
    },
    {
      "source": 642,
      "target": 570
    },
    {
      "source": 643,
      "target": 570
    },
    {
      "source": 644,
      "target": 570
    },
    {
      "source": 645,
      "target": 570
    },
    {
      "source": 646,
      "target": 570
    },
    {
      "source": 647,
      "target": 570
    },
    {
      "source": 648,
      "target": 570
    },
    {
      "source": 649,
      "target": 570
    },
    {
      "source": 650,
      "target": 304
    },
    {
      "source": 651,
      "target": 304
    },
    {
      "source": 651,
      "target": 731
    },
    {
      "source": 651,
      "target": 880
    },
    {
      "source": 651,
      "target": 1386
    },
    {
      "source": 652,
      "target": 304
    },
    {
      "source": 653,
      "target": 304
    },
    {
      "source": 654,
      "target": 304
    },
    {
      "source": 655,
      "target": 304
    },
    {
      "source": 656,
      "target": 304
    },
    {
      "source": 657,
      "target": 304
    },
    {
      "source": 658,
      "target": 304
    },
    {
      "source": 659,
      "target": 304
    },
    {
      "source": 660,
      "target": 304
    },
    {
      "source": 661,
      "target": 304
    },
    {
      "source": 662,
      "target": 304
    },
    {
      "source": 663,
      "target": 304
    },
    {
      "source": 664,
      "target": 304
    },
    {
      "source": 665,
      "target": 304
    },
    {
      "source": 666,
      "target": 304
    },
    {
      "source": 667,
      "target": 304
    },
    {
      "source": 668,
      "target": 304
    },
    {
      "source": 669,
      "target": 304
    },
    {
      "source": 670,
      "target": 304
    },
    {
      "source": 671,
      "target": 304
    },
    {
      "source": 672,
      "target": 304
    },
    {
      "source": 673,
      "target": 304
    },
    {
      "source": 674,
      "target": 304
    },
    {
      "source": 675,
      "target": 304
    },
    {
      "source": 676,
      "target": 304
    },
    {
      "source": 677,
      "target": 304
    },
    {
      "source": 677,
      "target": 9
    },
    {
      "source": 678,
      "target": 304
    },
    {
      "source": 679,
      "target": 304
    },
    {
      "source": 679,
      "target": 531
    },
    {
      "source": 680,
      "target": 304
    },
    {
      "source": 681,
      "target": 304
    },
    {
      "source": 681,
      "target": 531
    },
    {
      "source": 682,
      "target": 304
    },
    {
      "source": 683,
      "target": 304
    },
    {
      "source": 684,
      "target": 304
    },
    {
      "source": 685,
      "target": 304
    },
    {
      "source": 686,
      "target": 304
    },
    {
      "source": 687,
      "target": 304
    },
    {
      "source": 688,
      "target": 304
    },
    {
      "source": 689,
      "target": 304
    },
    {
      "source": 690,
      "target": 304
    },
    {
      "source": 691,
      "target": 304
    },
    {
      "source": 692,
      "target": 304
    },
    {
      "source": 693,
      "target": 304
    },
    {
      "source": 694,
      "target": 304
    },
    {
      "source": 695,
      "target": 304
    },
    {
      "source": 696,
      "target": 304
    },
    {
      "source": 697,
      "target": 304
    },
    {
      "source": 698,
      "target": 304
    },
    {
      "source": 699,
      "target": 304
    },
    {
      "source": 700,
      "target": 304
    },
    {
      "source": 701,
      "target": 304
    },
    {
      "source": 702,
      "target": 304
    },
    {
      "source": 703,
      "target": 304
    },
    {
      "source": 704,
      "target": 304
    },
    {
      "source": 704,
      "target": 531
    },
    {
      "source": 705,
      "target": 304
    },
    {
      "source": 706,
      "target": 304
    },
    {
      "source": 707,
      "target": 304
    },
    {
      "source": 708,
      "target": 304
    },
    {
      "source": 708,
      "target": 531
    },
    {
      "source": 709,
      "target": 304
    },
    {
      "source": 710,
      "target": 304
    },
    {
      "source": 711,
      "target": 304
    },
    {
      "source": 712,
      "target": 304
    },
    {
      "source": 713,
      "target": 304
    },
    {
      "source": 714,
      "target": 304
    },
    {
      "source": 715,
      "target": 304
    },
    {
      "source": 716,
      "target": 304
    },
    {
      "source": 717,
      "target": 304
    },
    {
      "source": 718,
      "target": 304
    },
    {
      "source": 719,
      "target": 304
    },
    {
      "source": 719,
      "target": 531
    },
    {
      "source": 720,
      "target": 304
    },
    {
      "source": 721,
      "target": 304
    },
    {
      "source": 722,
      "target": 304
    },
    {
      "source": 722,
      "target": 531
    },
    {
      "source": 723,
      "target": 304
    },
    {
      "source": 724,
      "target": 304
    },
    {
      "source": 725,
      "target": 304
    },
    {
      "source": 726,
      "target": 304
    },
    {
      "source": 727,
      "target": 304
    },
    {
      "source": 728,
      "target": 304
    },
    {
      "source": 729,
      "target": 304
    },
    {
      "source": 730,
      "target": 304
    },
    {
      "source": 731,
      "target": 1
    },
    {
      "source": 731,
      "target": 880
    },
    {
      "source": 731,
      "target": 1145
    },
    {
      "source": 731,
      "target": 1150
    },
    {
      "source": 731,
      "target": 1386
    },
    {
      "source": 731,
      "target": 1778
    },
    {
      "source": 732,
      "target": 731
    },
    {
      "source": 733,
      "target": 731
    },
    {
      "source": 734,
      "target": 731
    },
    {
      "source": 735,
      "target": 731
    },
    {
      "source": 736,
      "target": 731
    },
    {
      "source": 736,
      "target": 1570
    },
    {
      "source": 737,
      "target": 731
    },
    {
      "source": 738,
      "target": 731
    },
    {
      "source": 739,
      "target": 731
    },
    {
      "source": 739,
      "target": 1570
    },
    {
      "source": 739,
      "target": 1778
    },
    {
      "source": 740,
      "target": 731
    },
    {
      "source": 740,
      "target": 1145
    },
    {
      "source": 740,
      "target": 1778
    },
    {
      "source": 741,
      "target": 731
    },
    {
      "source": 741,
      "target": 1570
    },
    {
      "source": 742,
      "target": 731
    },
    {
      "source": 743,
      "target": 731
    },
    {
      "source": 744,
      "target": 731
    },
    {
      "source": 744,
      "target": 880
    },
    {
      "source": 744,
      "target": 1145
    },
    {
      "source": 744,
      "target": 1150
    },
    {
      "source": 744,
      "target": 1386
    },
    {
      "source": 744,
      "target": 1778
    },
    {
      "source": 745,
      "target": 731
    },
    {
      "source": 746,
      "target": 731
    },
    {
      "source": 746,
      "target": 880
    },
    {
      "source": 746,
      "target": 1145
    },
    {
      "source": 746,
      "target": 1778
    },
    {
      "source": 747,
      "target": 731
    },
    {
      "source": 747,
      "target": 880
    },
    {
      "source": 747,
      "target": 1145
    },
    {
      "source": 747,
      "target": 1386
    },
    {
      "source": 748,
      "target": 731
    },
    {
      "source": 749,
      "target": 731
    },
    {
      "source": 750,
      "target": 731
    },
    {
      "source": 750,
      "target": 1145
    },
    {
      "source": 751,
      "target": 731
    },
    {
      "source": 751,
      "target": 527
    },
    {
      "source": 752,
      "target": 731
    },
    {
      "source": 753,
      "target": 731
    },
    {
      "source": 754,
      "target": 731
    },
    {
      "source": 754,
      "target": 880
    },
    {
      "source": 754,
      "target": 1386
    },
    {
      "source": 754,
      "target": 1570
    },
    {
      "source": 755,
      "target": 731
    },
    {
      "source": 756,
      "target": 731
    },
    {
      "source": 756,
      "target": 1570
    },
    {
      "source": 757,
      "target": 731
    },
    {
      "source": 757,
      "target": 1570
    },
    {
      "source": 758,
      "target": 731
    },
    {
      "source": 758,
      "target": 880
    },
    {
      "source": 758,
      "target": 1386
    },
    {
      "source": 759,
      "target": 731
    },
    {
      "source": 760,
      "target": 731
    },
    {
      "source": 760,
      "target": 1060
    },
    {
      "source": 761,
      "target": 731
    },
    {
      "source": 762,
      "target": 731
    },
    {
      "source": 762,
      "target": 880
    },
    {
      "source": 762,
      "target": 1386
    },
    {
      "source": 763,
      "target": 731
    },
    {
      "source": 763,
      "target": 1386
    },
    {
      "source": 764,
      "target": 731
    },
    {
      "source": 764,
      "target": 880
    },
    {
      "source": 765,
      "target": 731
    },
    {
      "source": 765,
      "target": 880
    },
    {
      "source": 765,
      "target": 1386
    },
    {
      "source": 766,
      "target": 731
    },
    {
      "source": 766,
      "target": 880
    },
    {
      "source": 767,
      "target": 731
    },
    {
      "source": 768,
      "target": 731
    },
    {
      "source": 769,
      "target": 731
    },
    {
      "source": 770,
      "target": 731
    },
    {
      "source": 770,
      "target": 531
    },
    {
      "source": 771,
      "target": 731
    },
    {
      "source": 772,
      "target": 731
    },
    {
      "source": 772,
      "target": 1570
    },
    {
      "source": 773,
      "target": 731
    },
    {
      "source": 773,
      "target": 522
    },
    {
      "source": 774,
      "target": 731
    },
    {
      "source": 775,
      "target": 731
    },
    {
      "source": 775,
      "target": 880
    },
    {
      "source": 775,
      "target": 1570
    },
    {
      "source": 776,
      "target": 731
    },
    {
      "source": 776,
      "target": 522
    },
    {
      "source": 776,
      "target": 1386
    },
    {
      "source": 777,
      "target": 731
    },
    {
      "source": 777,
      "target": 1570
    },
    {
      "source": 778,
      "target": 731
    },
    {
      "source": 779,
      "target": 731
    },
    {
      "source": 780,
      "target": 731
    },
    {
      "source": 780,
      "target": 1570
    },
    {
      "source": 781,
      "target": 731
    },
    {
      "source": 782,
      "target": 731
    },
    {
      "source": 782,
      "target": 1570
    },
    {
      "source": 783,
      "target": 731
    },
    {
      "source": 784,
      "target": 731
    },
    {
      "source": 785,
      "target": 731
    },
    {
      "source": 786,
      "target": 731
    },
    {
      "source": 786,
      "target": 880
    },
    {
      "source": 786,
      "target": 1386
    },
    {
      "source": 787,
      "target": 731
    },
    {
      "source": 788,
      "target": 731
    },
    {
      "source": 789,
      "target": 731
    },
    {
      "source": 789,
      "target": 880
    },
    {
      "source": 790,
      "target": 731
    },
    {
      "source": 791,
      "target": 731
    },
    {
      "source": 791,
      "target": 1150
    },
    {
      "source": 792,
      "target": 731
    },
    {
      "source": 793,
      "target": 731
    },
    {
      "source": 793,
      "target": 1570
    },
    {
      "source": 794,
      "target": 731
    },
    {
      "source": 795,
      "target": 731
    },
    {
      "source": 795,
      "target": 880
    },
    {
      "source": 795,
      "target": 1570
    },
    {
      "source": 796,
      "target": 731
    },
    {
      "source": 797,
      "target": 731
    },
    {
      "source": 798,
      "target": 731
    },
    {
      "source": 799,
      "target": 731
    },
    {
      "source": 799,
      "target": 880
    },
    {
      "source": 800,
      "target": 731
    },
    {
      "source": 800,
      "target": 1150
    },
    {
      "source": 801,
      "target": 731
    },
    {
      "source": 802,
      "target": 731
    },
    {
      "source": 802,
      "target": 880
    },
    {
      "source": 803,
      "target": 731
    },
    {
      "source": 804,
      "target": 731
    },
    {
      "source": 805,
      "target": 522
    },
    {
      "source": 806,
      "target": 522
    },
    {
      "source": 806,
      "target": 1150
    },
    {
      "source": 807,
      "target": 522
    },
    {
      "source": 808,
      "target": 522
    },
    {
      "source": 808,
      "target": 1778
    },
    {
      "source": 809,
      "target": 522
    },
    {
      "source": 809,
      "target": 1386
    },
    {
      "source": 810,
      "target": 522
    },
    {
      "source": 810,
      "target": 1413
    },
    {
      "source": 811,
      "target": 522
    },
    {
      "source": 811,
      "target": 1145
    },
    {
      "source": 811,
      "target": 1150
    },
    {
      "source": 812,
      "target": 522
    },
    {
      "source": 812,
      "target": 1145
    },
    {
      "source": 812,
      "target": 531
    },
    {
      "source": 812,
      "target": 1150
    },
    {
      "source": 813,
      "target": 522
    },
    {
      "source": 814,
      "target": 522
    },
    {
      "source": 815,
      "target": 522
    },
    {
      "source": 815,
      "target": 1145
    },
    {
      "source": 816,
      "target": 522
    },
    {
      "source": 817,
      "target": 522
    },
    {
      "source": 817,
      "target": 1004
    },
    {
      "source": 818,
      "target": 522
    },
    {
      "source": 819,
      "target": 522
    },
    {
      "source": 820,
      "target": 522
    },
    {
      "source": 820,
      "target": 1150
    },
    {
      "source": 821,
      "target": 522
    },
    {
      "source": 822,
      "target": 522
    },
    {
      "source": 822,
      "target": 1150
    },
    {
      "source": 822,
      "target": 1386
    },
    {
      "source": 823,
      "target": 522
    },
    {
      "source": 824,
      "target": 522
    },
    {
      "source": 824,
      "target": 1150
    },
    {
      "source": 824,
      "target": 1386
    },
    {
      "source": 825,
      "target": 522
    },
    {
      "source": 826,
      "target": 522
    },
    {
      "source": 826,
      "target": 531
    },
    {
      "source": 827,
      "target": 522
    },
    {
      "source": 828,
      "target": 522
    },
    {
      "source": 828,
      "target": 527
    },
    {
      "source": 829,
      "target": 522
    },
    {
      "source": 830,
      "target": 522
    },
    {
      "source": 831,
      "target": 522
    },
    {
      "source": 831,
      "target": 1150
    },
    {
      "source": 832,
      "target": 522
    },
    {
      "source": 833,
      "target": 522
    },
    {
      "source": 834,
      "target": 522
    },
    {
      "source": 835,
      "target": 522
    },
    {
      "source": 835,
      "target": 1150
    },
    {
      "source": 836,
      "target": 522
    },
    {
      "source": 837,
      "target": 522
    },
    {
      "source": 837,
      "target": 531
    },
    {
      "source": 837,
      "target": 1150
    },
    {
      "source": 838,
      "target": 522
    },
    {
      "source": 839,
      "target": 522
    },
    {
      "source": 840,
      "target": 522
    },
    {
      "source": 840,
      "target": 1150
    },
    {
      "source": 841,
      "target": 522
    },
    {
      "source": 841,
      "target": 880
    },
    {
      "source": 842,
      "target": 522
    },
    {
      "source": 843,
      "target": 522
    },
    {
      "source": 843,
      "target": 1150
    },
    {
      "source": 844,
      "target": 522
    },
    {
      "source": 845,
      "target": 522
    },
    {
      "source": 846,
      "target": 522
    },
    {
      "source": 847,
      "target": 522
    },
    {
      "source": 848,
      "target": 522
    },
    {
      "source": 849,
      "target": 522
    },
    {
      "source": 850,
      "target": 522
    },
    {
      "source": 851,
      "target": 522
    },
    {
      "source": 852,
      "target": 522
    },
    {
      "source": 852,
      "target": 531
    },
    {
      "source": 853,
      "target": 522
    },
    {
      "source": 854,
      "target": 522
    },
    {
      "source": 855,
      "target": 522
    },
    {
      "source": 856,
      "target": 522
    },
    {
      "source": 857,
      "target": 522
    },
    {
      "source": 858,
      "target": 522
    },
    {
      "source": 858,
      "target": 531
    },
    {
      "source": 859,
      "target": 522
    },
    {
      "source": 860,
      "target": 522
    },
    {
      "source": 861,
      "target": 522
    },
    {
      "source": 862,
      "target": 522
    },
    {
      "source": 863,
      "target": 522
    },
    {
      "source": 863,
      "target": 1413
    },
    {
      "source": 864,
      "target": 522
    },
    {
      "source": 865,
      "target": 522
    },
    {
      "source": 865,
      "target": 531
    },
    {
      "source": 866,
      "target": 522
    },
    {
      "source": 867,
      "target": 522
    },
    {
      "source": 868,
      "target": 522
    },
    {
      "source": 869,
      "target": 522
    },
    {
      "source": 869,
      "target": 305
    },
    {
      "source": 870,
      "target": 522
    },
    {
      "source": 871,
      "target": 522
    },
    {
      "source": 872,
      "target": 522
    },
    {
      "source": 873,
      "target": 522
    },
    {
      "source": 873,
      "target": 527
    },
    {
      "source": 874,
      "target": 522
    },
    {
      "source": 875,
      "target": 522
    },
    {
      "source": 876,
      "target": 522
    },
    {
      "source": 877,
      "target": 522
    },
    {
      "source": 878,
      "target": 522
    },
    {
      "source": 879,
      "target": 522
    },
    {
      "source": 880,
      "target": 1
    },
    {
      "source": 880,
      "target": 1145
    },
    {
      "source": 880,
      "target": 1386
    },
    {
      "source": 880,
      "target": 1778
    },
    {
      "source": 881,
      "target": 880
    },
    {
      "source": 882,
      "target": 880
    },
    {
      "source": 882,
      "target": 1386
    },
    {
      "source": 883,
      "target": 880
    },
    {
      "source": 883,
      "target": 1386
    },
    {
      "source": 883,
      "target": 1570
    },
    {
      "source": 883,
      "target": 1778
    },
    {
      "source": 884,
      "target": 880
    },
    {
      "source": 884,
      "target": 1150
    },
    {
      "source": 884,
      "target": 1386
    },
    {
      "source": 885,
      "target": 880
    },
    {
      "source": 885,
      "target": 1145
    },
    {
      "source": 885,
      "target": 1150
    },
    {
      "source": 885,
      "target": 1386
    },
    {
      "source": 886,
      "target": 880
    },
    {
      "source": 886,
      "target": 1386
    },
    {
      "source": 887,
      "target": 880
    },
    {
      "source": 887,
      "target": 1145
    },
    {
      "source": 887,
      "target": 1386
    },
    {
      "source": 888,
      "target": 880
    },
    {
      "source": 888,
      "target": 1386
    },
    {
      "source": 888,
      "target": 1778
    },
    {
      "source": 889,
      "target": 880
    },
    {
      "source": 890,
      "target": 880
    },
    {
      "source": 891,
      "target": 880
    },
    {
      "source": 892,
      "target": 880
    },
    {
      "source": 893,
      "target": 880
    },
    {
      "source": 894,
      "target": 880
    },
    {
      "source": 895,
      "target": 880
    },
    {
      "source": 896,
      "target": 880
    },
    {
      "source": 897,
      "target": 880
    },
    {
      "source": 898,
      "target": 880
    },
    {
      "source": 899,
      "target": 880
    },
    {
      "source": 900,
      "target": 880
    },
    {
      "source": 901,
      "target": 880
    },
    {
      "source": 902,
      "target": 880
    },
    {
      "source": 903,
      "target": 880
    },
    {
      "source": 904,
      "target": 880
    },
    {
      "source": 905,
      "target": 880
    },
    {
      "source": 905,
      "target": 1150
    },
    {
      "source": 906,
      "target": 880
    },
    {
      "source": 907,
      "target": 880
    },
    {
      "source": 908,
      "target": 880
    },
    {
      "source": 909,
      "target": 880
    },
    {
      "source": 910,
      "target": 880
    },
    {
      "source": 911,
      "target": 880
    },
    {
      "source": 912,
      "target": 880
    },
    {
      "source": 913,
      "target": 880
    },
    {
      "source": 914,
      "target": 880
    },
    {
      "source": 915,
      "target": 880
    },
    {
      "source": 916,
      "target": 880
    },
    {
      "source": 917,
      "target": 880
    },
    {
      "source": 918,
      "target": 880
    },
    {
      "source": 919,
      "target": 880
    },
    {
      "source": 920,
      "target": 880
    },
    {
      "source": 921,
      "target": 880
    },
    {
      "source": 922,
      "target": 880
    },
    {
      "source": 923,
      "target": 880
    },
    {
      "source": 924,
      "target": 880
    },
    {
      "source": 925,
      "target": 880
    },
    {
      "source": 926,
      "target": 880
    },
    {
      "source": 927,
      "target": 880
    },
    {
      "source": 928,
      "target": 880
    },
    {
      "source": 929,
      "target": 880
    },
    {
      "source": 930,
      "target": 527
    },
    {
      "source": 931,
      "target": 527
    },
    {
      "source": 932,
      "target": 527
    },
    {
      "source": 932,
      "target": 1145
    },
    {
      "source": 933,
      "target": 527
    },
    {
      "source": 934,
      "target": 527
    },
    {
      "source": 935,
      "target": 527
    },
    {
      "source": 936,
      "target": 527
    },
    {
      "source": 937,
      "target": 527
    },
    {
      "source": 937,
      "target": 1150
    },
    {
      "source": 937,
      "target": 1386
    },
    {
      "source": 938,
      "target": 527
    },
    {
      "source": 939,
      "target": 527
    },
    {
      "source": 940,
      "target": 527
    },
    {
      "source": 940,
      "target": 1004
    },
    {
      "source": 941,
      "target": 527
    },
    {
      "source": 942,
      "target": 527
    },
    {
      "source": 943,
      "target": 527
    },
    {
      "source": 943,
      "target": 1150
    },
    {
      "source": 944,
      "target": 527
    },
    {
      "source": 945,
      "target": 527
    },
    {
      "source": 946,
      "target": 527
    },
    {
      "source": 947,
      "target": 527
    },
    {
      "source": 948,
      "target": 527
    },
    {
      "source": 949,
      "target": 527
    },
    {
      "source": 950,
      "target": 527
    },
    {
      "source": 951,
      "target": 527
    },
    {
      "source": 952,
      "target": 527
    },
    {
      "source": 953,
      "target": 527
    },
    {
      "source": 954,
      "target": 527
    },
    {
      "source": 955,
      "target": 527
    },
    {
      "source": 956,
      "target": 527
    },
    {
      "source": 957,
      "target": 527
    },
    {
      "source": 958,
      "target": 527
    },
    {
      "source": 959,
      "target": 527
    },
    {
      "source": 960,
      "target": 527
    },
    {
      "source": 961,
      "target": 527
    },
    {
      "source": 962,
      "target": 527
    },
    {
      "source": 963,
      "target": 527
    },
    {
      "source": 964,
      "target": 527
    },
    {
      "source": 965,
      "target": 527
    },
    {
      "source": 966,
      "target": 527
    },
    {
      "source": 967,
      "target": 527
    },
    {
      "source": 968,
      "target": 527
    },
    {
      "source": 969,
      "target": 527
    },
    {
      "source": 970,
      "target": 527
    },
    {
      "source": 971,
      "target": 527
    },
    {
      "source": 972,
      "target": 527
    },
    {
      "source": 973,
      "target": 527
    },
    {
      "source": 973,
      "target": 1413
    },
    {
      "source": 974,
      "target": 527
    },
    {
      "source": 975,
      "target": 527
    },
    {
      "source": 976,
      "target": 527
    },
    {
      "source": 977,
      "target": 527
    },
    {
      "source": 978,
      "target": 527
    },
    {
      "source": 979,
      "target": 527
    },
    {
      "source": 980,
      "target": 527
    },
    {
      "source": 981,
      "target": 527
    },
    {
      "source": 982,
      "target": 527
    },
    {
      "source": 983,
      "target": 527
    },
    {
      "source": 984,
      "target": 527
    },
    {
      "source": 985,
      "target": 527
    },
    {
      "source": 986,
      "target": 527
    },
    {
      "source": 987,
      "target": 527
    },
    {
      "source": 988,
      "target": 527
    },
    {
      "source": 989,
      "target": 527
    },
    {
      "source": 990,
      "target": 527
    },
    {
      "source": 991,
      "target": 527
    },
    {
      "source": 992,
      "target": 527
    },
    {
      "source": 993,
      "target": 527
    },
    {
      "source": 994,
      "target": 527
    },
    {
      "source": 995,
      "target": 527
    },
    {
      "source": 996,
      "target": 527
    },
    {
      "source": 997,
      "target": 527
    },
    {
      "source": 998,
      "target": 527
    },
    {
      "source": 999,
      "target": 527
    },
    {
      "source": 1000,
      "target": 527
    },
    {
      "source": 1001,
      "target": 527
    },
    {
      "source": 1002,
      "target": 527
    },
    {
      "source": 1003,
      "target": 527
    },
    {
      "source": 1004,
      "target": 1
    },
    {
      "source": 1005,
      "target": 1004
    },
    {
      "source": 1006,
      "target": 1004
    },
    {
      "source": 1007,
      "target": 1004
    },
    {
      "source": 1008,
      "target": 1004
    },
    {
      "source": 1009,
      "target": 1004
    },
    {
      "source": 1010,
      "target": 1004
    },
    {
      "source": 1011,
      "target": 1004
    },
    {
      "source": 1012,
      "target": 1004
    },
    {
      "source": 1013,
      "target": 1004
    },
    {
      "source": 1014,
      "target": 1004
    },
    {
      "source": 1015,
      "target": 1004
    },
    {
      "source": 1016,
      "target": 1004
    },
    {
      "source": 1017,
      "target": 1004
    },
    {
      "source": 1018,
      "target": 1004
    },
    {
      "source": 1019,
      "target": 1004
    },
    {
      "source": 1020,
      "target": 1004
    },
    {
      "source": 1021,
      "target": 1004
    },
    {
      "source": 1022,
      "target": 1004
    },
    {
      "source": 1023,
      "target": 1004
    },
    {
      "source": 1024,
      "target": 1004
    },
    {
      "source": 1025,
      "target": 1004
    },
    {
      "source": 1026,
      "target": 1004
    },
    {
      "source": 1027,
      "target": 1004
    },
    {
      "source": 1028,
      "target": 1004
    },
    {
      "source": 1029,
      "target": 1004
    },
    {
      "source": 1030,
      "target": 1004
    },
    {
      "source": 1031,
      "target": 1004
    },
    {
      "source": 1032,
      "target": 1004
    },
    {
      "source": 1033,
      "target": 1004
    },
    {
      "source": 1034,
      "target": 1004
    },
    {
      "source": 1035,
      "target": 1004
    },
    {
      "source": 1036,
      "target": 1004
    },
    {
      "source": 1037,
      "target": 1004
    },
    {
      "source": 1038,
      "target": 1004
    },
    {
      "source": 1039,
      "target": 1004
    },
    {
      "source": 1040,
      "target": 1004
    },
    {
      "source": 1041,
      "target": 1004
    },
    {
      "source": 1042,
      "target": 1004
    },
    {
      "source": 1043,
      "target": 1004
    },
    {
      "source": 1044,
      "target": 1004
    },
    {
      "source": 1045,
      "target": 1004
    },
    {
      "source": 1046,
      "target": 1004
    },
    {
      "source": 1047,
      "target": 1004
    },
    {
      "source": 1048,
      "target": 1004
    },
    {
      "source": 1049,
      "target": 1004
    },
    {
      "source": 1050,
      "target": 1004
    },
    {
      "source": 1051,
      "target": 1004
    },
    {
      "source": 1052,
      "target": 1004
    },
    {
      "source": 1053,
      "target": 1004
    },
    {
      "source": 1054,
      "target": 1004
    },
    {
      "source": 1055,
      "target": 1004
    },
    {
      "source": 1056,
      "target": 1004
    },
    {
      "source": 1057,
      "target": 1004
    },
    {
      "source": 1058,
      "target": 1004
    },
    {
      "source": 1059,
      "target": 1004
    },
    {
      "source": 1060,
      "target": 1
    },
    {
      "source": 1061,
      "target": 1060
    },
    {
      "source": 1062,
      "target": 1060
    },
    {
      "source": 1062,
      "target": 1494
    },
    {
      "source": 1063,
      "target": 1060
    },
    {
      "source": 1064,
      "target": 1060
    },
    {
      "source": 1065,
      "target": 1060
    },
    {
      "source": 1066,
      "target": 1060
    },
    {
      "source": 1067,
      "target": 1060
    },
    {
      "source": 1068,
      "target": 1060
    },
    {
      "source": 1069,
      "target": 1060
    },
    {
      "source": 1070,
      "target": 1060
    },
    {
      "source": 1070,
      "target": 1386
    },
    {
      "source": 1070,
      "target": 1778
    },
    {
      "source": 1071,
      "target": 1060
    },
    {
      "source": 1072,
      "target": 1060
    },
    {
      "source": 1073,
      "target": 1060
    },
    {
      "source": 1074,
      "target": 1060
    },
    {
      "source": 1075,
      "target": 1060
    },
    {
      "source": 1076,
      "target": 1060
    },
    {
      "source": 1077,
      "target": 1060
    },
    {
      "source": 1078,
      "target": 1060
    },
    {
      "source": 1079,
      "target": 1060
    },
    {
      "source": 1080,
      "target": 1060
    },
    {
      "source": 1081,
      "target": 1060
    },
    {
      "source": 1082,
      "target": 1060
    },
    {
      "source": 1083,
      "target": 1060
    },
    {
      "source": 1084,
      "target": 1060
    },
    {
      "source": 1085,
      "target": 1060
    },
    {
      "source": 1086,
      "target": 1060
    },
    {
      "source": 1087,
      "target": 1060
    },
    {
      "source": 1088,
      "target": 1060
    },
    {
      "source": 1089,
      "target": 1060
    },
    {
      "source": 1090,
      "target": 1060
    },
    {
      "source": 1091,
      "target": 1060
    },
    {
      "source": 1092,
      "target": 1060
    },
    {
      "source": 1093,
      "target": 1060
    },
    {
      "source": 1094,
      "target": 1060
    },
    {
      "source": 1095,
      "target": 1060
    },
    {
      "source": 1096,
      "target": 1060
    },
    {
      "source": 1097,
      "target": 1060
    },
    {
      "source": 1098,
      "target": 1060
    },
    {
      "source": 1099,
      "target": 1060
    },
    {
      "source": 1100,
      "target": 1060
    },
    {
      "source": 1101,
      "target": 1060
    },
    {
      "source": 1102,
      "target": 1060
    },
    {
      "source": 1103,
      "target": 1060
    },
    {
      "source": 1104,
      "target": 1060
    },
    {
      "source": 1105,
      "target": 1060
    },
    {
      "source": 1106,
      "target": 1060
    },
    {
      "source": 1107,
      "target": 1060
    },
    {
      "source": 1108,
      "target": 1060
    },
    {
      "source": 1109,
      "target": 1060
    },
    {
      "source": 1110,
      "target": 1060
    },
    {
      "source": 1111,
      "target": 1060
    },
    {
      "source": 1112,
      "target": 1060
    },
    {
      "source": 1113,
      "target": 1060
    },
    {
      "source": 1114,
      "target": 1060
    },
    {
      "source": 1115,
      "target": 1060
    },
    {
      "source": 1116,
      "target": 1060
    },
    {
      "source": 1117,
      "target": 1060
    },
    {
      "source": 1118,
      "target": 1060
    },
    {
      "source": 1119,
      "target": 1060
    },
    {
      "source": 1120,
      "target": 1060
    },
    {
      "source": 1121,
      "target": 1060
    },
    {
      "source": 1122,
      "target": 1060
    },
    {
      "source": 1123,
      "target": 1060
    },
    {
      "source": 1124,
      "target": 1060
    },
    {
      "source": 1125,
      "target": 1060
    },
    {
      "source": 1126,
      "target": 1060
    },
    {
      "source": 1127,
      "target": 1060
    },
    {
      "source": 1128,
      "target": 1060
    },
    {
      "source": 1129,
      "target": 1060
    },
    {
      "source": 1130,
      "target": 1060
    },
    {
      "source": 1131,
      "target": 1060
    },
    {
      "source": 1132,
      "target": 1060
    },
    {
      "source": 1133,
      "target": 1060
    },
    {
      "source": 1134,
      "target": 1060
    },
    {
      "source": 1135,
      "target": 1060
    },
    {
      "source": 1136,
      "target": 1060
    },
    {
      "source": 1137,
      "target": 1060
    },
    {
      "source": 1138,
      "target": 1060
    },
    {
      "source": 1139,
      "target": 1060
    },
    {
      "source": 1140,
      "target": 1060
    },
    {
      "source": 1141,
      "target": 1060
    },
    {
      "source": 1142,
      "target": 1060
    },
    {
      "source": 1143,
      "target": 1060
    },
    {
      "source": 1144,
      "target": 1060
    },
    {
      "source": 1145,
      "target": 1
    },
    {
      "source": 1145,
      "target": 1778
    },
    {
      "source": 1146,
      "target": 1145
    },
    {
      "source": 1146,
      "target": 1570
    },
    {
      "source": 1146,
      "target": 1778
    },
    {
      "source": 1147,
      "target": 1145
    },
    {
      "source": 1148,
      "target": 1145
    },
    {
      "source": 1148,
      "target": 1778
    },
    {
      "source": 1149,
      "target": 1145
    },
    {
      "source": 1149,
      "target": 1778
    },
    {
      "source": 1150,
      "target": 1145
    },
    {
      "source": 1150,
      "target": 1
    },
    {
      "source": 1150,
      "target": 1386
    },
    {
      "source": 1150,
      "target": 1778
    },
    {
      "source": 1151,
      "target": 1145
    },
    {
      "source": 1151,
      "target": 1778
    },
    {
      "source": 1152,
      "target": 1145
    },
    {
      "source": 1152,
      "target": 1386
    },
    {
      "source": 1153,
      "target": 1145
    },
    {
      "source": 1154,
      "target": 1145
    },
    {
      "source": 1154,
      "target": 1150
    },
    {
      "source": 1155,
      "target": 1145
    },
    {
      "source": 1156,
      "target": 1145
    },
    {
      "source": 1156,
      "target": 1386
    },
    {
      "source": 1156,
      "target": 1778
    },
    {
      "source": 1157,
      "target": 1145
    },
    {
      "source": 1157,
      "target": 1386
    },
    {
      "source": 1157,
      "target": 1778
    },
    {
      "source": 1158,
      "target": 1145
    },
    {
      "source": 1159,
      "target": 1145
    },
    {
      "source": 1159,
      "target": 1778
    },
    {
      "source": 1160,
      "target": 1145
    },
    {
      "source": 1160,
      "target": 1150
    },
    {
      "source": 1160,
      "target": 1386
    },
    {
      "source": 1160,
      "target": 1778
    },
    {
      "source": 1161,
      "target": 1145
    },
    {
      "source": 1162,
      "target": 1145
    },
    {
      "source": 1162,
      "target": 1778
    },
    {
      "source": 1163,
      "target": 1145
    },
    {
      "source": 1163,
      "target": 1150
    },
    {
      "source": 1163,
      "target": 1386
    },
    {
      "source": 1163,
      "target": 1778
    },
    {
      "source": 1164,
      "target": 1145
    },
    {
      "source": 1164,
      "target": 1778
    },
    {
      "source": 1165,
      "target": 1145
    },
    {
      "source": 1165,
      "target": 1150
    },
    {
      "source": 1165,
      "target": 1386
    },
    {
      "source": 1165,
      "target": 1778
    },
    {
      "source": 1166,
      "target": 1145
    },
    {
      "source": 1167,
      "target": 1145
    },
    {
      "source": 1168,
      "target": 1145
    },
    {
      "source": 1169,
      "target": 1145
    },
    {
      "source": 1169,
      "target": 1778
    },
    {
      "source": 1170,
      "target": 1145
    },
    {
      "source": 1171,
      "target": 1145
    },
    {
      "source": 1172,
      "target": 1145
    },
    {
      "source": 1173,
      "target": 1145
    },
    {
      "source": 1173,
      "target": 1413
    },
    {
      "source": 1174,
      "target": 1145
    },
    {
      "source": 1175,
      "target": 1145
    },
    {
      "source": 1175,
      "target": 1150
    },
    {
      "source": 1175,
      "target": 1386
    },
    {
      "source": 1175,
      "target": 1778
    },
    {
      "source": 1176,
      "target": 1145
    },
    {
      "source": 1177,
      "target": 1145
    },
    {
      "source": 1178,
      "target": 1145
    },
    {
      "source": 1178,
      "target": 1778
    },
    {
      "source": 1179,
      "target": 1145
    },
    {
      "source": 1180,
      "target": 1145
    },
    {
      "source": 1180,
      "target": 1778
    },
    {
      "source": 1181,
      "target": 1145
    },
    {
      "source": 1181,
      "target": 1150
    },
    {
      "source": 1181,
      "target": 1386
    },
    {
      "source": 1182,
      "target": 1145
    },
    {
      "source": 1182,
      "target": 1386
    },
    {
      "source": 1183,
      "target": 1145
    },
    {
      "source": 1183,
      "target": 1778
    },
    {
      "source": 1184,
      "target": 1145
    },
    {
      "source": 1184,
      "target": 1778
    },
    {
      "source": 1185,
      "target": 1145
    },
    {
      "source": 1185,
      "target": 1386
    },
    {
      "source": 1186,
      "target": 1145
    },
    {
      "source": 1187,
      "target": 1145
    },
    {
      "source": 1187,
      "target": 1150
    },
    {
      "source": 1187,
      "target": 1778
    },
    {
      "source": 1188,
      "target": 1145
    },
    {
      "source": 1189,
      "target": 1145
    },
    {
      "source": 1189,
      "target": 1150
    },
    {
      "source": 1190,
      "target": 1145
    },
    {
      "source": 1190,
      "target": 1150
    },
    {
      "source": 1190,
      "target": 1386
    },
    {
      "source": 1190,
      "target": 1778
    },
    {
      "source": 1191,
      "target": 1145
    },
    {
      "source": 1191,
      "target": 1778
    },
    {
      "source": 1192,
      "target": 1145
    },
    {
      "source": 1193,
      "target": 1145
    },
    {
      "source": 1194,
      "target": 1145
    },
    {
      "source": 1194,
      "target": 1778
    },
    {
      "source": 1195,
      "target": 1145
    },
    {
      "source": 1195,
      "target": 1778
    },
    {
      "source": 1196,
      "target": 1145
    },
    {
      "source": 1197,
      "target": 1145
    },
    {
      "source": 1198,
      "target": 1145
    },
    {
      "source": 1198,
      "target": 1150
    },
    {
      "source": 1198,
      "target": 1778
    },
    {
      "source": 1199,
      "target": 1145
    },
    {
      "source": 1199,
      "target": 1150
    },
    {
      "source": 1199,
      "target": 1386
    },
    {
      "source": 1199,
      "target": 1778
    },
    {
      "source": 1200,
      "target": 531
    },
    {
      "source": 1201,
      "target": 531
    },
    {
      "source": 1202,
      "target": 531
    },
    {
      "source": 1203,
      "target": 531
    },
    {
      "source": 1204,
      "target": 531
    },
    {
      "source": 1205,
      "target": 531
    },
    {
      "source": 1206,
      "target": 531
    },
    {
      "source": 1207,
      "target": 531
    },
    {
      "source": 1208,
      "target": 531
    },
    {
      "source": 1209,
      "target": 531
    },
    {
      "source": 1210,
      "target": 531
    },
    {
      "source": 1211,
      "target": 531
    },
    {
      "source": 1212,
      "target": 531
    },
    {
      "source": 1213,
      "target": 531
    },
    {
      "source": 1214,
      "target": 531
    },
    {
      "source": 1215,
      "target": 531
    },
    {
      "source": 1216,
      "target": 531
    },
    {
      "source": 1217,
      "target": 531
    },
    {
      "source": 1218,
      "target": 531
    },
    {
      "source": 1219,
      "target": 531
    },
    {
      "source": 1220,
      "target": 531
    },
    {
      "source": 1221,
      "target": 531
    },
    {
      "source": 1222,
      "target": 531
    },
    {
      "source": 1223,
      "target": 531
    },
    {
      "source": 1224,
      "target": 531
    },
    {
      "source": 1225,
      "target": 531
    },
    {
      "source": 1226,
      "target": 531
    },
    {
      "source": 1227,
      "target": 531
    },
    {
      "source": 1228,
      "target": 531
    },
    {
      "source": 1229,
      "target": 531
    },
    {
      "source": 1230,
      "target": 531
    },
    {
      "source": 1231,
      "target": 531
    },
    {
      "source": 1232,
      "target": 531
    },
    {
      "source": 1233,
      "target": 531
    },
    {
      "source": 1234,
      "target": 531
    },
    {
      "source": 1235,
      "target": 531
    },
    {
      "source": 1236,
      "target": 531
    },
    {
      "source": 1237,
      "target": 531
    },
    {
      "source": 1238,
      "target": 531
    },
    {
      "source": 1239,
      "target": 531
    },
    {
      "source": 1240,
      "target": 531
    },
    {
      "source": 1241,
      "target": 531
    },
    {
      "source": 1242,
      "target": 531
    },
    {
      "source": 1243,
      "target": 531
    },
    {
      "source": 1244,
      "target": 531
    },
    {
      "source": 1245,
      "target": 531
    },
    {
      "source": 1246,
      "target": 531
    },
    {
      "source": 1247,
      "target": 531
    },
    {
      "source": 1248,
      "target": 531
    },
    {
      "source": 1249,
      "target": 531
    },
    {
      "source": 1250,
      "target": 531
    },
    {
      "source": 1251,
      "target": 531
    },
    {
      "source": 1252,
      "target": 531
    },
    {
      "source": 1253,
      "target": 531
    },
    {
      "source": 1254,
      "target": 531
    },
    {
      "source": 1255,
      "target": 531
    },
    {
      "source": 1256,
      "target": 531
    },
    {
      "source": 1257,
      "target": 531
    },
    {
      "source": 1258,
      "target": 531
    },
    {
      "source": 1259,
      "target": 531
    },
    {
      "source": 1260,
      "target": 531
    },
    {
      "source": 1261,
      "target": 531
    },
    {
      "source": 1262,
      "target": 1150
    },
    {
      "source": 1262,
      "target": 1570
    },
    {
      "source": 1262,
      "target": 1778
    },
    {
      "source": 1263,
      "target": 1150
    },
    {
      "source": 1264,
      "target": 1150
    },
    {
      "source": 1265,
      "target": 1150
    },
    {
      "source": 1265,
      "target": 1386
    },
    {
      "source": 1265,
      "target": 1570
    },
    {
      "source": 1266,
      "target": 1150
    },
    {
      "source": 1267,
      "target": 1150
    },
    {
      "source": 1268,
      "target": 1150
    },
    {
      "source": 1269,
      "target": 1150
    },
    {
      "source": 1270,
      "target": 1150
    },
    {
      "source": 1271,
      "target": 1150
    },
    {
      "source": 1271,
      "target": 1386
    },
    {
      "source": 1272,
      "target": 1150
    },
    {
      "source": 1273,
      "target": 1150
    },
    {
      "source": 1273,
      "target": 1386
    },
    {
      "source": 1274,
      "target": 1150
    },
    {
      "source": 1275,
      "target": 1150
    },
    {
      "source": 1276,
      "target": 1150
    },
    {
      "source": 1277,
      "target": 1150
    },
    {
      "source": 1278,
      "target": 1150
    },
    {
      "source": 1279,
      "target": 1150
    },
    {
      "source": 1280,
      "target": 1150
    },
    {
      "source": 1281,
      "target": 1150
    },
    {
      "source": 1282,
      "target": 1150
    },
    {
      "source": 1283,
      "target": 1150
    },
    {
      "source": 1284,
      "target": 1150
    },
    {
      "source": 1285,
      "target": 1150
    },
    {
      "source": 1286,
      "target": 1150
    },
    {
      "source": 1286,
      "target": 1413
    },
    {
      "source": 1287,
      "target": 1150
    },
    {
      "source": 1288,
      "target": 1150
    },
    {
      "source": 1289,
      "target": 1150
    },
    {
      "source": 1290,
      "target": 1150
    },
    {
      "source": 1291,
      "target": 1150
    },
    {
      "source": 1292,
      "target": 1150
    },
    {
      "source": 1293,
      "target": 1150
    },
    {
      "source": 1294,
      "target": 1150
    },
    {
      "source": 1295,
      "target": 1
    },
    {
      "source": 1295,
      "target": 1778
    },
    {
      "source": 1296,
      "target": 1295
    },
    {
      "source": 1297,
      "target": 1295
    },
    {
      "source": 1298,
      "target": 1295
    },
    {
      "source": 1299,
      "target": 1295
    },
    {
      "source": 1300,
      "target": 1295
    },
    {
      "source": 1301,
      "target": 1295
    },
    {
      "source": 1301,
      "target": 1572
    },
    {
      "source": 1302,
      "target": 1295
    },
    {
      "source": 1303,
      "target": 1295
    },
    {
      "source": 1304,
      "target": 1295
    },
    {
      "source": 1305,
      "target": 1295
    },
    {
      "source": 1306,
      "target": 1295
    },
    {
      "source": 1307,
      "target": 1295
    },
    {
      "source": 1308,
      "target": 1295
    },
    {
      "source": 1309,
      "target": 1295
    },
    {
      "source": 1310,
      "target": 1295
    },
    {
      "source": 1311,
      "target": 1295
    },
    {
      "source": 1312,
      "target": 1295
    },
    {
      "source": 1313,
      "target": 1295
    },
    {
      "source": 1314,
      "target": 1295
    },
    {
      "source": 1315,
      "target": 1295
    },
    {
      "source": 1316,
      "target": 1295
    },
    {
      "source": 1317,
      "target": 1295
    },
    {
      "source": 1318,
      "target": 1295
    },
    {
      "source": 1319,
      "target": 1295
    },
    {
      "source": 1320,
      "target": 1295
    },
    {
      "source": 1321,
      "target": 1295
    },
    {
      "source": 1322,
      "target": 1295
    },
    {
      "source": 1323,
      "target": 1295
    },
    {
      "source": 1324,
      "target": 1295
    },
    {
      "source": 1325,
      "target": 1295
    },
    {
      "source": 1326,
      "target": 1295
    },
    {
      "source": 1327,
      "target": 1295
    },
    {
      "source": 1328,
      "target": 1295
    },
    {
      "source": 1329,
      "target": 1295
    },
    {
      "source": 1330,
      "target": 1295
    },
    {
      "source": 1331,
      "target": 1295
    },
    {
      "source": 1332,
      "target": 1295
    },
    {
      "source": 1333,
      "target": 1295
    },
    {
      "source": 1334,
      "target": 1295
    },
    {
      "source": 1335,
      "target": 1295
    },
    {
      "source": 1336,
      "target": 1295
    },
    {
      "source": 1337,
      "target": 1295
    },
    {
      "source": 1338,
      "target": 1295
    },
    {
      "source": 1339,
      "target": 1295
    },
    {
      "source": 1340,
      "target": 1295
    },
    {
      "source": 1341,
      "target": 1295
    },
    {
      "source": 1342,
      "target": 1295
    },
    {
      "source": 1343,
      "target": 1295
    },
    {
      "source": 1344,
      "target": 1295
    },
    {
      "source": 1345,
      "target": 1295
    },
    {
      "source": 1346,
      "target": 1295
    },
    {
      "source": 1347,
      "target": 1295
    },
    {
      "source": 1348,
      "target": 1295
    },
    {
      "source": 1349,
      "target": 1295
    },
    {
      "source": 1350,
      "target": 1295
    },
    {
      "source": 1351,
      "target": 1295
    },
    {
      "source": 1352,
      "target": 1295
    },
    {
      "source": 1353,
      "target": 1295
    },
    {
      "source": 1354,
      "target": 1295
    },
    {
      "source": 1355,
      "target": 1295
    },
    {
      "source": 1356,
      "target": 1295
    },
    {
      "source": 1357,
      "target": 1295
    },
    {
      "source": 1358,
      "target": 1295
    },
    {
      "source": 1359,
      "target": 1295
    },
    {
      "source": 1360,
      "target": 1295
    },
    {
      "source": 1361,
      "target": 1295
    },
    {
      "source": 1362,
      "target": 1295
    },
    {
      "source": 1363,
      "target": 1295
    },
    {
      "source": 1364,
      "target": 1295
    },
    {
      "source": 1365,
      "target": 1295
    },
    {
      "source": 1366,
      "target": 1295
    },
    {
      "source": 1367,
      "target": 1295
    },
    {
      "source": 1368,
      "target": 1295
    },
    {
      "source": 1369,
      "target": 1295
    },
    {
      "source": 1370,
      "target": 1295
    },
    {
      "source": 1371,
      "target": 1295
    },
    {
      "source": 1372,
      "target": 1295
    },
    {
      "source": 1373,
      "target": 1295
    },
    {
      "source": 1374,
      "target": 1295
    },
    {
      "source": 1375,
      "target": 1295
    },
    {
      "source": 1376,
      "target": 1295
    },
    {
      "source": 1377,
      "target": 1295
    },
    {
      "source": 1378,
      "target": 1295
    },
    {
      "source": 1379,
      "target": 1295
    },
    {
      "source": 1380,
      "target": 1295
    },
    {
      "source": 1381,
      "target": 1295
    },
    {
      "source": 1382,
      "target": 1295
    },
    {
      "source": 1383,
      "target": 1295
    },
    {
      "source": 1384,
      "target": 1295
    },
    {
      "source": 1385,
      "target": 1295
    },
    {
      "source": 1386,
      "target": 1
    },
    {
      "source": 1387,
      "target": 1386
    },
    {
      "source": 1387,
      "target": 1778
    },
    {
      "source": 1388,
      "target": 1386
    },
    {
      "source": 1389,
      "target": 1386
    },
    {
      "source": 1390,
      "target": 1386
    },
    {
      "source": 1390,
      "target": 1778
    },
    {
      "source": 1391,
      "target": 1386
    },
    {
      "source": 1392,
      "target": 1386
    },
    {
      "source": 1393,
      "target": 1386
    },
    {
      "source": 1394,
      "target": 1386
    },
    {
      "source": 1395,
      "target": 1386
    },
    {
      "source": 1396,
      "target": 1386
    },
    {
      "source": 1397,
      "target": 1386
    },
    {
      "source": 1398,
      "target": 1386
    },
    {
      "source": 1399,
      "target": 1386
    },
    {
      "source": 1400,
      "target": 1386
    },
    {
      "source": 1401,
      "target": 1386
    },
    {
      "source": 1402,
      "target": 1386
    },
    {
      "source": 1402,
      "target": 1570
    },
    {
      "source": 1403,
      "target": 1386
    },
    {
      "source": 1404,
      "target": 1386
    },
    {
      "source": 1405,
      "target": 1386
    },
    {
      "source": 1406,
      "target": 1386
    },
    {
      "source": 1407,
      "target": 1386
    },
    {
      "source": 1408,
      "target": 1386
    },
    {
      "source": 1409,
      "target": 1386
    },
    {
      "source": 1410,
      "target": 1386
    },
    {
      "source": 1411,
      "target": 1386
    },
    {
      "source": 1412,
      "target": 1386
    },
    {
      "source": 1413,
      "target": 1
    },
    {
      "source": 1414,
      "target": 1413
    },
    {
      "source": 1415,
      "target": 1413
    },
    {
      "source": 1416,
      "target": 1413
    },
    {
      "source": 1417,
      "target": 1413
    },
    {
      "source": 1418,
      "target": 1413
    },
    {
      "source": 1419,
      "target": 1413
    },
    {
      "source": 1420,
      "target": 1413
    },
    {
      "source": 1421,
      "target": 1413
    },
    {
      "source": 1422,
      "target": 1413
    },
    {
      "source": 1423,
      "target": 1413
    },
    {
      "source": 1424,
      "target": 1413
    },
    {
      "source": 1425,
      "target": 1413
    },
    {
      "source": 1426,
      "target": 1413
    },
    {
      "source": 1427,
      "target": 1413
    },
    {
      "source": 1428,
      "target": 1413
    },
    {
      "source": 1429,
      "target": 1413
    },
    {
      "source": 1430,
      "target": 1413
    },
    {
      "source": 1431,
      "target": 1413
    },
    {
      "source": 1432,
      "target": 1413
    },
    {
      "source": 1433,
      "target": 1413
    },
    {
      "source": 1434,
      "target": 1413
    },
    {
      "source": 1435,
      "target": 1413
    },
    {
      "source": 1435,
      "target": 1494
    },
    {
      "source": 1436,
      "target": 1413
    },
    {
      "source": 1437,
      "target": 1413
    },
    {
      "source": 1438,
      "target": 1413
    },
    {
      "source": 1439,
      "target": 1413
    },
    {
      "source": 1440,
      "target": 1413
    },
    {
      "source": 1441,
      "target": 1413
    },
    {
      "source": 1442,
      "target": 1413
    },
    {
      "source": 1443,
      "target": 1413
    },
    {
      "source": 1444,
      "target": 1413
    },
    {
      "source": 1445,
      "target": 1413
    },
    {
      "source": 1446,
      "target": 1413
    },
    {
      "source": 1447,
      "target": 1413
    },
    {
      "source": 1448,
      "target": 1413
    },
    {
      "source": 1449,
      "target": 1413
    },
    {
      "source": 1450,
      "target": 1413
    },
    {
      "source": 1451,
      "target": 1413
    },
    {
      "source": 1452,
      "target": 1413
    },
    {
      "source": 1453,
      "target": 1413
    },
    {
      "source": 1454,
      "target": 1413
    },
    {
      "source": 1455,
      "target": 1413
    },
    {
      "source": 1456,
      "target": 1413
    },
    {
      "source": 1457,
      "target": 1413
    },
    {
      "source": 1458,
      "target": 1413
    },
    {
      "source": 1459,
      "target": 1413
    },
    {
      "source": 1460,
      "target": 1413
    },
    {
      "source": 1461,
      "target": 1413
    },
    {
      "source": 1462,
      "target": 1413
    },
    {
      "source": 1463,
      "target": 1413
    },
    {
      "source": 1464,
      "target": 1413
    },
    {
      "source": 1465,
      "target": 1413
    },
    {
      "source": 1466,
      "target": 1413
    },
    {
      "source": 1467,
      "target": 1413
    },
    {
      "source": 1468,
      "target": 1413
    },
    {
      "source": 1469,
      "target": 1413
    },
    {
      "source": 1470,
      "target": 1413
    },
    {
      "source": 1471,
      "target": 1413
    },
    {
      "source": 1472,
      "target": 1413
    },
    {
      "source": 1473,
      "target": 1413
    },
    {
      "source": 1474,
      "target": 1413
    },
    {
      "source": 1475,
      "target": 1413
    },
    {
      "source": 1476,
      "target": 1413
    },
    {
      "source": 1477,
      "target": 1413
    },
    {
      "source": 1478,
      "target": 1413
    },
    {
      "source": 1479,
      "target": 1413
    },
    {
      "source": 1480,
      "target": 1413
    },
    {
      "source": 1481,
      "target": 1413
    },
    {
      "source": 1482,
      "target": 1413
    },
    {
      "source": 1483,
      "target": 1413
    },
    {
      "source": 1484,
      "target": 1413
    },
    {
      "source": 1485,
      "target": 1413
    },
    {
      "source": 1486,
      "target": 1413
    },
    {
      "source": 1487,
      "target": 1413
    },
    {
      "source": 1488,
      "target": 1413
    },
    {
      "source": 1489,
      "target": 1413
    },
    {
      "source": 1490,
      "target": 1413
    },
    {
      "source": 1491,
      "target": 1413
    },
    {
      "source": 1492,
      "target": 1413
    },
    {
      "source": 1493,
      "target": 1413
    },
    {
      "source": 1494,
      "target": 1
    },
    {
      "source": 1495,
      "target": 1494
    },
    {
      "source": 1496,
      "target": 1494
    },
    {
      "source": 1497,
      "target": 1494
    },
    {
      "source": 1498,
      "target": 1494
    },
    {
      "source": 1499,
      "target": 1494
    },
    {
      "source": 1500,
      "target": 1494
    },
    {
      "source": 1501,
      "target": 1494
    },
    {
      "source": 1502,
      "target": 1494
    },
    {
      "source": 1502,
      "target": 1572
    },
    {
      "source": 1503,
      "target": 1494
    },
    {
      "source": 1504,
      "target": 1494
    },
    {
      "source": 1505,
      "target": 1494
    },
    {
      "source": 1506,
      "target": 1494
    },
    {
      "source": 1507,
      "target": 1494
    },
    {
      "source": 1508,
      "target": 1494
    },
    {
      "source": 1509,
      "target": 1494
    },
    {
      "source": 1510,
      "target": 1494
    },
    {
      "source": 1511,
      "target": 1494
    },
    {
      "source": 1512,
      "target": 1494
    },
    {
      "source": 1513,
      "target": 1494
    },
    {
      "source": 1514,
      "target": 1494
    },
    {
      "source": 1515,
      "target": 1494
    },
    {
      "source": 1516,
      "target": 1494
    },
    {
      "source": 1517,
      "target": 1494
    },
    {
      "source": 1518,
      "target": 1494
    },
    {
      "source": 1519,
      "target": 1494
    },
    {
      "source": 1520,
      "target": 1494
    },
    {
      "source": 1521,
      "target": 1494
    },
    {
      "source": 1522,
      "target": 1494
    },
    {
      "source": 1523,
      "target": 1494
    },
    {
      "source": 1524,
      "target": 1494
    },
    {
      "source": 1525,
      "target": 1494
    },
    {
      "source": 1526,
      "target": 1494
    },
    {
      "source": 1527,
      "target": 1494
    },
    {
      "source": 1528,
      "target": 1494
    },
    {
      "source": 1529,
      "target": 1494
    },
    {
      "source": 1530,
      "target": 1494
    },
    {
      "source": 1531,
      "target": 1494
    },
    {
      "source": 1532,
      "target": 1494
    },
    {
      "source": 1533,
      "target": 1494
    },
    {
      "source": 1534,
      "target": 1494
    },
    {
      "source": 1535,
      "target": 1494
    },
    {
      "source": 1536,
      "target": 1494
    },
    {
      "source": 1537,
      "target": 1494
    },
    {
      "source": 1538,
      "target": 1494
    },
    {
      "source": 1539,
      "target": 1494
    },
    {
      "source": 1540,
      "target": 1494
    },
    {
      "source": 1541,
      "target": 1494
    },
    {
      "source": 1542,
      "target": 1494
    },
    {
      "source": 1543,
      "target": 1494
    },
    {
      "source": 1544,
      "target": 1494
    },
    {
      "source": 1545,
      "target": 1494
    },
    {
      "source": 1546,
      "target": 1494
    },
    {
      "source": 1547,
      "target": 1494
    },
    {
      "source": 1548,
      "target": 1494
    },
    {
      "source": 1549,
      "target": 1494
    },
    {
      "source": 1550,
      "target": 1494
    },
    {
      "source": 1551,
      "target": 1494
    },
    {
      "source": 1552,
      "target": 1494
    },
    {
      "source": 1553,
      "target": 1494
    },
    {
      "source": 1554,
      "target": 1494
    },
    {
      "source": 1555,
      "target": 1494
    },
    {
      "source": 1556,
      "target": 1494
    },
    {
      "source": 1557,
      "target": 1494
    },
    {
      "source": 1558,
      "target": 1494
    },
    {
      "source": 1559,
      "target": 1494
    },
    {
      "source": 1560,
      "target": 1494
    },
    {
      "source": 1561,
      "target": 1494
    },
    {
      "source": 1562,
      "target": 1494
    },
    {
      "source": 1563,
      "target": 1494
    },
    {
      "source": 1564,
      "target": 1494
    },
    {
      "source": 1565,
      "target": 1494
    },
    {
      "source": 1566,
      "target": 1494
    },
    {
      "source": 1567,
      "target": 1494
    },
    {
      "source": 1568,
      "target": 1494
    },
    {
      "source": 1569,
      "target": 1494
    },
    {
      "source": 1570,
      "target": 1
    },
    {
      "source": 1571,
      "target": 1570
    },
    {
      "source": 1572,
      "target": 1570
    },
    {
      "source": 1572,
      "target": 1
    },
    {
      "source": 1572,
      "target": 1778
    },
    {
      "source": 1573,
      "target": 1570
    },
    {
      "source": 1574,
      "target": 1570
    },
    {
      "source": 1575,
      "target": 1570
    },
    {
      "source": 1576,
      "target": 1570
    },
    {
      "source": 1577,
      "target": 1570
    },
    {
      "source": 1578,
      "target": 1570
    },
    {
      "source": 1579,
      "target": 1570
    },
    {
      "source": 1579,
      "target": 1778
    },
    {
      "source": 1580,
      "target": 1570
    },
    {
      "source": 1581,
      "target": 1570
    },
    {
      "source": 1582,
      "target": 1570
    },
    {
      "source": 1583,
      "target": 1570
    },
    {
      "source": 1584,
      "target": 1570
    },
    {
      "source": 1584,
      "target": 1778
    },
    {
      "source": 1585,
      "target": 1570
    },
    {
      "source": 1586,
      "target": 1570
    },
    {
      "source": 1587,
      "target": 1570
    },
    {
      "source": 1588,
      "target": 1570
    },
    {
      "source": 1589,
      "target": 1570
    },
    {
      "source": 1590,
      "target": 1570
    },
    {
      "source": 1591,
      "target": 1570
    },
    {
      "source": 1592,
      "target": 1570
    },
    {
      "source": 1593,
      "target": 1570
    },
    {
      "source": 1594,
      "target": 1570
    },
    {
      "source": 1595,
      "target": 1570
    },
    {
      "source": 1596,
      "target": 1570
    },
    {
      "source": 1597,
      "target": 1570
    },
    {
      "source": 1598,
      "target": 1570
    },
    {
      "source": 1599,
      "target": 1570
    },
    {
      "source": 1600,
      "target": 1570
    },
    {
      "source": 1601,
      "target": 1570
    },
    {
      "source": 1602,
      "target": 1570
    },
    {
      "source": 1603,
      "target": 1570
    },
    {
      "source": 1604,
      "target": 1570
    },
    {
      "source": 1605,
      "target": 1570
    },
    {
      "source": 1606,
      "target": 1570
    },
    {
      "source": 1607,
      "target": 1570
    },
    {
      "source": 1608,
      "target": 1570
    },
    {
      "source": 1609,
      "target": 1570
    },
    {
      "source": 1610,
      "target": 1570
    },
    {
      "source": 1611,
      "target": 1570
    },
    {
      "source": 1612,
      "target": 1570
    },
    {
      "source": 1613,
      "target": 1570
    },
    {
      "source": 1614,
      "target": 1570
    },
    {
      "source": 1615,
      "target": 1570
    },
    {
      "source": 1616,
      "target": 1570
    },
    {
      "source": 1617,
      "target": 1570
    },
    {
      "source": 1618,
      "target": 1570
    },
    {
      "source": 1619,
      "target": 1570
    },
    {
      "source": 1620,
      "target": 1570
    },
    {
      "source": 1621,
      "target": 1570
    },
    {
      "source": 1622,
      "target": 1570
    },
    {
      "source": 1623,
      "target": 1570
    },
    {
      "source": 1624,
      "target": 1570
    },
    {
      "source": 1625,
      "target": 1570
    },
    {
      "source": 1626,
      "target": 1570
    },
    {
      "source": 1627,
      "target": 1572
    },
    {
      "source": 1628,
      "target": 1572
    },
    {
      "source": 1629,
      "target": 1572
    },
    {
      "source": 1630,
      "target": 1572
    },
    {
      "source": 1631,
      "target": 1572
    },
    {
      "source": 1632,
      "target": 1572
    },
    {
      "source": 1633,
      "target": 1572
    },
    {
      "source": 1634,
      "target": 1572
    },
    {
      "source": 1635,
      "target": 1572
    },
    {
      "source": 1636,
      "target": 1572
    },
    {
      "source": 1637,
      "target": 1572
    },
    {
      "source": 1638,
      "target": 1572
    },
    {
      "source": 1639,
      "target": 1572
    },
    {
      "source": 1640,
      "target": 1572
    },
    {
      "source": 1641,
      "target": 1572
    },
    {
      "source": 1642,
      "target": 1572
    },
    {
      "source": 1643,
      "target": 1572
    },
    {
      "source": 1644,
      "target": 1572
    },
    {
      "source": 1645,
      "target": 1572
    },
    {
      "source": 1646,
      "target": 1572
    },
    {
      "source": 1647,
      "target": 1572
    },
    {
      "source": 1648,
      "target": 1572
    },
    {
      "source": 1649,
      "target": 1572
    },
    {
      "source": 1650,
      "target": 1572
    },
    {
      "source": 1651,
      "target": 1572
    },
    {
      "source": 1652,
      "target": 1572
    },
    {
      "source": 1653,
      "target": 1572
    },
    {
      "source": 1654,
      "target": 1572
    },
    {
      "source": 1655,
      "target": 1572
    },
    {
      "source": 1656,
      "target": 1572
    },
    {
      "source": 1657,
      "target": 1572
    },
    {
      "source": 1658,
      "target": 1572
    },
    {
      "source": 1659,
      "target": 1572
    },
    {
      "source": 1660,
      "target": 1572
    },
    {
      "source": 1661,
      "target": 1572
    },
    {
      "source": 1662,
      "target": 1572
    },
    {
      "source": 1663,
      "target": 1572
    },
    {
      "source": 1664,
      "target": 1572
    },
    {
      "source": 1665,
      "target": 1572
    },
    {
      "source": 1666,
      "target": 1572
    },
    {
      "source": 1667,
      "target": 1572
    },
    {
      "source": 1668,
      "target": 1572
    },
    {
      "source": 1669,
      "target": 1572
    },
    {
      "source": 1670,
      "target": 1572
    },
    {
      "source": 1671,
      "target": 1572
    },
    {
      "source": 1672,
      "target": 1572
    },
    {
      "source": 1673,
      "target": 1572
    },
    {
      "source": 1674,
      "target": 1572
    },
    {
      "source": 1675,
      "target": 1572
    },
    {
      "source": 1676,
      "target": 1572
    },
    {
      "source": 1677,
      "target": 1572
    },
    {
      "source": 1678,
      "target": 1572
    },
    {
      "source": 1679,
      "target": 1572
    },
    {
      "source": 1680,
      "target": 1572
    },
    {
      "source": 1681,
      "target": 1572
    },
    {
      "source": 1682,
      "target": 1572
    },
    {
      "source": 1683,
      "target": 1572
    },
    {
      "source": 1684,
      "target": 1572
    },
    {
      "source": 1685,
      "target": 1572
    },
    {
      "source": 1686,
      "target": 1572
    },
    {
      "source": 1687,
      "target": 1572
    },
    {
      "source": 1688,
      "target": 1572
    },
    {
      "source": 1689,
      "target": 1572
    },
    {
      "source": 1690,
      "target": 1572
    },
    {
      "source": 1691,
      "target": 1572
    },
    {
      "source": 1692,
      "target": 1572
    },
    {
      "source": 1693,
      "target": 1572
    },
    {
      "source": 1694,
      "target": 1572
    },
    {
      "source": 1695,
      "target": 1572
    },
    {
      "source": 1696,
      "target": 1572
    },
    {
      "source": 1697,
      "target": 1572
    },
    {
      "source": 1698,
      "target": 1572
    },
    {
      "source": 1699,
      "target": 1572
    },
    {
      "source": 1700,
      "target": 1572
    },
    {
      "source": 1701,
      "target": 1572
    },
    {
      "source": 1702,
      "target": 9
    },
    {
      "source": 1703,
      "target": 9
    },
    {
      "source": 1704,
      "target": 9
    },
    {
      "source": 1705,
      "target": 9
    },
    {
      "source": 1706,
      "target": 9
    },
    {
      "source": 1707,
      "target": 9
    },
    {
      "source": 1708,
      "target": 9
    },
    {
      "source": 1709,
      "target": 9
    },
    {
      "source": 1710,
      "target": 9
    },
    {
      "source": 1711,
      "target": 9
    },
    {
      "source": 1712,
      "target": 9
    },
    {
      "source": 1713,
      "target": 9
    },
    {
      "source": 1714,
      "target": 9
    },
    {
      "source": 1715,
      "target": 9
    },
    {
      "source": 1716,
      "target": 9
    },
    {
      "source": 1717,
      "target": 9
    },
    {
      "source": 1718,
      "target": 9
    },
    {
      "source": 1719,
      "target": 9
    },
    {
      "source": 1720,
      "target": 9
    },
    {
      "source": 1721,
      "target": 9
    },
    {
      "source": 1722,
      "target": 9
    },
    {
      "source": 1723,
      "target": 9
    },
    {
      "source": 1724,
      "target": 9
    },
    {
      "source": 1725,
      "target": 9
    },
    {
      "source": 1726,
      "target": 9
    },
    {
      "source": 1727,
      "target": 9
    },
    {
      "source": 1728,
      "target": 9
    },
    {
      "source": 1729,
      "target": 9
    },
    {
      "source": 1730,
      "target": 9
    },
    {
      "source": 1731,
      "target": 9
    },
    {
      "source": 1732,
      "target": 9
    },
    {
      "source": 1733,
      "target": 9
    },
    {
      "source": 1734,
      "target": 9
    },
    {
      "source": 1735,
      "target": 9
    },
    {
      "source": 1736,
      "target": 9
    },
    {
      "source": 1737,
      "target": 9
    },
    {
      "source": 1738,
      "target": 9
    },
    {
      "source": 1739,
      "target": 9
    },
    {
      "source": 1740,
      "target": 9
    },
    {
      "source": 1741,
      "target": 9
    },
    {
      "source": 1742,
      "target": 9
    },
    {
      "source": 1743,
      "target": 9
    },
    {
      "source": 1744,
      "target": 9
    },
    {
      "source": 1745,
      "target": 9
    },
    {
      "source": 1746,
      "target": 9
    },
    {
      "source": 1747,
      "target": 9
    },
    {
      "source": 1748,
      "target": 9
    },
    {
      "source": 1749,
      "target": 9
    },
    {
      "source": 1750,
      "target": 9
    },
    {
      "source": 1751,
      "target": 9
    },
    {
      "source": 1752,
      "target": 9
    },
    {
      "source": 1753,
      "target": 9
    },
    {
      "source": 1754,
      "target": 9
    },
    {
      "source": 1755,
      "target": 9
    },
    {
      "source": 1756,
      "target": 9
    },
    {
      "source": 1757,
      "target": 9
    },
    {
      "source": 1758,
      "target": 9
    },
    {
      "source": 1759,
      "target": 9
    },
    {
      "source": 1760,
      "target": 9
    },
    {
      "source": 1761,
      "target": 9
    },
    {
      "source": 1762,
      "target": 9
    },
    {
      "source": 1763,
      "target": 9
    },
    {
      "source": 1764,
      "target": 9
    },
    {
      "source": 1765,
      "target": 9
    },
    {
      "source": 1766,
      "target": 9
    },
    {
      "source": 1767,
      "target": 9
    },
    {
      "source": 1768,
      "target": 9
    },
    {
      "source": 1769,
      "target": 9
    },
    {
      "source": 1770,
      "target": 9
    },
    {
      "source": 1771,
      "target": 9
    },
    {
      "source": 1772,
      "target": 9
    },
    {
      "source": 1773,
      "target": 9
    },
    {
      "source": 1774,
      "target": 9
    },
    {
      "source": 1775,
      "target": 9
    },
    {
      "source": 1776,
      "target": 9
    },
    {
      "source": 1777,
      "target": 9
    },
    {
      "source": 1778,
      "target": 1
    },
    {
      "source": 1779,
      "target": 1778
    },
    {
      "source": 1780,
      "target": 1778
    },
    {
      "source": 1781,
      "target": 1778
    },
    {
      "source": 1782,
      "target": 1778
    },
    {
      "source": 1783,
      "target": 1778
    },
    {
      "source": 1784,
      "target": 1778
    },
    {
      "source": 1785,
      "target": 1778
    },
    {
      "source": 1786,
      "target": 1778
    },
    {
      "source": 1787,
      "target": 1778
    },
    {
      "source": 1788,
      "target": 1778
    },
    {
      "source": 1789,
      "target": 1778
    },
    {
      "source": 1790,
      "target": 1778
    },
    {
      "source": 1791,
      "target": 1778
    },
    {
      "source": 1792,
      "target": 1778
    },
    {
      "source": 1793,
      "target": 1778
    },
    {
      "source": 1794,
      "target": 1778
    },
    {
      "source": 1795,
      "target": 1778
    },
    {
      "source": 1796,
      "target": 1778
    },
    {
      "source": 1797,
      "target": 1778
    },
    {
      "source": 1798,
      "target": 1778
    },
    {
      "source": 1799,
      "target": 1778
    },
    {
      "source": 1800,
      "target": 1778
    },
    {
      "source": 1801,
      "target": 1778
    },
    {
      "source": 1802,
      "target": 1778
    },
    {
      "source": 1803,
      "target": 1778
    },
    {
      "source": 1804,
      "target": 1778
    },
    {
      "source": 1805,
      "target": 305
    },
    {
      "source": 1806,
      "target": 305
    },
    {
      "source": 1807,
      "target": 305
    },
    {
      "source": 1808,
      "target": 305
    },
    {
      "source": 1809,
      "target": 305
    },
    {
      "source": 1810,
      "target": 305
    },
    {
      "source": 1811,
      "target": 305
    },
    {
      "source": 1812,
      "target": 305
    },
    {
      "source": 1813,
      "target": 305
    },
    {
      "source": 1814,
      "target": 305
    },
    {
      "source": 1815,
      "target": 305
    },
    {
      "source": 1816,
      "target": 305
    },
    {
      "source": 1817,
      "target": 305
    },
    {
      "source": 1818,
      "target": 305
    },
    {
      "source": 1819,
      "target": 305
    },
    {
      "source": 1820,
      "target": 305
    },
    {
      "source": 1821,
      "target": 305
    },
    {
      "source": 1822,
      "target": 305
    },
    {
      "source": 1823,
      "target": 305
    },
    {
      "source": 1824,
      "target": 305
    },
    {
      "source": 1825,
      "target": 305
    },
    {
      "source": 1826,
      "target": 305
    },
    {
      "source": 1827,
      "target": 305
    },
    {
      "source": 1828,
      "target": 305
    },
    {
      "source": 1829,
      "target": 305
    },
    {
      "source": 1830,
      "target": 305
    },
    {
      "source": 1831,
      "target": 305
    },
    {
      "source": 1832,
      "target": 305
    },
    {
      "source": 1833,
      "target": 305
    },
    {
      "source": 1834,
      "target": 305
    },
    {
      "source": 1835,
      "target": 305
    },
    {
      "source": 1836,
      "target": 305
    },
    {
      "source": 1837,
      "target": 305
    },
    {
      "source": 1838,
      "target": 305
    },
    {
      "source": 1839,
      "target": 305
    },
    {
      "source": 1840,
      "target": 305
    },
    {
      "source": 1841,
      "target": 305
    },
    {
      "source": 1842,
      "target": 305
    },
    {
      "source": 1843,
      "target": 305
    },
    {
      "source": 1844,
      "target": 305
    },
    {
      "source": 1845,
      "target": 305
    },
    {
      "source": 1846,
      "target": 305
    },
    {
      "source": 1847,
      "target": 305
    },
    {
      "source": 1848,
      "target": 305
    },
    {
      "source": 1849,
      "target": 305
    },
    {
      "source": 1850,
      "target": 305
    },
    {
      "source": 1851,
      "target": 305
    },
    {
      "source": 1852,
      "target": 305
    },
    {
      "source": 1853,
      "target": 305
    },
    {
      "source": 1854,
      "target": 305
    },
    {
      "source": 1855,
      "target": 305
    },
    {
      "source": 1856,
      "target": 305
    },
    {
      "source": 1857,
      "target": 305
    },
    {
      "source": 1858,
      "target": 305
    },
    {
      "source": 1859,
      "target": 305
    },
    {
      "source": 1860,
      "target": 305
    },
    {
      "source": 1861,
      "target": 305
    },
    {
      "source": 1862,
      "target": 305
    },
    {
      "source": 1863,
      "target": 305
    },
    {
      "source": 1864,
      "target": 305
    },
    {
      "source": 1865,
      "target": 305
    },
    {
      "source": 1866,
      "target": 305
    },
    {
      "source": 1867,
      "target": 305
    },
    {
      "source": 1868,
      "target": 305
    },
    {
      "source": 1869,
      "target": 305
    },
    {
      "source": 1870,
      "target": 305
    },
    {
      "source": 1871,
      "target": 305
    },
    {
      "source": 1872,
      "target": 305
    },
    {
      "source": 1873,
      "target": 305
    }
  ]
};
      var w = window.innerWidth;
      var h = window.innerHeight;

      var focusNode = null;
      var highlightNode = null;

      var textCenter = false;
      var outline = false;

      var minScore = Math.min(...graph.nodes.map(n => n.modularity));
      var maxScore = Math.max(...graph.nodes.map(n => n.modularity));

      var color = d3.scale
        .linear()
        .domain([
          minScore,
          (minScore + maxScore) / 4,
          (minScore + maxScore) / 2,
          ((minScore + maxScore) * 3) / 4,
          maxScore,
        ])
        .range(["lime", "yellow", "red", "deepskyblue"]);

      var highlightColor = "blue";
      var highlightTrans = 0.1;

      const citedBy = graph.nodes
        .map(n => n.cited_by)
        .filter(n => n != null)

      const maxCitedBy = Math.max(...citedBy)
      const minCitedBy = Math.min(...citedBy)

      var size = d3.scale
        .pow()
        .exponent(1)
        .domain([minCitedBy, maxCitedBy])
        .range([8, 24]);

      var force = d3.layout
        .force()
        .linkDistance(h / (graph.nodes.length / 10))
        .charge(-300)
        .size([w, h]);

      var defaultNodeColor = "#ccc";
      var defaultLinkColor = "#888";
      var nominalBaseNodeSize = 8;
      var nominalTextSize = 10;
      var maxTextSize = 24;
      var nominalStroke = 1.5;
      var maxStroke = 4.5;
      var maxBaseNodeSize = 36;
      var minZoom = 0.1;
      var maxZoom = 7;
      var svg = d3.select("body").append("svg");
      var zoom = d3.behavior.zoom().scaleExtent([minZoom, maxZoom]);
      var g = svg.append("g");
      svg.style("cursor", "move");

      var linkedByIndex = {};
      graph.links.forEach(function (d) {
        linkedByIndex[d.source + "," + d.target] = true;
      });

      function isConnected(a, b) {
        return (
          linkedByIndex[a.index + "," + b.index] ||
          linkedByIndex[b.index + "," + a.index] ||
          a.index == b.index
        );
      }

      force.size([w, h]);

      force
        .nodes(graph.nodes)
        .links(graph.links)
        .start();

      function getLine(data) {

        const x1 = data.source.x;
        const y1= data.source.y;
        const x2 = data.target.x;
        const y2 = data.target.y;

        const r = size(data.target.cited_by) + 1;

        const m = (y2 - y1) / (x2 - x1);
        const b = y1 - m * x1;

        const c = Math.sqrt(Math.pow((y2 - y1), 2) + Math.pow((x2 - x1), 2))
        const a = y2 - y1
        const cos = a / c

        const a2 = cos * r
        const b2 = Math.sqrt(Math.pow(r, 2) - Math.pow(a2, 2))

        const x = x2 > x1 ? x2 - b2 : x2 + b2;
        const y = y2 - a2;

        const path = 'M ' + data.source.x + ',' + data.source.y + ' L ' + x + ',' + y;
        return path;
      }

      var link = g
        .selectAll(".link")
        .data(graph.links)
        .enter()
        .append("svg:path")
        .attr("d", getLine) 
        .attr("stroke", defaultLinkColor)
        .attr("fill", "red")
        .style("stroke-width", nominalStroke)
        .style("marker-end", "url(#end)")

      var node = g
        .selectAll(".node")
        .data(graph.nodes)
        .enter()
        .append("g")
        .attr("class", "node")
        .call(force.drag);

      var timeout = null;

      node.on("dblclick", function (d) {
        clearTimeout(timeout);

        timeout = setTimeout(function () {
          window.open(d.url, "_blank");
          d3.event.stopPropagation();
        }, 300);
      });

      var tocolor = "fill";
      var towhite = "stroke";
      if (outline) {
        tocolor = "stroke";
        towhite = "fill";
      }

      var circle = node
        .append("path")
        .attr(
          "d",
          d3.svg
            .symbol()
            .size(function (d) {
              return (
                Math.PI * Math.pow(size(d.cited_by) || nominalBaseNodeSize, 2)
              );
            })
            .type(function (d) {
              return d.type;
            })
        )
        .style(tocolor, function (d) {
          if (isNumber(d.modularity) && d.modularity >= 0) return color(d.modularity);
          else return defaultNodeColor;
        })
        .style("stroke-width", nominalStroke)
        .style(towhite, "white");

      svg.append("svg:defs").selectAll("marker")
	  .data(["end"])
	.enter().append("svg:marker")
	  .attr("id", String)
	  .attr("viewBox", "0 -5 10 10")
	  .attr("refX", 10)
	  .attr("refY", 0)
	  .attr("markerWidth", 6)
	  .attr("markerHeight", 6)
	  .attr("orient", "auto")
          .style("fill", defaultLinkColor)
	.append("svg:path")
	  .attr("d", "M 0,-5 L 10,0 L 0,5")
          .style("stroke", defaultLinkColor);

      var text = g
        .selectAll(".text")
        .data(graph.nodes)
        .enter()
        .append("text")
        .attr("dy", ".35em")
        .style("font-size", nominalTextSize + "px");

      node
        .on("mouseover", function (d) {
          setHighlight(d);
        })
        .on("mousedown", function (d) {
          d3.event.stopPropagation();
          focusNode = d;
          setFocus(d);
          if (highlightNode === null) setHighlight(d);
        })
        .on("mouseout", function (d) {
          exitHighlight();
        });

      d3.select(window).on("mouseup", function () {
        if (focusNode !== null) {
          focusNode = null;
          if (highlightTrans < 1) {
            circle.style("opacity", 1);
            text.style("opacity", 1);
            link.style("opacity", 1);
          }
        }

        if (highlightNode === null) exitHighlight();
      });

      function exitHighlight() {
        highlightNode = null;
        if (focusNode === null) {
          svg.style("cursor", "move");
          if (highlightColor != "white") {
            circle.style(towhite, "white");
            text.text('')
            link.style("stroke", function (o) {
              return isNumber(o.score) && o.score >= 0
                ? color(o.score)
                : defaultLinkColor;
            });
          }
        }
      }

      function setFocus(d) {
        if (highlightTrans < 1) {
          circle.style("opacity", function (o) {
            return isConnected(d, o) ? 1 : highlightTrans;
          });

          text.style("opacity", function (o) {
            return isConnected(d, o) ? 1 : highlightTrans;
          });

          link.style("opacity", function (o) {
            return o.source.index == d.index || o.target.index == d.index
              ? 1
              : highlightTrans;
          });
        }
      }

      function setHighlight(d) {
        svg.style("cursor", "pointer");
        if (focusNode !== null) d = focusNode;
        highlightNode = d;

        if (highlightColor != "white") {

          circle.style(towhite, function (o) {
            return isConnected(d, o) ? highlightColor : "white";
          });
          
          text.attr("dx", function (d) {
            return size(d.cited_by)
          });

          text.text(function (o) {
            if (isConnected(d, o)) {
              let title = o.title;
              if (o.year) title = title + " (" + o.year + ")";
              if (o.authors) title = title + " - " + o.authors;
              return title
            } else {
              return ""
            }
          });

        }
      }

      zoom.on("zoom", function () {
        var stroke = nominalStroke;
        if (nominalStroke * zoom.scale() > maxStroke)
          stroke = maxStroke / zoom.scale();
        link.style("stroke-width", stroke);
        circle.style("stroke-width", stroke);

        var baseRadius = nominalBaseNodeSize;
        if (nominalBaseNodeSize * zoom.scale() > maxBaseNodeSize)
          baseRadius = maxBaseNodeSize / zoom.scale();
        circle.attr(
          "d",
          d3.svg
            .symbol()
            .size(function (d) {
              return (
                Math.PI *
                Math.pow(
                  (size(d.cited_by) * baseRadius) / nominalBaseNodeSize ||
                    baseRadius,
                  2
                )
              );
            })
        );

        if (!textCenter)
          text.attr("dx", function (d) {
            return (
              (size(d.cited_by) * baseRadius) / nominalBaseNodeSize ||
              baseRadius
            );
          });

        var textSize = nominalTextSize;
        if (nominalTextSize * zoom.scale() > maxTextSize)
          textSize = maxTextSize / zoom.scale();
        text.style("font-size", textSize + "px");

        g.attr(
          "transform",
          "translate(" + d3.event.translate + ")scale(" + d3.event.scale + ")"
        );
      });

      svg.call(zoom);

      resize();
      d3.select(window).on("resize", resize);

      force.on("tick", function () {
        node.attr("transform", function (d) {
          return "translate(" + d.x + "," + d.y + ")";
        });
        text.attr("transform", function (d) {
          return "translate(" + d.x + "," + d.y + ")";
        });

        link.attr("d", getLine)

        node
          .attr("cx", function (d) {
            return d.x;
          })
          .attr("cy", function (d) {
            return d.y;
          });
      });

      function resize() {
        var width = window.innerWidth,
          height = window.innerHeight;
        svg.attr("width", width).attr("height", height);

        force
          .size([
            force.size()[0] + (width - w) / zoom.scale(),
            force.size()[1] + (height - h) / zoom.scale(),
          ])
          .resume();
        w = width;
        h = height;
      }

      function isNumber(n) {
        return !isNaN(parseFloat(n)) && isFinite(n);
      }

    </script>
  </body>
</html>
